
*19nov27
** trying on laptop

do not have netpyne on laptop

python3
import netpyne

pip3 install netpyne

Traceback (most recent call last):
  File "/usr/bin/pip3", line 9, in <module>
    from pip import main
ImportError: cannot import name 'main'

what's wrong with pip3?

https://stackoverflow.com/questions/49836676/error-after-upgrading-pip-cannot-import-name-main

sudo python3 -m pip uninstall pip && sudo apt install python3-pip --reinstall

pip3 install netpyne

hmm, needs newer version of python (>= 3.6 ), only have python 3.5 on laptop ...

will try on neurosim ... 

python3
import netpyne
netpyne.__version__ # '0.9.3.1'

pip3 install gym --user
pip3 install atari-py --user

compile:
nrnivmodl

for running on 1 node:
py3env
python3 trainSmartAgent.py

mpirun -n 16 python trainSmartAgent.py

was able to run with 1 core, took 2.5 GB with 500 ms interval for saving weights and 1000 ms simulation
will need to record from only a small fraction of the cells

*20feb13
** make new branch to avoid conflict with haroon's work

git branch samn
git checkout samn
git add snnotes.dol
git commit -m 'new branch for samn test'
git push origin samn

make an alias for that: gpushsamn

** try compile and then run 

nrnivmodl

mpirun -n 16 python trainSmartAgent.py

myrun

mpirun -n 16 python trainSmartAgent.py

even after calling py3env to set the environment to use anaconda ... 
it's showing many different pong windows ... should only be 1 window  (this was run on zn)

aigame.py loads the gym environment with the pong game
where is aigame.py called from?

trainSmartAgent.py is the main sim setup
it imports SMARTAgent from aigame

hmm, not running it properly ...

mpiexec -n 16 python -mpi trainSmartAgent.py

*20feb24
** HA fixed the MPI issues
** set env.frameskip to a constant value on environment init to avoid random frameskip in a range
** setup code for some more flexibility

can use json for config file

*20feb25
** adjust architecture add direct V1 -> M popoulations

that way M has higher resolution visual information
and M still receives the lower resolution visual information from V2, IT as well ...

** simple test - reward for moving up, punish for moving down

does it produce expected behavior?

myrun 16

python
import numpy as np
from pylab import *
ion()
d = np.loadtxt('ActionsRewards.txt')
len(np.where(d[:,1]==3)[0]) # 232
len(np.where(d[:,1]==4)[0]) # 246
len(np.where(d[:,1]==1)[0]) # 272

plot(d[:,0],d[:,1],'ko')
hist(d[:,1])

to test if it's working just check the RL weights onto ML vs MR; weights onto ML neurons should
increase, while weights onto MR should decrease ...  if that's not happening, something is wrong ...

*20feb26
** looking at the output weights for the fake training task

myrun 1
quit()

python3
import numpy as np
from pylab import *
ion()
awt = np.loadtxt('data/AdjustableWeights.txt')
awt.shape # (21999, 5) # columns are time, preid, postid, stdptype, weight

plot(awt[:,0],awt[:,4],'ko')
savefig('gif/20feb26_a0.png')

need to know cell types ...

import pandas as pd
pdf = pd.DataFrame(awt,columns=['time','preid','postid','stdptype','weight'])
len(pdf) # 21999

pdfs = pdf[(pdf.postid==1184) & (pdf.stdptype==1)]
len(pdfs) # 879
plot(pdfs.time,pdfs.weight,'r')
savefig('gif/20feb26_a1.png') # looks incorrect ?? does it go up and down or are those two different synapses?

min(pdfs.preid),max(pdfs.preid) # (403.0, 924.0)
yeah, two preids ... and they're differnet because different source populations ...

pdfs = pdf[(pdf.postid==1184) & (pdf.stdptype==1) & (pdf.preid==403)]
len(pdfs) # 20
plot(pdfs.time,pdfs.weight,'b')
savefig('gif/20feb26_a2.png')
ok, that weight is increasing gradually ... but is that the ML or MR output population?

ID 1159 through 1183 (inclusive) are the ML neurons? (/u/samn/SMARTAgent/trainSmartAgent.py:754)

pdfs = pdf[(pdf.postid==1159) & (pdf.stdptype==1)]
len(pdfs) # 0

pdfs = pdf[(pdf.postid==1160) & (pdf.stdptype==1)]
len(pdfs) # 0

pdfs = pdf[(pdf.postid>=1159) & (pdf.postid<=1183) & (pdf.stdptype==1)]
len(pdfs) # 0

hmm, are any of the ML weights getting saved??

note that this was run with a single core ...

ah, a bug in new code ...

fix, rerun ...

myrun 1

python3
import numpy as np
from pylab import *
ion()
awt = np.loadtxt('data/AdjustableWeights.txt')
awt.shape # (22000, 5) # columns are time, preid, postid, stdptype, weight

plot(awt[:,0],awt[:,4],'ko')

import pandas as pd
pdf = pd.DataFrame(awt,columns=['time','preid','postid','stdptype','weight'])
pdfs = pdf[(pdf.postid>=1159) & (pdf.postid<=1183) & (pdf.stdptype==1)]
len(pdfs) # 11000

should save types in the file ... 

plot(pdfs.time,pdfs.weight,'b')

myrun 1
sim.net.cells[0].tags['pop'] # 'R'

sim.net.cells[1184].tags['pop'] # 'MR'
sim.net.cells[1159].tags['pop'] # 'ML'

*20feb27
** continue debugging

to get the network/cell info use this:
simConfig.savePickle = True            # Save params, network and sim output to pickle file

myrun 1

from pylab import *
savefig('gif/20feb27_rast_a0.png')

simConfig.filename = 'data/simConfig'
sim.saveFolder = 'data'

python3
import numpy as np
from pylab import *
ion()
awt = np.loadtxt('data/AdjustableWeights.txt')

import pandas as pd
pdf = pd.DataFrame(awt,columns=['time','preid','postid','stdptype','weight'])
pdfs = pdf[(pdf.postid>=1159) & (pdf.postid<=1183) & (pdf.stdptype==1)]

import pickle
simConfig = pickle.load(open('data/simConfig.pkl','rb'))
simConfig.keys() # dict_keys(['netpyne_version', 'netpyne_changeset', 'net', 'simConfig', 'simData'])

simConfig['net'].keys() # dict_keys(['params', 'cells', 'pops'])
simConfig['net']['pops'].keys() # odict_keys(['R', 'V1', 'V4', 'IT', 'IR', 'IV1', 'IV4', 'IIT', 'ML', 'MR'])
simConfig['net']['pops']['MR'].keys() # dict_keys(['tags', 'cellGids'])
simConfig['net']['pops']['MR']['cellGids'] # [1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208]
simConfig['net']['pops']['ML']['cellGids'] # [1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183]

ok, good ...

dstartidx = {p:simConfig['net']['pops'][p]['cellGids'][0] for p in simConfig['net']['pops'].keys()}
dendidx = {p:simConfig['net']['pops'][p]['cellGids'][-1] for p in simConfig['net']['pops'].keys()}

dstartidx # {'R': 0, 'V1': 400, 'V4': 800, 'IT': 900, 'IR': 925, 'IV1': 1025, 'IV4': 1125, 'IIT': 1150, 'ML': 1159, 'MR': 1184}
dendidx # {'R': 399, 'V1': 799, 'V4': 899, 'IT': 924, 'IR': 1024, 'IV1': 1124, 'IV4': 1149, 'IIT': 1158, 'ML': 1183, 'MR': 1208}

pdfs = pdf[(pdf.postid>=dstartidx['ML']) & (pdf.postid<=dendidx['ML']) & (pdf.preid>=dstartidx['V1']) & (pdf.preid<=dendidx['V1']) & (pdf.stdptype==1)]
len(pdfs) # 4000

plot(pdfs.time,pdfs.weight,'bo')

savefig('gif/20feb27_wghts_a1.png')

pdfs = pdf[(pdf.postid>=dstartidx['MR']) & (pdf.postid<=dendidx['MR']) & (pdf.preid>=dstartidx['V1']) & (pdf.preid<=dendidx['V1']) & (pdf.stdptype==1)]
len(pdfs) # 4000

plot(pdfs.time,pdfs.weight,'ro')

savefig('gif/20feb27_wghts_a2.png')

so both ML and MR weights are increasing - that's incorrect

checking if recording the synaptic weights into sim.simData['synweights'] will work
with netpyne gathering the info across nodes automatically ...

python3
import numpy as np
from pylab import *
import pickle

simConfig = pickle.load(open('data/simConfig.pkl','rb'))
simConfig.keys() # dict_keys(['netpyne_version', 'netpyne_changeset', 'net', 'simConfig', 'simData'])
simConfig['simData'].keys() # dict_keys(['spkt', 'spkid', 'V_soma', 't', 'synweights', 'avgRate'])
len(simConfig['simData']['synweights']) # 22000
simConfig['simData']['synweights'][0] # [99.9999999999986, 0.0025, 1184, 900, 1]

and that was when running with 1 node ... try again with > 1 to see if same

myrun 16

Traceback (most recent call last):
  File "sim.py", line 988, in <module>
    sim.gatherData() # gather data from different nodes
  File "/usr/site/python/netpyne/netpyne/sim/gather.py", line 165, in gatherData
    sim.allSimData[key].update(val)           # update simData dicts which are not Vectors
ValueError: dictionary update sequence element #0 has length 5; 2 is required

change sim.simData['synweights'] to a dict (with key 0 pointing to a list of lists)

type(sim.simData['synweights']) # <class 'dict'>
sim.simData['synweights'][0][0] # [99.9999999999986, 0.0025, 1184, 912, 1]
len(sim.simData['synweights'][0]) # 1320
len(sim.allSimData['synweights'][0]) # 1320
sim.allSimData['synweights'].keys() # dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])
len(sim.allSimData['synweights'][15]) # 1320
sum([len(sim.allSimData['synweights'][i]) for i in range(16)]) # 22000

import pickle
simConfig = pickle.load(open('data/simConfig.pkl','rb'))
len(simConfig['simData']['synweights'][0]) # 1320
simConfig['simData']['synweights'].keys() # dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])
simConfig['simData']['synweights'][0][0] # [99.9999999999986, 0.0025, 1184, 912, 1]

ion()
awt = np.loadtxt('data/AdjustableWeights.txt')

import pandas as pd
pdf = pd.DataFrame(awt,columns=['time','preid','postid','stdptype','weight'])


ok, good ...

dstartidx = {p:simConfig['net']['pops'][p]['cellGids'][0] for p in simConfig['net']['pops'].keys()}
dendidx = {p:simConfig['net']['pops'][p]['cellGids'][-1] for p in simConfig['net']['pops'].keys()}

testing basic mechanism again , with RL exp off and fake up rule ... 

myrun 16

plw

savefig('gif/20feb27_rewards_wghts_a3.png')

seems to generally work, once separated out the population specific projections (V1->ML and V1->MR) ...
but not clear why V1->MR is getting reinforced when MR produces down moves ...

could be that MR getting reinforced since V1 projects to both MR and ML and V1->MR synapses are tagged
within the interval when V1->ML synapses are tagged for reward ...

try cutting off some of the higher connections connections and see what happens ... e.g. no V1 -> MR
and no V4, IT -> ML or -> MR; and may need to set wbase to 0 as well ...

myrun 16

now for some reason ML never firing ... ??? no, ML firing but MR not firing (that was the test)
but mostly only producing move 3 (down), instead of 4 (up) ... why?

savefig('gif/20feb27_rewards_wghts_a4.png')
savefig('gif/20feb27_rewards_wghts_a5.png')

hmm, had the rule backwards:
            if F_R1>F_L1:
                actions.append(dconf['moves']['UP']) #UP
            elif F_R1<F_L1:
                actions.append(dconf['moves']['DOWN']) # Down
            else:
            actions.append(dconf['moves']['NOMOVE']) # No move

R produces up, L produces down ...

ok, fixing that, now V->MR weights go up as they should (but now have turned off inputs to ML)
savefig('gif/20feb27_rewards_wghts_a6.png')

so, turned back on the inputs to ML to see if -> MR weights still go up with time ...

savefig('gif/20feb27_raster_a7.png')

savefig('gif/20feb27_rewards_weights_a8.png')

it does look like the V -> MR weights increase more than the V -> ML weights, which
is correct, but the V -> ML weights still seem to correlate with the V -> MR weights, and go up in parallel
perhaps, as long as overall more of the correct moves are made, it doesn't matter if the V -> ML weights
are increased too ... ?

what is the move command as a function of time? more correct moves later on compared to earlier?

pad = pd.DataFrame(actreward,columns=['time','action','reward'])

figure(); pads = pad[pad.action==3]; plot(pads.time,pads.action,'bo'); pads = pad[pad.action==4]; plot(pads.time,pads.action,'ro')

#
ldown,lup = [],[]
ltt = linspace(0,99,100)
for tt in ltt:
  pads = pad[(pad.action==3) & (pad.time>=tt*1e3) & (pad.time<=(tt+1)*1e3)]
  ldown.append(len(pads))
  pads = pad[(pad.action==4) & (pad.time>=tt*1e3) & (pad.time<=(tt+1)*1e3)]
  lup.append(len(pads))

clf(); plot(ltt,ldown,'r',linewidth=4); plot(ltt,lup,'b',linewidth=4); xlabel('Time (s)'); ylabel('Move frequency (Hz)');
import matplotlib.patches as mpatches
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','r'],['Up','Down'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/20feb27_action_freq_a9.png')

most of the time, up moves have higher rate than down moves ...

see if it's reversed when using the down fake rule ...

ok, using sim.json sim:name to specify simulation name so can save output files for different sim in data ...

also may as well adjust plotWeights to draw actions in top panel ...? suppose only useful when using fake rule ... 
otherwise up/down rates not so important ...  

sim name is 20feb27_FakeDownRule_B0_

myrun 16

  Cells: 1209
  Connections: 27879 (23.06 per cell)
  Spikes: 173390 (1.43 Hz)
  Simulated time: 100.0 s; 16 workers
  Run time: 2309.54 s

savefig('gif/20feb27_raster_b0.png')

more spikes at bottom, where they should be ... ML has higher firing rate (ML produces down move), much more than in previous example where MR had
slightly higher firing rate than ML  ... maybe a bug somewhere? why the difference?

and now check the weights and action freqs ... 

plw

savefig('gif/20feb27_rewards_weights_b1.png')

#
ldown,lup = [],[]
ltt = linspace(0,99,100)
for tt in ltt:
  actrewards = actreward[(actreward.action==3) & (actreward.time>=tt*1e3) & (actreward.time<=(tt+1)*1e3)]
  ldown.append(len(actrewards))
  actrewards = actreward[(actreward.action==4) & (actreward.time>=tt*1e3) & (actreward.time<=(tt+1)*1e3)]
  lup.append(len(actrewards))

figure(); plot(ltt,ldown,'r',linewidth=4); plot(ltt,lup,'b',linewidth=4); xlabel('Time (s)'); ylabel('Move frequency (Hz)');
import matplotlib.patches as mpatches
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','r'],['Up','Down'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/20feb27_action_freq_b2.png')

so, there are more down actions generally ..., particularly as the sim progresses ... maybe less consistent
than in previous FAKE MOVEUP test ...

not clear why would get diff results for the two fake rule tests ... one up and one down ... maybe some bug,
or some runaway effect ... 

could run another test to see if teach net to hold paddle still ... leading to suppression of ML and MR ...

ok, will try that ... with this sim name: 20feb27_FakeStayRule_C0_
and RLFakeStayRule == 1

note that any move up or down (in the 5 action block) is a penalty and any stay command is opposite (for the critic signal)... 

myrun 16

  Cells: 1209
  Connections: 27879 (23.06 per cell)
  Spikes: 173771 (1.44 Hz)
  Simulated time: 100.0 s; 16 workers
  Run time: 2286.23 s
Saving output as data/20feb27_FakeStayRule_C0_simConfig.pkl ... 
Finished saving!
Done; saving time = 11.18 s.

savefig('gif/20feb27_FakeStayRule_C0_raster.png')
lower firing rates for MR, ML ... next, look at behavior and weights...

plw

savefig('gif/20feb27_FakeStayRule_C0_rewards_weights_c0.png')

both sets of weights stay close to baseline ... 
would have expected both sets to decrease towards 0

savefig('gif/20feb27_FakeStayRule_C0_action_freq_c0.png')

well, at least neither action dominates here ...

*20feb28
** continue 

should make it easier to load the output data ... maybe consolidate plotting funcs too ...

question about architecture - how much of the higher level areas do we need/want? and should
allow easier scaling of the simulation in case need larger-sized populations  ... 

homeostatic plasticity will likely be needed - the weights were increasing, and could push
the net to epilepsy ...

try full architecture with the fake rules ... possible that higher order connections are not a problem ...

myrun 24

looks like M population might be too small ... ML and MR neurons should receive largely overlapping inputs from V1
because of the much higher number of V1 (400) compared to ML (25) and MR (25) neurons , with the high convergence (16)
this might be reason see highly synchronous firing in ML, MR neurons and correlation between the weight changes for the
fake tasks... whether or not topography is needed for ML,MR is unclear - random inputs may allow more complex encodings.
but can at least try increasing populaion size of ML, MR.

try that out ...

also, looks like noise inputs are off ... may want to reintroduce them ...
other source of artificial synchronization is the image inputs, which arrive to the network at a fixed interval (~30 ms?)

adjusted some of the convergence/weights onto ML,MR to have same convergence from each V1,V4,IT source
and lower weights 1/2 of original to prevent too high firing ...

savefig('gif/20feb28_rast_a0.png')
savefig('gif/20feb28_reward_weights_a1.png')
some separation between them in all projections ...
savefig('gif/20feb28_action_freq_a2.png')

try same, but longer ...

125 s ...

  Cells: 1359
  Connections: 38281 (28.17 per cell)
  Spikes: 484922 (2.85 Hz)
  Simulated time: 125.0 s; 16 workers
  Run time: 2823.09 s
Saving output as data/20feb28_A0_simConfig.pkl ... 
Finished saving!
Done; saving time = 97.79 s.

savefig('gif/20feb28_rast_b0.png')
rates go up too much ... another indication that need some form of homeostasis

savefig('gif/20feb28_reward_weight_b1.png')

#
ldown,lup = [],[]
ltt = linspace(0,124,125)
for tt in ltt:
  actrewards = actreward[(actreward.action==3) & (actreward.time>=tt*1e3) & (actreward.time<=(tt+1)*1e3)]
  ldown.append(len(actrewards))
  actrewards = actreward[(actreward.action==4) & (actreward.time>=tt*1e3) & (actreward.time<=(tt+1)*1e3)]
  lup.append(len(actrewards))

figure(); plot(ltt,ldown,'r',linewidth=4); plot(ltt,lup,'b',linewidth=4); xlabel('Time (s)'); ylabel('Move frequency (Hz)');
import matplotlib.patches as mpatches
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','r'],['Up','Down'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)
xlim((0,125))

savefig('gif/20feb28_move_rate_b2.png')
ok, clearly moving up more than down after training ... (as it should)

can try training in DOWN direction as precaution or run actual game test ...

will try game test ...

ok running this with no fake rule, and duration of 250e3 ... 
"20feb28_G0_"

if there was a weaker opponent, might be easier to train as starting point?
or play against self ...
does openai allow controlling difficulty level of opponent?

well, did see the model score a point...but pretty rare so far ...
intermediate rewards after ball contacts racket might be sensible, though less generic...
can also have multidimensional error for reward/punishment, consisting of distance
between racket/ball (0.25), contact with racket (0.5), actual points (+1/-1)
or sign(current distance to ball - last distance to ball) -- but once using those
types of rules, no longer need the visual input at all ... 

separately, also need to be able to save/restore learned weights ...

stoped sim ~1/2 way through since it ends up mostly staying still, probably due to lot of punishments, as discussed before ...

openai allows easily saving mp4 videos ... added that option ...

ok, will set wbase to starting level, since starts with pretty low level of firing anyway ...

can also reduce the frequency of saving the synaptic weights ...

  Cells: 1359
  Connections: 38281 (28.17 per cell)
  Spikes: 986134 (1.45 Hz)
  Simulated time: 500.0 s; 24 workers
  Run time: 11678.73 s
  Saving output as data/20feb28_G0_simConfig.pkl ...

savefig('gif/20feb28_rast_g0.png')  

movie is useful: videos/20feb28_G0_/openaigym.video.0.24912.video000000.mp4
but only lasts a single episode  which took ~35 s, so lost viewing movie activity from most of the sim ...

simdat

savefig('gif/20feb28_reward_weights_g0.png')  

reward frequency might increase over time ... ? weights certainly have not stabilized yet
and although rewards compared to punishments are much less frequent, they still influence
the weights substantially - the weights are not at minimum ...

so, need to allow movies generated to encompass entired simulation, and to allow setting
the initial weights to the final ones generated by previous run ...

*20feb29
** run longer - check if video saved after each episode

ran but did not save data:
Done; run time = 37584.81 s; real-time ratio: 0.04.
ran out of memory...

Gathering data...
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
[zn:32842] *** Process received signal ***
[zn:32842] Signal: Aborted (6)
[zn:32842] Signal code:  (-6)
[zn:32842] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x12890)[0x7f3ec802f890]
[zn:32842] [ 1] /lib/x86_64-linux-gnu/libc.so.6(gsignal+0xc7)[0x7f3ec7c6ae97]
[zn:32842] [ 2] /lib/x86_64-linux-gnu/libc.so.6(abort+0x141)[0x7f3ec7c6c801]
[zn:32842] [ 3] /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0x8c957)[0x7f3ec84e0957]
[zn:32842] [ 4] /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0x92ab6)[0x7f3ec84e6ab6]
[zn:32842] [ 5] /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0x92af1)[0x7f3ec84e6af1]
[zn:32842] [ 6] /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0x92d24)[0x7f3ec84e6d24]
[zn:32842] [ 7] /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0x9329c)[0x7f3ec84e729c]
[zn:32842] [ 8] /usr/site/../arch/nrn/share/nrn/../../x86_64/lib/libnrnpython3.so(+0x1bd7a)[0x7f3ea9420d7a]
[zn:32842] [ 9] /usr/site/../arch/nrn/x86_64/lib/libnrniv.so.0(+0xb4227)[0x7f3eca326227]
[zn:32842] [10] /usr/site/../arch/nrn/x86_64/lib/libnrnoc.so.0(hoc_call_ob_proc+0x23a)[0x7f3eca5f1d7a]
[zn:32842] [11] /usr/site/../arch/nrn/x86_64/lib/libnrnoc.so.0(hoc_object_component+0x51e)[0x7f3eca5f2a8e]
[zn:32842] [12] /usr/site/../arch/nrn/share/nrn/../../x86_64/lib/libnrnpython3.so(+0xef3a)[0x7f3ea9413f3a]
[zn:32842] [13] /usr/site/../arch/nrn/share/nrn/../../x86_64/lib/libnrnpython3.so(+0x141fb)[0x7f3ea94191fb]
[zn:32842] [14] /usr/site/../arch/nrn/x86_64/lib/libnrniv.so.0(_ZN10OcJumpImpl7fpycallEPFPvS0_S0_ES0_S0_+0x3e)[0x7f3eca2ff5fe]
[zn:32842] [15] /usr/site/../arch/nrn/share/nrn/../../x86_64/lib/libnrnpython3.so(+0xeb37)[0x7f3ea9413b37]
[zn:32842] [16] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(_PyObject_FastCallDict+0x8a)[0x7f3ea97d424a]
[zn:32842] [17] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(+0x2084b7)[0x7f3ea98504b7]
[zn:32842] [18] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(_PyEval_EvalFrameDefault+0x3373)[0x7f3ea97a6153]
[zn:32842] [19] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(+0x208063)[0x7f3ea9850063]
[zn:32842] [20] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(+0x208616)[0x7f3ea9850616]
[zn:32842] [21] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(_PyEval_EvalFrameDefault+0x3373)[0x7f3ea97a6153]
[zn:32842] [22] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(+0x208063)[0x7f3ea9850063]
[zn:32842] [23] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(PyEval_EvalCodeEx+0x3e)[0x7f3ea9850a6e]
[zn:32842] [24] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(PyEval_EvalCode+0x1c)[0x7f3ea97a2b2c]
[zn:32842] [25] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(PyRun_FileExFlags+0xb7)[0x7f3ea97344d7]
[zn:32842] [26] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(PyRun_SimpleFileExFlags+0xf4)[0x7f3ea9738734]
[zn:32842] [27] /usr/site/../arch/nrn/share/nrn/../../x86_64/lib/libnrnpython3.so(nrnpy_pyrun+0x2c)[0x7f3ea941323c]
[zn:32842] [28] /usr/site/../arch/nrn/share/nrn/../../x86_64/lib/libnrnpython3.so(nrnpython_start+0x288)[0x7f3ea9413888]
[zn:32842] [29] nrniv(ivocmain+0x5cb)[0x563f75882bfb]
[zn:32842] *** End of error message ***
--------------------------------------------------------------------------
mpiexec noticed that process rank 0 with PID 0 on node zn exited on signal 6 (Aborted).
--------------------------------------------------------------------------

so will probably have to run simulation for shorter duration ...

*20mar1
** run 750 s again - adjust critic for punishments

can try critic with -0.1 or -0.01 so it's less pronounced compared to reward

750 s, with critic at -0.01 ...

myrun 24

*20mar2
** continue - look at output from last sim

  Cells: 1359
  Connections: 38281 (28.17 per cell)
  Spikes: 3478200 (3.41 Hz)
  Simulated time: 750.0 s; 24 workers
  Run time: 18652.00 s
Saving output as data/20mar1_G2_simConfig.pkl ... 
Finished saving!
  Done; saving time = 83.59 s.
Plotting recorded cell traces ... cell
QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-samn'
Plotting raster...
Saving figure data as data/20mar1_G2_RasterData.pkl ... 
  Done; plotting time = 1282.06 s

savefig('gif/20mar2_G2_Raster.png')
  
savefig('gif/20mar2_G2_reward_weights.png')

ok, weights do not have as much time to decay now ...

but still need a way to save/restore the weights, and produce videos capturing whole simulation ...

*20mar5 - testing on laptop after conda/neurosim setup 
** conda/packages

had installed anaconda with python36 and then recompiled neuron, etc.

for ffmpeg if you're on ubuntu & have root can use sudo apt-get install ffmpeg

py3env <<-- that now sets conda to use py36
conda install numpy
conda install scipy
conda install pandas
conda install matplotlib
used new version of netpyne from github (development branch) with pip after activating the conda
env above; note that netpyne does not support latest matplotlib or latest pandas (sal mentioned
bug in those latest versions)

this is the alias in .tcshrc for setting the py env with conda:
alias py3env 'alias py3env setenv NSUF 'py3';source /usr/site/config/nrnenv.csh; setenv PYTHONPATH {$PYTHONPATH}:/usr/site/nrniv/local/python; conda activate py36'

once that env is activated can just use pip (it points to the right pip3 for that py env) and
don't have to explicitly indicate pip3

myrun 16

here's first error:

ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.22' not found
(required by
/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/fft/_pocketfft/pypocketfft.cpython-36m-x86_64-linux-gnu.so)

according to : https://github.com/facebookresearch/detectron2/issues/609
should do:
conda update libgcc

PackageNotInstalledError: Package is not installed in prefix.
  prefix: /usr/site/nrniv/local/python/anaconda3/envs/py36
  package name: libgcc

conda install libgcc

ok, that fixed that problem ...

next error:
python
import sim
ModuleNotFoundError: No module named 'skimage'

conda install skimage

not found ...

it's scikit-image

conda install scikit-image

and also need openai gym
can install with conda as:
conda install -c akode gym

hmm, did not find it ...

ok, just use pip ...

pip install gym

pip install 'gym[atari]'

sudo add-apt-repository ppa:ubuntu-toolchain-r/test
sudo apt-get update
sudo apt-get install gcc-4.9
sudo apt-get install --only-upgrade libstdc++6

ok, that fixed error ... based on this:
 https://github.com/lhelontra/tensorflow-on-arm/issues/13#issuecomment-489296444

myrun 12

also have this in pythonpath:
 setenv PYTHONPATH {$PYTHONPATH}:$ND/share/python/lib/python:/usr/site/nrniv/local/python

*20mar6 - long run with restarts?
** testing

since haroon implemented weight save/restore, could let it run a few times with restarts ...

may not need to save video for now ... could instead run video once run a few rounds of training
...

*20mar8 - notes on changes
** started setting up multistepSim.py
which generates run file to call a few sims in a row, with each one reloading weights saved from
end of previous run; still testing - not working properly yet

** noticed on mar6 that the temperature was wrong (6.3 instead of 37)
changing temperature required readjusting the connection weights between cells
added the standard cfg. EEGain, EIGain, IEGain, IIGain to allow easier modulation of
these weights

this also required changing threshold for spikes - however, voltage traces do not currently
look great, so this will require some further adjustment. may want to use simple models of
PV cells nad or PYR cells ... although their dynamics with multiple ion channels will be
more costly than simpler standalone HH

** also changed population names so they'd be consistent
some populations seemd to have inconsistent names
now always using E as prefix for excitatory population and I as prefix for inhibitory population

** ran fake up rule test with new setup

produced higher weights for expected population

*20mar8 - fix for multistepsim, run test
** multistep test - still not working properly? fixed ... 

python multistepSim.py sim.json 16 2 multirun

individual sims do not stop after plot ... ?

ok, fixed problems ... conf.py was not reading correct json, was not passing it to sim.py either, etc.

** replace cell types?

voltage traces don't look great now after temp adjustment ...

** try a multistepsim test run with game (300 s run with 12 steps = 1 hr.)

not using fake rules ...

python multistepSim.py sim.json 16 12 multirun

*20mar9 - adjustments to cell types/architecture
** code reorg - moved mod files to mod subdir; moved cell types to cells subdir; compile script (nrnivmodl mod)
** HA added Mainen PYR2 and FS basket cells to model
this then required adjusting weights and...
** adjusted rules to have AMPA synapses of PYR on dend; AMPA of I cells on soma; GABAA for E,I on soma
** ...then had to adjust architecture slightly (new interneuron population)
to include IM interneuron population in motor area; this reduces likelihood of depolarization blockade
of the EMR and EML populations (seems to work after some adjustment to the weights)
a 10 s run shows one population of EM neurons firing faster than the other leading to paddle
staying at top of screen for much of the sim - not sure where this assymetry comes from

right now there's one interneuron population in M area providing feedback inhibition onto both EM and ER
populations; in future may want multiple interneuron populations that receive excitation from one population
and suppress the other (easy to implement in netpyne, but thought that might lead to further positive feedback
and one EMR vs EML population dominating the dynamics)

still, where does the assymetry come from?

*20mar10 - adjustments to connectivity, thresholds, E/I balance
** using dnumc as dictionary for number of cells
** set different thresholds for E and I cells (lower for I cells) via cellRule

netParams.cellParams['PYR_Mainen_rule']['secs']['soma']['threshold'] = 0.0
netParams.cellParams['FS_BasketCell_rule']['secs']['soma']['threshold'] = -10.0

** lack of symmetry fix? use convergence instead of probability

probably due to higher/lower number of inputs from IM to EMR vs EML
can fix that via using convergence rather than random connectivity

conv = pmat[from][to] * numc[from]

ok, try that with fake up rule ... 

myrun 16

hmm, something messed up ... was getting too much dep blockade ... 

ok, after adjusting the thresholds, other connection weights and gains ...

(note that IV4 was acting differently since receives extra inhibition from the large IV1 population; reduced
the weights from IV1 -> IV4 to reduce that effect)

get more reasonable raster, with higher I than E rates ... 

savefig('gif/20mar10_rast_a0.png')

testing fake up rule for 10 s ... still stable at end ...

raster looks ok:
savefig('gif/20mar10_rast_a1.png')
cells look ok:
savefig('gif/20mar10_IM_a1.png')
savefig('gif/20mar10_EMR_a1.png')
savefig('gif/20mar10_EML_a1.png')
savefig('gif/20mar10_IIT_a1.png')
savefig('gif/20mar10_EIT_a1.png')
savefig('gif/20mar10_IV4_a1.png')
savefig('gif/20mar10_EV4_a1.png')
savefig('gif/20mar10_IV1_a1.png')
savefig('gif/20mar10_EV1_a1.png')
savefig('gif/20mar10_IR_a1.png')
savefig('gif/20mar10_ER_a1.png')

and the weights ?
simdat
savefig('gif/20mar10_reward_weights_a1.png')
weights look biased towards correct population
(note that only recording weights every 1 s here, while reward signal recorded every 0.1 s so
cannot always see correspondence closely in figure above)

** Note: should change R and L to up and down (as appropriate)!
EMR, EML population names

** meanwhile, try multistep test again

python multistepSim.py sim.json 16 12 multirun

that did not seem to work ... paddle ends up becoming stationary after a while ...
probably too much punishment suppressing EMR,EML

*20mar11
** add noise?
** check haroon's updated intermediate reward rules

has these in sim.json:
"rewardcodes": {"scorePoint": 1, "losePoint": -0.01, "followBall": 0.001, "avoidBall": -0.001, "hitBall": 0.05},

will reward following ball and hitting ball more ... take a look to see if works, etc.

can try:
"rewardcodes": {"scorePoint": 1, "losePoint": -1, "followBall": 0.5, "avoidBall": -0.001, "hitBall": 0.75},

myrun 16

*20mar24
** discussion on retinal circuitry, movement selectivity

14:22
samn this paper looks useful https://senselab.med.yale.edu/ModelDB/ShowModel?model=116837&file=/RM_STDP/#tabs-1
14:23
https://paperpile.com/app/p/f2db9a70-4380-0c3c-9bc0-36a1fc7402f9
14:24
haroon found this paper for motion selectivity in retina: https://paperpile.com/app/p/7b54db25-10b2-0afe-af21-4538acf0def0
14:26
not sure if that model has retina with motion selectivity
14:28
here's another: https://senselab.med.yale.edu/ModelDB/ShowModel?model=118524#tabs-1
14:28
"virtual retina"
14:28
Haroon Anwar looks very phenomenological
14:29
samn https://paperpile.com/app/p/4c5b9cb8-6eb7-00f2-b3c9-fa42ea6d2595
14:30
"Abstract We propose a new retina simulation software, called Virtual Retina, which transforms a video into spike trains. Our goal is twofold: Allow large scale simulations (up to 100,000 neurons) in reasonable processing times and keep a strong biological plausibility, taking into account implementation constraints. The underlying model includes a linear model of filtering in the Outer Plexiform Layer, a shunting feedback at the level of bipolar cells accounting for rapid contrast gain control, and a spike generation process modeling ganglion cells. We prove the pertinence of our software by reproducing several experimental measurements from single ganglion cells such as cat X and Y cells. This software will be an evolutionary tool for neuroscientists that need realistic large-scale input spike trains in subsequent treatments, and for educational purposes"
14:30
maybe worth trying that if it has motion selectivity ... or check if can replicate relevant aspects of model
14:32
Haroon Anwar doesn’t look like- as i didnt find any keyword ‘direction’
14:33
samn does it emerge from the circuitry?
14:35
that one or different one, let's see if we can find good model that has the features needed and/or whether to replicate
14:38
Haroon Anwar may be--but if we can come up with a simpler circuit to implement direction selectivity of  ganglion cells, would prefer that….seems not difficult
14:38
samn ok - if you have an idea
14:38
Haroon Anwar the difficult part is how such information is carried out along the dorsal stream
14:39
and presented in V1, IT etc
14:39
samn if you have a simple circuit that can accomplish what we need, good
14:39
Haroon Anwar at input level. should be straight forward
14:39
at later stages-not sure
14:40
samn ok, can try first stages first...then wire it to higher after
14:40
Haroon Anwar ok
14:40
thanks
14:40
samn was that figure you shared from review paper enough to produce direction selectivity?
14:41
Haroon Anwar this shows the circuitry involved ----so its part of it…not complete
14:42
Screen Shot 2020-03-24 at 2.12.16 PM.png 
Screen Shot 2020-03-24 at 2.12.16 PM.png
14:42
how we arrange Bipolar inputs is not shown here
14:43
topologically bipolar inputs
14:43
samn some of this may be relevant: some of these papers look relevant too: https://www-sop.inria.fr/members/Pierre.Kornprobst/
14:43
hmm, since you already have the temporally decaying activation ... would it be simpler to take differences between current and previous frame and calculate direction vectors then feed to another population?
14:44
to avoid additional detailed circuitry
14:45
Haroon Anwar minimally we will have to add neurons which are not only showing position but all direction
14:45
right now its only position
14:45
samn right
14:45
Haroon Anwar so need more for direction
14:45
samn just question of whether to have circuit compute directions or to estimate it ourselves from images (optic flow)
14:46
Haroon Anwar yes thats simple way, can do that
14:46
samn ok sg

WikipediaWikipedia
Optical flow
Optical flow or optic flow is the pattern of apparent motion of objects, surfaces, and edges in a visual scene caused by the relative motion between an observer and a scene. Optical flow can also be defined as the distribution of apparent velocities of movement of brightness pattern in an image. The concept of optical flow was introduced by the American psychologist James J. Gibson in the 1940s to describe the visual stimulus provided to animals moving through the world. Gibson stressed the importance of optic flow for affordance perception, the ability to discern possibilities for action within the environment.  Followers of Gibson and his ecological approach to psychology have further demon… Show more(531 kB)
https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Opticfloweg.png/1200px-Opticfloweg.png
14:46
probably some of those image processing functions you're using can calculate that for you
14:46
Haroon Anwar right
14:47
OK - so will include the direction precomputed
:+1:
1
14:47
samn sg
14:50
if anyone else saw relevant approaches, let us know

*20mar25
** zlib error

cd ~/SM*
py3env
myrun 16

ImportError: /lib/x86_64-linux-gnu/libz.so.1: version `ZLIB_1.2.9' not found (required by
/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/site-packages/matplotlib/../../.././libpng16.so.16)

https://stackoverflow.com/questions/48306849/lib-x86-64-linux-gnu-libz-so-1-version-zlib-1-2-9-not-found

fix?

download:
https://sourceforge.net/projects/libpng/files/zlib/1.2.9/zlib-1.2.9.tar.gz/download

then:
cd ~/Downloads
tar -xvf ~/Downloads/zlib-1.2.9.tar.gz
cd zlib-1.2.9
sudo -s
./configure; make; make install
cd /lib/x86_64-linux-gnu
ln -s -f /usr/local/lib/libz.so.1.2.9/lib libz.so.1
cd ~/Downloads
rm -rf zlib-1.2.9

cd ~/SM*
myrun 16

ok, runs now without an error ...

** check dynamics
** how to implement direction selectivity

use optical flow on successive images to produce movement vectors at each coordinate.

then, need at least 4X number of pixels to represent the movement info from frame to frame?
and it has to be topographically arranged

...where does each pixel of movement selective neurons project?

*20mar31
** back to testing

myrun 16

*20apr1
** fixing up plotSpatioTemporalActivity.py

myrun 16

python -i plotSpatioTemporalActivity.py

seems to work now ... there weren't any loops, functions, dictionaries, etc.
really used in the file ...

*20apr7
** sal code for animation

def animateRateVsWeight(dataFolder, batchLabel, params):
    import imageio
    from pathlib import Path
    Lvals = params[0]['values']
    Ivals = params[1]['values']
    for ipop, pop in enumerate(Lvals):
        print('Generating traces gif for pop %s ...' % (pop))
        #v22_batch1_18_98_traces.png
        images = ['%s/%s/%s_%d_%d_traces.png' % (dataFolder, batchLabel, batchLabel, ipop, iweight) for iweight in range(len(Ivals))]
        #images = list(image_path.glob())
        image_list = []
        for file_name in images:
            image_list.append(imageio.imread(file_name))
        pass
        imageio.mimwrite('%s/%s/%s_%s_traces.gif' % (dataFolder, batchLabel, batchLabel, pop), image_list)

should adapt for plotSpatioTemporalActivity.py to allow saving output
and/or for video ...

** test update

a lot more cells now (1e3 more motor cells, and 800 direction selective cells), so runs slower,
+ image processing slows it down some more ... not clear by how much

python -i plotSpatioTemporalActivity.py

fig, axs, plt = plotActivityMaps(pauset=0,gifpath='20apr7_activity.gif')

*20apr8
** save spatiotemporal activity as movie instead (using ffmpeg)

could use imageio ffmpeg interface
https://imageio.readthedocs.io/en/stable/format_ffmpeg.html#parameters-for-saving

or ffmpeg-python https://github.com/kkroening/ffmpeg-python
though that is more comprehensive, so may not need full package installed ...

https://imageio.readthedocs.io/en/stable/examples.html#writing-videos-with-ffmpeg-and-vaapi

https://github.com/imageio/imageio-ffmpeg

pip install imageio-ffmpeg

should have used conda to install
with
conda install imageio-ffmpeg -c conda-forge
but without the ffmpeg binary

python -i plotSpatioTemporalActivity.py

lfnimage = ['/tmp/'+str(x)+'.png' for x in range(1,50,1)]
limage = [imageio.imread(fn) for fn in lfnimage]


from imageio_ffmpeg import write_frames

w = imageio.get_writer('my_video.mp4', format='FFMPEG', mode='I', fps=1,
                       codec='h264_vaapi',
                       output_params=['format=gray'],
                       pixelformat='gray')

for img in limage: w.append_data(img)                       

w.close()

gen = write_frames('test.mp4', (limage[0].shape[0],limage[0].shape[1],limage[0].shape[2]), pix_fmt_in="gray")
gen.send(None)  # seed the generator
for img in limage: gen.send(img)
gen.close()  # don't forget this

hmm, getting errors ... ffmpeg-python seems easier to use?

pip install ffmpeg-python

import ffmpeg
(
    ffmpeg
    .input('/tmp/*.png', pattern_type='glob', framerate=10)
    .output('movie.mp4')
    .run()
)

that works ... fast to run and makes small files

ok, put that into plotSpatioTemporalActivity.py ...

and added animation saving functions to anim.py

** testing network

number of IM was too low, after the increase in EMR, EML populations
so increased IM to 690, to be about 20% of IM (690) + EMR (1350) + EML (1350)

now, when run network, get too high firing rates for EMR, EML

savefig('gif/20apr8_rast_a0.png')

is same obtained with fewer IM cells?

reset IM to 50 ... 

myrun 12

hmm, now EMR,EML firing rates look better, but not clear why. no depolarization
blockade seen in EMR,EML

savefig('gif/20apr8_rast_a1.png')

check connectivity in sim.py ... something off?

might be due to using fixed convergence instead of probability ... for larger pop sizes
seems better to use probability ... had used convergence before to ensure minimum number
of inputs (more relevant with smaller populations)

try with probability of 0.25 and larger IM population of 690 ...

myrun 12

ok, rates of EMR, EML went down, and IM rates are OK
but now activity looks highly synchronized to 100 ms interval when visual inputs come in:
 gif/20apr8_rast_a2.png
 gif/20apr8_EMR_a2.png
 gif/20apr8_IM_a2.png

so, should avoid it ... probably can reduce weights between EMR->IM, EML->IM, IM->IM, IM->EMR, IM->EML

can try cutting probabilities between those populations in half (from 0.25 to 0.125)

myrun 12

savefig('gif/20apr8_rast_a3.png') 
looks ~same

try cutting down probabilities further ... 0.0625

myrun 12

little better ...

gif/20apr8_rast_a4.png
gif/20apr8_EMR_a4.png
gif/20apr8_IM_a4.png

should run longer to see if remains stable ... 
some of the other E vs I populations have wrong rates, e.g. EV4 faster than IV4, EV1 faster than IV1
EMT only a little slower than IMT
and no inhibitory populations in the direction selective cells...

run for 5 s to see if patterns similar, then may consider adjusting weights/probabilities further ...

myrun 12

ok, looks like decent rates ... less synchrony ... should be OK for now ... can adjust further as needed ... 
gif/20apr8_rast_a5.png
gif/20apr8_rast_a5b.png <- some alternation between synch and asynch state
gif/20apr8_IM_a5.png
gif/20apr8_EMR_a5.png
gif/20apr8_EML_a5.png

python -i actmap.py

made this movie: data/20april08_A0__movie.mp4

** try longer sim ("name":"20april08_B0_")

to test and watch output ...

"rewardcodes": {"scorePoint": 1, "losePoint": -0.01, "followBall": 0.01, "avoidBall": -0.001, "hitBall": 0.25},

and duration of 100 s ...

myrun 12

started ~17:32 ...

finished @ ~22:15 ...

rates ok:
 gif/20apr8_rast_b0.png
 gif/20apr8_rast_b0b.png

cells look ok?
 gif/20apr8_IM_b0.png
 gif/20apr8_EML_b0.png
 gif/20apr8_EV1DSE_b0.png
 gif/20apr8_EV1DS_b0.png
 gif/20apr8_EV1_b0.png
 yeah, most cells look ok. some populations fire much less than others.
 direction cells - many directions not firing too mcuh (E, W), could be due to the
 ball mostly moving at a diagonal; but N,S higher since paddles move up,down
 
and now to create the movie ...

python -i actmap.py

*20apr9 - trying to speed up animation production
** continue

hmm, took > 12 hours so far to spit out the pngs up to 66 s, and hasn't even started on movie creation yet ...

should stop it and figure out how to speed up that process ...

can make movie from the frames that were produced so far

python
import anim
anim.savemp4('/tmp/*.png', 'data/20april08_B0_actmap.mp4', 10)

very slow encoding of mp4 ...

there's support in matplotlib for making animations and exporting to mp4 via ffmpeg but that's
slow too ...

imagemagick gif writing faster?

sudo apt-get install imagemagick

already have imagemagick ...

hmm, even the imagemagick gif writer is slow . . .

*20apr13 - animation fixing
** HA fixing collision detection code since not working in all cases
algorithm relies on position, direction, score
** movie fix

would concat of smaller mp4 files together run faster than producing one giant mp4?

https://stackoverflow.com/questions/7333232/how-to-concatenate-two-mp4-files-using-ffmpeg

could try ffmpeg concat demuxer : 

"Use this method when you want to avoid a re-encode and your format does not support file level
concatenation (most files used by general users do not support file level concatenation).

$ cat mylist.txt
file '/path/to/file1'
file '/path/to/file2'
file '/path/to/file3'

$ ffmpeg -f concat -safe 0 -i mylist.txt -c copy output.mp4"

hmm, problem seems to be that matplotlib takes longer and longer to save output files
in beginning, saves 15 files per minute, then gradually decreases to 5 per minute ...

and that's particularly true when setting figsize to high resolution values ...

might be due to matplotlib slowing down with all the redrawing ... not even having to do
with file saving ...

yes, not ffmpeg issue - ffmpeg runs very quickly once all frames are available ... so that
isolates slowness to matplotlib

this related issue mentions slowing down:
https://github.com/matplotlib/matplotlib/issues/16182

https://stackoverflow.com/questions/40747181/slow-ploting-using-animation-function-in-matplotlib-python
also relevant ...

fig, axs, plt = animActivityMaps(mp4path='test.mp4', framerate=10)

*20apr14
** HA made nice movie showing activity/dynamics/actions from random game (testPong.py)
will use it to generate similar with additional inclusion of network dynamics

** other movie fixes needed for simdat.py

first rerun sim for 10 s ... since now have a new column in ActionsRewards.txt

myrun 12

  Cells: 5349
  Connections: 1103176 (206.24 per cell)
  Synaptic contacts: 1105826 (206.74 per cell)
  Spikes: 78992 (1.48 Hz)
  Simulated time: 10.0 s; 12 workers
  Run time: 1974.00 s
Saving output as data/20april14_A0_simConfig.pkl ... 
Finished saving!
  Done; saving time = 82.23 s.
SAVING RASTER DATA
plot raster:
Plotting raster...
QApplication: invalid style override passed, ignoring it.
Saving figure data as 20april14_A0_raster.pkl ... 
Plotting recorded cell traces ... cell
Plotting raster...
Saving figure data as data/20april14_A0_RasterData.pkl ... 
  Done; plotting time = 30.80 s

Total time = 2191.62 s

End time:  2020-04-14 12:31:15.408575

output looks ok ... cells and rates in raster

20apr14_rast_a0.png
20apr14_rast_a0b.png
20apr14_EV1DN_a0.png
20apr14_EV1DS_a0.png
20apr14_EV1DSW_a0.png
20apr14_IMT_a0.png
20apr14_IV4_a0.png

let's see actmap.py ... then simdat.py

python -i actmap.py

produces
data/20april14_A0_actmap.mp4
fairly quickly...

and simdat.py ...

python -i simdat.py -1

that calls
plotSynWeightsPerTimeStep(pdf,pauset=1,mp4path='data/'+dconf['sim']['name']+'weightmap.mp4', framerate=10) #plot images

python -i simdat.py -1

** discussion on smooth direction selective RFs

13:17
samn btw, should E neurons always fire (but at a slower rate) when NE neurons fire?
13:17
since they're not orthogonal directions
13:17
Haroon Anwar no
13:17
samn why
13:18
Haroon Anwar E is between 337.5 degrees and 22.5 degrees
13:18
and NE is between 22.5 and 67.5 degrees
13:19
360 is divided into 8 angular regions
13:19
and each population is assigned that
13:19
samn understand but that means sharp cutoffs
13:19
Haroon Anwar right
13:19
samn could also have smooth fall-off and smoother receptive fields
13:19
Haroon Anwar possible
13:20
might be a good idea…
13:20
samn can put that on list for later
13:20
seems more realistic (?)
13:21
Haroon Anwar sure…more realistic
13:21
samn do all neurons of a population have exact same receptive field?
13:21
Haroon Anwar will also reduce number of neurons
13:21
because we could have directions coded using 4 pops instead of 8
13:22
NE will evoke e.g. 5 Hz in N and 5 Hz in E
13:22
if its exactly 45 degrees
13:22
samn you could have it with 1 pop probably too if you had receptive fields with some width tuning
13:22
width to the receptive field around a mean angle
13:22
Haroon Anwar that would be unrealistic
13:23
samn why?
13:23
Haroon Anwar we have neurons with very fine tuned directions
13:23
1 pop would not be able to encode all directions
13:23
samn it would be 1 pop in the model
13:23
where each neuron selects a mean angle randomly
13:23
then overall you'd have representations in all directions
13:24
Haroon Anwar ok --- yes possible that way---
13:24
implementation might be a bit tricky----but yes possible
13:25
samn tricky for how they project to other areas?
13:25
Haroon Anwar or assigning firing rates to each of the neurons in that pop
13:25
and generating connection lists
13:25
but yeah thats more realistic
13:26
samn if each one had a location in space and there were enough of the full directions in any locatin, seems ok
13:26
anyway, can put that on list of things to adjust. reducing # of neurons could help as you said
13:27
Haroon Anwar yes definitely to do list--- i need to think.. may be its not as difficult as i think right now…. but i will think about it
13:27
samn ok sg
13:28
Haroon Anwar will look at it after performance analysis---
13:28
samn sg

*20apr15
** continue fixup of animSynWeights in simdat.py

this example animation https://matplotlib.org/gallery/animation/basic_example.html
shows how to set line data dynamically ...

and simpler way to save to mp4

animSynWeights(pdf,'data/'+dconf['sim']['name']+'weightmap.mp4', framerate=10) #plot/save images as movie

ok, works faster now ...

but some of the text is not visible ... adjust size of fig

python -i simdat.py -1
animSynWeights(pdf,'data/'+dconf['sim']['name']+'weightmap.mp4', framerate=10, figsize=(8,6)) #plot/save images as movie

animSynWeights(pdf,'data/'+dconf['sim']['name']+'weightmap.mp4', framerate=10, figsize=(7,5)) #plot/save images as movie

also turn off interactive mode during animation, goes faster...

animSynWeights(pdf,'data/'+dconf['sim']['name']+'weightmap.mp4', framerate=10, figsize=(7,4)) #plot/save images as movie

** discuss opt (image processing for direction selective neurons vs population reduction)
** looking through code for what to optimize/improve

moved some connection functions from sim.py to connUtils.py

cleaned up some of the code that calculates firing rates based on image contents
to use dictionaries and loops instead of previous code duplication ...

that cleanup will help with modifications in future ...

tested network with short run after first adjustments

myrun 12

20april15_A0_rast.png
20april15_A0_EMR.png
20april15_A0_IM.png
20april15_A0_EV4.png
20april15_A0_EV1DS.png

looks ok ...

check videos ...

python -i simdat.py -1

data/20april15_A0_weightmap.mp4

python -i actmap.py

data/20april15_A0_actmap.mp4

looks ok ... should try more thorough tests to make sure nothing broken ...

*20apr16
** cleaning up code in aigame.py

moved motion computations to separate function in aigame.py
should move pong-specific code to separate place too

myrun 12

python -i simdat.py -1

data/20april16_A0_weightmap.mp4

python -i actmap.py

data/20april16_A0_actmap.mp4

*20apr17
** continue adjustments/cleanup

myrun 12

hmm, getting depolarization blockade and black input images
values were between 0-1 after rgb2gray, so need to multiply by 255

try again ...

after Haroon's last fix (input firing rates re-adjusted), no dep blockade with the newer version of the code/image processing...

run a bit longer

myrun 12

10 s sim

Total time = 1888.37 s

20april17_A0_rast.png

rates look ok, as do neuron membrane potentials ...

python -i actmap.py

data/20april17_A0_actmap.mp4

python -i simdat.py -1

data/20april17_A0_weightmap.mp4

looks interesting but does not seem to improve over 10 s ... can run longer ...

try longer ...

100 s ...

myrun 12

Total time = 16952.75 s

End time:  2020-04-18 04:30:30.562465

*20apr18
** check output from last run

20april17_A0B_EV1DN.png
20april17_A0B_EV1DW.png
20april17_A0B_EV1DS.png
20april17_A0B_EV1D4.png
20april17_A0B_IV1.png
20april17_A0B_IMT.png
20april17_A0B_EMT.png
20april17_A0B_IM.png
20april17_A0B_rast.png
20april17_A0B_rastB.png

rates and activity looks ok

some populations almost silent EV1DE (east direction sensitive; maybe get rid of them or adjust/reduce numbers?)

python -i simdat.py -1

data/20april17_A0_weightmap.mp4

python -i actmap.py
data/20april17_A0_actmap.mp4

does not improve in terms of following ball after 100 s ... can run longer ...

can continue for 100 s from there ... see if it improves at all ...

"simtype": {"ResumeSim":1,"ResumeSimFromFile":"20april17_A0_simConfig.pkl"},

"sim": {"duration": 100000, "dt": 0.2, "verbose": 0, "recordStep":0.2,"recordWeightStepSize":1,"RLFakeUpRule": 0,"RLFakeDownRule": 0,"RLFakeStayRule": 0,"name":"20april18_B0_","doquit":0,"doplot":1},

myrun 12

hmm, restore sim not working ... can run for 200 s ... see if improves ... fix resume later ...

    "simtype": {"ResumeSim":0,"ResumeSimFromFile":"20april17_A0_simConfig.pkl"},        
    "sim": {"duration": 200000, "dt": 0.2, "verbose": 0, "recordStep":0.2,"recordWeightStepSize":1,"RLFakeUpRule": 0,"RLFakeDownRule": 0,"RLFakeStayRule": 0,"name":"20april18_A0_","doquit":0,"doplot":1},

myrun 12    
*20apr22 - RFs for direction selective neurons
** add gaussian profile to direction selective neurons

most of that can go into aigame.py where the rates for those neurons are set

may want to try other optical flow algorithm first ... might be faster to
use a standard implementation

https://scikit-image.org/docs/dev/auto_examples/registration/plot_opticalflow.html#sphx-glr-auto-examples-registration-plot-opticalflow-py

"By definition, the optical flow is the vector field (u, v) verifying image1(x+u, y+v) =
image0(x, y), where (image0, image1) is a couple of consecutive 2D frames from a sequence. This
vector field can then be used for registration by image warping."

try images saved from game ...

python

import numpy as np

Input_Images = np.loadtxt('data/20april21_A0_InputImages.txt')
New_InputImages = []
NB_Images = int(Input_Images.shape[0]/Input_Images.shape[1])
for x in range(NB_Images):
    fp = x*Input_Images.shape[1]
    cImage = Input_Images[fp:fp+20,:] # 20 is sqrt of 400 (20x20 pixels)
    New_InputImages.append(cImage)
New_InputImages = np.array(New_InputImages)

New_InputImages.shape # (10, 20, 20)

from pylab import *

ion()
imshow(New_InputImages[3,:,:],cmap='gray'); savefig('gif/20apr22_a0.png')
imshow(New_InputImages[4,:,:],cmap='gray'); savefig('gif/20apr22_a1.png')

from skimage.color import rgb2gray
from skimage.data import stereo_motorcycle
from skimage.registration import optical_flow_tvl1
# --- Convert the images to gray level: color is not supported.
image0 = New_InputImages[3,:,:]
image1 = New_InputImages[4,:,:]
flow = optical_flow_tvl1(image1, image0)

imshow(flow[0,:,:],cmap='gray'); savefig('gif/20apr22_a2.png')
imshow(flow[1,:,:],cmap='gray'); savefig('gif/20apr22_a3.png')

amin(flow[0,:,:]) # -29.32014
amax(flow[0,:,:]) # 16.496756
amin(flow[1,:,:]) # -19.863085
amax(flow[1,:,:]) # 32.638676

those colors don't have directions ... 

in the example here:
 https://scikit-image.org/docs/dev/auto_examples/registration/plot_opticalflow.html#sphx-glr-auto-examples-registration-plot-opticalflow-py

the two arrays returned by optical flow are the row and column displacements?

e.g.:
# --- Compute the optical flow
v, u = optical_flow_tvl1(image0, image1)
# --- Use the estimated optical flow for registration
nr, nc = image0.shape
row_coords, col_coords = np.meshgrid(np.arange(nr), np.arange(nc), indexing='ij')
image1_warp = warp(image1, np.array([row_coords + v, col_coords + u]), mode='nearest')

other simple code for motion detection/tracking:
 https://www.pyimagesearch.com/2015/05/25/basic-motion-detection-and-tracking-with-python-and-opencv/
more general ... uses opencv2

implemented exp decay in each direction as
           fctr = np.exp(-1.0*((theta-dAngPk[pop])**2)/AngSigma**2)
          print('updateDirSensitiveRates',pop,x,y,fctr,dAngPk[pop],motiondir[y][x])
          if fctr > 0.:
            self.dFiringRates[pop][y,x] = AngVal * fctr

with AngSigma as 45 ... (can tweak) and AngVal as 30
            
... ran a small test ... (still have to fix E direction!!)

gif/20apr22_rast_a4.png
gif/20apr22_EV1DS_a4.png

not sure what data/20april22_A0_randGameBehavior.mp4 is supposed to show but looks incomplete ... only runs
up to 50 ms ... yeah, used old files from hours ago ... should cleanup the pngs

python -i actmap.py

data/20april22_A0_actmap.mp4

looks OK but E needs to be fixed

python -i simdat.py -1

data/20april22_A0_weightmap.mp4

*20apr23 - RFs for direction selective neurons
** RFs for direction selective neurons

right now the RFs are setup to have peaks every 45 degrees with 45 degree sigma for exp fall-off
in magnitude of firing rate ...

could randomize directions between 0-360 degrees and potentially reduce number of direction selective neurons?
8 directions for RF is also somewhat limiting. movement can occur in other directions ...

or increase spread of RFs ...

also can change size of direction selective neuron populations ...

original values:
"net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":100,"EV1DNE":100,"EV1DN":100,"EV1DNW":100,"EV1DW":100,"EV1DSW":100,"EV1DS":100,"EV1DSE":100,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EML":1350,"EMR":1350,"IM":690,"AngRFSigma":45,"DirMinRate":0.0001,"DirMaxRate":30.0}

change to:
"net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":49,"EV1DNE":49,"EV1DN":49,"EV1DNW":49,"EV1DW":49,"EV1DSW":49,"EV1DS":49,"EV1DSE":49,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EML":1350,"EMR":1350,"IM":690,"AngRFSigma":90,"DirMinRate":0.0001,"DirMaxRate":30.0}

to cut the number of dir sensitive neurons in ~1/2 and have wider RFs...

sim name ... 20april23_A0

myrun 12

Done; run time = 432.66 s; real-time ratio: 0.00.

python -i actmap.py

data/20april23_A0_actmap.mp4

python -i simdat.py -1

data/20april23_A0_weightmap.mp4

right now there are 1350 EMR and 1350 EML neurons

reduced direction selection neurons from 10x10 to 7x7
and there are 8 pops, so 51*8=408 fewer neurons
then HA mentioned number of EMR is equal to number of all other E neurons projecting to them
so can reduce those as well ...

original EMR was 400 (EV1) + 100*8 (dir sensitive) + 100 (EV4) + 25 (EMT) = 1325
but there were 1350 ... 25 extra?

was supposed to be 1325

so new number for current architecture should be

400 + 49*8 + 100 + 25  = 917

try that one ... noticeable faster?

"net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":49,"EV1DNE":49,"EV1DN":49,"EV1DNW":49,"EV1DW":49,"EV1DSW":49,"EV1DS":49,"EV1DSE":49,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EML":917,"EMR":917,"IM":690,"AngRFSigma":90,"DirMinRate":0.0001,"DirMaxRate":30.0}

20april23_A1_

myrun 12

Done; run time = 291.53 s; real-time ratio: 0.00.

yeah, noticeably faster ...

savefig('gif/20apr23_rast_a1.png')

rates and cell activity looks ok

python -i actmap.py

data/20april23_A1_actmap.mp4

python -i simdat.py -1

data/20april23_A1_weightmap.mp4

** adjust one-to-one to random connectivity

will have to reduce convergence most likely ...

20april23_B0_

myrun 12

something making this run very slowly now ... not clear why ...

also, did not adjust number of IM neurons ... should be lower

x / (917*2+x) = 0.2
0.2*(917*2+x) = x
366.8 + .2x = x
.8x = 366.8
x = 366.8/.8 = 458.5

459/(917*2+459) # 0.20017444395987788

so should have 459 IM neurons ...

but doubt that's reason for slowdown ...

there were some bugs in connectivity from visual to motor areas and from premotor to motor areas
EV1DW connected to EML and EMR two times both for AMPA and NMDA

used loops to reduce those errors ... 

*20apr24
** debug connectivity/speed issues

myrun 12

  Done; run time = 257.86 s; real-time ratio: 0.00.
  Done; gather time = 455.45 s.

that's for 1 s of sim time ... seems a bit faster to run sim ... why is gather so slow?

getting hyperactivation/synchrony ... probably too much EE connectivity  

python -i actmap.py

data/20april24_A0_actmap.mp4

python -i simdat.py -1

got an error about wrong size in image ... 

** discuss net/motion selectivity with HA

also i think after neuron reduction in direction selective cells, motioncomputation is not capturing whole image
samn ok, i'll restore their number
but may keep EML, EMR numbers lower
Haroon Anwar yes, probably that way we can narrow down the issue…. can lower direction selective neuron nb later
samn sg
one other question i had was ...
Haroon Anwar sure
samn now we use 2 frames to compute direction
and we did that to have 1 action for each frame
could we use 5 frames for motion calculation but still have 1 action for 5 frames?
Haroon Anwar so in sim.json, we specify 1 frame….but in aigame.py, it uses last_obs to compute motion direction.
i dont think so
we could do so but back in time
so for time t, we could use t-4,t-3,t-2,t-1 and t
and use 1 action
samn so we could do 5 frames for motion, 1 action for 5 frames?
Haroon Anwar for 1 action for 1 frame
1 action for 5 frames will compromise the performance severly
samn ok, so we can keep as is.
think any problems with how you modified it to? if we have 100 neurons for each direction population
Haroon Anwar how i modified it to? — which part?
samn 1 action per 1 frame
and 2 frames for motion
Haroon Anwar no it should not effect
samn so it should be good
ok, and to follow up, 20 ms is time for 1 frame. if it's longer, will that help?
Haroon Anwar problem is with computing motion not activating neurons
samn so there is a problem of computing motion from 2 frames. and possibly optical flow algorithm will help
Haroon Anwar 20 ms for 1 frame should nicely scale, as we were using 100 ms for 5 frames. so it
means that firing rate has to be 50 Hz to have one spike per action
samn ok sg


** restore # dir selective neurons but reduce # motor neurons & debug/test

x / (400*2+x) = 0.2
0.2*(400*2+x) = x
160 + 0.2x = x
0.8x = 160
x=160/.8=200

"EML":400,"EMR":400,"IM":200

    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":100,"EV1DNE":100,"EV1DN":100,"EV1DNW":100,"EV1DW":100,"EV1DSW":100,"EV1DS":100,"EV1DSE":100,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EML":400,"EMR":400,"IM":200,"AngRFSigma":90,"DirMinRate":0.0001,"DirMaxRate":30.0}

20april24_B0_

myrun 12

Done; run time = 159.11 s; real-time ratio: 0.01.

most cells at decent rates, runs quicker than before ... but EMR,EML,IM cells fire too fast and with depolarization blockade 
20apr24_rast_a1.png
20apr24_IM_a1.png
20apr24_EML_a1.png

to remove that problem could reduce probability of inputs to EML,EMR neurons ...

python -i actmap.py

data/20april24_B0_actmap.mp4

python -i simdat.py -1

simdat.py:97: UserWarning: Attempting to set identical bottom == top == 0 results in singular transformations; automatically expanding.
  f_ax4.set_ylim((0,np.max([cumHits[-1],cumMissed[-1]])))
Traceback (most recent call last):
  File "simdat.py", line 415, in <module>
    animSynWeights(pdf,'data/'+dconf['sim']['name']+'weightmap.mp4', framerate=10) #plot/save images as movie
  File "simdat.py", line 127, in animSynWeights
    wtsL, wtsR = getwts(0, src)
  File "simdat.py", line 111, in getwts
    wtsL = np.reshape(wtsl,(int(np.sqrt(len(wtsl))),int(np.sqrt(len(wtsl))))) 
  File "<__array_function__ internals>", line 6, in reshape
  File "/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py", line 301, in reshape
    return _wrapfunc(a, 'reshape', newshape, order=order)
  File "/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py", line 61, in _wrapfunc
    return bound(*args, **kwds)
ValueError: cannot reshape array of size 15964 into shape (126,126)

hmm, keep getting those errors in animSynWeights in getwts

must happen since have probabilistic connectivity, no longer exact number of inputs specified ... ?

will fix ... also reduce weight to EML, EMR ... try that out ...

myrun 12

Run time: 156.21 s
Done; saving time = 121.36 s.

raster looks ok ...

20apr22_rast_b0.png
most cells look ok, though EML,EMR rates still a little high ...
20apr22_EMR_b0.png
20apr22_IM_b0.png
20apr22_EML_b0.png

python -i actmap.py

data/20april24_B0_actmap.mp4

directions look decent but mabe the RF angle sigma is too high ...

python -i simdat.py -1

simdat.py:97: UserWarning: Attempting to set identical bottom == top == 0 results in singular transformations; automatically expanding.
  f_ax4.set_ylim((0,np.max([cumHits[-1],cumMissed[-1]])))
Traceback (most recent call last):
  File "simdat.py", line 415, in <module>
    animSynWeights(pdf,'data/'+dconf['sim']['name']+'weightmap.mp4', framerate=10) #plot/save images as movie
  File "simdat.py", line 127, in animSynWeights
    wtsL, wtsR = getwts(0, src)
  File "simdat.py", line 111, in getwts
    wtsL = np.reshape(wtsl,(int(np.sqrt(len(wtsl))),int(np.sqrt(len(wtsl))))) 
  File "<__array_function__ internals>", line 6, in reshape
  File "/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py", line 301, in reshape
    return _wrapfunc(a, 'reshape', newshape, order=order)
  File "/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py", line 61, in _wrapfunc
    return bound(*args, **kwds)
ValueError: cannot reshape array of size 15964 into shape (126,126)

have to fix simdat.py ! ! !

*20apr27 - fixup simdat.py animation (AMPA & NMDA separate); continue tuning network
** fixup simdat.py

ok, adjusted - separating out AMPA, NMDA weights

  animSynWeights(pdf[pdf.syntype=='AMPA'],'data/'+dconf['sim']['name']+'_AMPA_weightmap.mp4', framerate=10) #plot/save images as movie
  animSynWeights(pdf[pdf.syntype=='NMDA'],'data/'+dconf['sim']['name']+'_NMDA_weightmap.mp4', framerate=10) #plot/save images as movie  

can combine AMPA and NMDA later if needed ...

though no reason to assume the two sets of weights should change at same time-scale

** continue adjusting network - reduce hyperexcit

well, EML, EMR rates were a bit high ... can adjust that ...

try cutting down E -> EML, EMR weights by 1/2

for strty,synmech,weight,plastty in zip(['','n'],['AMPA', 'NMDA'],[0.005*cfg.EEGain, 0.0005*cfg.EEGain],[STDPparamsRL1,STDPparamsRL2]):

myrun 12

Done; run time = 160.28 s; real-time ratio: 0.01.
Done; gather time = 280.91 s.
Total time = 604.62 s

rates a little better ...
20apr27_rast_a0.png

would rather have higher density and lower starting weights, so have possibility for right structure to develop

for now will continue from here ... will try longer sim ... 

python -i actmap.py

saved animation to data/20april27_A0_actmap.mp4

python -i simdat.py -1

saved animation to data/20april27_A0__AMPA_weightmap.mp4
saved animation to data/20april27_A0__NMDA_weightmap.mp4

weights to EMR increased more than EML ... and this is without fake rule

anyway, try longer sim now ...

myrun 12

*20apr28 - adjusting network
** optical flow in python

https://nanonets.com/blog/optical-flow/
https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_video/py_lucas_kanade/py_lucas_kanade.html

** sim crashes with memory problem

occurs even for 2.5 s sim during gatherdata

what if only recorded weights every 5 steps? with "recordWeightStepSize":5

myrun 12

  Done; run time = 191.75 s; real-time ratio: 0.01.
Gathering data...
  Done; gather time = 108.16 s.
    Cells: 2959
  Connections: 299852 (101.34 per cell)
  Synaptic contacts: 405671 (137.10 per cell)
  Spikes: 30546 (4.13 Hz)
  Simulated time: 2.5 s; 12 workers
  Run time: 191.75 s
Saving output as data/20april28_A0_simConfig.pkl ...

Total time = 383.88 s

ok, good, did not crash ...

20apr28_rast_a0.png

rates and membrane potential traces look ok but EMR,EML,IM rates somewhat high ... (~5-6 Hz for
EMR,EML and ~18 Hz for IM); could reduce weights to EMR,EML further ...

python -i actmap.py

data/20april28_A0_actmap.mp4

python -i simdat.py -1

data/20april28_A0__AMPA_weightmap.mp4
data/20april28_A0__NMDA_weightmap.mp4

try again with:
 larger recordStep and comment out the connection rules for weights that are 0 (feedback connections)
 do not need to plot raster twice and to save raster data in separate file
 do not need to plot voltage traces from every direction cells, one type should be enough to see if looks ok
 also reduce weight to EMR,EML
 
does this simConfig.recordTraces = {'V_soma':{'sec':'soma','loc':0.5,'var':'v'}}  # Dict with traces to record
cause recording of all cells' membrane potential? probably do not want that ...

based on this:
"recordCells - List of cells from which to record traces. Can include cell gids (e.g. 5 or [2,
3]), population labels (e.g. 'S' to record from one cell of the ‘S’ population), or 'all', to
record from all cells. NOTE: All cells selected in the include argument of
simConfig.analysis['plotTraces'] will be automatically included in recordCells. (default: [])

recordTraces - Dict of traces to record (default: {} ; example: {‘V_soma’:{‘sec’:’soma’,’loc’:0.5,’var’:’v’}})"

... it does NOT record ALL cells; just the ones in include:
simConfig.analysis['plotTraces'] = {'include': [(pop, 0) for pop in ['ER','IR','EV1','EV1DE','IV1','EV4','IV4','EMT','IMT','EML','EMR','IM']]}

myrun 12

  Done; gather time = 108.10 s.

hmm, did not save much time or space ... must be saving a lot of other stuff in the 680 MB 20april28_A0_simConfig.pkl
also rate of EMR,EML did not decrease ...

https://www.neuron.yale.edu/phpBB/viewtopic.php?f=45&t=3770&p=16227&hilit=memory#p16122

so try with those options, see if saves time/space ...

myrun 12

Gathering data...
  Gathering only sim data...
  Done; gather time = 70.73 s.

  saved some time ...

  but got error:
  File "sim.py", line 983, in <module>
    sim.saveData() # save data to disk
  File "/u/samn/netpyne/netpyne/sim/save.py", line 127, in saveData
    pickle.dump(dataSave, fileObj)
    TypeError: HocObject: Only Vector instance can be pickled
    
  and then simConfig.pkl output was empty ...

 so will run as it was before ... but still need to adjust the weights

ok, first try with higher ->EMR, ->EML weights
for strty,synmech,weight,plastty in zip(['','n'],['AMPA', 'NMDA'],[0.00375*cfg.EEGain, 0.000375*cfg.EEGain],[STDPparamsRL1,STDPparamsRL2]):
to make sure those synapses have an impact ...

when the weights were 0.005*cfg.EEGain and 0.0005*cfg.EEGain had similar rates ... which means other inputs driving most
of the activity ... 

also see recurrent connectivity ... should adjust for EMR->EMR and EML->EML to allow some plasticity ...

python -i simdat.py

simConfig, pdf, actreward, dstartidx, dendidx = loadsimdat()
simConfig.keys() # dict_keys(['netpyne_version', 'netpyne_changeset', 'net', 'simConfig', 'simData'])
simConfig['simData'].keys() # dict_keys(['spkt', 'spkid', 'V_soma', 't', 'synweights', 'avgRate'])
len(simConfig['simData']['spkt']) # 29862
len(simConfig['simData']['spkid']) # 29862

python -i actmap.py

also see if these options make output smaller:
cfg.saveCellSecs = False     # removes all data on cell sections prior to gathering from nodes
cfg.saveCellConns = False    # removes all data on cell connections prior to gathering from nodes

myrun 12

Gathering data...
Done; gather time = 72.30 s.

ok, that reduced main output file size to ~210 MB vs ~690 MB (for 2.5 s sim)
and a shorter gather time (without a crash)

python -i actmap.py

data/20april28_A0_actmap.mp4

python -i simdat.py -1

...

can put that into option in sim.json ... in case want connectivity info at some point

** test the targetted RL rule in fake up

added option to sim.json to specify whether to use targetted rule (only rewards actions to
motor neurons responsible for the action)

first without targetted RL:
10 s sim with name 20april28_T0_
myrun 12

20apr28_rast_T0.png
20apr28_rast_T0b.png

EMR,EML get too fast  ...
IM hits depolarization blockade: 20apr28_IM_T0.png
so does EMR, EML: 20apr28_EMR_T0.png, 20apr28_EML_T0.png

python -i actmap.py

data/20april28_T0_actmap.mp4

doesn't seem like direction selective neurons activating properly ... all activity
in each population seems to go together ...

python -i simdat.py -1

data/20april28_T0__AMPA_weightmap.mp4
data/20april28_T0__NMDA_weightmap.mp4 <<-- NMDA weights look much different compared to AMPA, perhaps NMDA weights
are not helping, as the populations are not differentiated. strange pattern for NMDA, spikes and decays...similar times with AMPA
what is the cause for those spikes? high rate of rewards??

UP is 4, DOWN is 3; EMR is for UP, EML is for DOWN; so in those movies, overall
the weights to EMR are larger

and next with targetted RL:
10 s sim with name 20april28_T1_
myrun 12

Done; run time = 2946.54 s; real-time ratio: 0.00.
Gathering data...
  Done; gather time = 1267.64 s.
Analyzing...
  Cells: 2959
  Connections: 0 (0.00 per cell)
  Spikes: 598894 (20.24 Hz)
  Simulated time: 10.0 s; 12 workers
  Run time: 2946.54 s
Saving output as data/20april28_T1_simConfig.pkl ... 
Finished saving!
  Done; saving time = 436.50 s.
SAVING RASTER DATA
plot raster:
Plotting recorded cell traces ... cell
QApplication: invalid style override passed, ignoring it.
Plotting raster...
  Done; plotting time = 828.98 s

Total time = 5536.42 s
End time:  2020-04-28 17:36:51.533489

takes a surprisingly long time to save and plot the data ... 

well, there's depolarization blockade:

20apr28_IM_T1.png
20apr28_EMR_T1.png
20apr28_EML_T1.png
20apr28_rast_T1.png <<-- very high rates for EML
IM,EMR are in depolarization blockade. weights to EMR probably increased too much.
better if there was some homeostasis built in

python -i actmap.py

data/20april28_T1_actmap.mp4   <<-- paddle goes up fairly quickly but then goes way down near end of sim and stays
there, probably due to depolarization blockade of EMR cells; EML might be firing quickly since does not receive and
inhibition from IM since IM in depolarization blockade. but then why does the racket stay near top of court for most
of the simulation, until the very end. is it drawn incorrectly??

python -i simdat.py -1

data/20april28_T1__AMPA_weightmap.mp4
data/20april28_T1__NMDA_weightmap.mp4

weights diverge towards EMR population quickly, weights to EML drop quickly, and then they stay that way
same pattern with AMPA and NMDA weights ...


confused by the variable names (ts_end is end time? ts_beg is beginning time? or opposite?)
            ts_end = t-tstepPerAction*(dconf['actionsPerPlay']-ts)
            ts_beg = t-tstepPerAction*(dconf['actionsPerPlay']-ts-1)
            F_Rs.append(getFiringRatesWithInterval([ts_end,ts_beg], sim.net.pops['EMR'].cellGids))

            and
def getFiringRatesWithInterval (trange = None, neuronal_pop = None):
has
if trange[0] <= spkts[i] <= trange[1] and spkids[i] in neuronal_pop:


tstepPerAction = 20
actionsPerPlay = 1
ts_beg = t - 20*(1-0-1) = t - 0
ts_end = t - 20*(1-0) = t - 20

ok, so ts_end is smaller, so it's correct, but the names are confusing ...

anyway, getting back to why actmap.py appears incorrect ... need to check that ...

the depolarization blockade issues suggest need for homeostasis built-in to the synapse ... should also try adding that ...

*20apr29 - debug actmap.py animations
** check actmap.py

make sure has input images / activity displayed at right times

python -i actmap.py

fig = animInput(New_InputImages, 'test.mp4')

hmm, maybe y-axis for input images should be reversed ...

fig, axs, plt = animActivityMaps('test2.mp4', framerate=10)

limg = New_InputImages = loadInputImages('data/'+dconf['sim']['name']+'InputImages.txt')

limg.shape # (500, 20, 20)
imshow(limg[0,:,:],origin='upper')
imshow(limg[7,:,:],origin='upper')

row 0 of input images is top

was using wrong timestep in actmap.py ... made a variable for it tstepPerAction, also used in sim.json
and sim.py

*20apr30 - opt flow/quiver
** optical flow

this is what haroon tried last time:
(/u/samn/SMARTAgent/hanotes.org:1432)

see how to use it to produce direction vectors at each pixel ...

python

from pylab import *
import numpy as np
import gym
import cv2 # opencv
from skimage.color import rgb2gray
from skimage.registration import optical_flow_tvl1

env = gym.make('Pong-v0')
env.reset()
observation, reward, done, info = env.step(3)

for _ in range(30): #running 30 times, so that ball appears in the court.
  observation, reward, done, info = env.step(3)
  observation, reward, done, info = env.step(4)
  observation, reward, done, info = env.step(4)
  observation, reward, done, info = env.step(4)
  observation, reward, done, info = env.step(4)
  
o1, reward, done, info = env.step(4)
o2, reward, done, info = env.step(4)
o3, reward, done, info = env.step(4)
o4, reward, done, info = env.step(4)
o5, reward, done, info = env.step(4)

imshow(o1); savefig('gif/20apr30_a0.png')
imshow(o2); savefig('gif/20apr30_a1.png')
imshow(o3); savefig('gif/20apr30_a2.png')
imshow(o4); savefig('gif/20apr30_a3.png')
imshow(o5); savefig('gif/20apr30_a4.png')

g1 = rgb2gray(o1)
g2 = rgb2gray(o2)
g3 = rgb2gray(o3)

subplot(1,2,1); imshow(g1,cmap='gray'); subplot(1,2,2); imshow(g3,cmap='gray')
savefig('gif/20apr30_a5.png')

#
winsz = 10 # win size. flow is computed over the window....larger value is more robust to the noise.
imgscale = 1.0 # image pyramid or simple image scale
nlayer = 1 # nb of pyramidal layer. if used 1 means flow is calculated only from previous image.
niter = 3 # num iterations
polydeg = 5 # polynominal degree expansion. (recommended 5-7)
smooth = 1.2 # standard deviation used to smooth used derivatives. (recommended 1.1-1.5)
flow = cv2.calcOpticalFlowFarneback(g1,g3, None, imgscale, nlayer, winsz, niter, polydeg, smooth, 0)
flow = cv2.calcOpticalFlowFarneback(g1,g3, None, 0.5, 3, 15, 3, 5, 1.2, 0)
flow = cv2.calcOpticalFlowFarneback(g1,g3, None, 1.0, 3, 15, 3, 5, 1.2, 0)
mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])
goodInds = np.where(mag<1e-10,0,1)

#
clf()
subplot(2,2,1); imshow(g1,cmap='gray'); title('Frame1'); subplot(2,2,2); imshow(g3,cmap='gray'); title('Frame2');
subplot(2,2,3); imshow(np.multiply(mag,goodInds),cmap='gray'); title('Mag'); colorbar()
subplot(2,2,4); imshow(np.degrees(np.multiply(ang,goodInds)),cmap='gray'); title('Dir'); colorbar()

savefig('gif/20apr30_a6.png')

try quiver for directions:
https://matplotlib.org/3.1.0/api/_as_gen/matplotlib.pyplot.quiver.html
https://matplotlib.org/3.1.0/gallery/images_contours_and_fields/quiver_simple_demo.html#sphx-glr-gallery-images-contours-and-fields-quiver-simple-demo-py

figure(); quiver(flow[:,:,0],flow[:,:,1])

savefig('gif/20apr30_a7.png')

looks upside down ...

flow.shape # (210, 160, 2)

g1.shape # (210, 160)
top is row 0

what is value at x=17, y=120
flow[120][17][0],flow[120][17][1] # (1.1408521e-09, -1.1311174e-06)

figure(); plot(flow[120,:,1])
savefig('gif/20apr30_a8.png')
so that's negative, movement towards smaller y-values, which in original frame is up

so draw quiver with negated flow in y direction to make easier to visualize ...

#
clf()
subplot(2,3,1); imshow(g1,cmap='gray'); title('Frame1'); subplot(2,3,2); imshow(g3,cmap='gray'); title('Frame2');
subplot(2,3,4); imshow(np.multiply(mag,goodInds),cmap='gray'); title('Mag'); colorbar()
subplot(2,3,5); imshow(np.degrees(np.multiply(ang,goodInds)),cmap='gray'); title('Dir'); colorbar()

X, Y = np.meshgrid(np.arange(0, 160, 1), np.arange(0, 210, 1))
subplot(2,3,6); quiver(X, Y, flow[:,:,0],-flow[:,:,1], units='width')

savefig('gif/20apr30_a9.png')

looks ok ... zoom-in shows mostly pointing in right direction ... could make movie to show
and then use that for dir selective neurons; doesn't have to be completely accurate ... 

#imshow(np.degrees(np.multiply(ang,goodInds)),cmap='gray'); title('Dir'); colorbar()
#
#X,Y = np.meshgrid(flow.shape[1], -flow.shape[0])

*20may1 - tested optical flow / integrated with sim/model
** continue optical flow

restart to make sure params correct ...

python

from pylab import *
import numpy as np
import gym
import cv2 # opencv
from skimage.color import rgb2gray
from skimage.registration import optical_flow_tvl1

env = gym.make('Pong-v0')
env.reset()
observation, reward, done, info = env.step(3)

for _ in range(30): #running 30 times, so that ball appears in the court.
  observation, reward, done, info = env.step(3)
  observation, reward, done, info = env.step(4)
  observation, reward, done, info = env.step(4)
  observation, reward, done, info = env.step(4)
  observation, reward, done, info = env.step(4)
  
o1, reward, done, info = env.step(4)
o2, reward, done, info = env.step(4)
o3, reward, done, info = env.step(4)
o4, reward, done, info = env.step(4)
o5, reward, done, info = env.step(4)

g1 = rgb2gray(o1)
g2 = rgb2gray(o2)
g3 = rgb2gray(o3)

help(calcOpticalFlowFarneback)

 calcOpticalFlowFarneback(prev, next, flow, pyr_scale, levels, winsize, iterations, poly_n, poly_sigma, flags) -> flow
    .   @brief Computes a dense optical flow using the Gunnar Farneback's algorithm.
    .   @param prev first 8-bit single-channel input image.
    .   @param next second input image of the same size and the same type as prev.
    .   @param flow computed flow image that has the same size as prev and type CV_32FC2.
    .   @param pyr_scale parameter, specifying the image scale (\<1) to build pyramids for each image;
    .   pyr_scale=0.5 means a classical pyramid, where each next layer is twice smaller than the previous
    .   one.
    .   @param levels number of pyramid layers including the initial image; levels=1 means that no extra
    .   layers are created and only the original images are used.
    .   @param winsize averaging window size; larger values increase the algorithm robustness to image
    .   noise and give more chances for fast motion detection, but yield more blurred motion field.
    .   @param iterations number of iterations the algorithm does at each pyramid level.
    .   @param poly_n size of the pixel neighborhood used to find polynomial expansion in each pixel;
    .   larger values mean that the image will be approximated with smoother surfaces, yielding more
    .   robust algorithm and more blurred motion field, typically poly_n =5 or 7.
    .   @param poly_sigma standard deviation of the Gaussian that is used to smooth derivatives used as a
    .   basis for the polynomial expansion; for poly_n=5, you can set poly_sigma=1.1, for poly_n=7, a
    .   good value would be poly_sigma=1.5.
    .   @param flags operation flags that can be a combination of the following:
    .    -   **OPTFLOW_USE_INITIAL_FLOW** uses the input flow as an initial flow approximation.
    .    -   **OPTFLOW_FARNEBACK_GAUSSIAN** uses the Gaussian \f$\texttt{winsize}\times\texttt{winsize}\f$
    .        filter instead of a box filter of the same size for optical flow estimation; usually, this
    .        option gives z more accurate flow than with a box filter, at the cost of lower speed;
    .        normally, winsize for a Gaussian window should be set to a larger value to achieve the same
    .        level of robustness.

#
winsz = 10 # win size. flow is computed over the window....larger value is more robust to the noise.
pyrscale = 0.5 # image pyramid or simple image scale
nlayer = 3 # nb of pyramidal layer. if used 1 means flow is calculated only from previous image.
niter = 3 # num iterations
polyn = 7 # polynominal degree expansion. (recommended 5-7)
polysigma = 1.5 # standard deviation used to smooth used derivatives. (recommended 1.1-1.5)
flow = cv2.calcOpticalFlowFarneback(g1,g3, None, pyrscale, nlayer, winsz, niter, polyn, polysigma, 0)
mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])
goodInds = np.where(mag<1e-10,0,1)
clf()
subplot(2,3,1); imshow(g1,cmap='gray'); title('Frame1'); subplot(2,3,2); imshow(g3,cmap='gray'); title('Frame2');
subplot(2,3,4); imshow(np.multiply(mag,goodInds),cmap='gray'); title('Mag'); colorbar()
subplot(2,3,5); imshow(np.degrees(np.multiply(ang,goodInds)),cmap='gray'); title('Dir'); colorbar()
X, Y = np.meshgrid(np.arange(0, 160, 1), np.arange(210, 0, -1))
ax=subplot(2,3,6); quiver(X, Y, flow[:,:,0],-flow[:,:,1], units='width', color='r')
ax.set_xlim((0,160)); ax.set_ylim((0,210))
ax.invert_yaxis()

savefig('gif/20may1_a0.png')

looks decent ...

ok...will try that in a movie to make sure looks ok

may not want to use the thresholding?

#
winsz = 10 # win size. flow is computed over the window....larger value is more robust to the noise.
pyrscale = 0.5 # image pyramid or simple image scale
nlayer = 3 # nb of pyramidal layer. if used 1 means flow is calculated only from previous image.
niter = 3 # num iterations
polyn = 7 # polynominal degree expansion. (recommended 5-7)
polysigma = 1.5 # standard deviation used to smooth used derivatives. (recommended 1.1-1.5)
flow = cv2.calcOpticalFlowFarneback(g1,g3, None, pyrscale, nlayer, winsz, niter, polyn, polysigma, 0)
mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])
clf()
subplot(2,3,1); imshow(g1,cmap='gray'); title('Frame1'); subplot(2,3,2); imshow(g3,cmap='gray'); title('Frame2');
subplot(2,3,4); imshow(mag,cmap='gray'); title('Mag'); colorbar()
subplot(2,3,5); imshow(np.degrees(ang),cmap='gray'); title('Dir'); colorbar()
X, Y = np.meshgrid(np.arange(0, 160, 1), np.arange(210, 0, -1))
ax=subplot(2,3,6); qdat=quiver(X, Y, flow[:,:,0],-flow[:,:,1], units='width', color='k')
ax.set_xlim((0,160)); ax.set_ylim((0,210))
ax.invert_yaxis()

savefig('gif/20may1_a1.png')

can use quiver.set_UVC from within an animation set_UVC(U, V, C=None) method of matplotlib.quiver.Quiver instance
to update its data ...

qdat.set_UVC([],[])

or follow example here ...

https://stackoverflow.com/questions/19329039/plotting-animated-quivers-in-python

fig = animInput(New_InputImages, 'test.mp4', showflow=True)

looks pretty good ...

added imgutils.py as wrapper that calculates optical flow for 2 images and for a set of frames
can put other image processing utilities there

should put the direction fields into actmap animation too ...

will make it easier to assess whether the direction selective populations are firing properly ...
after that should plugin the optical flow into aigame.py

hmm, should actually save the direction fields calculated during the simulation
so make sure calculated same way as displayed ...

** integrating optical flow with game,sim

cleaning up some of the code since have to adjust it to use different type of motion calculation ...
having AIGame save its own InputImages (ReducedImages) and Images (FullImages)
to avoid passing that info back and forth between AIGame and sim ...

based on discussion with HA could use 20x20 or even 160x160 input images to calculate motion
directions, then downsample to 10x10 direction field that is projected to the direction
selective neurons ...

*20may4
** check opt flow integration, make sure working properly

when ran it last time, there was incorrect activity in different populations

actually, had started saving the motion fields computed so need to finish that
for display in the movies ...

run a short 2 s sim for testing ... named 20may4_A0_

myrun 12

  Cells: 2959
  Connections: 0 (0.00 per cell)
  Spikes: 79757 (13.48 Hz)
  Simulated time: 2.0 s; 12 workers
  Run time: 412.59 s
Saving output as data/20may4_A0_simConfig.pkl ... 
Finished saving!
  Done; saving time = 95.63 s.
SAVING RASTER DATA
plot raster:
Plotting recorded cell traces ... cell
QApplication: invalid style override passed, ignoring it.
Plotting raster...
  Done; plotting time = 117.68 s

Total time = 925.17 s

End time:  2020-05-04 12:45:31.363310

lot of cells go into block ...
20may4_a0_rast.png
20may4_a0_IM.png
20may4_a0_EML.png
20may4_a0_EV1DE.png

probably since direction selective cells not setup properly with the new optical flow ...

motion fields saved ... 20may4_A0_MotionFields.pkl

now check the output

python -i actmap.py

len(ldflow) # 99
99*20 # 1980 - that's amount of time covered, since first frame has no optical flow
and used 20 ms interval

first adjust animInput

fig=animInput(InputImages,'testflow.mp4',ldflow=ldflow)

something wrong with the output movie ...

same problem if calc the optflow here?

from imgutils import getoptflowframes
ldflow2 = getoptflowframes(InputImages)
fig=animInput(InputImages,'testflow.mp4',ldflow=ldflow2)

hmm, same error opening in vlc ...

opens fine in parole media player

fig=animInput(InputImages,'testflow.mp4',ldflow=ldflow)

in general it's working but probably need higher spatial resolution ...

fig, axs, plt = animActivityMaps('testact2.mp4', framerate=10)

looks interesting but hard to see what's going on in motion fields there because so small ... should reduce size/width of arrows

hmm, may need bigger figure size ... 

fig, axs, plt = animActivityMaps('testact3.mp4', framerate=10,figsize=(9,5))

well, optical flow generally follows motion with wide spread, but the direction selective populations not following
the motion directions properly ... 

also add motor pops to activity map ...

fig, axs, plt = animActivityMaps('testact4.mp4', framerate=10,figsize=(9,5))

looks interesting ... need IM too ... and the rewards, and the weights, etc.
first fixup direction selectivity ...

does activity look more clear without vmax restriction?
fig, axs, plt = animActivityMaps('testact5.mp4', framerate=10,figsize=(9,5))
looks even worse ... 

how about reducing AngRFSigma from 45 to 22.5 ... ??
since there's 45 degrees between primary directions but only 22.5 half-way in either direction ...

20may4_A1_

AngRFSigma:22.5

myrun 12

  Cells: 2959
  Connections: 0 (0.00 per cell)
  Spikes: 43011 (7.27 Hz)
  Simulated time: 2.0 s; 12 workers
  Run time: 445.23 s
Saving output as data/20may4_A1_simConfig.pkl ... 
Finished saving!
  Done; saving time = 87.67 s.
SAVING RASTER DATA
plot raster:
Plotting recorded cell traces ... cell
QApplication: invalid style override passed, ignoring it.
Plotting raster...
  Done; plotting time = 64.77 s

Total time = 894.50 s

End time:  2020-05-04 22:54:32.382426

20may4_a1_IM.png
20may4_a1_EMR.png
20may4_a1_EV1DE.png
20may4_a1_rast.png

still hyperactive, but not as much as last run ...
E, NE only directions that seem to be activated
and then too strongly activating EML, EMR?

python -i actmap.py

fig, axs, plt = animActivityMaps('data/20may4_A1_actmap.mp4', framerate=10,figsize=(9,5))

data/20may4_A1_actmap.mp4

a little better ... for some reason only E, NE cells getting activated ... and not even at right times ...
so have to debug the projections from optical flow -> direction selective populations


*20may5
** fixing optical flow input

looks like motiondir units are in radians ...

myrun 12

sim.AIGame.ldflow[0].keys() # dict_keys(['flow', 'mag', 'ang', 'goodInds'])
np.amin(sim.AIGame.ldflow[0]['ang']),np.amax(sim.AIGame.ldflow[0]['ang']) # (5.553319e-13, 6.2265844)

so use this in imgutils.py:
  return {'flow':flow,'mag':mag,'ang':np.rad2deg(ang),'goodInds':goodInds}

ok, now rerun 2 s sim ... 
  
myrun 12

  Cells: 2959
  Connections: 0 (0.00 per cell)
  Spikes: 55939 (9.45 Hz)
  Simulated time: 2.0 s; 12 workers
  Run time: 178.73 s
Saving output as data/20may5_A0_simConfig.pkl ... 
Finished saving!
  Done; saving time = 25.08 s.
SAVING RASTER DATA
plot raster:
Plotting recorded cell traces ... cell
QApplication: invalid style override passed, ignoring it.
Plotting raster...
  Done; plotting time = 23.70 s

Total time = 315.73 s

End time:  2020-05-05 10:03:32.129322


20may5_a0_EV1DE.png
20may5_a0_IM.png
20may5_a0_EMR.png
20may5_a0_rast.png

overall better since there appears to be some direction selectivity, though the rate of direciton selective cells
remains too high ... leading to depolarization blockade of EMR,EML,IM cells ...
can reduce rate of direction selective neurons by reducing DirMaxRate from 30 down to x ...

python -i actmap.py

fig, axs, plt = animActivityMaps('data/20may5_A0_actmap.mp4', framerate=10,figsize=(9,5))

triy lower DirMaxRate ... 1 Hz ...

20may5_A1_

myrun 12

still hard to see what's going on but the rates are better ...

also do not see much activity in ER that corresponds with the input images ... ER is very subdued

fig, axs, plt = animActivityMaps('data/20may5_A1_actmap.mp4', framerate=10,figsize=(9,5))

firing rates for most populations are decent ... but don't see much direction selectivity that would expect/want to see ...
seems somewhat random ... 

20may5_a1_EV1DE.png
20may5_a1_EMR.png
20may5_a1_IM.png
20may5_a1_rast.png

fig=animInput(InputImages,'testflow.mp4',ldflow=ldflow)

should find better params to increase resolution for the optical flow ...

ldflow2 = getoptflowframes(InputImages,winsz=3, pyrscale=0.5, nlayer=3, niter=3, polyn=5, polysigma=1.1)
fig=animInput(InputImages,'testflow.mp4',ldflow=ldflow2)

ok, those param values a bit better in getting higher resolution optical flow, but then somewhat more noisy ...

will try that in sim ...

20may5_A2_

myrun 12

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may5_A2_actmap.mp4', framerate=10,figsize=(9,5))

hmm, most of the activity appears to be due to the recurrent connectivity ... getting rid of that
and the direction selective neurons do not fire any more ... and do not seem to receive any inputs (EPSPs) ...
must be a bug somewhere ...

does it have to do with 20x20 for direction image and 10x10 for each population of E dir selective neurons??

check in actmap.py animInput ...

from skimage.transform import downscale_local_mean, resize

ldflow = loadMotionFields(dconf['sim']['name'])
for dflow in ldflow:
  u = resize(dflow['flow'][:,:,0], (10,10), anti_aliasing=True)
  v = resize(dflow['flow'][:,:,1], (10,10), anti_aliasing=True)
  dflow['flow'] = np.array([u,v]).T

fig=animInput(InputImages,'testflow2.mp4',ldflow=ldflow)

yeah, looks like the resize operation is messing things up ... which means may
need to use more neurons for direction selective ... or distribute their RFs
over all angles and assign each a coordinate in 2D grid ... hmm, already have
that, so maybe need to restore 3200 neurons ... 

*20may6
** restore each dir selective neuron as 20x20 - motion fields better?

doesnt run too slowly ...

myrun 12

has 5359 neurons ... 

fig, axs, plt = animActivityMaps('gif/20may6_A0_actmap.mp4', framerate=10,figsize=(9,5))

looks better but still very noisy ...

needs more debugging ...

would longer time windows help??

can try 50 ms tstepPerAction instead of 20 ...

200 ms needed for 5 Hz max rate ...

probably easier to see if motion field info sent/detected properly by combining activity of
all the motion selective neurons together to produce estimated direction map

maxdirX,maxdirY = getmaxdir(dact,ddir)

fig=animDetectedMotionMaps('testdetectm.mp4', framerate=10, figsize=(7,3))

estimates based on max firing of direction selective neurons looks way off

for some reason E (EV1DE) neurons are almost always firing ...

something about 0 degrees for E ... when change it to have peak at 2 degrees much less firing ...

*20may7 - more on optical flow; some fixes
** discuss optical flow with ha

conclusion: will see if can tweak params to get example motion below to produce correct results
with existing params, detected motion didn't look great

** ha example code to test optical flow on single frame motion, fix, start testing network

python
from netpyne import specs, sim
from neuron import h
import numpy as np
import random
from conf import dconf # configuration dictionary
import pandas as pd
import pickle
from collections import OrderedDict
from connUtils import *
from matplotlib import pyplot as plt
import os
import anim
from matplotlib import animation
from aigame import AIGame
sim.AIGame = AIGame()
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[3], epCount = 0)
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[3], epCount = 0)
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[3], epCount = 0)
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[3], epCount = 0)
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[3], epCount = 0)
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[4], epCount = 0)
sim.AIGame.dFiringRates # to see the firing rates of 8 different populations
sim.AIGame.ldflow[-1]['ang'] # to see the angle computed for object motion

from pylab import *
ion()

#
fig = figure(figsize=(8,4))
cbaxes = fig.add_axes([0.92, 0.3, 0.01, 0.5])
subplot(1,3,1); imshow(sim.AIGame.FullImages[-2]); title('Frame1')
subplot(1,3,2); imshow(sim.AIGame.FullImages[-1]); title('Frame2')
subplot(1,3,3); imshow(sim.AIGame.ldflow[-1]['ang'],vmin=0, vmax=359, cmap='Dark2'); title('Angle')
c1 = colorbar(fa,cax = cbaxes)
c1.set_ticks([22,67,112,157,202,247,292,337])
c1.set_ticklabels(['E','NE','N','NW','W','SW','S','SE'])

savefig('gif/20may7_test_ha_0.png')

ha suggests thresholding by magnitude

E directions might dominate if angle 0 is default

opposite sign in y direction?


from imgutils import getoptflow

#
dflow = getoptflow(sim.AIGame.ReducedImages[-2], sim.AIGame.ReducedImages[-1],winsz=3,nlayer=3,niter=3,polyn=5,polysigma=1.1)
thflow = np.zeros(dflow['ang'].shape)
th = mean(dflow['mag']) + std(dflow['mag'])
for y in range(thflow.shape[0]):
  for x in range(thflow.shape[1]):
    if dflow['mag'][y,x] < th:
      thflow[y,x] = -100
    else:
      thflow[y,x] = dflow['ang'][y,x]

fig = figure(figsize=(8,4))

#
clf()
cbaxes = fig.add_axes([0.92, 0.3, 0.01, 0.5])
subplot(1,3,1); imshow(sim.AIGame.ReducedImages[-2]); title('Frame1')
subplot(1,3,2); imshow(sim.AIGame.ReducedImages[-1]); title('Frame2')
subplot(1,3,3); imshow(thflow,vmin=-100, vmax=359, cmap='Dark2'); title('Angle')
c1 = colorbar(fa,cax = cbaxes)
c1.set_ticks([22,67,112,157,202,247,292,337])
c1.set_ticklabels(['NONE','E','NE','N','NW','W','SW','S','SE'])

savefig('gif/20may7_test_2.png')

not terrible ...

python -i actmap.py
fig=animInput(InputImages,'testflow2.mp4',ldflow=None)

looks better than before ...

try in sim after checking for valid angles there ...

myrun 12

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may7_A0_actmap.mp4', framerate=10,figsize=(9,5))

saved animation to gif/20may7_A0_actmap.mp4

looks much better ...

20may7_a0_rast.png
most rates ok but EMR,EML fire too much and are too synchronized
possibly due to high drive from EV1DN, EV1DS which fire a lot more than the other direction selective cells (since
most motion is up and down due to paddles moving in those directions)
20may7_a0_IM.png
20may7_a0_EML.png

next will test with some angular RF spread ... also need to make sure EMR,EML fire less frequently/synchronously ...

set AngRFSigma to 22.5 and run again

name = 20may7_A1_

myrun 12

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may7_A1_actmap.mp4', framerate=10,figsize=(9,5))

saved animation to gif/20may7_A1_actmap.mp4

animation looks ok ... rates all right?

all rates decent but EML,EMR,IM rates too high ...
20may7_a1_rast.png
20may7_a1_EML.png
20may7_a1_EMR.png
20may7_a1_IM.png

so, next try decreasing the E projection weights to the EMR,EML neurons ...

20may7_A2_

set down from 0.00375, 0.000375 to 0.002, 0.0002 in this loop in sim.py to:
    for strty,synmech,weight,plastty in zip(['','n'],['AMPA', 'NMDA'],[0.0001*cfg.EEGain, 0.00001*cfg.EEGain],[STDPparamsRL1,STDPparamsRL2]):

EMR,EML still firing too much , though slightly lower ... 
    
** other discussion with ha points towards potential benefits of explicit object detection/tracking

e.g. threshold image, extract bbox, then use that to see motion

opencv supports this with efficient algorithms, though also have some code for it in OEvent

problem with this approach is some loss of generality
and may not even need image pixels as inputs if use explicit object locations as
neuronal representations

** put some object detection, bbox, image code into imgutils.py

can possibly use them for object detection/tracking, though opencv code probably more efficient

*20may8 - continue optical flow, testing
** reduce EMR,EML,IM rates

adding these params to control from json file:
"EEMWghtAM":0.0001,"EEMWghtNM":0.0001

will continue reducing until get better rates ...

20may8_A0_

make sure no firing of EMR,EML when those values are at 0...

strange, EMR,EML still firing ... :
 20may8_test_rast_a0.png

dconf['net']['EEMWghtAM'], dconf['net']['EEMWghtNM'] # (0.0, 0.0)

so what's driving them so strongly ...

maybe it's because of the wbase param of RL STDP mechanism?

#For AMPA-faster synapses
STDPparamsRL1 = {'hebbwt': 0.0000, 'antiwt':-0.0000, 'wbase': 0.0005, 'wmax': 1, 'RLon': 1 , 'RLhebbwt': 0.001 , 'RLantiwt': -0.000,
                'tauhebb': 10, 'RLlenhebb': 50 ,'RLlenanti': 50, 'RLwindhebb': 50, 'useRLexp': 1, 'softthresh': 0, 'verbose':0}
#for NMDA (slower) synapses
STDPparamsRL2 = {'hebbwt': 0.0000, 'antiwt':-0.0000, 'wbase': 0.0005, 'wmax': 1, 'RLon': 1 , 'RLhebbwt': 0.001 , 'RLantiwt': -0.000,
                'tauhebb': 10, 'RLlenhebb': 800 ,'RLlenanti': 100, 'RLwindhebb': 50, 'useRLexp': 0, 'softthresh': 0, 'verbose':0}

wbase sets a lower limit for the weights ... try setting wbase to 0 to see if reduces the EMR,EML activity ...

myrun 12                               

20may8_test_rast_a1.png

yeah, that's reason why EMR,EML were firing so fast ... so, will have to set wbase to starting value
for those params, or even lower ...

adding these:
"RL":{"AMPA":{"WBase":0.0,"WMax":1.0,"ON":1,"lenhebb":50,"lenanti":50,"exp":1},"NMDA":{"WBase":0.0,"WMax":1.0,"ON":1,"lenhebb":800,"lenanti":100,"exp":0}}
to sim.json
can add other RL params, as needed

wbase was 0.0005 before and even that had high rates, so set the start weight much lower ...

myrun 12

  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 13277 (2.48 Hz)
  Simulated time: 1.0 s; 12 workers
  Run time: 131.85 s
Saving output as data/20may8_A0_simConfig.pkl ... 
Finished saving!
  Done; saving time = 35.32 s.
SAVING RASTER DATA
plot raster:
Plotting recorded cell traces ... cell
QApplication: invalid style override passed, ignoring it.
Plotting raster...
  Done; plotting time = 7.62 s

Total time = 298.91 s

these params seem ok:

    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EML":400,"EMR":400,"IM":200,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.0001,"EEMWghtNM":0.00001},
    "RL":{"AMPA":
	  {"WBase":0.0001,"WMax":1.0,"ON":1,"lenhebb":50,"lenanti":50,"exp":1},
	  "NMDA":
	  {"WBase":0.00001,"WMax":1.0,"ON":1,"lenhebb":800,"lenanti":100,"exp":1}
    }

there are a few initial M pop spikes but then desynchronizes ... 20may8_test_rast_a2.png
20may8_test_EMR_a3.png
20may8_test_IM_a4.png


should have WMax much lower ... maybe at 0.00075, 0.000075

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may8_actmap_a5.mp4', framerate=10,figsize=(9,5))

looks ok ...

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may8_AMPA_weightmap_a6.mp4', framerate=10) #plot/save images as movie
animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may8_NMDA_weightmap_a7.mp4', framerate=10) #plot/save images as movie

try longer run to see if activity remains reasonable ...

tried run for 10 s ... but crashed in gatherdata ... 

  Done; run time = 1413.07 s; real-time ratio: 0.01.

Gathering data...
[samndp7730:08851] *** Process received signal ***
[samndp7730:08851] Signal: Segmentation fault (11)
[samndp7730:08851] Associated errno: Unknown error 32686 (32686)
[samndp7730:08851] Signal code:  (334043992)
[samndp7730:08851] Failing at address: 0x7fff13e91b54
[samndp7730:08851] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x354b0)[0x7fae6d8cd4b0]
[samndp7730:08851] [ 1] /lib/x86_64-linux-gnu/libc.so.6(+0x14e156)[0x7fae6d9e6156]
[samndp7730:08851] [ 2] /usr/lib/libopen-pal.so.13(opal_convertor_unpack+0xa8)[0x7fae6c4596b8]
[samndp7730:08851] [ 3] /usr/lib/openmpi/lib/openmpi/mca_pml_ob1.so(mca_pml_ob1_recv_request_progress_rndv+0x181)[0x7fae5fcdc2b1]
[samndp7730:08851] [ 4] /usr/lib/openmpi/lib/openmpi/mca_pml_ob1.so(mca_pml_ob1_recv_frag_callback_rndv+0x271)[0x7fae5fcd7cd1]
[samndp7730:08851] [ 5] /usr/lib/openmpi/lib/openmpi/mca_btl_vader.so(mca_btl_vader_poll_handle_frag+0x93)[0x7fae60523813]
[samndp7730:08851] [ 6] /usr/lib/openmpi/lib/openmpi/mca_btl_vader.so(+0x3cc3)[0x7fae60523cc3]
[samndp7730:08851] [ 7] /usr/lib/libopen-pal.so.13(opal_progress+0x4a)[0x7fae6c44d1ea]
[samndp7730:08851] [ 8] /usr/lib/libmpi.so.12(ompi_request_default_wait_all+0x315)[0x7fae6d0f4f65]
[samndp7730:08851] [ 9] /usr/lib/openmpi/lib/openmpi/mca_coll_tuned.so(ompi_coll_tuned_sendrecv_nonzero_actual+0x11a)[0x7fae5f24faca]
[samndp7730:08851] [10] /usr/lib/openmpi/lib/openmpi/mca_coll_tuned.so(ompi_coll_tuned_alltoallv_intra_pairwise+0x150)[0x7fae5f256780]
[samndp7730:08851] [11] /usr/lib/libmpi.so.12(PMPI_Alltoallv+0x1fc)[0x7fae6d105c9c]
[samndp7730:08851] [12] /usr/site/../arch/nrn/x86_64/lib/libnrnmpi.so.0(nrnmpi_char_alltoallv+0x25)[0x7fae6f7b7d35]

if network activity looks decent could run longer sims on zn ...

same problem/crash on zn?

yeah, crashes on zn in gatherdata, zn with 12 cores takes ~900s to run instead of 1413 on laptop ...

try with fewer traces recorded from ... and longer recording interval (recordStep=0.6)
only record voltage from 1 cell of these pops: ['ER','IR','EV1','EV1DE','IV1','EML','IM']

this may be where the extra data causing gather crash is coming from:
 sim.simData['synweights'][sim.rank].append([t,conn.plast.params.RLon,conn.preGid,cell.gid,float(conn['hObj'].weight[0]),conn.synMech])

probably do not need the RLon flag ...
could also use preGid, gid, synmech as index so don't have to save them each time ...
or could save to separate files for each rank and then join them together in simdat.py ...

still crashes at GatherData:
  Done; run time = 1321.29 s; real-time ratio: 0.01.

Gathering data...
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
[samndp7730:15458] *** Process received signal ***
[samndp7730:15458] Signal: Aborted (6)
[samndp7730:15458] Signal code:  (-6)
[samndp7730:15458] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x11390)[0x7fe32f7dd390]
[samndp7730:15458] [ 1] /lib/x86_64-linux-gnu/libc.so.6(gsignal+0x38)[0x7fe32f437428]

if shut off the record weights same problem?

myrun 12

Game rewards: [-0.001]
  Done; run time = 1297.58 s; real-time ratio: 0.01.

Gathering data...
  Done; gather time = 1.49 s.

Analyzing...
>>> >>> >>> >>> >>> >>> >>> >>> >>> >>> 

  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 105073 (1.96 Hz)
  Simulated time: 10.0 s; 12 workers
  Run time: 1297.58 s
>>> 
Saving output as data/20may8_A0_simConfig.pkl ... 
Finished saving!
  Done; saving time = 1.09 s.
SAVING RASTER DATA
plot raster:
Plotting recorded cell traces ... cell
QApplication: invalid style override passed, ignoring it.
Plotting raster...
  Done; plotting time = 38.63 s

Total time = 1360.35 s

ok, this time it did not crash in gatherdata ... 

may not want to gather all cell tags each time input rates updated, assuming the tags
do not change during simulation, seems ok... and there's a clear,del in there
which might cause a memory problem later on in gatherdata, which has same deletes??
https://github.com/Neurosim-lab/netpyne/blob/development/netpyne/sim/gather.py
py_alltoall

can also rewrite code to have each node save its own synaptic weight data and then at end
merge the data into a single file ...

*20may11 - continue fixes - gatherdata issue, workaround
** debugging gatherdata issue, way to avoid it -->> save syn weights on each node, then combine

still crashes without all the extra calls to sim._gatherAllCellTags
main issue is that the plasticity data is getting saved ...

other option sal suggested:
sim.runSimWithIntervalFunc(cfg.saveInterval, sim.saveSimDataInNode)
use that instead of sim.runSim()
if already running a different interval func, would need to call sim.saveSimDataInNode()

got this error:
AttributeError: module 'netpyne.sim' has no attribute 'saveSimDataInNode'

must not have latest version of netpyne ...

netpyne.__version__ # '0.9.5'

looks like that interval saving functionality was added in version 0.9.6:
https://github.com/Neurosim-lab/netpyne/releases

pip install netpyne --upgrade

python
import netpyne
netpyne.__version__ '0.9.6'
quit()

myrun 12

seemed to work but also caused some errors ...

and did not plot properly since sim.net.allCells was not created

can use sim._gatherCells()
to get all the cells gathered ...

ok, saving as a list for now ... each node saves it and then it's merged together
at the end of the sim; takes a lot of space ~2 GB, but works pretty quickly (much
faster than gatherdata)

myrun 12

Analyzing...
  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 104487 (1.95 Hz)
  Simulated time: 10.0 s; 12 workers
  Run time: 989.55 s
fatal: No names found, cannot describe anything.
Saving output as data/20may11_A0_simConfig.pkl ... 
Finished saving!
Done; saving time = 1.34 s.

20may11_a0_rast.png

note that EML fires much less than EMR ... could be due to initial bias
in wiring from probabalistic connectivity ... could fix with convergence if that's the issue

also had targettedRL==1...that could also lead to a bias towards one population dominating..?
will retry with targettedRL off ... 

python -i actmap.py
  
fig, axs, plt = animActivityMaps('gif/20may11_actmap_a0.mp4', framerate=10,figsize=(9,5))

gif/20may11_actmap_a0.mp4

python -i simdat.py

hmm, using matplotlib 2.2.4 (newer ones not supported in netpyne) there's an error about fig.add_gridspec ...
in simdat.py animsynweights ... fixup to use matplotlib.gridspec.GridSpec

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may11_AMPA_weightmap_a0.mp4', framerate=10) #plot/save images as movie
animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may11_NMDA_weightmap_a0.mp4', framerate=10) #plot/save images as movie

compress pickle to reduce file size?

https://lucianopaz.github.io/compress_pickle/html/

pip install lz4
pip install compress_pickle

python
import pickle, compress_pickle
d = pickle.load(open('data/20may11_A0_synWeights.pkl','rb'))
compress_pickle.dump(d, 'tmp.pkl', compression="lzma", set_default_extension=False)

takes too long ...

see if reformatting weights as dict will save space ...

python
import pickle
din = pickle.load(open('data/20may11_A0_synWeights.pkl','rb'))
len(din) # 59676000
# [t,conn.preGid,cell.gid,conn.synMech,float(conn['hObj'].weight[0])]

#
dout = {}
for row in din:
  t,preID,poID,syn,w = row
  if preID not in dout:
    dout[preID] = {}
  if poID not in dout[preID]:
    dout[preID][poID] = {}
  if syn not in dout[preID][poID]:
    dout[preID][poID][syn] = []
  dout[preID][poID][syn].append([t,w])

pickle.dump(dout, open('tmp.pkl','wb'))

saves some space, but not enough:
(-rw-rw-r-- 1 samn samn 1562509212 May 11 23:06 tmp.pkl; new size is ~1.6 GB)
(original size is ~2.2GB  -rw-rw-r-- 1 samn samn 2193401415 May 11 16:26 20may11_A0_synWeights.pkl)

*20may12 - check balanced inputs to EMR,EML, rename pops, avoid hypersynch, longer sims, targettedRL prob?
** try reducing size of output synaptic weight data

could also run for 100 s and save weights every 1 s instead of every 100 ms ...

python

import pickle
din = pickle.load(open('data/20may11_A0_synWeights.pkl','rb'))
len(din) # 59676000
# [t,conn.preGid,cell.gid,conn.synMech,float(conn['hObj'].weight[0])]

import pandas as pd
pdf = pd.DataFrame(din,columns=['time','preid','postid','syntype','weight'])

first need to run
conda install PyTables

pdf.to_hdf('tmp.hdf',key='synweight')

-rw-rw-r-- 1 samn samn 2507588016 May 12 11:57 tmp.hdf

hmm, that's too big, so not much help ... 

pdf.to_pickle('tmp.pkl',compression='bz2') # takes way too long

#
dout = {}
for row in din:
  t,preID,poID,syn,w = row
  if preID not in dout:
    dout[preID] = {}
  if poID not in dout[preID]:
    dout[preID][poID] = {}
  if syn not in dout[preID][poID]:
    dout[preID][poID][syn] = []
  dout[preID][poID][syn].append([t,w])

pickle.dump(dout, open('tmp.pkl','wb'))

will use the dictionary format since it saves ~30% of the total size ...

** other question: why were EMR weights only increasing? targettedRL seems to bias towards one population

get same when have targettedRL off?

try that with recording weights every 1 s

myrun 12

20may12_rast_a0.png
20may12_IM_a0.png
12may12_EML_a0.png
12may12_IV1_a0.png

paddle seems to get stuck at top of screen ...

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may12_actmap_a0.mp4', framerate=10,figsize=(9,5))

gif/20may12_actmap_a0.mp4

yes, paddle stuck at top and EMR fires more than EML ... then hypersynchrony develops

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may12_AMPA_weightmap_a0.mp4', framerate=10) 
animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may12_NMDA_weightmap_a0.mp4', framerate=10) 

this time weights go up for both populations ...

** make sure balanced inputs to E motor populations

all EMR, EML neurons should have same number of inputs ... use convergence instead of probability
otherwise there will be biases in relative activation of the two populations

IM -> EML, EMR has probability of 0.125

conv = int(0.5 + pij * numfrom)

could make a pmat to use ...

EML -> IM, EMR -> IM
had connection probability of 0.125/2 and 400 EML, EMR neurons ...
conv = int(0.5 + 0.125/2 * dnumc[EML]) = 25

IM -> EML, IM -> EMR
had connection probability of 0.125 and 200 IM neurons
conv = int(0.5 + 0.125 * 200) = 25

ok, put in a helper function in connUtils to get convergence from probability and num presynaptic neurons
and used it to get convergence number in the connection rules ... will see if that produces more similar
firing rates for EMR and EML ...

and try sim with the new ~equivalent convergence-based connectivity ...

20may12_B0_

myrun 12

  Cells: 5359
  Connections: 0 (0.00 per cell) <<-- that's because not saving cellconn, there are synapses in this simulation
  Spikes: 222076 (4.14 Hz)
  Simulated time: 10.0 s; 12 workers
  Run time: 1002.30 s

ok, rates for EMR, EML are more similar now:
 20may12_rast_b0.png
 20may12_EML_b0.png
 20may12_IM_b0.png

the paddle does get stuck at top for part of simulation ... seems less likely
to get stuck at bottom? 
 
the network also transitions to too much synchronous EMR,EML activity quickly ... should reduce that
maybe via different starting and max weights ... 

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may12_actmap_b0.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may12_AMPA_weightmap_b0.mp4', framerate=10, figsize=(14,8)) 
animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may12_NMDA_weightmap_b0.mp4', framerate=10, figsize=(14,8))

** change EMR -> EMUP, EML -> EMDOWN

since confusing to read code ...

ok ... adjusted in sim.py, sim.json, simdat.py, actmap.py

** get rid of hypersynch -->> ends up developing after ~10 s even with lower starting weights some improvement in performance?

can reduce "EEMWghtAM":0.0001,"EEMWghtNM":0.00001 to lower values ...

and also the RL weight increment ... which variable is that ... ?
'RLhebbwt': 0.001 , 'RLantiwt': -0.000, ??

yeah, looks like RLhebbwt ... and it's very large compared to starting weights ... so should
reduce it and add as a param for sim.json ...

note that RLhebbwt may be ok since it's multiplied by the reward/punishment value in mod/stdp.mod ...
so it only moves by a fraction anyway (when using critic values of 0.001, 0.01, etc.)
(/u/samn/SMARTAgent/mod/stdp.mod:156)

ok, try adjustments ...

myrun 12

20may12_EMDOWN_c0.png

looks better overall...but only a matter of time until epileptic/highly synchronized activity returns ...
without homeostatic plasticity that's likely to occur...unless use soft thresholding and have lower wmax values?
could also have easier homeostatic plasticity rule to check rates of all populations and increase random
inhibitory noise when cells begin to fire too fast

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may12_actmap_c0.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may12_AMPA_weightmap_c0.mp4', framerate=10, figsize=(14,8)) 
animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may12_NMDA_weightmap_c0.mp4', framerate=10, figsize=(14,8))

ok, will try a soft threshold and 10 s sim ...

not sure if want NMDA RL plasticity yet ... has very long eligibility trace (~800 ms) ...

dynamics look decent overall, but have to run longer and see if remains stable,
since rates seem to increase somewhat over time ...

20may12_rast_c1.png
20may12_IM_c1.png
20may12_EMDOWN_c1.png
20may12_IV1_C1.png

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may12_actmap_c1.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may12_AMPA_weightmap_c1.mp4', framerate=10, figsize=(14,8));animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may12_NMDA_weightmap_c1.mp4', framerate=10, figsize=(14,8))

ok, try a 100 s sim with same params ...

ran to completion & saved output but then crashed some time after display ... so did
not have chance to save raster ... can redraw from data ... looked like hypersynch
emerged eventually with fairly high rates for EMUP,EMDOWN,IM populations

synweights file is ~1.6 GB
simconfig ~540 MB

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may12_actmap_c2.mp4', framerate=10,figsize=(18,10))

that movie shows it does seem to improve by the end, though paddle gets stuck a lot ... 

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may12_AMPA_weightmap_c2.mp4', framerate=10, figsize=(14,8));animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may12_NMDA_weightmap_c2.mp4', framerate=10, figsize=(14,8))

some slight improvement in performance near the end ... looks like would need a lot longer to get anywhere reasonable, though
the hypersynchrony could cause problems far sooner ...

also worth testing the targetted RL rule keeping everything else the same ...

not sure need the NMDA RL since ball can get across screen in a few 100 ms ... can keep for now ...

can try two 300 s sims on zn and see which does better (with or without targetted RL)


** longer sims
*** 300 s same params as last (20may12_NOTARG_Z0_)

myrun 12

started ~23:29

End time:  2020-05-14 01:14:01.856790

too much time in plotting, which is not needed ... synweights ~4.6 GB
weights of EMDOWN,EMUP get too high by the end, as usual
20may12_NOTARG_Z0_rast.png
20may12_NOTARG_Z0_EMDOWN.png
20may12_NOTARG_Z0_IM.png

python -i actmap.py backupcfg/20may12_NOTARG_Z0_sim.json

fig, axs, plt = animActivityMaps('gif/20may12_NOTARG_Z0_actmap_300s.mp4', framerate=10,figsize=(18,10))

python -i simdat.py backupcfg/20may12_NOTARG_Z0_sim.json

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may12_NOTARG_Z0_AMPA_weightmap_300s.mp4', framerate=10, figsize=(14,8));animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may12_NOTARG_Z0_NMDA_weightmap_300s.mp4', framerate=10, figsize=(14,8))


*** 300 s same params as last but with targetted RL on (20may12_TARG_Z0_)

myrun 12

started ~23:31

  Run time: 82911.72 s
Total time = 86993.01 s

End time:  2020-05-13 23:41:08.873020

that's on zn with 12 cores (but many other jobs were running so took longer)

rates for EMUP,EMDOWN very unbalanced, with EMDOWN very low

20may12_TARG_Z0_rast.png
20may12_TARG_Z0_IM.png
20may12_TAG_Z0_EMDOWN.png

get rid of the 4.6GB data from this sim since did not work properly ... 

*20may13 - longer sims; hyperexcit; read weights works with AM/NM?
** 300 s sims still running on zn ~12 hours later (~1/2 done)
** discuss object detection / optical flow

had suggestion to use object detection as a mask for optical flow to
constrain spatial resolution for the flow

** still have issue of hyperexcit

reduce the min weights for RL, use targetted RL, and run for 10 s

20may13_A0_rast.png

prevents the hyperexcit; enough M activity generated? will hyperexcit just emerge later?

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may13_A0_actmap.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may13_A0_AMPA_weightmap.mp4', framerate=10, figsize=(14,8));animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may13_A0_NMDA_weightmap.mp4', framerate=10, figsize=(14,8))

not much M activity generated ... could run for 100 s to see if emerges ... or goes overboard

myrun 12

  Done; plotting time = 284.79 s

Total time = 10613.54 s

20may13_A0_rast_1.png
2-may13_A0_IM_1.png

one of the E populations ends up dominating, so that's a problem ... due to targetted rule?
the rates are for EMUP are not terrible though...so params apart from targetted might be ok?

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may13_A0_actmap_100s.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may13_A0_AMPA_weightmap_100s.mp4', framerate=10, figsize=(14,8));animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may13_A0_NMDA_weightmap_100s.mp4', framerate=10, figsize=(14,8))

targetted rule seems not to be working properly ... ?? is it due to slight bias in beginning
that gets amplified by other M population getting suppressed through lower weights, and other
populations getting strengthened ... ? or it could occur if one population gets strengthened
for right reason a couple of times, and that strengthening increases bias towards that
action and avoiding other action, which gets suppressed if no more activation

should redo this sim but without the targetted RL , just to check if one M pop gets suppressed
...

ok, run 20may13_B0_
with targettedRL == 0  , all else same ...

myrun 12

  Spikes: 2149938 (4.01 Hz)
  Simulated time: 100.0 s; 12 workers
  Run time: 12102.82 s
Saving output as data/20may13_B0_simConfig.pkl ... 
Finished saving!
  Done; saving time = 13.08 s.
  Done; plotting time = 1262.04 s
Total time = 13866.31 s

20may13_B0_rast.png
20may13_B0_IM.png
20may13_B0_EMDOWN.png
looks like gets to hypersynch ... but at least both populations of M neurons firing

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may13_B0_actmap_100s.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may13_B0_AMPA_weightmap_100s.mp4', framerate=10, figsize=(14,8));animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may13_B0_NMDA_weightmap_100s.mp4', framerate=10, figsize=(14,8))


** does readinweights work properly with AMPA and NMDA weights?

do not see any check for AMPA vs NMDA ...

not clear the NMDA plasticity needed ... could just have long time constant for AMPA eligibility
trace with exp decay ...

*20may14 - no NMDAR RL plasticity; implement/test simple weight normalization
** get rid of the NMDA RL plasticity for now

ok, check the RLon option in sim.json to determine whether to use plasticity for the specific
synapse

    "RL":{"AMPA":
	  {"wbase":0.00001,"wmax":0.00075,"RLon":1,"RLlenhebb":50,"RLlenanti":50,"useRLexp":1,"RLhebbwt":0.0005,"RLantiwt":-0.0,"hebbwt":0,"antiwt":0,"tauhebb":10,"RLwindhebb":50,"softthresh":1,"verbose":0},
	  "NMDA":
	  {"wbase":0.000001,"wmax":0.000075,"RLon":0,"RLlenhebb":800,"RLlenanti":100,"useRLexp":1,"RLhebbwt":0.0005,"RLantiwt":-0.0,"hebbwt":0,"antiwt":0,"tauhebb":10,"RLwindhebb":50,"softthresh":1,"verbose":0}
	 }

there, it's specified to shut off RL for NMDA ...

may want to adjust the NMDA weights too since they're pretty low and probably just as well to leave
them off ...

try a fast sim to test with the NMDA RL off ...

myrun 12

  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 32264 (2.01 Hz)
  Simulated time: 3.0 s; 12 workers
  Run time: 300.88 s

using 100 ms resolution for the AMPA weights ...

20may14_A0_rast.png

looks ok ... did it run any faster? perhaps ...

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may14_A0_actmap_3s.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may14_A0_AMPA_weightmap_3s.mp4', framerate=10, figsize=(14,8))

looks ok ... those videos show reward after ball hit and point scored but not in the hit ball / miss ball panel ...
is that a bug? probably hit/miss code just needs a minor adjustment

** there was a bug in paddle/ball hit detection, ha fixed
** weight rescaling every so often? seems to work/prevent hyperexcit

could normalize incoming AMPA/NMDA weights of EMUP,EMDOWN populations
to have same average or sum as start with ... 

ok, implemented some of that, testing it now ...

normalizeWeightStepSize in sim.json controls how many action steps to use for normalizing the
weights; uses a mult factor for each population based on EEMWghtAM
so when average weights dip below, they're pushed towards that value, and when they're above, they are reduced
scaling as EEMWghtAM / average_weight

seems to work based on printouts ... and some short sims

tried in 10 s sim ... with weight normalization every 500 ms ...

average weights moved in both directions and were scaled up or down ... 

maybe works ... ?

at least no hyperexcit here:
20may14_T0_rast.png

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may14_T0_actmap_10s.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may14_T0_AMPA_weightmap_10s.mp4', framerate=10, figsize=(14,8))

looks like ~avg value maintained fairly well, and some hotspots with high weight emerge too ... 

next, to test in longer sim ... can use 1 s between normalizations ... 

run for 300 s ... with 12 cores ... on zn (20may14_T0_Z0_)

myrun 12

  Simulated time: 300.0 s; 12 workers
  Run time: 22489.13 s

20may14_T0_Z0_rast.png

rates are ok

python -i actmap.py backupcfg/20may14_T0_Z0_sim.json

fig, axs, plt = animActivityMaps('gif/20may14_T0_Z0_300s.mp4')

python -i simdat.py backupcfg/20may14_T0_Z0_sim.json

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may14_T0_Z0_AMPA_weightmap_300s.mp4')

myrun 12

also run same on laptop for 100 s with 12 cores

Analyzing...
  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 1076136 (2.01 Hz)
  Simulated time: 100.0 s; 12 workers
  Run time: 9454.24 s

20may14_T0_L0_rast.png
20may14_T0_L0_EMDOWN.png
20may14_T0_L0_IM.png
20may14_T0_L0_EMUP.png

activity looks ok - EMUP,EMDOWN,IM rates pretty low
  
python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may14_T0_L0_actmap_100s.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may14_T0_L0_AMPA_weightmap_100s.mp4', framerate=10, figsize=(14,8))

looks ok though seems to need a lot more time to improve, if ever ... may want to adjust normalization
rule to only scale weights down if they pass some threshold, and at a higher threshold than initial average weight

or perhaps maintaining the initial average weight would allow for sparse firing and more efficient coding??

probably need long runs with comparisons to determine ...

could have upper and lower threshold for normalizing weights; when average weight higher than upper threshold
scale down; when average weight below lower threshold scale up. lower threshold could be set to starting
average weight but upper threshold could be set to some positive multiple of starting weight. that way normalization
would push average weight to be within a reasonable range...

ok, try that rule with lower bound of original and upper bound of 5X original ... weights will likely go up
and hover around upper bound ... 

myrun 12

20may14_T0_M0_rast.png

rates look ok so far ... 

python -i actmap.py 

fig, axs, plt = animActivityMaps('gif/20may14_T0_M0_actmap_10s.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may14_T0_M0_AMPA_weightmap_10s.mp4', framerate=10, figsize=(14,8))

based on previous sims 2X original weight probably high enough and even that may produce hypersynchrony ...
can try the 2X anyway to check ... see if it does any better than the 1X original weight rule (same min
and max threshold)

will run that on zn for 300 s ... and compare to other sim currently running ...

myrun 12

  Simulated time: 300.0 s; 12 workers
  Run time: 21025.55 s
  Done; plotting time = 1867.69 s  
  Total time = 23540.60 s

20may14_Min1Max2Thresh_Z0_rast.png
rates look ok at end, only slightly higher than other sim
but the scaling factor used was 1.0 for most of simulation (after initial scaling up
of all stdp/rl weights). the 1.0 scaling means that the weights never got up to the
upper limit; so then it's surprising the network did not reach hypersynchrony ...
something seems off ...

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may14_Min1Max2Thresh_Z0_300s.mp4')

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may14_Min1Max2Thresh_Z0_AMPA_weightmap_300s.mp4', framerate=10, figsize=(14,8))

*20may15
** check the weight normalization

why does hyperexcit not emerge when weights are below the max, but
continuously increasing?

due to soft thresholding? should the min,max weight thresholds be closer to the wbase, wmax params for the
STPD/RL??

if starting EEMWghtAM is at max for RL weights (0.00075) is there hyperexcit?

myrun 12

20may15_rast_a0.png

yeah, there's hyperexcit, then after weights normalized (lower) at t=500 ms, the hyperexcit
disappears

t= 500.0000000000452 - adjusting weights based on RL critic value: -0.001
sim.rank= 0 davg: {'EMUP': 0.0005615105765452703, 'EMDOWN': 0.0005615055487169171} dfctr: {'EMUP': 0.26713655319350277, 'EMDOWN': 0.2671389451854241}

then later it moves up a bit and is normalized downward some more:
t= 1000.0000000001588 - adjusting weights based on RL critic value: -0.001
sim.rank= 0 davg: {'EMUP': 0.00015004612430169018, 'EMDOWN': 0.0001500624095345771} dfctr:
{'EMUP': 0.9996925991797199, 'EMDOWN': 0.9995841094730473}

what if EEMWghtAM starts at 0.00015 ... ?

myrun 12

savefig('gif/20may15_rast_a0.png') # hmm, overwrote last file

less hypersynch and it decays anyway from the RL ... if RL was off, what would happen?

myrun 12

savefig('gif/20may15_rast_a1.png') # not much hypersynch ...

so 0.00015 would be a decent upper limit ... can it be higher?

try with "EEMWghtAM":0.000375

myrun 12

savefig('gif/20may15_rast_a2.png') # mostly ok but some periods of overly (?) synchronous firing

so, that might be ok as upper bound ... higher upper bound could allow larger set of weights ...
but could run another sim with lower upper bound for comparison ... 

** movies from zn 300 s sims -->> gradual increase in probability of following ball?

20may14_Min1Max2Thresh_Z0_AMPA_weightmap_300s.mp4 <<-- that one looks better
than 20may14_T0_Z0_AMPA_weightmap_300s.mp4

the better sim (20may14_Min1Max2Thresh_Z0_) has higher max weight before normalization, and follow ball probability is
increasing with the weights. longer duration might allow the follow ball probability to surpass the not follow ball probability

the other sim (20may14_T0_Z0_) has lower max weight before normalization, and the probability of follow and not follow seem
to have hit a plateau corresponding with the weights, or at least a lower slope compared to the other simulation

that suggests higher max weight would perform better in the long run... at least encouraging that the follow
ball probability seems to be increasing ... 

** fixup/check resumesim

also check if can run sim saving everything but not drawing the raster ... that takes a long time

first run with raster for comparison ...

savefig('gif/20may15_b0_rast.png')

ok, with doplot==0, doquit==1 it runs ok

and then should have quick func to draw raster ...

python -i simdat.py

simConfig.keys() # dict_keys(['netpyne_version', 'netpyne_changeset', 'net', 'simConfig', 'simData'])
simConfig['simData'].keys() # dict_keys(['spkt', 'spkid', 'V_soma', 't', 'dminID', 'avgRate'])
simConfig['simData']['avgRate'] # 1.9083784288113455

plot(simConfig['simData']['spkt'],simConfig['simData']['spkid'],'ko',markersize=2)

savefig('gif/20may15_rast_b1.png')

looks ok, though no color/type/rate, can add that in or see if netpyne raster func supported here ...

simConfig['simData']['V_soma'].keys() 
dict_keys(['cell_0', 'cell_900', 'cell_4359', 'cell_400', 'cell_4759', 'cell_500', 'cell_4100', 'cell_5159'])

python -i simdat.py

dspkID.keys() # dict_keys(['ER', 'IR', 'EV1', 'EV1DE', 'EV1DNE', 'EV1DN', 'EV1DNW', 'EV1DW', 'EV1DSW', 'EV1DS', 'EV1DSE', 'IV1', 'EV4', 'IV4', 'EMT', 'IMT', 'EMDOWN', 'EMUP', 'IM'])
dspkT.keys() # dict_keys(['ER', 'IR', 'EV1', 'EV1DE', 'EV1DNE', 'EV1DN', 'EV1DNW', 'EV1DW', 'EV1DSW', 'EV1DS', 'EV1DSE', 'IV1', 'EV4', 'IV4', 'EMT', 'IMT', 'EMDOWN', 'EMUP', 'IM'])

drawraster(dspkT,dspkID)

savefig('gif/20may15_rast_b2.png')

looks pretty good...

should run much longer sim with resume ... with sim duration on order of 1000 of s ...

1 reason to use resume is if sim crashes in middle, would not have any intermediate output ...

try a 2 step sim ... make sure everything working 

python multistepSim.py sim.json 12 2 multirun

got error about not being able to restore STDP weights ...

ok, fixed up ...

try 3 steps to make sure working ...

python multistepSim.py sim.json 12 3 multirun

well, no crashes, so that's good ... check rasters

python -i simdat.py backupcfg/20may15_C0__step_0_sim.json
drawraster(dspkT,dspkID)
savefig('gif/20may15_step0_b3.png')
quit()

python -i simdat.py backupcfg/20may15_C0__step_1_sim.json
drawraster(dspkT,dspkID)
savefig('gif/20may15_step1_b3.png')
quit()

python -i simdat.py backupcfg/20may15_C0__step_2_sim.json
drawraster(dspkT,dspkID)
savefig('gif/20may15_step2_b3.png')

there are some diffs in firing patterns and rates ... check the weights too ...

python -i simdat.py backupcfg/20may15_C0__step_0_sim.json
animSynWeights(pdf)
gif/20may15_C0__step_0_weightmap.mp4

python -i simdat.py backupcfg/20may15_C0__step_1_sim.json
animSynWeights(pdf)
gif/20may15_C0__step_1_weightmap.mp4

python -i simdat.py backupcfg/20may15_C0__step_2_sim.json
animSynWeights(pdf)
gif/20may15_C0__step_2_weightmap.mp4

seems like the weights are properly loaded, and sim continues from there ...

one thing that seems to recur is paddle getting stuck at top ... that bias
seems difficult to overcome, hopefully not an intrinsic bias ...e.g. in the
wiring ... 

** setup long multistep sim on zn (20may15_ZN_MultiStep_A_)

python multistepSim.py sim.json 12 10 multirun

sim base name is 20may15_ZN_MultiStep_A_

with "EEMWghtThreshMax":0.000375

started ~17:16 ... 10 steps of 300 s ... total of 3000 s ...

** other multistep sim on zn (20may15_ZN_MultiStep_B_)

with slightly higher max weight ...

with "EEMWghtThreshMax":0.0005

python multistepSim.py sim.json 12 10 multirun

started ~17:27 ...

*20may18
** start looking at output from latest multistep runs

each sim finished ~4 steps each for total of ~1200 s

first just look at hit/miss ball probabilities ... 

*** simA 20may15_ZN_MultiStep_A_

python
import numpy as np
import pandas as pd
from pylab import *
from simdat import plotRewards,plotFollowBall,plotHitMiss

name = '20may15_ZN_MultiStep_A__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,4,1):
  name = '20may15_ZN_MultiStep_A__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)

np.amax(pda.time) # 1200000.0
  
pda.columns # Index(['time', 'action', 'reward', 'proposed', 'hit'], dtype='object')

#
plotRewards(pda,ax=subplot(3,1,1),msz=3,xl=(0,120e3))
plotFollowBall(pda,ax=subplot(3,1,2),msz=3)
plotHitMiss(pda,ax=subplot(3,1,3),msz=3)

tight_layout()

savefig('gif/20may18_multistep_A_reward_1200s_a0.png')

in middle panel follow vs not follow might be improving, though somewhat slowly...could also just be converging towards 50/50 (random)

*** simB 20may15_ZN_MultiStep_B_

python
import numpy as np
import pandas as pd
from pylab import *
from simdat import plotRewards,plotFollowBall,plotHitMiss

name = '20may15_ZN_MultiStep_B__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,4,1):
  name = '20may15_ZN_MultiStep_B__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)

np.amax(pda.time) # 1200000.0
  
pda.columns # Index(['time', 'action', 'reward', 'proposed', 'hit'], dtype='object')

#
clf()
plotRewards(pda,ax=subplot(3,1,1),msz=3,xl=(0,120e3))
plotFollowBall(pda,ax=subplot(3,1,2),msz=3)
plotHitMiss(pda,ax=subplot(3,1,3),msz=3)

tight_layout()

savefig('gif/20may18_multistep_B_reward_1200s_b0.png')

*** compare the two

python
import numpy as np
import pandas as pd
from pylab import *
from simdat import plotRewards,plotFollowBall,plotHitMiss

lpda = []

name = '20may15_ZN_MultiStep_A__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,4,1):
  name = '20may15_ZN_MultiStep_A__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)

lpda.append(pda)
  
name = '20may15_ZN_MultiStep_B__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,4,1):
  name = '20may15_ZN_MultiStep_B__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)
  
lpda.append(pda)

# sim A on left (lower max weight threshold), sim B on right (higher max weight threshold)
plotFollowBall(lpda[0],ax=subplot(1,2,1),msz=3); plotFollowBall(lpda[1],ax=subplot(1,2,2),msz=3)

savefig('gif/20may18_multistep_A_B_reward_1200s_c0.png')

the one with lower max weights seems to converge faster ... and get toward slightly higher accuracy ... ?

plotHitMiss(lpda[0],ax=subplot(1,2,1),msz=3); plotHitMiss(lpda[1],ax=subplot(1,2,2),msz=3)

savefig('gif/20may18_multistep_A_B_hit_miss_1200s_c1.png')

for hit,miss the one with higher max weights gets slightly higher number of hits

plotRewards(lpda[0],ax=subplot(1,2,1),msz=3); plotRewards(lpda[1],ax=subplot(1,2,2),msz=3)

savefig('gif/20may18_multistep_A_B_rewards_1200s_c2.png')

can't see diffs from reward fig ...

sum(lpda[0].reward) # 290.6
sum(lpda[1].reward) # 289.36
so, almost identical total reward ...

may as well let those sims run some more to see if they improve further ... possible that
learning is taking place, just at a slow rate ... 

** build a map of which info received by each/all M neurons

otherwise will not know if architecture supports proper decision making

** try higher conn probability for inputs to M populations

that will increase likelihood that M populations have enough info to make decisions

can make a param to control it ... EEMProb, and as scale up prob, scale down the incoming weights ...

EEMProb ... original was 0.1 ... try at double probability ... and 1/2 weight ... 

change "EEMWghtAM":0.000075,"EEMWghtNM":0.0000075
to
"EEMWghtAM":0.0000375,"EEMWghtNM":0.00000375

also change "EEMWghtThreshMin":0.000075,"EEMWghtThreshMax":0.0005
to
"EEMWghtThreshMin":0.0000375,"EEMWghtThreshMax":0.0005

myrun 12

ok...

python -i simdat.py

drawraster(dspkT,dspkID)
savefig('gif/20may18_d0.png')

rates are ok ... 

animSynWeights(pdf,'gif/20may18_d0_weightmap.mp4')

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may18_d0_actmap.mp4')

well, activity not epileptic ... could run a long sim to compare to how others performing ...

even 100 s worth trying ...

20may18_L0_

myrun 12

