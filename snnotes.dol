
*19nov27
** trying on laptop

do not have netpyne on laptop

python3
import netpyne

pip3 install netpyne

Traceback (most recent call last):
  File "/usr/bin/pip3", line 9, in <module>
    from pip import main
ImportError: cannot import name 'main'

what's wrong with pip3?

https://stackoverflow.com/questions/49836676/error-after-upgrading-pip-cannot-import-name-main

sudo python3 -m pip uninstall pip && sudo apt install python3-pip --reinstall

pip3 install netpyne

hmm, needs newer version of python (>= 3.6 ), only have python 3.5 on laptop ...

will try on neurosim ... 

python3
import netpyne
netpyne.__version__ # '0.9.3.1'

pip3 install gym --user
pip3 install atari-py --user

compile:
nrnivmodl

for running on 1 node:
py3env
python3 trainSmartAgent.py

mpirun -n 16 python trainSmartAgent.py

was able to run with 1 core, took 2.5 GB with 500 ms interval for saving weights and 1000 ms simulation
will need to record from only a small fraction of the cells

*20feb13
** make new branch to avoid conflict with haroon's work

git branch samn
git checkout samn
git add snnotes.dol
git commit -m 'new branch for samn test'
git push origin samn

make an alias for that: gpushsamn

** try compile and then run 

nrnivmodl

mpirun -n 16 python trainSmartAgent.py

myrun

mpirun -n 16 python trainSmartAgent.py

even after calling py3env to set the environment to use anaconda ... 
it's showing many different pong windows ... should only be 1 window  (this was run on zn)

aigame.py loads the gym environment with the pong game
where is aigame.py called from?

trainSmartAgent.py is the main sim setup
it imports SMARTAgent from aigame

hmm, not running it properly ...

mpiexec -n 16 python -mpi trainSmartAgent.py

*20feb24
** HA fixed the MPI issues
** set env.frameskip to a constant value on environment init to avoid random frameskip in a range
** setup code for some more flexibility

can use json for config file

*20feb25
** adjust architecture add direct V1 -> M popoulations

that way M has higher resolution visual information
and M still receives the lower resolution visual information from V2, IT as well ...

** simple test - reward for moving up, punish for moving down

does it produce expected behavior?

myrun 16

python
import numpy as np
from pylab import *
ion()
d = np.loadtxt('ActionsRewards.txt')
len(np.where(d[:,1]==3)[0]) # 232
len(np.where(d[:,1]==4)[0]) # 246
len(np.where(d[:,1]==1)[0]) # 272

plot(d[:,0],d[:,1],'ko')
hist(d[:,1])

to test if it's working just check the RL weights onto ML vs MR; weights onto ML neurons should
increase, while weights onto MR should decrease ...  if that's not happening, something is wrong ...

*20feb26
** looking at the output weights for the fake training task

myrun 1
quit()

python3
import numpy as np
from pylab import *
ion()
awt = np.loadtxt('data/AdjustableWeights.txt')
awt.shape # (21999, 5) # columns are time, preid, postid, stdptype, weight

plot(awt[:,0],awt[:,4],'ko')
savefig('gif/20feb26_a0.png')

need to know cell types ...

import pandas as pd
pdf = pd.DataFrame(awt,columns=['time','preid','postid','stdptype','weight'])
len(pdf) # 21999

pdfs = pdf[(pdf.postid==1184) & (pdf.stdptype==1)]
len(pdfs) # 879
plot(pdfs.time,pdfs.weight,'r')
savefig('gif/20feb26_a1.png') # looks incorrect ?? does it go up and down or are those two different synapses?

min(pdfs.preid),max(pdfs.preid) # (403.0, 924.0)
yeah, two preids ... and they're differnet because different source populations ...

pdfs = pdf[(pdf.postid==1184) & (pdf.stdptype==1) & (pdf.preid==403)]
len(pdfs) # 20
plot(pdfs.time,pdfs.weight,'b')
savefig('gif/20feb26_a2.png')
ok, that weight is increasing gradually ... but is that the ML or MR output population?

ID 1159 through 1183 (inclusive) are the ML neurons? (/u/samn/SMARTAgent/trainSmartAgent.py:754)

pdfs = pdf[(pdf.postid==1159) & (pdf.stdptype==1)]
len(pdfs) # 0

pdfs = pdf[(pdf.postid==1160) & (pdf.stdptype==1)]
len(pdfs) # 0

pdfs = pdf[(pdf.postid>=1159) & (pdf.postid<=1183) & (pdf.stdptype==1)]
len(pdfs) # 0

hmm, are any of the ML weights getting saved??

note that this was run with a single core ...

ah, a bug in new code ...

fix, rerun ...

myrun 1

python3
import numpy as np
from pylab import *
ion()
awt = np.loadtxt('data/AdjustableWeights.txt')
awt.shape # (22000, 5) # columns are time, preid, postid, stdptype, weight

plot(awt[:,0],awt[:,4],'ko')

import pandas as pd
pdf = pd.DataFrame(awt,columns=['time','preid','postid','stdptype','weight'])
pdfs = pdf[(pdf.postid>=1159) & (pdf.postid<=1183) & (pdf.stdptype==1)]
len(pdfs) # 11000

should save types in the file ... 

plot(pdfs.time,pdfs.weight,'b')

myrun 1
sim.net.cells[0].tags['pop'] # 'R'

sim.net.cells[1184].tags['pop'] # 'MR'
sim.net.cells[1159].tags['pop'] # 'ML'

*20feb27
** continue debugging

to get the network/cell info use this:
simConfig.savePickle = True            # Save params, network and sim output to pickle file

myrun 1

from pylab import *
savefig('gif/20feb27_rast_a0.png')

simConfig.filename = 'data/simConfig'
sim.saveFolder = 'data'

python3
import numpy as np
from pylab import *
ion()
awt = np.loadtxt('data/AdjustableWeights.txt')

import pandas as pd
pdf = pd.DataFrame(awt,columns=['time','preid','postid','stdptype','weight'])
pdfs = pdf[(pdf.postid>=1159) & (pdf.postid<=1183) & (pdf.stdptype==1)]

import pickle
simConfig = pickle.load(open('data/simConfig.pkl','rb'))
simConfig.keys() # dict_keys(['netpyne_version', 'netpyne_changeset', 'net', 'simConfig', 'simData'])

simConfig['net'].keys() # dict_keys(['params', 'cells', 'pops'])
simConfig['net']['pops'].keys() # odict_keys(['R', 'V1', 'V4', 'IT', 'IR', 'IV1', 'IV4', 'IIT', 'ML', 'MR'])
simConfig['net']['pops']['MR'].keys() # dict_keys(['tags', 'cellGids'])
simConfig['net']['pops']['MR']['cellGids'] # [1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208]
simConfig['net']['pops']['ML']['cellGids'] # [1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183]

ok, good ...

dstartidx = {p:simConfig['net']['pops'][p]['cellGids'][0] for p in simConfig['net']['pops'].keys()}
dendidx = {p:simConfig['net']['pops'][p]['cellGids'][-1] for p in simConfig['net']['pops'].keys()}

dstartidx # {'R': 0, 'V1': 400, 'V4': 800, 'IT': 900, 'IR': 925, 'IV1': 1025, 'IV4': 1125, 'IIT': 1150, 'ML': 1159, 'MR': 1184}
dendidx # {'R': 399, 'V1': 799, 'V4': 899, 'IT': 924, 'IR': 1024, 'IV1': 1124, 'IV4': 1149, 'IIT': 1158, 'ML': 1183, 'MR': 1208}

pdfs = pdf[(pdf.postid>=dstartidx['ML']) & (pdf.postid<=dendidx['ML']) & (pdf.preid>=dstartidx['V1']) & (pdf.preid<=dendidx['V1']) & (pdf.stdptype==1)]
len(pdfs) # 4000

plot(pdfs.time,pdfs.weight,'bo')

savefig('gif/20feb27_wghts_a1.png')

pdfs = pdf[(pdf.postid>=dstartidx['MR']) & (pdf.postid<=dendidx['MR']) & (pdf.preid>=dstartidx['V1']) & (pdf.preid<=dendidx['V1']) & (pdf.stdptype==1)]
len(pdfs) # 4000

plot(pdfs.time,pdfs.weight,'ro')

savefig('gif/20feb27_wghts_a2.png')

so both ML and MR weights are increasing - that's incorrect

checking if recording the synaptic weights into sim.simData['synweights'] will work
with netpyne gathering the info across nodes automatically ...

python3
import numpy as np
from pylab import *
import pickle

simConfig = pickle.load(open('data/simConfig.pkl','rb'))
simConfig.keys() # dict_keys(['netpyne_version', 'netpyne_changeset', 'net', 'simConfig', 'simData'])
simConfig['simData'].keys() # dict_keys(['spkt', 'spkid', 'V_soma', 't', 'synweights', 'avgRate'])
len(simConfig['simData']['synweights']) # 22000
simConfig['simData']['synweights'][0] # [99.9999999999986, 0.0025, 1184, 900, 1]

and that was when running with 1 node ... try again with > 1 to see if same

myrun 16

Traceback (most recent call last):
  File "sim.py", line 988, in <module>
    sim.gatherData() # gather data from different nodes
  File "/usr/site/python/netpyne/netpyne/sim/gather.py", line 165, in gatherData
    sim.allSimData[key].update(val)           # update simData dicts which are not Vectors
ValueError: dictionary update sequence element #0 has length 5; 2 is required

change sim.simData['synweights'] to a dict (with key 0 pointing to a list of lists)

type(sim.simData['synweights']) # <class 'dict'>
sim.simData['synweights'][0][0] # [99.9999999999986, 0.0025, 1184, 912, 1]
len(sim.simData['synweights'][0]) # 1320
len(sim.allSimData['synweights'][0]) # 1320
sim.allSimData['synweights'].keys() # dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])
len(sim.allSimData['synweights'][15]) # 1320
sum([len(sim.allSimData['synweights'][i]) for i in range(16)]) # 22000

import pickle
simConfig = pickle.load(open('data/simConfig.pkl','rb'))
len(simConfig['simData']['synweights'][0]) # 1320
simConfig['simData']['synweights'].keys() # dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])
simConfig['simData']['synweights'][0][0] # [99.9999999999986, 0.0025, 1184, 912, 1]

ion()
awt = np.loadtxt('data/AdjustableWeights.txt')

import pandas as pd
pdf = pd.DataFrame(awt,columns=['time','preid','postid','stdptype','weight'])


ok, good ...

dstartidx = {p:simConfig['net']['pops'][p]['cellGids'][0] for p in simConfig['net']['pops'].keys()}
dendidx = {p:simConfig['net']['pops'][p]['cellGids'][-1] for p in simConfig['net']['pops'].keys()}

testing basic mechanism again , with RL exp off and fake up rule ... 

myrun 16

plw

savefig('gif/20feb27_rewards_wghts_a3.png')

seems to generally work, once separated out the population specific projections (V1->ML and V1->MR) ...
but not clear why V1->MR is getting reinforced when MR produces down moves ...

could be that MR getting reinforced since V1 projects to both MR and ML and V1->MR synapses are tagged
within the interval when V1->ML synapses are tagged for reward ...

try cutting off some of the higher connections connections and see what happens ... e.g. no V1 -> MR
and no V4, IT -> ML or -> MR; and may need to set wbase to 0 as well ...

myrun 16

now for some reason ML never firing ... ??? no, ML firing but MR not firing (that was the test)
but mostly only producing move 3 (down), instead of 4 (up) ... why?

savefig('gif/20feb27_rewards_wghts_a4.png')
savefig('gif/20feb27_rewards_wghts_a5.png')

hmm, had the rule backwards:
            if F_R1>F_L1:
                actions.append(dconf['moves']['UP']) #UP
            elif F_R1<F_L1:
                actions.append(dconf['moves']['DOWN']) # Down
            else:
            actions.append(dconf['moves']['NOMOVE']) # No move

R produces up, L produces down ...

ok, fixing that, now V->MR weights go up as they should (but now have turned off inputs to ML)
savefig('gif/20feb27_rewards_wghts_a6.png')

so, turned back on the inputs to ML to see if -> MR weights still go up with time ...

savefig('gif/20feb27_raster_a7.png')

savefig('gif/20feb27_rewards_weights_a8.png')

it does look like the V -> MR weights increase more than the V -> ML weights, which
is correct, but the V -> ML weights still seem to correlate with the V -> MR weights, and go up in parallel
perhaps, as long as overall more of the correct moves are made, it doesn't matter if the V -> ML weights
are increased too ... ?

what is the move command as a function of time? more correct moves later on compared to earlier?

pad = pd.DataFrame(actreward,columns=['time','action','reward'])

figure(); pads = pad[pad.action==3]; plot(pads.time,pads.action,'bo'); pads = pad[pad.action==4]; plot(pads.time,pads.action,'ro')

#
ldown,lup = [],[]
ltt = linspace(0,99,100)
for tt in ltt:
  pads = pad[(pad.action==3) & (pad.time>=tt*1e3) & (pad.time<=(tt+1)*1e3)]
  ldown.append(len(pads))
  pads = pad[(pad.action==4) & (pad.time>=tt*1e3) & (pad.time<=(tt+1)*1e3)]
  lup.append(len(pads))

clf(); plot(ltt,ldown,'r',linewidth=4); plot(ltt,lup,'b',linewidth=4); xlabel('Time (s)'); ylabel('Move frequency (Hz)');
import matplotlib.patches as mpatches
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','r'],['Up','Down'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/20feb27_action_freq_a9.png')

most of the time, up moves have higher rate than down moves ...

see if it's reversed when using the down fake rule ...

ok, using sim.json sim:name to specify simulation name so can save output files for different sim in data ...

also may as well adjust plotWeights to draw actions in top panel ...? suppose only useful when using fake rule ... 
otherwise up/down rates not so important ...  

sim name is 20feb27_FakeDownRule_B0_

myrun 16

  Cells: 1209
  Connections: 27879 (23.06 per cell)
  Spikes: 173390 (1.43 Hz)
  Simulated time: 100.0 s; 16 workers
  Run time: 2309.54 s

savefig('gif/20feb27_raster_b0.png')

more spikes at bottom, where they should be ... ML has higher firing rate (ML produces down move), much more than in previous example where MR had
slightly higher firing rate than ML  ... maybe a bug somewhere? why the difference?

and now check the weights and action freqs ... 

plw

savefig('gif/20feb27_rewards_weights_b1.png')

#
ldown,lup = [],[]
ltt = linspace(0,99,100)
for tt in ltt:
  actrewards = actreward[(actreward.action==3) & (actreward.time>=tt*1e3) & (actreward.time<=(tt+1)*1e3)]
  ldown.append(len(actrewards))
  actrewards = actreward[(actreward.action==4) & (actreward.time>=tt*1e3) & (actreward.time<=(tt+1)*1e3)]
  lup.append(len(actrewards))

figure(); plot(ltt,ldown,'r',linewidth=4); plot(ltt,lup,'b',linewidth=4); xlabel('Time (s)'); ylabel('Move frequency (Hz)');
import matplotlib.patches as mpatches
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','r'],['Up','Down'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/20feb27_action_freq_b2.png')

so, there are more down actions generally ..., particularly as the sim progresses ... maybe less consistent
than in previous FAKE MOVEUP test ...

not clear why would get diff results for the two fake rule tests ... one up and one down ... maybe some bug,
or some runaway effect ... 

could run another test to see if teach net to hold paddle still ... leading to suppression of ML and MR ...

ok, will try that ... with this sim name: 20feb27_FakeStayRule_C0_
and RLFakeStayRule == 1

note that any move up or down (in the 5 action block) is a penalty and any stay command is opposite (for the critic signal)... 

myrun 16

  Cells: 1209
  Connections: 27879 (23.06 per cell)
  Spikes: 173771 (1.44 Hz)
  Simulated time: 100.0 s; 16 workers
  Run time: 2286.23 s
Saving output as data/20feb27_FakeStayRule_C0_simConfig.pkl ... 
Finished saving!
Done; saving time = 11.18 s.

savefig('gif/20feb27_FakeStayRule_C0_raster.png')
lower firing rates for MR, ML ... next, look at behavior and weights...

plw

savefig('gif/20feb27_FakeStayRule_C0_rewards_weights_c0.png')

both sets of weights stay close to baseline ... 
would have expected both sets to decrease towards 0

savefig('gif/20feb27_FakeStayRule_C0_action_freq_c0.png')

well, at least neither action dominates here ...

*20feb28
** continue 

should make it easier to load the output data ... maybe consolidate plotting funcs too ...

question about architecture - how much of the higher level areas do we need/want? and should
allow easier scaling of the simulation in case need larger-sized populations  ... 

homeostatic plasticity will likely be needed - the weights were increasing, and could push
the net to epilepsy ...

try full architecture with the fake rules ... possible that higher order connections are not a problem ...

myrun 24

looks like M population might be too small ... ML and MR neurons should receive largely overlapping inputs from V1
because of the much higher number of V1 (400) compared to ML (25) and MR (25) neurons , with the high convergence (16)
this might be reason see highly synchronous firing in ML, MR neurons and correlation between the weight changes for the
fake tasks... whether or not topography is needed for ML,MR is unclear - random inputs may allow more complex encodings.
but can at least try increasing populaion size of ML, MR.

try that out ...

also, looks like noise inputs are off ... may want to reintroduce them ...
other source of artificial synchronization is the image inputs, which arrive to the network at a fixed interval (~30 ms?)

adjusted some of the convergence/weights onto ML,MR to have same convergence from each V1,V4,IT source
and lower weights 1/2 of original to prevent too high firing ...

savefig('gif/20feb28_rast_a0.png')
savefig('gif/20feb28_reward_weights_a1.png')
some separation between them in all projections ...
savefig('gif/20feb28_action_freq_a2.png')

try same, but longer ...

125 s ...

  Cells: 1359
  Connections: 38281 (28.17 per cell)
  Spikes: 484922 (2.85 Hz)
  Simulated time: 125.0 s; 16 workers
  Run time: 2823.09 s
Saving output as data/20feb28_A0_simConfig.pkl ... 
Finished saving!
Done; saving time = 97.79 s.

savefig('gif/20feb28_rast_b0.png')
rates go up too much ... another indication that need some form of homeostasis

savefig('gif/20feb28_reward_weight_b1.png')

#
ldown,lup = [],[]
ltt = linspace(0,124,125)
for tt in ltt:
  actrewards = actreward[(actreward.action==3) & (actreward.time>=tt*1e3) & (actreward.time<=(tt+1)*1e3)]
  ldown.append(len(actrewards))
  actrewards = actreward[(actreward.action==4) & (actreward.time>=tt*1e3) & (actreward.time<=(tt+1)*1e3)]
  lup.append(len(actrewards))

figure(); plot(ltt,ldown,'r',linewidth=4); plot(ltt,lup,'b',linewidth=4); xlabel('Time (s)'); ylabel('Move frequency (Hz)');
import matplotlib.patches as mpatches
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','r'],['Up','Down'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)
xlim((0,125))

savefig('gif/20feb28_move_rate_b2.png')
ok, clearly moving up more than down after training ... (as it should)

can try training in DOWN direction as precaution or run actual game test ...

will try game test ...

ok running this with no fake rule, and duration of 250e3 ... 
"20feb28_G0_"

if there was a weaker opponent, might be easier to train as starting point?
or play against self ...
does openai allow controlling difficulty level of opponent?

well, did see the model score a point...but pretty rare so far ...
intermediate rewards after ball contacts racket might be sensible, though less generic...
can also have multidimensional error for reward/punishment, consisting of distance
between racket/ball (0.25), contact with racket (0.5), actual points (+1/-1)
or sign(current distance to ball - last distance to ball) -- but once using those
types of rules, no longer need the visual input at all ... 

separately, also need to be able to save/restore learned weights ...

stoped sim ~1/2 way through since it ends up mostly staying still, probably due to lot of punishments, as discussed before ...

openai allows easily saving mp4 videos ... added that option ...

ok, will set wbase to starting level, since starts with pretty low level of firing anyway ...

can also reduce the frequency of saving the synaptic weights ...

  Cells: 1359
  Connections: 38281 (28.17 per cell)
  Spikes: 986134 (1.45 Hz)
  Simulated time: 500.0 s; 24 workers
  Run time: 11678.73 s
  Saving output as data/20feb28_G0_simConfig.pkl ...

savefig('gif/20feb28_rast_g0.png')  

movie is useful: videos/20feb28_G0_/openaigym.video.0.24912.video000000.mp4
but only lasts a single episode  which took ~35 s, so lost viewing movie activity from most of the sim ...

simdat

savefig('gif/20feb28_reward_weights_g0.png')  

reward frequency might increase over time ... ? weights certainly have not stabilized yet
and although rewards compared to punishments are much less frequent, they still influence
the weights substantially - the weights are not at minimum ...

so, need to allow movies generated to encompass entired simulation, and to allow setting
the initial weights to the final ones generated by previous run ...

*20feb29
** run longer - check if video saved after each episode

ran but did not save data:
Done; run time = 37584.81 s; real-time ratio: 0.04.
ran out of memory...

Gathering data...
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
[zn:32842] *** Process received signal ***
[zn:32842] Signal: Aborted (6)
[zn:32842] Signal code:  (-6)
[zn:32842] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x12890)[0x7f3ec802f890]
[zn:32842] [ 1] /lib/x86_64-linux-gnu/libc.so.6(gsignal+0xc7)[0x7f3ec7c6ae97]
[zn:32842] [ 2] /lib/x86_64-linux-gnu/libc.so.6(abort+0x141)[0x7f3ec7c6c801]
[zn:32842] [ 3] /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0x8c957)[0x7f3ec84e0957]
[zn:32842] [ 4] /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0x92ab6)[0x7f3ec84e6ab6]
[zn:32842] [ 5] /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0x92af1)[0x7f3ec84e6af1]
[zn:32842] [ 6] /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0x92d24)[0x7f3ec84e6d24]
[zn:32842] [ 7] /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0x9329c)[0x7f3ec84e729c]
[zn:32842] [ 8] /usr/site/../arch/nrn/share/nrn/../../x86_64/lib/libnrnpython3.so(+0x1bd7a)[0x7f3ea9420d7a]
[zn:32842] [ 9] /usr/site/../arch/nrn/x86_64/lib/libnrniv.so.0(+0xb4227)[0x7f3eca326227]
[zn:32842] [10] /usr/site/../arch/nrn/x86_64/lib/libnrnoc.so.0(hoc_call_ob_proc+0x23a)[0x7f3eca5f1d7a]
[zn:32842] [11] /usr/site/../arch/nrn/x86_64/lib/libnrnoc.so.0(hoc_object_component+0x51e)[0x7f3eca5f2a8e]
[zn:32842] [12] /usr/site/../arch/nrn/share/nrn/../../x86_64/lib/libnrnpython3.so(+0xef3a)[0x7f3ea9413f3a]
[zn:32842] [13] /usr/site/../arch/nrn/share/nrn/../../x86_64/lib/libnrnpython3.so(+0x141fb)[0x7f3ea94191fb]
[zn:32842] [14] /usr/site/../arch/nrn/x86_64/lib/libnrniv.so.0(_ZN10OcJumpImpl7fpycallEPFPvS0_S0_ES0_S0_+0x3e)[0x7f3eca2ff5fe]
[zn:32842] [15] /usr/site/../arch/nrn/share/nrn/../../x86_64/lib/libnrnpython3.so(+0xeb37)[0x7f3ea9413b37]
[zn:32842] [16] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(_PyObject_FastCallDict+0x8a)[0x7f3ea97d424a]
[zn:32842] [17] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(+0x2084b7)[0x7f3ea98504b7]
[zn:32842] [18] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(_PyEval_EvalFrameDefault+0x3373)[0x7f3ea97a6153]
[zn:32842] [19] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(+0x208063)[0x7f3ea9850063]
[zn:32842] [20] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(+0x208616)[0x7f3ea9850616]
[zn:32842] [21] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(_PyEval_EvalFrameDefault+0x3373)[0x7f3ea97a6153]
[zn:32842] [22] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(+0x208063)[0x7f3ea9850063]
[zn:32842] [23] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(PyEval_EvalCodeEx+0x3e)[0x7f3ea9850a6e]
[zn:32842] [24] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(PyEval_EvalCode+0x1c)[0x7f3ea97a2b2c]
[zn:32842] [25] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(PyRun_FileExFlags+0xb7)[0x7f3ea97344d7]
[zn:32842] [26] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(PyRun_SimpleFileExFlags+0xf4)[0x7f3ea9738734]
[zn:32842] [27] /usr/site/../arch/nrn/share/nrn/../../x86_64/lib/libnrnpython3.so(nrnpy_pyrun+0x2c)[0x7f3ea941323c]
[zn:32842] [28] /usr/site/../arch/nrn/share/nrn/../../x86_64/lib/libnrnpython3.so(nrnpython_start+0x288)[0x7f3ea9413888]
[zn:32842] [29] nrniv(ivocmain+0x5cb)[0x563f75882bfb]
[zn:32842] *** End of error message ***
--------------------------------------------------------------------------
mpiexec noticed that process rank 0 with PID 0 on node zn exited on signal 6 (Aborted).
--------------------------------------------------------------------------

so will probably have to run simulation for shorter duration ...

*20mar1
** run 750 s again - adjust critic for punishments

can try critic with -0.1 or -0.01 so it's less pronounced compared to reward

750 s, with critic at -0.01 ...

myrun 24

*20mar2
** continue - look at output from last sim

  Cells: 1359
  Connections: 38281 (28.17 per cell)
  Spikes: 3478200 (3.41 Hz)
  Simulated time: 750.0 s; 24 workers
  Run time: 18652.00 s
Saving output as data/20mar1_G2_simConfig.pkl ... 
Finished saving!
  Done; saving time = 83.59 s.
Plotting recorded cell traces ... cell
QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-samn'
Plotting raster...
Saving figure data as data/20mar1_G2_RasterData.pkl ... 
  Done; plotting time = 1282.06 s

savefig('gif/20mar2_G2_Raster.png')
  
savefig('gif/20mar2_G2_reward_weights.png')

ok, weights do not have as much time to decay now ...

but still need a way to save/restore the weights, and produce videos capturing whole simulation ...

*20mar5 - testing on laptop after conda/neurosim setup 
** conda/packages

had installed anaconda with python36 and then recompiled neuron, etc.

for ffmpeg if you're on ubuntu & have root can use sudo apt-get install ffmpeg

py3env <<-- that now sets conda to use py36
conda install numpy
conda install scipy
conda install pandas
conda install matplotlib
used new version of netpyne from github (development branch) with pip after activating the conda
env above; note that netpyne does not support latest matplotlib or latest pandas (sal mentioned
bug in those latest versions)

this is the alias in .tcshrc for setting the py env with conda:
alias py3env 'alias py3env setenv NSUF 'py3';source /usr/site/config/nrnenv.csh; setenv PYTHONPATH {$PYTHONPATH}:/usr/site/nrniv/local/python; conda activate py36'

once that env is activated can just use pip (it points to the right pip3 for that py env) and
don't have to explicitly indicate pip3

myrun 16

here's first error:

ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.22' not found
(required by
/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/fft/_pocketfft/pypocketfft.cpython-36m-x86_64-linux-gnu.so)

according to : https://github.com/facebookresearch/detectron2/issues/609
should do:
conda update libgcc

PackageNotInstalledError: Package is not installed in prefix.
  prefix: /usr/site/nrniv/local/python/anaconda3/envs/py36
  package name: libgcc

conda install libgcc

ok, that fixed that problem ...

next error:
python
import sim
ModuleNotFoundError: No module named 'skimage'

conda install skimage

not found ...

it's scikit-image

conda install scikit-image

and also need openai gym
can install with conda as:
conda install -c akode gym

hmm, did not find it ...

ok, just use pip ...

pip install gym

pip install 'gym[atari]'

sudo add-apt-repository ppa:ubuntu-toolchain-r/test
sudo apt-get update
sudo apt-get install gcc-4.9
sudo apt-get install --only-upgrade libstdc++6

ok, that fixed error ... based on this:
 https://github.com/lhelontra/tensorflow-on-arm/issues/13#issuecomment-489296444

myrun 12

also have this in pythonpath:
 setenv PYTHONPATH {$PYTHONPATH}:$ND/share/python/lib/python:/usr/site/nrniv/local/python

*20mar6 - long run with restarts?
** testing

since haroon implemented weight save/restore, could let it run a few times with restarts ...

may not need to save video for now ... could instead run video once run a few rounds of training
...

*20mar8 - notes on changes
** started setting up multistepSim.py
which generates run file to call a few sims in a row, with each one reloading weights saved from
end of previous run; still testing - not working properly yet

** noticed on mar6 that the temperature was wrong (6.3 instead of 37)
changing temperature required readjusting the connection weights between cells
added the standard cfg. EEGain, EIGain, IEGain, IIGain to allow easier modulation of
these weights

this also required changing threshold for spikes - however, voltage traces do not currently
look great, so this will require some further adjustment. may want to use simple models of
PV cells nad or PYR cells ... although their dynamics with multiple ion channels will be
more costly than simpler standalone HH

** also changed population names so they'd be consistent
some populations seemd to have inconsistent names
now always using E as prefix for excitatory population and I as prefix for inhibitory population

** ran fake up rule test with new setup

produced higher weights for expected population

*20mar8 - fix for multistepsim, run test
** multistep test - still not working properly? fixed ... 

python multistepSim.py sim.json 16 2 multirun

individual sims do not stop after plot ... ?

ok, fixed problems ... conf.py was not reading correct json, was not passing it to sim.py either, etc.

** replace cell types?

voltage traces don't look great now after temp adjustment ...

** try a multistepsim test run with game (300 s run with 12 steps = 1 hr.)

not using fake rules ...

python multistepSim.py sim.json 16 12 multirun

*20mar9 - adjustments to cell types/architecture
** code reorg - moved mod files to mod subdir; moved cell types to cells subdir; compile script (nrnivmodl mod)
** HA added Mainen PYR2 and FS basket cells to model
this then required adjusting weights and...
** adjusted rules to have AMPA synapses of PYR on dend; AMPA of I cells on soma; GABAA for E,I on soma
** ...then had to adjust architecture slightly (new interneuron population)
to include IM interneuron population in motor area; this reduces likelihood of depolarization blockade
of the EMR and EML populations (seems to work after some adjustment to the weights)
a 10 s run shows one population of EM neurons firing faster than the other leading to paddle
staying at top of screen for much of the sim - not sure where this assymetry comes from

right now there's one interneuron population in M area providing feedback inhibition onto both EM and ER
populations; in future may want multiple interneuron populations that receive excitation from one population
and suppress the other (easy to implement in netpyne, but thought that might lead to further positive feedback
and one EMR vs EML population dominating the dynamics)

still, where does the assymetry come from?

*20mar10 - adjustments to connectivity, thresholds, E/I balance
** using dnumc as dictionary for number of cells
** set different thresholds for E and I cells (lower for I cells) via cellRule

netParams.cellParams['PYR_Mainen_rule']['secs']['soma']['threshold'] = 0.0
netParams.cellParams['FS_BasketCell_rule']['secs']['soma']['threshold'] = -10.0

** lack of symmetry fix? use convergence instead of probability

probably due to higher/lower number of inputs from IM to EMR vs EML
can fix that via using convergence rather than random connectivity

conv = pmat[from][to] * numc[from]

ok, try that with fake up rule ... 

myrun 16

hmm, something messed up ... was getting too much dep blockade ... 

ok, after adjusting the thresholds, other connection weights and gains ...

(note that IV4 was acting differently since receives extra inhibition from the large IV1 population; reduced
the weights from IV1 -> IV4 to reduce that effect)

get more reasonable raster, with higher I than E rates ... 

savefig('gif/20mar10_rast_a0.png')

testing fake up rule for 10 s ... still stable at end ...

raster looks ok:
savefig('gif/20mar10_rast_a1.png')
cells look ok:
savefig('gif/20mar10_IM_a1.png')
savefig('gif/20mar10_EMR_a1.png')
savefig('gif/20mar10_EML_a1.png')
savefig('gif/20mar10_IIT_a1.png')
savefig('gif/20mar10_EIT_a1.png')
savefig('gif/20mar10_IV4_a1.png')
savefig('gif/20mar10_EV4_a1.png')
savefig('gif/20mar10_IV1_a1.png')
savefig('gif/20mar10_EV1_a1.png')
savefig('gif/20mar10_IR_a1.png')
savefig('gif/20mar10_ER_a1.png')

and the weights ?
simdat
savefig('gif/20mar10_reward_weights_a1.png')
weights look biased towards correct population
(note that only recording weights every 1 s here, while reward signal recorded every 0.1 s so
cannot always see correspondence closely in figure above)

** Note: should change R and L to up and down (as appropriate)!
EMR, EML population names

** meanwhile, try multistep test again

python multistepSim.py sim.json 16 12 multirun

that did not seem to work ... paddle ends up becoming stationary after a while ...
probably too much punishment suppressing EMR,EML

*20mar11
** add noise?
** check haroon's updated intermediate reward rules

has these in sim.json:
"rewardcodes": {"scorePoint": 1, "losePoint": -0.01, "followBall": 0.001, "avoidBall": -0.001, "hitBall": 0.05},

will reward following ball and hitting ball more ... take a look to see if works, etc.

can try:
"rewardcodes": {"scorePoint": 1, "losePoint": -1, "followBall": 0.5, "avoidBall": -0.001, "hitBall": 0.75},

myrun 16

*20mar24
** discussion on retinal circuitry, movement selectivity

14:22
samn this paper looks useful https://senselab.med.yale.edu/ModelDB/ShowModel?model=116837&file=/RM_STDP/#tabs-1
14:23
https://paperpile.com/app/p/f2db9a70-4380-0c3c-9bc0-36a1fc7402f9
14:24
haroon found this paper for motion selectivity in retina: https://paperpile.com/app/p/7b54db25-10b2-0afe-af21-4538acf0def0
14:26
not sure if that model has retina with motion selectivity
14:28
here's another: https://senselab.med.yale.edu/ModelDB/ShowModel?model=118524#tabs-1
14:28
"virtual retina"
14:28
Haroon Anwar looks very phenomenological
14:29
samn https://paperpile.com/app/p/4c5b9cb8-6eb7-00f2-b3c9-fa42ea6d2595
14:30
"Abstract We propose a new retina simulation software, called Virtual Retina, which transforms a video into spike trains. Our goal is twofold: Allow large scale simulations (up to 100,000 neurons) in reasonable processing times and keep a strong biological plausibility, taking into account implementation constraints. The underlying model includes a linear model of filtering in the Outer Plexiform Layer, a shunting feedback at the level of bipolar cells accounting for rapid contrast gain control, and a spike generation process modeling ganglion cells. We prove the pertinence of our software by reproducing several experimental measurements from single ganglion cells such as cat X and Y cells. This software will be an evolutionary tool for neuroscientists that need realistic large-scale input spike trains in subsequent treatments, and for educational purposes"
14:30
maybe worth trying that if it has motion selectivity ... or check if can replicate relevant aspects of model
14:32
Haroon Anwar doesn’t look like- as i didnt find any keyword ‘direction’
14:33
samn does it emerge from the circuitry?
14:35
that one or different one, let's see if we can find good model that has the features needed and/or whether to replicate
14:38
Haroon Anwar may be--but if we can come up with a simpler circuit to implement direction selectivity of  ganglion cells, would prefer that….seems not difficult
14:38
samn ok - if you have an idea
14:38
Haroon Anwar the difficult part is how such information is carried out along the dorsal stream
14:39
and presented in V1, IT etc
14:39
samn if you have a simple circuit that can accomplish what we need, good
14:39
Haroon Anwar at input level. should be straight forward
14:39
at later stages-not sure
14:40
samn ok, can try first stages first...then wire it to higher after
14:40
Haroon Anwar ok
14:40
thanks
14:40
samn was that figure you shared from review paper enough to produce direction selectivity?
14:41
Haroon Anwar this shows the circuitry involved ----so its part of it…not complete
14:42
Screen Shot 2020-03-24 at 2.12.16 PM.png 
Screen Shot 2020-03-24 at 2.12.16 PM.png
14:42
how we arrange Bipolar inputs is not shown here
14:43
topologically bipolar inputs
14:43
samn some of this may be relevant: some of these papers look relevant too: https://www-sop.inria.fr/members/Pierre.Kornprobst/
14:43
hmm, since you already have the temporally decaying activation ... would it be simpler to take differences between current and previous frame and calculate direction vectors then feed to another population?
14:44
to avoid additional detailed circuitry
14:45
Haroon Anwar minimally we will have to add neurons which are not only showing position but all direction
14:45
right now its only position
14:45
samn right
14:45
Haroon Anwar so need more for direction
14:45
samn just question of whether to have circuit compute directions or to estimate it ourselves from images (optic flow)
14:46
Haroon Anwar yes thats simple way, can do that
14:46
samn ok sg

WikipediaWikipedia
Optical flow
Optical flow or optic flow is the pattern of apparent motion of objects, surfaces, and edges in a visual scene caused by the relative motion between an observer and a scene. Optical flow can also be defined as the distribution of apparent velocities of movement of brightness pattern in an image. The concept of optical flow was introduced by the American psychologist James J. Gibson in the 1940s to describe the visual stimulus provided to animals moving through the world. Gibson stressed the importance of optic flow for affordance perception, the ability to discern possibilities for action within the environment.  Followers of Gibson and his ecological approach to psychology have further demon… Show more(531 kB)
https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Opticfloweg.png/1200px-Opticfloweg.png
14:46
probably some of those image processing functions you're using can calculate that for you
14:46
Haroon Anwar right
14:47
OK - so will include the direction precomputed
:+1:
1
14:47
samn sg
14:50
if anyone else saw relevant approaches, let us know

*20mar25
** zlib error

cd ~/SM*
py3env
myrun 16

ImportError: /lib/x86_64-linux-gnu/libz.so.1: version `ZLIB_1.2.9' not found (required by
/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/site-packages/matplotlib/../../.././libpng16.so.16)

https://stackoverflow.com/questions/48306849/lib-x86-64-linux-gnu-libz-so-1-version-zlib-1-2-9-not-found

fix?

download:
https://sourceforge.net/projects/libpng/files/zlib/1.2.9/zlib-1.2.9.tar.gz/download

then:
cd ~/Downloads
tar -xvf ~/Downloads/zlib-1.2.9.tar.gz
cd zlib-1.2.9
sudo -s
./configure; make; make install
cd /lib/x86_64-linux-gnu
ln -s -f /usr/local/lib/libz.so.1.2.9/lib libz.so.1
cd ~/Downloads
rm -rf zlib-1.2.9

cd ~/SM*
myrun 16

ok, runs now without an error ...

** check dynamics
** how to implement direction selectivity

use optical flow on successive images to produce movement vectors at each coordinate.

then, need at least 4X number of pixels to represent the movement info from frame to frame?
and it has to be topographically arranged

...where does each pixel of movement selective neurons project?

*20mar31
** back to testing

myrun 16

*20apr1
** fixing up plotSpatioTemporalActivity.py

myrun 16

python -i plotSpatioTemporalActivity.py

seems to work now ... there weren't any loops, functions, dictionaries, etc.
really used in the file ...

*20apr7
** sal code for animation

def animateRateVsWeight(dataFolder, batchLabel, params):
    import imageio
    from pathlib import Path
    Lvals = params[0]['values']
    Ivals = params[1]['values']
    for ipop, pop in enumerate(Lvals):
        print('Generating traces gif for pop %s ...' % (pop))
        #v22_batch1_18_98_traces.png
        images = ['%s/%s/%s_%d_%d_traces.png' % (dataFolder, batchLabel, batchLabel, ipop, iweight) for iweight in range(len(Ivals))]
        #images = list(image_path.glob())
        image_list = []
        for file_name in images:
            image_list.append(imageio.imread(file_name))
        pass
        imageio.mimwrite('%s/%s/%s_%s_traces.gif' % (dataFolder, batchLabel, batchLabel, pop), image_list)

should adapt for plotSpatioTemporalActivity.py to allow saving output
and/or for video ...

** test update

a lot more cells now (1e3 more motor cells, and 800 direction selective cells), so runs slower,
+ image processing slows it down some more ... not clear by how much

python -i plotSpatioTemporalActivity.py

fig, axs, plt = plotActivityMaps(pauset=0,gifpath='20apr7_activity.gif')

*20apr8
** save spatiotemporal activity as movie instead (using ffmpeg)

could use imageio ffmpeg interface
https://imageio.readthedocs.io/en/stable/format_ffmpeg.html#parameters-for-saving

or ffmpeg-python https://github.com/kkroening/ffmpeg-python
though that is more comprehensive, so may not need full package installed ...

https://imageio.readthedocs.io/en/stable/examples.html#writing-videos-with-ffmpeg-and-vaapi

https://github.com/imageio/imageio-ffmpeg

pip install imageio-ffmpeg

should have used conda to install
with
conda install imageio-ffmpeg -c conda-forge
but without the ffmpeg binary

python -i plotSpatioTemporalActivity.py

lfnimage = ['/tmp/'+str(x)+'.png' for x in range(1,50,1)]
limage = [imageio.imread(fn) for fn in lfnimage]


from imageio_ffmpeg import write_frames

w = imageio.get_writer('my_video.mp4', format='FFMPEG', mode='I', fps=1,
                       codec='h264_vaapi',
                       output_params=['format=gray'],
                       pixelformat='gray')

for img in limage: w.append_data(img)                       

w.close()

gen = write_frames('test.mp4', (limage[0].shape[0],limage[0].shape[1],limage[0].shape[2]), pix_fmt_in="gray")
gen.send(None)  # seed the generator
for img in limage: gen.send(img)
gen.close()  # don't forget this

hmm, getting errors ... ffmpeg-python seems easier to use?

pip install ffmpeg-python

import ffmpeg
(
    ffmpeg
    .input('/tmp/*.png', pattern_type='glob', framerate=10)
    .output('movie.mp4')
    .run()
)

that works ... fast to run and makes small files

ok, put that into plotSpatioTemporalActivity.py ...

and added animation saving functions to anim.py

** testing network

number of IM was too low, after the increase in EMR, EML populations
so increased IM to 690, to be about 20% of IM (690) + EMR (1350) + EML (1350)

now, when run network, get too high firing rates for EMR, EML

savefig('gif/20apr8_rast_a0.png')

is same obtained with fewer IM cells?

reset IM to 50 ... 

myrun 12

hmm, now EMR,EML firing rates look better, but not clear why. no depolarization
blockade seen in EMR,EML

savefig('gif/20apr8_rast_a1.png')

check connectivity in sim.py ... something off?

might be due to using fixed convergence instead of probability ... for larger pop sizes
seems better to use probability ... had used convergence before to ensure minimum number
of inputs (more relevant with smaller populations)

try with probability of 0.25 and larger IM population of 690 ...

myrun 12

ok, rates of EMR, EML went down, and IM rates are OK
but now activity looks highly synchronized to 100 ms interval when visual inputs come in:
 gif/20apr8_rast_a2.png
 gif/20apr8_EMR_a2.png
 gif/20apr8_IM_a2.png

so, should avoid it ... probably can reduce weights between EMR->IM, EML->IM, IM->IM, IM->EMR, IM->EML

can try cutting probabilities between those populations in half (from 0.25 to 0.125)

myrun 12

savefig('gif/20apr8_rast_a3.png') 
looks ~same

try cutting down probabilities further ... 0.0625

myrun 12

little better ...

gif/20apr8_rast_a4.png
gif/20apr8_EMR_a4.png
gif/20apr8_IM_a4.png

should run longer to see if remains stable ... 
some of the other E vs I populations have wrong rates, e.g. EV4 faster than IV4, EV1 faster than IV1
EMT only a little slower than IMT
and no inhibitory populations in the direction selective cells...

run for 5 s to see if patterns similar, then may consider adjusting weights/probabilities further ...

myrun 12

ok, looks like decent rates ... less synchrony ... should be OK for now ... can adjust further as needed ... 
gif/20apr8_rast_a5.png
gif/20apr8_rast_a5b.png <- some alternation between synch and asynch state
gif/20apr8_IM_a5.png
gif/20apr8_EMR_a5.png
gif/20apr8_EML_a5.png

python -i actmap.py

made this movie: data/20april08_A0__movie.mp4

** try longer sim ("name":"20april08_B0_")

to test and watch output ...

"rewardcodes": {"scorePoint": 1, "losePoint": -0.01, "followBall": 0.01, "avoidBall": -0.001, "hitBall": 0.25},

and duration of 100 s ...

myrun 12

started ~17:32 ...

finished @ ~22:15 ...

rates ok:
 gif/20apr8_rast_b0.png
 gif/20apr8_rast_b0b.png

cells look ok?
 gif/20apr8_IM_b0.png
 gif/20apr8_EML_b0.png
 gif/20apr8_EV1DSE_b0.png
 gif/20apr8_EV1DS_b0.png
 gif/20apr8_EV1_b0.png
 yeah, most cells look ok. some populations fire much less than others.
 direction cells - many directions not firing too mcuh (E, W), could be due to the
 ball mostly moving at a diagonal; but N,S higher since paddles move up,down
 
and now to create the movie ...

python -i actmap.py

*20apr9 - trying to speed up animation production
** continue

hmm, took > 12 hours so far to spit out the pngs up to 66 s, and hasn't even started on movie creation yet ...

should stop it and figure out how to speed up that process ...

can make movie from the frames that were produced so far

python
import anim
anim.savemp4('/tmp/*.png', 'data/20april08_B0_actmap.mp4', 10)

very slow encoding of mp4 ...

there's support in matplotlib for making animations and exporting to mp4 via ffmpeg but that's
slow too ...

imagemagick gif writing faster?

sudo apt-get install imagemagick

already have imagemagick ...

hmm, even the imagemagick gif writer is slow . . .

*20apr13 - animation fixing
** HA fixing collision detection code since not working in all cases
algorithm relies on position, direction, score
** movie fix

would concat of smaller mp4 files together run faster than producing one giant mp4?

https://stackoverflow.com/questions/7333232/how-to-concatenate-two-mp4-files-using-ffmpeg

could try ffmpeg concat demuxer : 

"Use this method when you want to avoid a re-encode and your format does not support file level
concatenation (most files used by general users do not support file level concatenation).

$ cat mylist.txt
file '/path/to/file1'
file '/path/to/file2'
file '/path/to/file3'

$ ffmpeg -f concat -safe 0 -i mylist.txt -c copy output.mp4"

hmm, problem seems to be that matplotlib takes longer and longer to save output files
in beginning, saves 15 files per minute, then gradually decreases to 5 per minute ...

and that's particularly true when setting figsize to high resolution values ...

might be due to matplotlib slowing down with all the redrawing ... not even having to do
with file saving ...

yes, not ffmpeg issue - ffmpeg runs very quickly once all frames are available ... so that
isolates slowness to matplotlib

this related issue mentions slowing down:
https://github.com/matplotlib/matplotlib/issues/16182

https://stackoverflow.com/questions/40747181/slow-ploting-using-animation-function-in-matplotlib-python
also relevant ...

fig, axs, plt = animActivityMaps(mp4path='test.mp4', framerate=10)

*20apr14
** HA made nice movie showing activity/dynamics/actions from random game (testPong.py)
will use it to generate similar with additional inclusion of network dynamics

** other movie fixes needed for simdat.py

first rerun sim for 10 s ... since now have a new column in ActionsRewards.txt

myrun 12

  Cells: 5349
  Connections: 1103176 (206.24 per cell)
  Synaptic contacts: 1105826 (206.74 per cell)
  Spikes: 78992 (1.48 Hz)
  Simulated time: 10.0 s; 12 workers
  Run time: 1974.00 s
Saving output as data/20april14_A0_simConfig.pkl ... 
Finished saving!
  Done; saving time = 82.23 s.
SAVING RASTER DATA
plot raster:
Plotting raster...
QApplication: invalid style override passed, ignoring it.
Saving figure data as 20april14_A0_raster.pkl ... 
Plotting recorded cell traces ... cell
Plotting raster...
Saving figure data as data/20april14_A0_RasterData.pkl ... 
  Done; plotting time = 30.80 s

Total time = 2191.62 s

End time:  2020-04-14 12:31:15.408575

output looks ok ... cells and rates in raster

20apr14_rast_a0.png
20apr14_rast_a0b.png
20apr14_EV1DN_a0.png
20apr14_EV1DS_a0.png
20apr14_EV1DSW_a0.png
20apr14_IMT_a0.png
20apr14_IV4_a0.png

let's see actmap.py ... then simdat.py

python -i actmap.py

produces
data/20april14_A0_actmap.mp4
fairly quickly...

and simdat.py ...

python -i simdat.py -1

that calls
plotSynWeightsPerTimeStep(pdf,pauset=1,mp4path='data/'+dconf['sim']['name']+'weightmap.mp4', framerate=10) #plot images

python -i simdat.py -1

** discussion on smooth direction selective RFs

13:17
samn btw, should E neurons always fire (but at a slower rate) when NE neurons fire?
13:17
since they're not orthogonal directions
13:17
Haroon Anwar no
13:17
samn why
13:18
Haroon Anwar E is between 337.5 degrees and 22.5 degrees
13:18
and NE is between 22.5 and 67.5 degrees
13:19
360 is divided into 8 angular regions
13:19
and each population is assigned that
13:19
samn understand but that means sharp cutoffs
13:19
Haroon Anwar right
13:19
samn could also have smooth fall-off and smoother receptive fields
13:19
Haroon Anwar possible
13:20
might be a good idea…
13:20
samn can put that on list for later
13:20
seems more realistic (?)
13:21
Haroon Anwar sure…more realistic
13:21
samn do all neurons of a population have exact same receptive field?
13:21
Haroon Anwar will also reduce number of neurons
13:21
because we could have directions coded using 4 pops instead of 8
13:22
NE will evoke e.g. 5 Hz in N and 5 Hz in E
13:22
if its exactly 45 degrees
13:22
samn you could have it with 1 pop probably too if you had receptive fields with some width tuning
13:22
width to the receptive field around a mean angle
13:22
Haroon Anwar that would be unrealistic
13:23
samn why?
13:23
Haroon Anwar we have neurons with very fine tuned directions
13:23
1 pop would not be able to encode all directions
13:23
samn it would be 1 pop in the model
13:23
where each neuron selects a mean angle randomly
13:23
then overall you'd have representations in all directions
13:24
Haroon Anwar ok --- yes possible that way---
13:24
implementation might be a bit tricky----but yes possible
13:25
samn tricky for how they project to other areas?
13:25
Haroon Anwar or assigning firing rates to each of the neurons in that pop
13:25
and generating connection lists
13:25
but yeah thats more realistic
13:26
samn if each one had a location in space and there were enough of the full directions in any locatin, seems ok
13:26
anyway, can put that on list of things to adjust. reducing # of neurons could help as you said
13:27
Haroon Anwar yes definitely to do list--- i need to think.. may be its not as difficult as i think right now…. but i will think about it
13:27
samn ok sg
13:28
Haroon Anwar will look at it after performance analysis---
13:28
samn sg

*20apr15
** continue fixup of animSynWeights in simdat.py

this example animation https://matplotlib.org/gallery/animation/basic_example.html
shows how to set line data dynamically ...

and simpler way to save to mp4

animSynWeights(pdf,'data/'+dconf['sim']['name']+'weightmap.mp4', framerate=10) #plot/save images as movie

ok, works faster now ...

but some of the text is not visible ... adjust size of fig

python -i simdat.py -1
animSynWeights(pdf,'data/'+dconf['sim']['name']+'weightmap.mp4', framerate=10, figsize=(8,6)) #plot/save images as movie

animSynWeights(pdf,'data/'+dconf['sim']['name']+'weightmap.mp4', framerate=10, figsize=(7,5)) #plot/save images as movie

also turn off interactive mode during animation, goes faster...

animSynWeights(pdf,'data/'+dconf['sim']['name']+'weightmap.mp4', framerate=10, figsize=(7,4)) #plot/save images as movie

** discuss opt (image processing for direction selective neurons vs population reduction)
** looking through code for what to optimize/improve

moved some connection functions from sim.py to connUtils.py

cleaned up some of the code that calculates firing rates based on image contents
to use dictionaries and loops instead of previous code duplication ...

that cleanup will help with modifications in future ...

tested network with short run after first adjustments

myrun 12

20april15_A0_rast.png
20april15_A0_EMR.png
20april15_A0_IM.png
20april15_A0_EV4.png
20april15_A0_EV1DS.png

looks ok ...

check videos ...

python -i simdat.py -1

data/20april15_A0_weightmap.mp4

python -i actmap.py

data/20april15_A0_actmap.mp4

looks ok ... should try more thorough tests to make sure nothing broken ...

*20apr16
** cleaning up code in aigame.py

moved motion computations to separate function in aigame.py
should move pong-specific code to separate place too

myrun 12

python -i simdat.py -1

data/20april16_A0_weightmap.mp4

python -i actmap.py

data/20april16_A0_actmap.mp4

*20apr17
** continue adjustments/cleanup

myrun 12

hmm, getting depolarization blockade and black input images
values were between 0-1 after rgb2gray, so need to multiply by 255

try again ...

after Haroon's last fix (input firing rates re-adjusted), no dep blockade with the newer version of the code/image processing...

run a bit longer

myrun 12

10 s sim

Total time = 1888.37 s

20april17_A0_rast.png

rates look ok, as do neuron membrane potentials ...

python -i actmap.py

data/20april17_A0_actmap.mp4

python -i simdat.py -1

data/20april17_A0_weightmap.mp4

looks interesting but does not seem to improve over 10 s ... can run longer ...

try longer ...

100 s ...

myrun 12

Total time = 16952.75 s

End time:  2020-04-18 04:30:30.562465

*20apr18
** check output from last run

20april17_A0B_EV1DN.png
20april17_A0B_EV1DW.png
20april17_A0B_EV1DS.png
20april17_A0B_EV1D4.png
20april17_A0B_IV1.png
20april17_A0B_IMT.png
20april17_A0B_EMT.png
20april17_A0B_IM.png
20april17_A0B_rast.png
20april17_A0B_rastB.png

rates and activity looks ok

some populations almost silent EV1DE (east direction sensitive; maybe get rid of them or adjust/reduce numbers?)

python -i simdat.py -1

data/20april17_A0_weightmap.mp4

python -i actmap.py
data/20april17_A0_actmap.mp4

does not improve in terms of following ball after 100 s ... can run longer ...

can continue for 100 s from there ... see if it improves at all ...

"simtype": {"ResumeSim":1,"ResumeSimFromFile":"20april17_A0_simConfig.pkl"},

"sim": {"duration": 100000, "dt": 0.2, "verbose": 0, "recordStep":0.2,"recordWeightStepSize":1,"RLFakeUpRule": 0,"RLFakeDownRule": 0,"RLFakeStayRule": 0,"name":"20april18_B0_","doquit":0,"doplot":1},

myrun 12

hmm, restore sim not working ... can run for 200 s ... see if improves ... fix resume later ...

    "simtype": {"ResumeSim":0,"ResumeSimFromFile":"20april17_A0_simConfig.pkl"},        
    "sim": {"duration": 200000, "dt": 0.2, "verbose": 0, "recordStep":0.2,"recordWeightStepSize":1,"RLFakeUpRule": 0,"RLFakeDownRule": 0,"RLFakeStayRule": 0,"name":"20april18_A0_","doquit":0,"doplot":1},

myrun 12    
*20apr22 - RFs for direction selective neurons
** add gaussian profile to direction selective neurons

most of that can go into aigame.py where the rates for those neurons are set

may want to try other optical flow algorithm first ... might be faster to
use a standard implementation

https://scikit-image.org/docs/dev/auto_examples/registration/plot_opticalflow.html#sphx-glr-auto-examples-registration-plot-opticalflow-py

"By definition, the optical flow is the vector field (u, v) verifying image1(x+u, y+v) =
image0(x, y), where (image0, image1) is a couple of consecutive 2D frames from a sequence. This
vector field can then be used for registration by image warping."

try images saved from game ...

python

import numpy as np

Input_Images = np.loadtxt('data/20april21_A0_InputImages.txt')
New_InputImages = []
NB_Images = int(Input_Images.shape[0]/Input_Images.shape[1])
for x in range(NB_Images):
    fp = x*Input_Images.shape[1]
    cImage = Input_Images[fp:fp+20,:] # 20 is sqrt of 400 (20x20 pixels)
    New_InputImages.append(cImage)
New_InputImages = np.array(New_InputImages)

New_InputImages.shape # (10, 20, 20)

from pylab import *

ion()
imshow(New_InputImages[3,:,:],cmap='gray'); savefig('gif/20apr22_a0.png')
imshow(New_InputImages[4,:,:],cmap='gray'); savefig('gif/20apr22_a1.png')

from skimage.color import rgb2gray
from skimage.data import stereo_motorcycle
from skimage.registration import optical_flow_tvl1
# --- Convert the images to gray level: color is not supported.
image0 = New_InputImages[3,:,:]
image1 = New_InputImages[4,:,:]
flow = optical_flow_tvl1(image1, image0)

imshow(flow[0,:,:],cmap='gray'); savefig('gif/20apr22_a2.png')
imshow(flow[1,:,:],cmap='gray'); savefig('gif/20apr22_a3.png')

amin(flow[0,:,:]) # -29.32014
amax(flow[0,:,:]) # 16.496756
amin(flow[1,:,:]) # -19.863085
amax(flow[1,:,:]) # 32.638676

those colors don't have directions ... 

in the example here:
 https://scikit-image.org/docs/dev/auto_examples/registration/plot_opticalflow.html#sphx-glr-auto-examples-registration-plot-opticalflow-py

the two arrays returned by optical flow are the row and column displacements?

e.g.:
# --- Compute the optical flow
v, u = optical_flow_tvl1(image0, image1)
# --- Use the estimated optical flow for registration
nr, nc = image0.shape
row_coords, col_coords = np.meshgrid(np.arange(nr), np.arange(nc), indexing='ij')
image1_warp = warp(image1, np.array([row_coords + v, col_coords + u]), mode='nearest')

other simple code for motion detection/tracking:
 https://www.pyimagesearch.com/2015/05/25/basic-motion-detection-and-tracking-with-python-and-opencv/
more general ... uses opencv2

implemented exp decay in each direction as
           fctr = np.exp(-1.0*((theta-dAngPk[pop])**2)/AngSigma**2)
          print('updateDirSensitiveRates',pop,x,y,fctr,dAngPk[pop],motiondir[y][x])
          if fctr > 0.:
            self.dFiringRates[pop][y,x] = AngVal * fctr

with AngSigma as 45 ... (can tweak) and AngVal as 30
            
... ran a small test ... (still have to fix E direction!!)

gif/20apr22_rast_a4.png
gif/20apr22_EV1DS_a4.png

not sure what data/20april22_A0_randGameBehavior.mp4 is supposed to show but looks incomplete ... only runs
up to 50 ms ... yeah, used old files from hours ago ... should cleanup the pngs

python -i actmap.py

data/20april22_A0_actmap.mp4

looks OK but E needs to be fixed

python -i simdat.py -1

data/20april22_A0_weightmap.mp4

*20apr23 - RFs for direction selective neurons
** RFs for direction selective neurons

right now the RFs are setup to have peaks every 45 degrees with 45 degree sigma for exp fall-off
in magnitude of firing rate ...

could randomize directions between 0-360 degrees and potentially reduce number of direction selective neurons?
8 directions for RF is also somewhat limiting. movement can occur in other directions ...

or increase spread of RFs ...

also can change size of direction selective neuron populations ...

original values:
"net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":100,"EV1DNE":100,"EV1DN":100,"EV1DNW":100,"EV1DW":100,"EV1DSW":100,"EV1DS":100,"EV1DSE":100,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EML":1350,"EMR":1350,"IM":690,"AngRFSigma":45,"DirMinRate":0.0001,"DirMaxRate":30.0}

change to:
"net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":49,"EV1DNE":49,"EV1DN":49,"EV1DNW":49,"EV1DW":49,"EV1DSW":49,"EV1DS":49,"EV1DSE":49,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EML":1350,"EMR":1350,"IM":690,"AngRFSigma":90,"DirMinRate":0.0001,"DirMaxRate":30.0}

to cut the number of dir sensitive neurons in ~1/2 and have wider RFs...

sim name ... 20april23_A0

myrun 12

Done; run time = 432.66 s; real-time ratio: 0.00.

python -i actmap.py

data/20april23_A0_actmap.mp4

python -i simdat.py -1

data/20april23_A0_weightmap.mp4

right now there are 1350 EMR and 1350 EML neurons

reduced direction selection neurons from 10x10 to 7x7
and there are 8 pops, so 51*8=408 fewer neurons
then HA mentioned number of EMR is equal to number of all other E neurons projecting to them
so can reduce those as well ...

original EMR was 400 (EV1) + 100*8 (dir sensitive) + 100 (EV4) + 25 (EMT) = 1325
but there were 1350 ... 25 extra?

was supposed to be 1325

so new number for current architecture should be

400 + 49*8 + 100 + 25  = 917

try that one ... noticeable faster?

"net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":49,"EV1DNE":49,"EV1DN":49,"EV1DNW":49,"EV1DW":49,"EV1DSW":49,"EV1DS":49,"EV1DSE":49,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EML":917,"EMR":917,"IM":690,"AngRFSigma":90,"DirMinRate":0.0001,"DirMaxRate":30.0}

20april23_A1_

myrun 12

Done; run time = 291.53 s; real-time ratio: 0.00.

yeah, noticeably faster ...

savefig('gif/20apr23_rast_a1.png')

rates and cell activity looks ok

python -i actmap.py

data/20april23_A1_actmap.mp4

python -i simdat.py -1

data/20april23_A1_weightmap.mp4

** adjust one-to-one to random connectivity

will have to reduce convergence most likely ...

20april23_B0_

myrun 12

something making this run very slowly now ... not clear why ...

also, did not adjust number of IM neurons ... should be lower

x / (917*2+x) = 0.2
0.2*(917*2+x) = x
366.8 + .2x = x
.8x = 366.8
x = 366.8/.8 = 458.5

459/(917*2+459) # 0.20017444395987788

so should have 459 IM neurons ...

but doubt that's reason for slowdown ...

there were some bugs in connectivity from visual to motor areas and from premotor to motor areas
EV1DW connected to EML and EMR two times both for AMPA and NMDA

used loops to reduce those errors ... 

*20apr24
** debug connectivity/speed issues

myrun 12

  Done; run time = 257.86 s; real-time ratio: 0.00.
  Done; gather time = 455.45 s.

that's for 1 s of sim time ... seems a bit faster to run sim ... why is gather so slow?

getting hyperactivation/synchrony ... probably too much EE connectivity  

python -i actmap.py

data/20april24_A0_actmap.mp4

python -i simdat.py -1

got an error about wrong size in image ... 

** discuss net/motion selectivity with HA

also i think after neuron reduction in direction selective cells, motioncomputation is not capturing whole image
samn ok, i'll restore their number
but may keep EML, EMR numbers lower
Haroon Anwar yes, probably that way we can narrow down the issue…. can lower direction selective neuron nb later
samn sg
one other question i had was ...
Haroon Anwar sure
samn now we use 2 frames to compute direction
and we did that to have 1 action for each frame
could we use 5 frames for motion calculation but still have 1 action for 5 frames?
Haroon Anwar so in sim.json, we specify 1 frame….but in aigame.py, it uses last_obs to compute motion direction.
i dont think so
we could do so but back in time
so for time t, we could use t-4,t-3,t-2,t-1 and t
and use 1 action
samn so we could do 5 frames for motion, 1 action for 5 frames?
Haroon Anwar for 1 action for 1 frame
1 action for 5 frames will compromise the performance severly
samn ok, so we can keep as is.
think any problems with how you modified it to? if we have 100 neurons for each direction population
Haroon Anwar how i modified it to? — which part?
samn 1 action per 1 frame
and 2 frames for motion
Haroon Anwar no it should not effect
samn so it should be good
ok, and to follow up, 20 ms is time for 1 frame. if it's longer, will that help?
Haroon Anwar problem is with computing motion not activating neurons
samn so there is a problem of computing motion from 2 frames. and possibly optical flow algorithm will help
Haroon Anwar 20 ms for 1 frame should nicely scale, as we were using 100 ms for 5 frames. so it
means that firing rate has to be 50 Hz to have one spike per action
samn ok sg


** restore # dir selective neurons but reduce # motor neurons & debug/test

x / (400*2+x) = 0.2
0.2*(400*2+x) = x
160 + 0.2x = x
0.8x = 160
x=160/.8=200

"EML":400,"EMR":400,"IM":200

    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":100,"EV1DNE":100,"EV1DN":100,"EV1DNW":100,"EV1DW":100,"EV1DSW":100,"EV1DS":100,"EV1DSE":100,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EML":400,"EMR":400,"IM":200,"AngRFSigma":90,"DirMinRate":0.0001,"DirMaxRate":30.0}

20april24_B0_

myrun 12

Done; run time = 159.11 s; real-time ratio: 0.01.

most cells at decent rates, runs quicker than before ... but EMR,EML,IM cells fire too fast and with depolarization blockade 
20apr24_rast_a1.png
20apr24_IM_a1.png
20apr24_EML_a1.png

to remove that problem could reduce probability of inputs to EML,EMR neurons ...

python -i actmap.py

data/20april24_B0_actmap.mp4

python -i simdat.py -1

simdat.py:97: UserWarning: Attempting to set identical bottom == top == 0 results in singular transformations; automatically expanding.
  f_ax4.set_ylim((0,np.max([cumHits[-1],cumMissed[-1]])))
Traceback (most recent call last):
  File "simdat.py", line 415, in <module>
    animSynWeights(pdf,'data/'+dconf['sim']['name']+'weightmap.mp4', framerate=10) #plot/save images as movie
  File "simdat.py", line 127, in animSynWeights
    wtsL, wtsR = getwts(0, src)
  File "simdat.py", line 111, in getwts
    wtsL = np.reshape(wtsl,(int(np.sqrt(len(wtsl))),int(np.sqrt(len(wtsl))))) 
  File "<__array_function__ internals>", line 6, in reshape
  File "/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py", line 301, in reshape
    return _wrapfunc(a, 'reshape', newshape, order=order)
  File "/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py", line 61, in _wrapfunc
    return bound(*args, **kwds)
ValueError: cannot reshape array of size 15964 into shape (126,126)

hmm, keep getting those errors in animSynWeights in getwts

must happen since have probabilistic connectivity, no longer exact number of inputs specified ... ?

will fix ... also reduce weight to EML, EMR ... try that out ...

myrun 12

Run time: 156.21 s
Done; saving time = 121.36 s.

raster looks ok ...

20apr22_rast_b0.png
most cells look ok, though EML,EMR rates still a little high ...
20apr22_EMR_b0.png
20apr22_IM_b0.png
20apr22_EML_b0.png

python -i actmap.py

data/20april24_B0_actmap.mp4

directions look decent but mabe the RF angle sigma is too high ...

python -i simdat.py -1

simdat.py:97: UserWarning: Attempting to set identical bottom == top == 0 results in singular transformations; automatically expanding.
  f_ax4.set_ylim((0,np.max([cumHits[-1],cumMissed[-1]])))
Traceback (most recent call last):
  File "simdat.py", line 415, in <module>
    animSynWeights(pdf,'data/'+dconf['sim']['name']+'weightmap.mp4', framerate=10) #plot/save images as movie
  File "simdat.py", line 127, in animSynWeights
    wtsL, wtsR = getwts(0, src)
  File "simdat.py", line 111, in getwts
    wtsL = np.reshape(wtsl,(int(np.sqrt(len(wtsl))),int(np.sqrt(len(wtsl))))) 
  File "<__array_function__ internals>", line 6, in reshape
  File "/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py", line 301, in reshape
    return _wrapfunc(a, 'reshape', newshape, order=order)
  File "/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py", line 61, in _wrapfunc
    return bound(*args, **kwds)
ValueError: cannot reshape array of size 15964 into shape (126,126)

have to fix simdat.py ! ! !

*20apr27 - fixup simdat.py animation (AMPA & NMDA separate); continue tuning network
** fixup simdat.py

ok, adjusted - separating out AMPA, NMDA weights

  animSynWeights(pdf[pdf.syntype=='AMPA'],'data/'+dconf['sim']['name']+'_AMPA_weightmap.mp4', framerate=10) #plot/save images as movie
  animSynWeights(pdf[pdf.syntype=='NMDA'],'data/'+dconf['sim']['name']+'_NMDA_weightmap.mp4', framerate=10) #plot/save images as movie  

can combine AMPA and NMDA later if needed ...

though no reason to assume the two sets of weights should change at same time-scale

** continue adjusting network - reduce hyperexcit

well, EML, EMR rates were a bit high ... can adjust that ...

try cutting down E -> EML, EMR weights by 1/2

for strty,synmech,weight,plastty in zip(['','n'],['AMPA', 'NMDA'],[0.005*cfg.EEGain, 0.0005*cfg.EEGain],[STDPparamsRL1,STDPparamsRL2]):

myrun 12

Done; run time = 160.28 s; real-time ratio: 0.01.
Done; gather time = 280.91 s.
Total time = 604.62 s

rates a little better ...
20apr27_rast_a0.png

would rather have higher density and lower starting weights, so have possibility for right structure to develop

for now will continue from here ... will try longer sim ... 

python -i actmap.py

saved animation to data/20april27_A0_actmap.mp4

python -i simdat.py -1

saved animation to data/20april27_A0__AMPA_weightmap.mp4
saved animation to data/20april27_A0__NMDA_weightmap.mp4

weights to EMR increased more than EML ... and this is without fake rule

anyway, try longer sim now ...

myrun 12

*20apr28 - adjusting network
** optical flow in python

https://nanonets.com/blog/optical-flow/
https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_video/py_lucas_kanade/py_lucas_kanade.html

** sim crashes with memory problem

occurs even for 2.5 s sim during gatherdata

what if only recorded weights every 5 steps? with "recordWeightStepSize":5

myrun 12

  Done; run time = 191.75 s; real-time ratio: 0.01.
Gathering data...
  Done; gather time = 108.16 s.
    Cells: 2959
  Connections: 299852 (101.34 per cell)
  Synaptic contacts: 405671 (137.10 per cell)
  Spikes: 30546 (4.13 Hz)
  Simulated time: 2.5 s; 12 workers
  Run time: 191.75 s
Saving output as data/20april28_A0_simConfig.pkl ...

Total time = 383.88 s

ok, good, did not crash ...

20apr28_rast_a0.png

rates and membrane potential traces look ok but EMR,EML,IM rates somewhat high ... (~5-6 Hz for
EMR,EML and ~18 Hz for IM); could reduce weights to EMR,EML further ...

python -i actmap.py

data/20april28_A0_actmap.mp4

python -i simdat.py -1

data/20april28_A0__AMPA_weightmap.mp4
data/20april28_A0__NMDA_weightmap.mp4

try again with:
 larger recordStep and comment out the connection rules for weights that are 0 (feedback connections)
 do not need to plot raster twice and to save raster data in separate file
 do not need to plot voltage traces from every direction cells, one type should be enough to see if looks ok
 also reduce weight to EMR,EML
 
does this simConfig.recordTraces = {'V_soma':{'sec':'soma','loc':0.5,'var':'v'}}  # Dict with traces to record
cause recording of all cells' membrane potential? probably do not want that ...

based on this:
"recordCells - List of cells from which to record traces. Can include cell gids (e.g. 5 or [2,
3]), population labels (e.g. 'S' to record from one cell of the ‘S’ population), or 'all', to
record from all cells. NOTE: All cells selected in the include argument of
simConfig.analysis['plotTraces'] will be automatically included in recordCells. (default: [])

recordTraces - Dict of traces to record (default: {} ; example: {‘V_soma’:{‘sec’:’soma’,’loc’:0.5,’var’:’v’}})"

... it does NOT record ALL cells; just the ones in include:
simConfig.analysis['plotTraces'] = {'include': [(pop, 0) for pop in ['ER','IR','EV1','EV1DE','IV1','EV4','IV4','EMT','IMT','EML','EMR','IM']]}

myrun 12

  Done; gather time = 108.10 s.

hmm, did not save much time or space ... must be saving a lot of other stuff in the 680 MB 20april28_A0_simConfig.pkl
also rate of EMR,EML did not decrease ...

https://www.neuron.yale.edu/phpBB/viewtopic.php?f=45&t=3770&p=16227&hilit=memory#p16122

so try with those options, see if saves time/space ...

myrun 12

Gathering data...
  Gathering only sim data...
  Done; gather time = 70.73 s.

  saved some time ...

  but got error:
  File "sim.py", line 983, in <module>
    sim.saveData() # save data to disk
  File "/u/samn/netpyne/netpyne/sim/save.py", line 127, in saveData
    pickle.dump(dataSave, fileObj)
    TypeError: HocObject: Only Vector instance can be pickled
    
  and then simConfig.pkl output was empty ...

 so will run as it was before ... but still need to adjust the weights

ok, first try with higher ->EMR, ->EML weights
for strty,synmech,weight,plastty in zip(['','n'],['AMPA', 'NMDA'],[0.00375*cfg.EEGain, 0.000375*cfg.EEGain],[STDPparamsRL1,STDPparamsRL2]):
to make sure those synapses have an impact ...

when the weights were 0.005*cfg.EEGain and 0.0005*cfg.EEGain had similar rates ... which means other inputs driving most
of the activity ... 

also see recurrent connectivity ... should adjust for EMR->EMR and EML->EML to allow some plasticity ...

python -i simdat.py

simConfig, pdf, actreward, dstartidx, dendidx = loadsimdat()
simConfig.keys() # dict_keys(['netpyne_version', 'netpyne_changeset', 'net', 'simConfig', 'simData'])
simConfig['simData'].keys() # dict_keys(['spkt', 'spkid', 'V_soma', 't', 'synweights', 'avgRate'])
len(simConfig['simData']['spkt']) # 29862
len(simConfig['simData']['spkid']) # 29862

python -i actmap.py

also see if these options make output smaller:
cfg.saveCellSecs = False     # removes all data on cell sections prior to gathering from nodes
cfg.saveCellConns = False    # removes all data on cell connections prior to gathering from nodes

myrun 12

Gathering data...
Done; gather time = 72.30 s.

ok, that reduced main output file size to ~210 MB vs ~690 MB (for 2.5 s sim)
and a shorter gather time (without a crash)

python -i actmap.py

data/20april28_A0_actmap.mp4

python -i simdat.py -1

...

can put that into option in sim.json ... in case want connectivity info at some point

** test the targetted RL rule in fake up

added option to sim.json to specify whether to use targetted rule (only rewards actions to
motor neurons responsible for the action)

first without targetted RL:
10 s sim with name 20april28_T0_
myrun 12

20apr28_rast_T0.png
20apr28_rast_T0b.png

EMR,EML get too fast  ...
IM hits depolarization blockade: 20apr28_IM_T0.png
so does EMR, EML: 20apr28_EMR_T0.png, 20apr28_EML_T0.png

python -i actmap.py

data/20april28_T0_actmap.mp4

doesn't seem like direction selective neurons activating properly ... all activity
in each population seems to go together ...

python -i simdat.py -1

data/20april28_T0__AMPA_weightmap.mp4
data/20april28_T0__NMDA_weightmap.mp4 <<-- NMDA weights look much different compared to AMPA, perhaps NMDA weights
are not helping, as the populations are not differentiated. strange pattern for NMDA, spikes and decays...similar times with AMPA
what is the cause for those spikes? high rate of rewards??

UP is 4, DOWN is 3; EMR is for UP, EML is for DOWN; so in those movies, overall
the weights to EMR are larger

and next with targetted RL:
10 s sim with name 20april28_T1_
myrun 12

Done; run time = 2946.54 s; real-time ratio: 0.00.
Gathering data...
  Done; gather time = 1267.64 s.
Analyzing...
  Cells: 2959
  Connections: 0 (0.00 per cell)
  Spikes: 598894 (20.24 Hz)
  Simulated time: 10.0 s; 12 workers
  Run time: 2946.54 s
Saving output as data/20april28_T1_simConfig.pkl ... 
Finished saving!
  Done; saving time = 436.50 s.
SAVING RASTER DATA
plot raster:
Plotting recorded cell traces ... cell
QApplication: invalid style override passed, ignoring it.
Plotting raster...
  Done; plotting time = 828.98 s

Total time = 5536.42 s
End time:  2020-04-28 17:36:51.533489

takes a surprisingly long time to save and plot the data ... 

well, there's depolarization blockade:

20apr28_IM_T1.png
20apr28_EMR_T1.png
20apr28_EML_T1.png
20apr28_rast_T1.png <<-- very high rates for EML
IM,EMR are in depolarization blockade. weights to EMR probably increased too much.
better if there was some homeostasis built in

python -i actmap.py

data/20april28_T1_actmap.mp4   <<-- paddle goes up fairly quickly but then goes way down near end of sim and stays
there, probably due to depolarization blockade of EMR cells; EML might be firing quickly since does not receive and
inhibition from IM since IM in depolarization blockade. but then why does the racket stay near top of court for most
of the simulation, until the very end. is it drawn incorrectly??

python -i simdat.py -1

data/20april28_T1__AMPA_weightmap.mp4
data/20april28_T1__NMDA_weightmap.mp4

weights diverge towards EMR population quickly, weights to EML drop quickly, and then they stay that way
same pattern with AMPA and NMDA weights ...


confused by the variable names (ts_end is end time? ts_beg is beginning time? or opposite?)
            ts_end = t-tstepPerAction*(dconf['actionsPerPlay']-ts)
            ts_beg = t-tstepPerAction*(dconf['actionsPerPlay']-ts-1)
            F_Rs.append(getFiringRatesWithInterval([ts_end,ts_beg], sim.net.pops['EMR'].cellGids))

            and
def getFiringRatesWithInterval (trange = None, neuronal_pop = None):
has
if trange[0] <= spkts[i] <= trange[1] and spkids[i] in neuronal_pop:


tstepPerAction = 20
actionsPerPlay = 1
ts_beg = t - 20*(1-0-1) = t - 0
ts_end = t - 20*(1-0) = t - 20

ok, so ts_end is smaller, so it's correct, but the names are confusing ...

anyway, getting back to why actmap.py appears incorrect ... need to check that ...

the depolarization blockade issues suggest need for homeostasis built-in to the synapse ... should also try adding that ...

*20apr29 - debug actmap.py animations
** check actmap.py

make sure has input images / activity displayed at right times

python -i actmap.py

fig = animInput(New_InputImages, 'test.mp4')

hmm, maybe y-axis for input images should be reversed ...

fig, axs, plt = animActivityMaps('test2.mp4', framerate=10)

limg = New_InputImages = loadInputImages('data/'+dconf['sim']['name']+'InputImages.txt')

limg.shape # (500, 20, 20)
imshow(limg[0,:,:],origin='upper')
imshow(limg[7,:,:],origin='upper')

row 0 of input images is top

was using wrong timestep in actmap.py ... made a variable for it tstepPerAction, also used in sim.json
and sim.py

*20apr30 - opt flow/quiver
** optical flow

this is what haroon tried last time:
(/u/samn/SMARTAgent/hanotes.org:1432)

see how to use it to produce direction vectors at each pixel ...

python

from pylab import *
import numpy as np
import gym
import cv2 # opencv
from skimage.color import rgb2gray
from skimage.registration import optical_flow_tvl1

env = gym.make('Pong-v0')
env.reset()
observation, reward, done, info = env.step(3)

for _ in range(30): #running 30 times, so that ball appears in the court.
  observation, reward, done, info = env.step(3)
  observation, reward, done, info = env.step(4)
  observation, reward, done, info = env.step(4)
  observation, reward, done, info = env.step(4)
  observation, reward, done, info = env.step(4)
  
o1, reward, done, info = env.step(4)
o2, reward, done, info = env.step(4)
o3, reward, done, info = env.step(4)
o4, reward, done, info = env.step(4)
o5, reward, done, info = env.step(4)

imshow(o1); savefig('gif/20apr30_a0.png')
imshow(o2); savefig('gif/20apr30_a1.png')
imshow(o3); savefig('gif/20apr30_a2.png')
imshow(o4); savefig('gif/20apr30_a3.png')
imshow(o5); savefig('gif/20apr30_a4.png')

g1 = rgb2gray(o1)
g2 = rgb2gray(o2)
g3 = rgb2gray(o3)

subplot(1,2,1); imshow(g1,cmap='gray'); subplot(1,2,2); imshow(g3,cmap='gray')
savefig('gif/20apr30_a5.png')

#
winsz = 10 # win size. flow is computed over the window....larger value is more robust to the noise.
imgscale = 1.0 # image pyramid or simple image scale
nlayer = 1 # nb of pyramidal layer. if used 1 means flow is calculated only from previous image.
niter = 3 # num iterations
polydeg = 5 # polynominal degree expansion. (recommended 5-7)
smooth = 1.2 # standard deviation used to smooth used derivatives. (recommended 1.1-1.5)
flow = cv2.calcOpticalFlowFarneback(g1,g3, None, imgscale, nlayer, winsz, niter, polydeg, smooth, 0)
flow = cv2.calcOpticalFlowFarneback(g1,g3, None, 0.5, 3, 15, 3, 5, 1.2, 0)
flow = cv2.calcOpticalFlowFarneback(g1,g3, None, 1.0, 3, 15, 3, 5, 1.2, 0)
mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])
goodInds = np.where(mag<1e-10,0,1)

#
clf()
subplot(2,2,1); imshow(g1,cmap='gray'); title('Frame1'); subplot(2,2,2); imshow(g3,cmap='gray'); title('Frame2');
subplot(2,2,3); imshow(np.multiply(mag,goodInds),cmap='gray'); title('Mag'); colorbar()
subplot(2,2,4); imshow(np.degrees(np.multiply(ang,goodInds)),cmap='gray'); title('Dir'); colorbar()

savefig('gif/20apr30_a6.png')

try quiver for directions:
https://matplotlib.org/3.1.0/api/_as_gen/matplotlib.pyplot.quiver.html
https://matplotlib.org/3.1.0/gallery/images_contours_and_fields/quiver_simple_demo.html#sphx-glr-gallery-images-contours-and-fields-quiver-simple-demo-py

figure(); quiver(flow[:,:,0],flow[:,:,1])

savefig('gif/20apr30_a7.png')

looks upside down ...

flow.shape # (210, 160, 2)

g1.shape # (210, 160)
top is row 0

what is value at x=17, y=120
flow[120][17][0],flow[120][17][1] # (1.1408521e-09, -1.1311174e-06)

figure(); plot(flow[120,:,1])
savefig('gif/20apr30_a8.png')
so that's negative, movement towards smaller y-values, which in original frame is up

so draw quiver with negated flow in y direction to make easier to visualize ...

#
clf()
subplot(2,3,1); imshow(g1,cmap='gray'); title('Frame1'); subplot(2,3,2); imshow(g3,cmap='gray'); title('Frame2');
subplot(2,3,4); imshow(np.multiply(mag,goodInds),cmap='gray'); title('Mag'); colorbar()
subplot(2,3,5); imshow(np.degrees(np.multiply(ang,goodInds)),cmap='gray'); title('Dir'); colorbar()

X, Y = np.meshgrid(np.arange(0, 160, 1), np.arange(0, 210, 1))
subplot(2,3,6); quiver(X, Y, flow[:,:,0],-flow[:,:,1], units='width')

savefig('gif/20apr30_a9.png')

looks ok ... zoom-in shows mostly pointing in right direction ... could make movie to show
and then use that for dir selective neurons; doesn't have to be completely accurate ... 

#imshow(np.degrees(np.multiply(ang,goodInds)),cmap='gray'); title('Dir'); colorbar()
#
#X,Y = np.meshgrid(flow.shape[1], -flow.shape[0])

*20may1 - tested optical flow / integrated with sim/model
** continue optical flow

restart to make sure params correct ...

python

from pylab import *
import numpy as np
import gym
import cv2 # opencv
from skimage.color import rgb2gray
from skimage.registration import optical_flow_tvl1

env = gym.make('Pong-v0')
env.reset()
observation, reward, done, info = env.step(3)

for _ in range(30): #running 30 times, so that ball appears in the court.
  observation, reward, done, info = env.step(3)
  observation, reward, done, info = env.step(4)
  observation, reward, done, info = env.step(4)
  observation, reward, done, info = env.step(4)
  observation, reward, done, info = env.step(4)
  
o1, reward, done, info = env.step(4)
o2, reward, done, info = env.step(4)
o3, reward, done, info = env.step(4)
o4, reward, done, info = env.step(4)
o5, reward, done, info = env.step(4)

g1 = rgb2gray(o1)
g2 = rgb2gray(o2)
g3 = rgb2gray(o3)

help(calcOpticalFlowFarneback)

 calcOpticalFlowFarneback(prev, next, flow, pyr_scale, levels, winsize, iterations, poly_n, poly_sigma, flags) -> flow
    .   @brief Computes a dense optical flow using the Gunnar Farneback's algorithm.
    .   @param prev first 8-bit single-channel input image.
    .   @param next second input image of the same size and the same type as prev.
    .   @param flow computed flow image that has the same size as prev and type CV_32FC2.
    .   @param pyr_scale parameter, specifying the image scale (\<1) to build pyramids for each image;
    .   pyr_scale=0.5 means a classical pyramid, where each next layer is twice smaller than the previous
    .   one.
    .   @param levels number of pyramid layers including the initial image; levels=1 means that no extra
    .   layers are created and only the original images are used.
    .   @param winsize averaging window size; larger values increase the algorithm robustness to image
    .   noise and give more chances for fast motion detection, but yield more blurred motion field.
    .   @param iterations number of iterations the algorithm does at each pyramid level.
    .   @param poly_n size of the pixel neighborhood used to find polynomial expansion in each pixel;
    .   larger values mean that the image will be approximated with smoother surfaces, yielding more
    .   robust algorithm and more blurred motion field, typically poly_n =5 or 7.
    .   @param poly_sigma standard deviation of the Gaussian that is used to smooth derivatives used as a
    .   basis for the polynomial expansion; for poly_n=5, you can set poly_sigma=1.1, for poly_n=7, a
    .   good value would be poly_sigma=1.5.
    .   @param flags operation flags that can be a combination of the following:
    .    -   **OPTFLOW_USE_INITIAL_FLOW** uses the input flow as an initial flow approximation.
    .    -   **OPTFLOW_FARNEBACK_GAUSSIAN** uses the Gaussian \f$\texttt{winsize}\times\texttt{winsize}\f$
    .        filter instead of a box filter of the same size for optical flow estimation; usually, this
    .        option gives z more accurate flow than with a box filter, at the cost of lower speed;
    .        normally, winsize for a Gaussian window should be set to a larger value to achieve the same
    .        level of robustness.

#
winsz = 10 # win size. flow is computed over the window....larger value is more robust to the noise.
pyrscale = 0.5 # image pyramid or simple image scale
nlayer = 3 # nb of pyramidal layer. if used 1 means flow is calculated only from previous image.
niter = 3 # num iterations
polyn = 7 # polynominal degree expansion. (recommended 5-7)
polysigma = 1.5 # standard deviation used to smooth used derivatives. (recommended 1.1-1.5)
flow = cv2.calcOpticalFlowFarneback(g1,g3, None, pyrscale, nlayer, winsz, niter, polyn, polysigma, 0)
mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])
goodInds = np.where(mag<1e-10,0,1)
clf()
subplot(2,3,1); imshow(g1,cmap='gray'); title('Frame1'); subplot(2,3,2); imshow(g3,cmap='gray'); title('Frame2');
subplot(2,3,4); imshow(np.multiply(mag,goodInds),cmap='gray'); title('Mag'); colorbar()
subplot(2,3,5); imshow(np.degrees(np.multiply(ang,goodInds)),cmap='gray'); title('Dir'); colorbar()
X, Y = np.meshgrid(np.arange(0, 160, 1), np.arange(210, 0, -1))
ax=subplot(2,3,6); quiver(X, Y, flow[:,:,0],-flow[:,:,1], units='width', color='r')
ax.set_xlim((0,160)); ax.set_ylim((0,210))
ax.invert_yaxis()

savefig('gif/20may1_a0.png')

looks decent ...

ok...will try that in a movie to make sure looks ok

may not want to use the thresholding?

#
winsz = 10 # win size. flow is computed over the window....larger value is more robust to the noise.
pyrscale = 0.5 # image pyramid or simple image scale
nlayer = 3 # nb of pyramidal layer. if used 1 means flow is calculated only from previous image.
niter = 3 # num iterations
polyn = 7 # polynominal degree expansion. (recommended 5-7)
polysigma = 1.5 # standard deviation used to smooth used derivatives. (recommended 1.1-1.5)
flow = cv2.calcOpticalFlowFarneback(g1,g3, None, pyrscale, nlayer, winsz, niter, polyn, polysigma, 0)
mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])
clf()
subplot(2,3,1); imshow(g1,cmap='gray'); title('Frame1'); subplot(2,3,2); imshow(g3,cmap='gray'); title('Frame2');
subplot(2,3,4); imshow(mag,cmap='gray'); title('Mag'); colorbar()
subplot(2,3,5); imshow(np.degrees(ang),cmap='gray'); title('Dir'); colorbar()
X, Y = np.meshgrid(np.arange(0, 160, 1), np.arange(210, 0, -1))
ax=subplot(2,3,6); qdat=quiver(X, Y, flow[:,:,0],-flow[:,:,1], units='width', color='k')
ax.set_xlim((0,160)); ax.set_ylim((0,210))
ax.invert_yaxis()

savefig('gif/20may1_a1.png')

can use quiver.set_UVC from within an animation set_UVC(U, V, C=None) method of matplotlib.quiver.Quiver instance
to update its data ...

qdat.set_UVC([],[])

or follow example here ...

https://stackoverflow.com/questions/19329039/plotting-animated-quivers-in-python

fig = animInput(New_InputImages, 'test.mp4', showflow=True)

looks pretty good ...

added imgutils.py as wrapper that calculates optical flow for 2 images and for a set of frames
can put other image processing utilities there

should put the direction fields into actmap animation too ...

will make it easier to assess whether the direction selective populations are firing properly ...
after that should plugin the optical flow into aigame.py

hmm, should actually save the direction fields calculated during the simulation
so make sure calculated same way as displayed ...

** integrating optical flow with game,sim

cleaning up some of the code since have to adjust it to use different type of motion calculation ...
having AIGame save its own InputImages (ReducedImages) and Images (FullImages)
to avoid passing that info back and forth between AIGame and sim ...

based on discussion with HA could use 20x20 or even 160x160 input images to calculate motion
directions, then downsample to 10x10 direction field that is projected to the direction
selective neurons ...

*20may4
** check opt flow integration, make sure working properly

when ran it last time, there was incorrect activity in different populations

actually, had started saving the motion fields computed so need to finish that
for display in the movies ...

run a short 2 s sim for testing ... named 20may4_A0_

myrun 12

  Cells: 2959
  Connections: 0 (0.00 per cell)
  Spikes: 79757 (13.48 Hz)
  Simulated time: 2.0 s; 12 workers
  Run time: 412.59 s
Saving output as data/20may4_A0_simConfig.pkl ... 
Finished saving!
  Done; saving time = 95.63 s.
SAVING RASTER DATA
plot raster:
Plotting recorded cell traces ... cell
QApplication: invalid style override passed, ignoring it.
Plotting raster...
  Done; plotting time = 117.68 s

Total time = 925.17 s

End time:  2020-05-04 12:45:31.363310

lot of cells go into block ...
20may4_a0_rast.png
20may4_a0_IM.png
20may4_a0_EML.png
20may4_a0_EV1DE.png

probably since direction selective cells not setup properly with the new optical flow ...

motion fields saved ... 20may4_A0_MotionFields.pkl

now check the output

python -i actmap.py

len(ldflow) # 99
99*20 # 1980 - that's amount of time covered, since first frame has no optical flow
and used 20 ms interval

first adjust animInput

fig=animInput(InputImages,'testflow.mp4',ldflow=ldflow)

something wrong with the output movie ...

same problem if calc the optflow here?

from imgutils import getoptflowframes
ldflow2 = getoptflowframes(InputImages)
fig=animInput(InputImages,'testflow.mp4',ldflow=ldflow2)

hmm, same error opening in vlc ...

opens fine in parole media player

fig=animInput(InputImages,'testflow.mp4',ldflow=ldflow)

in general it's working but probably need higher spatial resolution ...

fig, axs, plt = animActivityMaps('testact2.mp4', framerate=10)

looks interesting but hard to see what's going on in motion fields there because so small ... should reduce size/width of arrows

hmm, may need bigger figure size ... 

fig, axs, plt = animActivityMaps('testact3.mp4', framerate=10,figsize=(9,5))

well, optical flow generally follows motion with wide spread, but the direction selective populations not following
the motion directions properly ... 

also add motor pops to activity map ...

fig, axs, plt = animActivityMaps('testact4.mp4', framerate=10,figsize=(9,5))

looks interesting ... need IM too ... and the rewards, and the weights, etc.
first fixup direction selectivity ...

does activity look more clear without vmax restriction?
fig, axs, plt = animActivityMaps('testact5.mp4', framerate=10,figsize=(9,5))
looks even worse ... 

how about reducing AngRFSigma from 45 to 22.5 ... ??
since there's 45 degrees between primary directions but only 22.5 half-way in either direction ...

20may4_A1_

AngRFSigma:22.5

myrun 12

  Cells: 2959
  Connections: 0 (0.00 per cell)
  Spikes: 43011 (7.27 Hz)
  Simulated time: 2.0 s; 12 workers
  Run time: 445.23 s
Saving output as data/20may4_A1_simConfig.pkl ... 
Finished saving!
  Done; saving time = 87.67 s.
SAVING RASTER DATA
plot raster:
Plotting recorded cell traces ... cell
QApplication: invalid style override passed, ignoring it.
Plotting raster...
  Done; plotting time = 64.77 s

Total time = 894.50 s

End time:  2020-05-04 22:54:32.382426

20may4_a1_IM.png
20may4_a1_EMR.png
20may4_a1_EV1DE.png
20may4_a1_rast.png

still hyperactive, but not as much as last run ...
E, NE only directions that seem to be activated
and then too strongly activating EML, EMR?

python -i actmap.py

fig, axs, plt = animActivityMaps('data/20may4_A1_actmap.mp4', framerate=10,figsize=(9,5))

data/20may4_A1_actmap.mp4

a little better ... for some reason only E, NE cells getting activated ... and not even at right times ...
so have to debug the projections from optical flow -> direction selective populations


*20may5
** fixing optical flow input

looks like motiondir units are in radians ...

myrun 12

sim.AIGame.ldflow[0].keys() # dict_keys(['flow', 'mag', 'ang', 'goodInds'])
np.amin(sim.AIGame.ldflow[0]['ang']),np.amax(sim.AIGame.ldflow[0]['ang']) # (5.553319e-13, 6.2265844)

so use this in imgutils.py:
  return {'flow':flow,'mag':mag,'ang':np.rad2deg(ang),'goodInds':goodInds}

ok, now rerun 2 s sim ... 
  
myrun 12

  Cells: 2959
  Connections: 0 (0.00 per cell)
  Spikes: 55939 (9.45 Hz)
  Simulated time: 2.0 s; 12 workers
  Run time: 178.73 s
Saving output as data/20may5_A0_simConfig.pkl ... 
Finished saving!
  Done; saving time = 25.08 s.
SAVING RASTER DATA
plot raster:
Plotting recorded cell traces ... cell
QApplication: invalid style override passed, ignoring it.
Plotting raster...
  Done; plotting time = 23.70 s

Total time = 315.73 s

End time:  2020-05-05 10:03:32.129322


20may5_a0_EV1DE.png
20may5_a0_IM.png
20may5_a0_EMR.png
20may5_a0_rast.png

overall better since there appears to be some direction selectivity, though the rate of direciton selective cells
remains too high ... leading to depolarization blockade of EMR,EML,IM cells ...
can reduce rate of direction selective neurons by reducing DirMaxRate from 30 down to x ...

python -i actmap.py

fig, axs, plt = animActivityMaps('data/20may5_A0_actmap.mp4', framerate=10,figsize=(9,5))

triy lower DirMaxRate ... 1 Hz ...

20may5_A1_

myrun 12

still hard to see what's going on but the rates are better ...

also do not see much activity in ER that corresponds with the input images ... ER is very subdued

fig, axs, plt = animActivityMaps('data/20may5_A1_actmap.mp4', framerate=10,figsize=(9,5))

firing rates for most populations are decent ... but don't see much direction selectivity that would expect/want to see ...
seems somewhat random ... 

20may5_a1_EV1DE.png
20may5_a1_EMR.png
20may5_a1_IM.png
20may5_a1_rast.png

fig=animInput(InputImages,'testflow.mp4',ldflow=ldflow)

should find better params to increase resolution for the optical flow ...

ldflow2 = getoptflowframes(InputImages,winsz=3, pyrscale=0.5, nlayer=3, niter=3, polyn=5, polysigma=1.1)
fig=animInput(InputImages,'testflow.mp4',ldflow=ldflow2)

ok, those param values a bit better in getting higher resolution optical flow, but then somewhat more noisy ...

will try that in sim ...

20may5_A2_

myrun 12

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may5_A2_actmap.mp4', framerate=10,figsize=(9,5))

hmm, most of the activity appears to be due to the recurrent connectivity ... getting rid of that
and the direction selective neurons do not fire any more ... and do not seem to receive any inputs (EPSPs) ...
must be a bug somewhere ...

does it have to do with 20x20 for direction image and 10x10 for each population of E dir selective neurons??

check in actmap.py animInput ...

from skimage.transform import downscale_local_mean, resize

ldflow = loadMotionFields(dconf['sim']['name'])
for dflow in ldflow:
  u = resize(dflow['flow'][:,:,0], (10,10), anti_aliasing=True)
  v = resize(dflow['flow'][:,:,1], (10,10), anti_aliasing=True)
  dflow['flow'] = np.array([u,v]).T

fig=animInput(InputImages,'testflow2.mp4',ldflow=ldflow)

yeah, looks like the resize operation is messing things up ... which means may
need to use more neurons for direction selective ... or distribute their RFs
over all angles and assign each a coordinate in 2D grid ... hmm, already have
that, so maybe need to restore 3200 neurons ... 

*20may6
** restore each dir selective neuron as 20x20 - motion fields better?

doesnt run too slowly ...

myrun 12

has 5359 neurons ... 

fig, axs, plt = animActivityMaps('gif/20may6_A0_actmap.mp4', framerate=10,figsize=(9,5))

looks better but still very noisy ...

needs more debugging ...

would longer time windows help??

can try 50 ms tstepPerAction instead of 20 ...

200 ms needed for 5 Hz max rate ...

probably easier to see if motion field info sent/detected properly by combining activity of
all the motion selective neurons together to produce estimated direction map

maxdirX,maxdirY = getmaxdir(dact,ddir)

fig=animDetectedMotionMaps('testdetectm.mp4', framerate=10, figsize=(7,3))

estimates based on max firing of direction selective neurons looks way off

for some reason E (EV1DE) neurons are almost always firing ...

something about 0 degrees for E ... when change it to have peak at 2 degrees much less firing ...

*20may7 - more on optical flow; some fixes
** discuss optical flow with ha

conclusion: will see if can tweak params to get example motion below to produce correct results
with existing params, detected motion didn't look great

** ha example code to test optical flow on single frame motion, fix, start testing network

python
from netpyne import specs, sim
from neuron import h
import numpy as np
import random
from conf import dconf # configuration dictionary
import pandas as pd
import pickle
from collections import OrderedDict
from connUtils import *
from matplotlib import pyplot as plt
import os
import anim
from matplotlib import animation
from aigame import AIGame
sim.AIGame = AIGame()
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[3], epCount = 0)
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[3], epCount = 0)
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[3], epCount = 0)
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[3], epCount = 0)
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[3], epCount = 0)
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[4], epCount = 0)
sim.AIGame.dFiringRates # to see the firing rates of 8 different populations
sim.AIGame.ldflow[-1]['ang'] # to see the angle computed for object motion

from pylab import *
ion()

#
fig = figure(figsize=(8,4))
cbaxes = fig.add_axes([0.92, 0.3, 0.01, 0.5])
subplot(1,3,1); imshow(sim.AIGame.FullImages[-2]); title('Frame1')
subplot(1,3,2); imshow(sim.AIGame.FullImages[-1]); title('Frame2')
subplot(1,3,3); imshow(sim.AIGame.ldflow[-1]['ang'],vmin=0, vmax=359, cmap='Dark2'); title('Angle')
c1 = colorbar(fa,cax = cbaxes)
c1.set_ticks([22,67,112,157,202,247,292,337])
c1.set_ticklabels(['E','NE','N','NW','W','SW','S','SE'])

savefig('gif/20may7_test_ha_0.png')

ha suggests thresholding by magnitude

E directions might dominate if angle 0 is default

opposite sign in y direction?


from imgutils import getoptflow

#
dflow = getoptflow(sim.AIGame.ReducedImages[-2], sim.AIGame.ReducedImages[-1],winsz=3,nlayer=3,niter=3,polyn=5,polysigma=1.1)
thflow = np.zeros(dflow['ang'].shape)
th = mean(dflow['mag']) + std(dflow['mag'])
for y in range(thflow.shape[0]):
  for x in range(thflow.shape[1]):
    if dflow['mag'][y,x] < th:
      thflow[y,x] = -100
    else:
      thflow[y,x] = dflow['ang'][y,x]

fig = figure(figsize=(8,4))

#
clf()
cbaxes = fig.add_axes([0.92, 0.3, 0.01, 0.5])
subplot(1,3,1); imshow(sim.AIGame.ReducedImages[-2]); title('Frame1')
subplot(1,3,2); imshow(sim.AIGame.ReducedImages[-1]); title('Frame2')
subplot(1,3,3); imshow(thflow,vmin=-100, vmax=359, cmap='Dark2'); title('Angle')
c1 = colorbar(fa,cax = cbaxes)
c1.set_ticks([22,67,112,157,202,247,292,337])
c1.set_ticklabels(['NONE','E','NE','N','NW','W','SW','S','SE'])

savefig('gif/20may7_test_2.png')

not terrible ...

python -i actmap.py
fig=animInput(InputImages,'testflow2.mp4',ldflow=None)

looks better than before ...

try in sim after checking for valid angles there ...

myrun 12

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may7_A0_actmap.mp4', framerate=10,figsize=(9,5))

saved animation to gif/20may7_A0_actmap.mp4

looks much better ...

20may7_a0_rast.png
most rates ok but EMR,EML fire too much and are too synchronized
possibly due to high drive from EV1DN, EV1DS which fire a lot more than the other direction selective cells (since
most motion is up and down due to paddles moving in those directions)
20may7_a0_IM.png
20may7_a0_EML.png

next will test with some angular RF spread ... also need to make sure EMR,EML fire less frequently/synchronously ...

set AngRFSigma to 22.5 and run again

name = 20may7_A1_

myrun 12

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may7_A1_actmap.mp4', framerate=10,figsize=(9,5))

saved animation to gif/20may7_A1_actmap.mp4

animation looks ok ... rates all right?

all rates decent but EML,EMR,IM rates too high ...
20may7_a1_rast.png
20may7_a1_EML.png
20may7_a1_EMR.png
20may7_a1_IM.png

so, next try decreasing the E projection weights to the EMR,EML neurons ...

20may7_A2_

set down from 0.00375, 0.000375 to 0.002, 0.0002 in this loop in sim.py to:
    for strty,synmech,weight,plastty in zip(['','n'],['AMPA', 'NMDA'],[0.0001*cfg.EEGain, 0.00001*cfg.EEGain],[STDPparamsRL1,STDPparamsRL2]):

EMR,EML still firing too much , though slightly lower ... 
    
** other discussion with ha points towards potential benefits of explicit object detection/tracking

e.g. threshold image, extract bbox, then use that to see motion

opencv supports this with efficient algorithms, though also have some code for it in OEvent

problem with this approach is some loss of generality
and may not even need image pixels as inputs if use explicit object locations as
neuronal representations

** put some object detection, bbox, image code into imgutils.py

can possibly use them for object detection/tracking, though opencv code probably more efficient

*20may8 - continue optical flow, testing
** reduce EMR,EML,IM rates

adding these params to control from json file:
"EEMWghtAM":0.0001,"EEMWghtNM":0.0001

will continue reducing until get better rates ...

20may8_A0_

make sure no firing of EMR,EML when those values are at 0...

strange, EMR,EML still firing ... :
 20may8_test_rast_a0.png

dconf['net']['EEMWghtAM'], dconf['net']['EEMWghtNM'] # (0.0, 0.0)

so what's driving them so strongly ...

maybe it's because of the wbase param of RL STDP mechanism?

#For AMPA-faster synapses
STDPparamsRL1 = {'hebbwt': 0.0000, 'antiwt':-0.0000, 'wbase': 0.0005, 'wmax': 1, 'RLon': 1 , 'RLhebbwt': 0.001 , 'RLantiwt': -0.000,
                'tauhebb': 10, 'RLlenhebb': 50 ,'RLlenanti': 50, 'RLwindhebb': 50, 'useRLexp': 1, 'softthresh': 0, 'verbose':0}
#for NMDA (slower) synapses
STDPparamsRL2 = {'hebbwt': 0.0000, 'antiwt':-0.0000, 'wbase': 0.0005, 'wmax': 1, 'RLon': 1 , 'RLhebbwt': 0.001 , 'RLantiwt': -0.000,
                'tauhebb': 10, 'RLlenhebb': 800 ,'RLlenanti': 100, 'RLwindhebb': 50, 'useRLexp': 0, 'softthresh': 0, 'verbose':0}

wbase sets a lower limit for the weights ... try setting wbase to 0 to see if reduces the EMR,EML activity ...

myrun 12                               

20may8_test_rast_a1.png

yeah, that's reason why EMR,EML were firing so fast ... so, will have to set wbase to starting value
for those params, or even lower ...

adding these:
"RL":{"AMPA":{"WBase":0.0,"WMax":1.0,"ON":1,"lenhebb":50,"lenanti":50,"exp":1},"NMDA":{"WBase":0.0,"WMax":1.0,"ON":1,"lenhebb":800,"lenanti":100,"exp":0}}
to sim.json
can add other RL params, as needed

wbase was 0.0005 before and even that had high rates, so set the start weight much lower ...

myrun 12

  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 13277 (2.48 Hz)
  Simulated time: 1.0 s; 12 workers
  Run time: 131.85 s
Saving output as data/20may8_A0_simConfig.pkl ... 
Finished saving!
  Done; saving time = 35.32 s.
SAVING RASTER DATA
plot raster:
Plotting recorded cell traces ... cell
QApplication: invalid style override passed, ignoring it.
Plotting raster...
  Done; plotting time = 7.62 s

Total time = 298.91 s

these params seem ok:

    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EML":400,"EMR":400,"IM":200,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.0001,"EEMWghtNM":0.00001},
    "RL":{"AMPA":
	  {"WBase":0.0001,"WMax":1.0,"ON":1,"lenhebb":50,"lenanti":50,"exp":1},
	  "NMDA":
	  {"WBase":0.00001,"WMax":1.0,"ON":1,"lenhebb":800,"lenanti":100,"exp":1}
    }

there are a few initial M pop spikes but then desynchronizes ... 20may8_test_rast_a2.png
20may8_test_EMR_a3.png
20may8_test_IM_a4.png


should have WMax much lower ... maybe at 0.00075, 0.000075

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may8_actmap_a5.mp4', framerate=10,figsize=(9,5))

looks ok ...

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may8_AMPA_weightmap_a6.mp4', framerate=10) #plot/save images as movie
animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may8_NMDA_weightmap_a7.mp4', framerate=10) #plot/save images as movie

try longer run to see if activity remains reasonable ...

tried run for 10 s ... but crashed in gatherdata ... 

  Done; run time = 1413.07 s; real-time ratio: 0.01.

Gathering data...
[samndp7730:08851] *** Process received signal ***
[samndp7730:08851] Signal: Segmentation fault (11)
[samndp7730:08851] Associated errno: Unknown error 32686 (32686)
[samndp7730:08851] Signal code:  (334043992)
[samndp7730:08851] Failing at address: 0x7fff13e91b54
[samndp7730:08851] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x354b0)[0x7fae6d8cd4b0]
[samndp7730:08851] [ 1] /lib/x86_64-linux-gnu/libc.so.6(+0x14e156)[0x7fae6d9e6156]
[samndp7730:08851] [ 2] /usr/lib/libopen-pal.so.13(opal_convertor_unpack+0xa8)[0x7fae6c4596b8]
[samndp7730:08851] [ 3] /usr/lib/openmpi/lib/openmpi/mca_pml_ob1.so(mca_pml_ob1_recv_request_progress_rndv+0x181)[0x7fae5fcdc2b1]
[samndp7730:08851] [ 4] /usr/lib/openmpi/lib/openmpi/mca_pml_ob1.so(mca_pml_ob1_recv_frag_callback_rndv+0x271)[0x7fae5fcd7cd1]
[samndp7730:08851] [ 5] /usr/lib/openmpi/lib/openmpi/mca_btl_vader.so(mca_btl_vader_poll_handle_frag+0x93)[0x7fae60523813]
[samndp7730:08851] [ 6] /usr/lib/openmpi/lib/openmpi/mca_btl_vader.so(+0x3cc3)[0x7fae60523cc3]
[samndp7730:08851] [ 7] /usr/lib/libopen-pal.so.13(opal_progress+0x4a)[0x7fae6c44d1ea]
[samndp7730:08851] [ 8] /usr/lib/libmpi.so.12(ompi_request_default_wait_all+0x315)[0x7fae6d0f4f65]
[samndp7730:08851] [ 9] /usr/lib/openmpi/lib/openmpi/mca_coll_tuned.so(ompi_coll_tuned_sendrecv_nonzero_actual+0x11a)[0x7fae5f24faca]
[samndp7730:08851] [10] /usr/lib/openmpi/lib/openmpi/mca_coll_tuned.so(ompi_coll_tuned_alltoallv_intra_pairwise+0x150)[0x7fae5f256780]
[samndp7730:08851] [11] /usr/lib/libmpi.so.12(PMPI_Alltoallv+0x1fc)[0x7fae6d105c9c]
[samndp7730:08851] [12] /usr/site/../arch/nrn/x86_64/lib/libnrnmpi.so.0(nrnmpi_char_alltoallv+0x25)[0x7fae6f7b7d35]

if network activity looks decent could run longer sims on zn ...

same problem/crash on zn?

yeah, crashes on zn in gatherdata, zn with 12 cores takes ~900s to run instead of 1413 on laptop ...

try with fewer traces recorded from ... and longer recording interval (recordStep=0.6)
only record voltage from 1 cell of these pops: ['ER','IR','EV1','EV1DE','IV1','EML','IM']

this may be where the extra data causing gather crash is coming from:
 sim.simData['synweights'][sim.rank].append([t,conn.plast.params.RLon,conn.preGid,cell.gid,float(conn['hObj'].weight[0]),conn.synMech])

probably do not need the RLon flag ...
could also use preGid, gid, synmech as index so don't have to save them each time ...
or could save to separate files for each rank and then join them together in simdat.py ...

still crashes at GatherData:
  Done; run time = 1321.29 s; real-time ratio: 0.01.

Gathering data...
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
[samndp7730:15458] *** Process received signal ***
[samndp7730:15458] Signal: Aborted (6)
[samndp7730:15458] Signal code:  (-6)
[samndp7730:15458] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x11390)[0x7fe32f7dd390]
[samndp7730:15458] [ 1] /lib/x86_64-linux-gnu/libc.so.6(gsignal+0x38)[0x7fe32f437428]

if shut off the record weights same problem?

myrun 12

Game rewards: [-0.001]
  Done; run time = 1297.58 s; real-time ratio: 0.01.

Gathering data...
  Done; gather time = 1.49 s.

Analyzing...
>>> >>> >>> >>> >>> >>> >>> >>> >>> >>> 

  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 105073 (1.96 Hz)
  Simulated time: 10.0 s; 12 workers
  Run time: 1297.58 s
>>> 
Saving output as data/20may8_A0_simConfig.pkl ... 
Finished saving!
  Done; saving time = 1.09 s.
SAVING RASTER DATA
plot raster:
Plotting recorded cell traces ... cell
QApplication: invalid style override passed, ignoring it.
Plotting raster...
  Done; plotting time = 38.63 s

Total time = 1360.35 s

ok, this time it did not crash in gatherdata ... 

may not want to gather all cell tags each time input rates updated, assuming the tags
do not change during simulation, seems ok... and there's a clear,del in there
which might cause a memory problem later on in gatherdata, which has same deletes??
https://github.com/Neurosim-lab/netpyne/blob/development/netpyne/sim/gather.py
py_alltoall

can also rewrite code to have each node save its own synaptic weight data and then at end
merge the data into a single file ...

*20may11 - continue fixes - gatherdata issue, workaround
** debugging gatherdata issue, way to avoid it -->> save syn weights on each node, then combine

still crashes without all the extra calls to sim._gatherAllCellTags
main issue is that the plasticity data is getting saved ...

other option sal suggested:
sim.runSimWithIntervalFunc(cfg.saveInterval, sim.saveSimDataInNode)
use that instead of sim.runSim()
if already running a different interval func, would need to call sim.saveSimDataInNode()

got this error:
AttributeError: module 'netpyne.sim' has no attribute 'saveSimDataInNode'

must not have latest version of netpyne ...

netpyne.__version__ # '0.9.5'

looks like that interval saving functionality was added in version 0.9.6:
https://github.com/Neurosim-lab/netpyne/releases

pip install netpyne --upgrade

python
import netpyne
netpyne.__version__ '0.9.6'
quit()

myrun 12

seemed to work but also caused some errors ...

and did not plot properly since sim.net.allCells was not created

can use sim._gatherCells()
to get all the cells gathered ...

ok, saving as a list for now ... each node saves it and then it's merged together
at the end of the sim; takes a lot of space ~2 GB, but works pretty quickly (much
faster than gatherdata)

myrun 12

Analyzing...
  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 104487 (1.95 Hz)
  Simulated time: 10.0 s; 12 workers
  Run time: 989.55 s
fatal: No names found, cannot describe anything.
Saving output as data/20may11_A0_simConfig.pkl ... 
Finished saving!
Done; saving time = 1.34 s.

20may11_a0_rast.png

note that EML fires much less than EMR ... could be due to initial bias
in wiring from probabalistic connectivity ... could fix with convergence if that's the issue

also had targettedRL==1...that could also lead to a bias towards one population dominating..?
will retry with targettedRL off ... 

python -i actmap.py
  
fig, axs, plt = animActivityMaps('gif/20may11_actmap_a0.mp4', framerate=10,figsize=(9,5))

gif/20may11_actmap_a0.mp4

python -i simdat.py

hmm, using matplotlib 2.2.4 (newer ones not supported in netpyne) there's an error about fig.add_gridspec ...
in simdat.py animsynweights ... fixup to use matplotlib.gridspec.GridSpec

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may11_AMPA_weightmap_a0.mp4', framerate=10) #plot/save images as movie
animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may11_NMDA_weightmap_a0.mp4', framerate=10) #plot/save images as movie

compress pickle to reduce file size?

https://lucianopaz.github.io/compress_pickle/html/

pip install lz4
pip install compress_pickle

python
import pickle, compress_pickle
d = pickle.load(open('data/20may11_A0_synWeights.pkl','rb'))
compress_pickle.dump(d, 'tmp.pkl', compression="lzma", set_default_extension=False)

takes too long ...

see if reformatting weights as dict will save space ...

python
import pickle
din = pickle.load(open('data/20may11_A0_synWeights.pkl','rb'))
len(din) # 59676000
# [t,conn.preGid,cell.gid,conn.synMech,float(conn['hObj'].weight[0])]

#
dout = {}
for row in din:
  t,preID,poID,syn,w = row
  if preID not in dout:
    dout[preID] = {}
  if poID not in dout[preID]:
    dout[preID][poID] = {}
  if syn not in dout[preID][poID]:
    dout[preID][poID][syn] = []
  dout[preID][poID][syn].append([t,w])

pickle.dump(dout, open('tmp.pkl','wb'))

saves some space, but not enough:
(-rw-rw-r-- 1 samn samn 1562509212 May 11 23:06 tmp.pkl; new size is ~1.6 GB)
(original size is ~2.2GB  -rw-rw-r-- 1 samn samn 2193401415 May 11 16:26 20may11_A0_synWeights.pkl)

*20may12 - check balanced inputs to EMR,EML, rename pops, avoid hypersynch, longer sims, targettedRL prob?
** try reducing size of output synaptic weight data

could also run for 100 s and save weights every 1 s instead of every 100 ms ...

python

import pickle
din = pickle.load(open('data/20may11_A0_synWeights.pkl','rb'))
len(din) # 59676000
# [t,conn.preGid,cell.gid,conn.synMech,float(conn['hObj'].weight[0])]

import pandas as pd
pdf = pd.DataFrame(din,columns=['time','preid','postid','syntype','weight'])

first need to run
conda install PyTables

pdf.to_hdf('tmp.hdf',key='synweight')

-rw-rw-r-- 1 samn samn 2507588016 May 12 11:57 tmp.hdf

hmm, that's too big, so not much help ... 

pdf.to_pickle('tmp.pkl',compression='bz2') # takes way too long

#
dout = {}
for row in din:
  t,preID,poID,syn,w = row
  if preID not in dout:
    dout[preID] = {}
  if poID not in dout[preID]:
    dout[preID][poID] = {}
  if syn not in dout[preID][poID]:
    dout[preID][poID][syn] = []
  dout[preID][poID][syn].append([t,w])

pickle.dump(dout, open('tmp.pkl','wb'))

will use the dictionary format since it saves ~30% of the total size ...

** other question: why were EMR weights only increasing? targettedRL seems to bias towards one population

get same when have targettedRL off?

try that with recording weights every 1 s

myrun 12

20may12_rast_a0.png
20may12_IM_a0.png
12may12_EML_a0.png
12may12_IV1_a0.png

paddle seems to get stuck at top of screen ...

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may12_actmap_a0.mp4', framerate=10,figsize=(9,5))

gif/20may12_actmap_a0.mp4

yes, paddle stuck at top and EMR fires more than EML ... then hypersynchrony develops

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may12_AMPA_weightmap_a0.mp4', framerate=10) 
animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may12_NMDA_weightmap_a0.mp4', framerate=10) 

this time weights go up for both populations ...

** make sure balanced inputs to E motor populations

all EMR, EML neurons should have same number of inputs ... use convergence instead of probability
otherwise there will be biases in relative activation of the two populations

IM -> EML, EMR has probability of 0.125

conv = int(0.5 + pij * numfrom)

could make a pmat to use ...

EML -> IM, EMR -> IM
had connection probability of 0.125/2 and 400 EML, EMR neurons ...
conv = int(0.5 + 0.125/2 * dnumc[EML]) = 25

IM -> EML, IM -> EMR
had connection probability of 0.125 and 200 IM neurons
conv = int(0.5 + 0.125 * 200) = 25

ok, put in a helper function in connUtils to get convergence from probability and num presynaptic neurons
and used it to get convergence number in the connection rules ... will see if that produces more similar
firing rates for EMR and EML ...

and try sim with the new ~equivalent convergence-based connectivity ...

20may12_B0_

myrun 12

  Cells: 5359
  Connections: 0 (0.00 per cell) <<-- that's because not saving cellconn, there are synapses in this simulation
  Spikes: 222076 (4.14 Hz)
  Simulated time: 10.0 s; 12 workers
  Run time: 1002.30 s

ok, rates for EMR, EML are more similar now:
 20may12_rast_b0.png
 20may12_EML_b0.png
 20may12_IM_b0.png

the paddle does get stuck at top for part of simulation ... seems less likely
to get stuck at bottom? 
 
the network also transitions to too much synchronous EMR,EML activity quickly ... should reduce that
maybe via different starting and max weights ... 

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may12_actmap_b0.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may12_AMPA_weightmap_b0.mp4', framerate=10, figsize=(14,8)) 
animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may12_NMDA_weightmap_b0.mp4', framerate=10, figsize=(14,8))

** change EMR -> EMUP, EML -> EMDOWN

since confusing to read code ...

ok ... adjusted in sim.py, sim.json, simdat.py, actmap.py

** get rid of hypersynch -->> ends up developing after ~10 s even with lower starting weights some improvement in performance?

can reduce "EEMWghtAM":0.0001,"EEMWghtNM":0.00001 to lower values ...

and also the RL weight increment ... which variable is that ... ?
'RLhebbwt': 0.001 , 'RLantiwt': -0.000, ??

yeah, looks like RLhebbwt ... and it's very large compared to starting weights ... so should
reduce it and add as a param for sim.json ...

note that RLhebbwt may be ok since it's multiplied by the reward/punishment value in mod/stdp.mod ...
so it only moves by a fraction anyway (when using critic values of 0.001, 0.01, etc.)
(/u/samn/SMARTAgent/mod/stdp.mod:156)

ok, try adjustments ...

myrun 12

20may12_EMDOWN_c0.png

looks better overall...but only a matter of time until epileptic/highly synchronized activity returns ...
without homeostatic plasticity that's likely to occur...unless use soft thresholding and have lower wmax values?
could also have easier homeostatic plasticity rule to check rates of all populations and increase random
inhibitory noise when cells begin to fire too fast

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may12_actmap_c0.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may12_AMPA_weightmap_c0.mp4', framerate=10, figsize=(14,8)) 
animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may12_NMDA_weightmap_c0.mp4', framerate=10, figsize=(14,8))

ok, will try a soft threshold and 10 s sim ...

not sure if want NMDA RL plasticity yet ... has very long eligibility trace (~800 ms) ...

dynamics look decent overall, but have to run longer and see if remains stable,
since rates seem to increase somewhat over time ...

20may12_rast_c1.png
20may12_IM_c1.png
20may12_EMDOWN_c1.png
20may12_IV1_C1.png

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may12_actmap_c1.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may12_AMPA_weightmap_c1.mp4', framerate=10, figsize=(14,8));animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may12_NMDA_weightmap_c1.mp4', framerate=10, figsize=(14,8))

ok, try a 100 s sim with same params ...

ran to completion & saved output but then crashed some time after display ... so did
not have chance to save raster ... can redraw from data ... looked like hypersynch
emerged eventually with fairly high rates for EMUP,EMDOWN,IM populations

synweights file is ~1.6 GB
simconfig ~540 MB

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may12_actmap_c2.mp4', framerate=10,figsize=(18,10))

that movie shows it does seem to improve by the end, though paddle gets stuck a lot ... 

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may12_AMPA_weightmap_c2.mp4', framerate=10, figsize=(14,8));animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may12_NMDA_weightmap_c2.mp4', framerate=10, figsize=(14,8))

some slight improvement in performance near the end ... looks like would need a lot longer to get anywhere reasonable, though
the hypersynchrony could cause problems far sooner ...

also worth testing the targetted RL rule keeping everything else the same ...

not sure need the NMDA RL since ball can get across screen in a few 100 ms ... can keep for now ...

can try two 300 s sims on zn and see which does better (with or without targetted RL)


** longer sims
*** 300 s same params as last (20may12_NOTARG_Z0_)

myrun 12

started ~23:29

End time:  2020-05-14 01:14:01.856790

too much time in plotting, which is not needed ... synweights ~4.6 GB
weights of EMDOWN,EMUP get too high by the end, as usual
20may12_NOTARG_Z0_rast.png
20may12_NOTARG_Z0_EMDOWN.png
20may12_NOTARG_Z0_IM.png

python -i actmap.py backupcfg/20may12_NOTARG_Z0_sim.json

fig, axs, plt = animActivityMaps('gif/20may12_NOTARG_Z0_actmap_300s.mp4', framerate=10,figsize=(18,10))

python -i simdat.py backupcfg/20may12_NOTARG_Z0_sim.json

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may12_NOTARG_Z0_AMPA_weightmap_300s.mp4', framerate=10, figsize=(14,8));animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may12_NOTARG_Z0_NMDA_weightmap_300s.mp4', framerate=10, figsize=(14,8))


*** 300 s same params as last but with targetted RL on (20may12_TARG_Z0_)

myrun 12

started ~23:31

  Run time: 82911.72 s
Total time = 86993.01 s

End time:  2020-05-13 23:41:08.873020

that's on zn with 12 cores (but many other jobs were running so took longer)

rates for EMUP,EMDOWN very unbalanced, with EMDOWN very low

20may12_TARG_Z0_rast.png
20may12_TARG_Z0_IM.png
20may12_TAG_Z0_EMDOWN.png

get rid of the 4.6GB data from this sim since did not work properly ... 

*20may13 - longer sims; hyperexcit; read weights works with AM/NM?
** 300 s sims still running on zn ~12 hours later (~1/2 done)
** discuss object detection / optical flow

had suggestion to use object detection as a mask for optical flow to
constrain spatial resolution for the flow

** still have issue of hyperexcit

reduce the min weights for RL, use targetted RL, and run for 10 s

20may13_A0_rast.png

prevents the hyperexcit; enough M activity generated? will hyperexcit just emerge later?

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may13_A0_actmap.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may13_A0_AMPA_weightmap.mp4', framerate=10, figsize=(14,8));animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may13_A0_NMDA_weightmap.mp4', framerate=10, figsize=(14,8))

not much M activity generated ... could run for 100 s to see if emerges ... or goes overboard

myrun 12

  Done; plotting time = 284.79 s

Total time = 10613.54 s

20may13_A0_rast_1.png
2-may13_A0_IM_1.png

one of the E populations ends up dominating, so that's a problem ... due to targetted rule?
the rates are for EMUP are not terrible though...so params apart from targetted might be ok?

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may13_A0_actmap_100s.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may13_A0_AMPA_weightmap_100s.mp4', framerate=10, figsize=(14,8));animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may13_A0_NMDA_weightmap_100s.mp4', framerate=10, figsize=(14,8))

targetted rule seems not to be working properly ... ?? is it due to slight bias in beginning
that gets amplified by other M population getting suppressed through lower weights, and other
populations getting strengthened ... ? or it could occur if one population gets strengthened
for right reason a couple of times, and that strengthening increases bias towards that
action and avoiding other action, which gets suppressed if no more activation

should redo this sim but without the targetted RL , just to check if one M pop gets suppressed
...

ok, run 20may13_B0_
with targettedRL == 0  , all else same ...

myrun 12

  Spikes: 2149938 (4.01 Hz)
  Simulated time: 100.0 s; 12 workers
  Run time: 12102.82 s
Saving output as data/20may13_B0_simConfig.pkl ... 
Finished saving!
  Done; saving time = 13.08 s.
  Done; plotting time = 1262.04 s
Total time = 13866.31 s

20may13_B0_rast.png
20may13_B0_IM.png
20may13_B0_EMDOWN.png
looks like gets to hypersynch ... but at least both populations of M neurons firing

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may13_B0_actmap_100s.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may13_B0_AMPA_weightmap_100s.mp4', framerate=10, figsize=(14,8));animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may13_B0_NMDA_weightmap_100s.mp4', framerate=10, figsize=(14,8))


** does readinweights work properly with AMPA and NMDA weights?

do not see any check for AMPA vs NMDA ...

not clear the NMDA plasticity needed ... could just have long time constant for AMPA eligibility
trace with exp decay ...

*20may14 - no NMDAR RL plasticity; implement/test simple weight normalization
** get rid of the NMDA RL plasticity for now

ok, check the RLon option in sim.json to determine whether to use plasticity for the specific
synapse

    "RL":{"AMPA":
	  {"wbase":0.00001,"wmax":0.00075,"RLon":1,"RLlenhebb":50,"RLlenanti":50,"useRLexp":1,"RLhebbwt":0.0005,"RLantiwt":-0.0,"hebbwt":0,"antiwt":0,"tauhebb":10,"RLwindhebb":50,"softthresh":1,"verbose":0},
	  "NMDA":
	  {"wbase":0.000001,"wmax":0.000075,"RLon":0,"RLlenhebb":800,"RLlenanti":100,"useRLexp":1,"RLhebbwt":0.0005,"RLantiwt":-0.0,"hebbwt":0,"antiwt":0,"tauhebb":10,"RLwindhebb":50,"softthresh":1,"verbose":0}
	 }

there, it's specified to shut off RL for NMDA ...

may want to adjust the NMDA weights too since they're pretty low and probably just as well to leave
them off ...

try a fast sim to test with the NMDA RL off ...

myrun 12

  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 32264 (2.01 Hz)
  Simulated time: 3.0 s; 12 workers
  Run time: 300.88 s

using 100 ms resolution for the AMPA weights ...

20may14_A0_rast.png

looks ok ... did it run any faster? perhaps ...

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may14_A0_actmap_3s.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may14_A0_AMPA_weightmap_3s.mp4', framerate=10, figsize=(14,8))

looks ok ... those videos show reward after ball hit and point scored but not in the hit ball / miss ball panel ...
is that a bug? probably hit/miss code just needs a minor adjustment

** there was a bug in paddle/ball hit detection, ha fixed
** weight rescaling every so often? seems to work/prevent hyperexcit

could normalize incoming AMPA/NMDA weights of EMUP,EMDOWN populations
to have same average or sum as start with ... 

ok, implemented some of that, testing it now ...

normalizeWeightStepSize in sim.json controls how many action steps to use for normalizing the
weights; uses a mult factor for each population based on EEMWghtAM
so when average weights dip below, they're pushed towards that value, and when they're above, they are reduced
scaling as EEMWghtAM / average_weight

seems to work based on printouts ... and some short sims

tried in 10 s sim ... with weight normalization every 500 ms ...

average weights moved in both directions and were scaled up or down ... 

maybe works ... ?

at least no hyperexcit here:
20may14_T0_rast.png

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may14_T0_actmap_10s.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may14_T0_AMPA_weightmap_10s.mp4', framerate=10, figsize=(14,8))

looks like ~avg value maintained fairly well, and some hotspots with high weight emerge too ... 

next, to test in longer sim ... can use 1 s between normalizations ... 

run for 300 s ... with 12 cores ... on zn (20may14_T0_Z0_)

myrun 12

  Simulated time: 300.0 s; 12 workers
  Run time: 22489.13 s

20may14_T0_Z0_rast.png

rates are ok

python -i actmap.py backupcfg/20may14_T0_Z0_sim.json

fig, axs, plt = animActivityMaps('gif/20may14_T0_Z0_300s.mp4')

python -i simdat.py backupcfg/20may14_T0_Z0_sim.json

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may14_T0_Z0_AMPA_weightmap_300s.mp4')

myrun 12

also run same on laptop for 100 s with 12 cores

Analyzing...
  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 1076136 (2.01 Hz)
  Simulated time: 100.0 s; 12 workers
  Run time: 9454.24 s

20may14_T0_L0_rast.png
20may14_T0_L0_EMDOWN.png
20may14_T0_L0_IM.png
20may14_T0_L0_EMUP.png

activity looks ok - EMUP,EMDOWN,IM rates pretty low
  
python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may14_T0_L0_actmap_100s.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may14_T0_L0_AMPA_weightmap_100s.mp4', framerate=10, figsize=(14,8))

looks ok though seems to need a lot more time to improve, if ever ... may want to adjust normalization
rule to only scale weights down if they pass some threshold, and at a higher threshold than initial average weight

or perhaps maintaining the initial average weight would allow for sparse firing and more efficient coding??

probably need long runs with comparisons to determine ...

could have upper and lower threshold for normalizing weights; when average weight higher than upper threshold
scale down; when average weight below lower threshold scale up. lower threshold could be set to starting
average weight but upper threshold could be set to some positive multiple of starting weight. that way normalization
would push average weight to be within a reasonable range...

ok, try that rule with lower bound of original and upper bound of 5X original ... weights will likely go up
and hover around upper bound ... 

myrun 12

20may14_T0_M0_rast.png

rates look ok so far ... 

python -i actmap.py 

fig, axs, plt = animActivityMaps('gif/20may14_T0_M0_actmap_10s.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may14_T0_M0_AMPA_weightmap_10s.mp4', framerate=10, figsize=(14,8))

based on previous sims 2X original weight probably high enough and even that may produce hypersynchrony ...
can try the 2X anyway to check ... see if it does any better than the 1X original weight rule (same min
and max threshold)

will run that on zn for 300 s ... and compare to other sim currently running ...

myrun 12

  Simulated time: 300.0 s; 12 workers
  Run time: 21025.55 s
  Done; plotting time = 1867.69 s  
  Total time = 23540.60 s

20may14_Min1Max2Thresh_Z0_rast.png
rates look ok at end, only slightly higher than other sim
but the scaling factor used was 1.0 for most of simulation (after initial scaling up
of all stdp/rl weights). the 1.0 scaling means that the weights never got up to the
upper limit; so then it's surprising the network did not reach hypersynchrony ...
something seems off ...

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may14_Min1Max2Thresh_Z0_300s.mp4')

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may14_Min1Max2Thresh_Z0_AMPA_weightmap_300s.mp4', framerate=10, figsize=(14,8))

*20may15 - check weight norm, fix resumesim (multistep)
** check the weight normalization

why does hyperexcit not emerge when weights are below the max, but
continuously increasing?

due to soft thresholding? should the min,max weight thresholds be closer to the wbase, wmax params for the
STPD/RL??

if starting EEMWghtAM is at max for RL weights (0.00075) is there hyperexcit?

myrun 12

20may15_rast_a0.png

yeah, there's hyperexcit, then after weights normalized (lower) at t=500 ms, the hyperexcit
disappears

t= 500.0000000000452 - adjusting weights based on RL critic value: -0.001
sim.rank= 0 davg: {'EMUP': 0.0005615105765452703, 'EMDOWN': 0.0005615055487169171} dfctr: {'EMUP': 0.26713655319350277, 'EMDOWN': 0.2671389451854241}

then later it moves up a bit and is normalized downward some more:
t= 1000.0000000001588 - adjusting weights based on RL critic value: -0.001
sim.rank= 0 davg: {'EMUP': 0.00015004612430169018, 'EMDOWN': 0.0001500624095345771} dfctr:
{'EMUP': 0.9996925991797199, 'EMDOWN': 0.9995841094730473}

what if EEMWghtAM starts at 0.00015 ... ?

myrun 12

savefig('gif/20may15_rast_a0.png') # hmm, overwrote last file

less hypersynch and it decays anyway from the RL ... if RL was off, what would happen?

myrun 12

savefig('gif/20may15_rast_a1.png') # not much hypersynch ...

so 0.00015 would be a decent upper limit ... can it be higher?

try with "EEMWghtAM":0.000375

myrun 12

savefig('gif/20may15_rast_a2.png') # mostly ok but some periods of overly (?) synchronous firing

so, that might be ok as upper bound ... higher upper bound could allow larger set of weights ...
but could run another sim with lower upper bound for comparison ... 

** movies from zn 300 s sims -->> gradual increase in probability of following ball?

20may14_Min1Max2Thresh_Z0_AMPA_weightmap_300s.mp4 <<-- that one looks better
than 20may14_T0_Z0_AMPA_weightmap_300s.mp4

the better sim (20may14_Min1Max2Thresh_Z0_) has higher max weight before normalization, and follow ball probability is
increasing with the weights. longer duration might allow the follow ball probability to surpass the not follow ball probability

the other sim (20may14_T0_Z0_) has lower max weight before normalization, and the probability of follow and not follow seem
to have hit a plateau corresponding with the weights, or at least a lower slope compared to the other simulation

that suggests higher max weight would perform better in the long run... at least encouraging that the follow
ball probability seems to be increasing ... 

** fixup/check resumesim

also check if can run sim saving everything but not drawing the raster ... that takes a long time

first run with raster for comparison ...

savefig('gif/20may15_b0_rast.png')

ok, with doplot==0, doquit==1 it runs ok

and then should have quick func to draw raster ...

python -i simdat.py

simConfig.keys() # dict_keys(['netpyne_version', 'netpyne_changeset', 'net', 'simConfig', 'simData'])
simConfig['simData'].keys() # dict_keys(['spkt', 'spkid', 'V_soma', 't', 'dminID', 'avgRate'])
simConfig['simData']['avgRate'] # 1.9083784288113455

plot(simConfig['simData']['spkt'],simConfig['simData']['spkid'],'ko',markersize=2)

savefig('gif/20may15_rast_b1.png')

looks ok, though no color/type/rate, can add that in or see if netpyne raster func supported here ...

simConfig['simData']['V_soma'].keys() 
dict_keys(['cell_0', 'cell_900', 'cell_4359', 'cell_400', 'cell_4759', 'cell_500', 'cell_4100', 'cell_5159'])

python -i simdat.py

dspkID.keys() # dict_keys(['ER', 'IR', 'EV1', 'EV1DE', 'EV1DNE', 'EV1DN', 'EV1DNW', 'EV1DW', 'EV1DSW', 'EV1DS', 'EV1DSE', 'IV1', 'EV4', 'IV4', 'EMT', 'IMT', 'EMDOWN', 'EMUP', 'IM'])
dspkT.keys() # dict_keys(['ER', 'IR', 'EV1', 'EV1DE', 'EV1DNE', 'EV1DN', 'EV1DNW', 'EV1DW', 'EV1DSW', 'EV1DS', 'EV1DSE', 'IV1', 'EV4', 'IV4', 'EMT', 'IMT', 'EMDOWN', 'EMUP', 'IM'])

drawraster(dspkT,dspkID)

savefig('gif/20may15_rast_b2.png')

looks pretty good...

should run much longer sim with resume ... with sim duration on order of 1000 of s ...

1 reason to use resume is if sim crashes in middle, would not have any intermediate output ...

try a 2 step sim ... make sure everything working 

python multistepSim.py sim.json 12 2 multirun

got error about not being able to restore STDP weights ...

ok, fixed up ...

try 3 steps to make sure working ...

python multistepSim.py sim.json 12 3 multirun

well, no crashes, so that's good ... check rasters

python -i simdat.py backupcfg/20may15_C0__step_0_sim.json
drawraster(dspkT,dspkID)
savefig('gif/20may15_step0_b3.png')
quit()

python -i simdat.py backupcfg/20may15_C0__step_1_sim.json
drawraster(dspkT,dspkID)
savefig('gif/20may15_step1_b3.png')
quit()

python -i simdat.py backupcfg/20may15_C0__step_2_sim.json
drawraster(dspkT,dspkID)
savefig('gif/20may15_step2_b3.png')

there are some diffs in firing patterns and rates ... check the weights too ...

python -i simdat.py backupcfg/20may15_C0__step_0_sim.json
animSynWeights(pdf)
gif/20may15_C0__step_0_weightmap.mp4

python -i simdat.py backupcfg/20may15_C0__step_1_sim.json
animSynWeights(pdf)
gif/20may15_C0__step_1_weightmap.mp4

python -i simdat.py backupcfg/20may15_C0__step_2_sim.json
animSynWeights(pdf)
gif/20may15_C0__step_2_weightmap.mp4

seems like the weights are properly loaded, and sim continues from there ...

one thing that seems to recur is paddle getting stuck at top ... that bias
seems difficult to overcome, hopefully not an intrinsic bias ...e.g. in the
wiring ... 

** setup long multistep sim on zn (20may15_ZN_MultiStep_A_)

python multistepSim.py sim.json 12 10 multirun

sim base name is 20may15_ZN_MultiStep_A_

with "EEMWghtThreshMax":0.000375

started ~17:16 ... 10 steps of 300 s ... total of 3000 s ...

** other multistep sim on zn (20may15_ZN_MultiStep_B_)

with slightly higher max weight ...

with "EEMWghtThreshMax":0.0005

python multistepSim.py sim.json 12 10 multirun

started ~17:27 ...

*20may18 - looking at output from long multistep runs, M encoding issues?
** start looking at output from latest multistep runs

each sim finished ~4 steps each for total of ~1200 s

first just look at hit/miss ball probabilities ... 

*** simA 20may15_ZN_MultiStep_A_

python
import numpy as np
import pandas as pd
from pylab import *
from simdat import plotRewards,plotFollowBall,plotHitMiss

name = '20may15_ZN_MultiStep_A__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,4,1):
  name = '20may15_ZN_MultiStep_A__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)

np.amax(pda.time) # 1200000.0
  
pda.columns # Index(['time', 'action', 'reward', 'proposed', 'hit'], dtype='object')

#
plotRewards(pda,ax=subplot(3,1,1),msz=3,xl=(0,120e3))
plotFollowBall(pda,ax=subplot(3,1,2),msz=3)
plotHitMiss(pda,ax=subplot(3,1,3),msz=3)

tight_layout()

savefig('gif/20may18_multistep_A_reward_1200s_a0.png')

in middle panel follow vs not follow might be improving, though somewhat slowly...could also just be converging towards 50/50 (random)

*** simB 20may15_ZN_MultiStep_B_

python
import numpy as np
import pandas as pd
from pylab import *
from simdat import plotRewards,plotFollowBall,plotHitMiss

name = '20may15_ZN_MultiStep_B__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,4,1):
  name = '20may15_ZN_MultiStep_B__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)

np.amax(pda.time) # 1200000.0
  
pda.columns # Index(['time', 'action', 'reward', 'proposed', 'hit'], dtype='object')

#
clf()
plotRewards(pda,ax=subplot(3,1,1),msz=3,xl=(0,120e3))
plotFollowBall(pda,ax=subplot(3,1,2),msz=3)
plotHitMiss(pda,ax=subplot(3,1,3),msz=3)

tight_layout()

savefig('gif/20may18_multistep_B_reward_1200s_b0.png')

*** compare the two

python
import numpy as np
import pandas as pd
from pylab import *
from simdat import plotRewards,plotFollowBall,plotHitMiss

lpda = []

name = '20may15_ZN_MultiStep_A__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,4,1):
  name = '20may15_ZN_MultiStep_A__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)

lpda.append(pda)
  
name = '20may15_ZN_MultiStep_B__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,4,1):
  name = '20may15_ZN_MultiStep_B__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)
  
lpda.append(pda)

# sim A on left (lower max weight threshold), sim B on right (higher max weight threshold)
plotFollowBall(lpda[0],ax=subplot(1,2,1),msz=3); plotFollowBall(lpda[1],ax=subplot(1,2,2),msz=3)

savefig('gif/20may18_multistep_A_B_reward_1200s_c0.png')

the one with lower max weights seems to converge faster ... and get toward slightly higher accuracy ... ?

plotHitMiss(lpda[0],ax=subplot(1,2,1),msz=3); plotHitMiss(lpda[1],ax=subplot(1,2,2),msz=3)

savefig('gif/20may18_multistep_A_B_hit_miss_1200s_c1.png')

for hit,miss the one with higher max weights gets slightly higher number of hits

plotRewards(lpda[0],ax=subplot(1,2,1),msz=3); plotRewards(lpda[1],ax=subplot(1,2,2),msz=3)

savefig('gif/20may18_multistep_A_B_rewards_1200s_c2.png')

can't see diffs from reward fig ...

sum(lpda[0].reward) # 290.6
sum(lpda[1].reward) # 289.36
so, almost identical total reward ...

may as well let those sims run some more to see if they improve further ... possible that
learning is taking place, just at a slow rate ...

make movies to see how weights changing ... use last available step

python -i simdat.py backupcfg/20may15_ZN_MultiStep_A__step_4_sim.json
animSynWeights(pdf)

python -i simdat.py backupcfg/20may15_ZN_MultiStep_B__step_4_sim.json
animSynWeights(pdf)



** build a map of which info received by each/all M neurons

otherwise will not know if architecture supports proper decision making

** try higher conn probability for inputs to M populations

that will increase likelihood that M populations have enough info to make decisions

can make a param to control it ... EEMProb, and as scale up prob, scale down the incoming weights ...

EEMProb ... original was 0.1 ... try at double probability ... and 1/2 weight ... 

change "EEMWghtAM":0.000075,"EEMWghtNM":0.0000075
to
"EEMWghtAM":0.0000375,"EEMWghtNM":0.00000375

also change "EEMWghtThreshMin":0.000075,"EEMWghtThreshMax":0.0005
to
"EEMWghtThreshMin":0.0000375,"EEMWghtThreshMax":0.0005

myrun 12

ok...

python -i simdat.py

drawraster(dspkT,dspkID)
savefig('gif/20may18_d0.png')

rates are ok ... 

animSynWeights(pdf,'gif/20may18_d0_weightmap.mp4')

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may18_d0_actmap.mp4')

well, activity not epileptic ... could run a long sim to compare to how others performing ...

even 100 s worth trying ...

20may18_L0_

myrun 12

hmm, laptop got closed in middle of run ... 

** info

right now, convergence onto any EM neuron is from 10% of presynaptic neurons
so that's 40 neurons of each direction selective class ... 40 x 8 = 320
40 from EV1, 10 from EV4, 2.5 from EMT, ... most of the inputs are from direction selective
neurons . . . is that reasonable?

when 20%, 80 neurons ...

** do M neurons need topography? recurrent connectivity with RL synapses? 

any E M neuron could receive information from spatially separated locations ...

if no topography, then should have recurrent connectivity in EM neurons with RL synapses ...

topographic arrangement of M neurons might allow better prediction on when to move ... for
example if ball is far away but moving in a certain direction, might want to initiate movement
in advance of the ball getting to the paddle ...

so while there's some spatial information with random connectivity, it's less organized/useful if
receiving random (from spatial perspective) inputs?

if ball in middle of screen moving SE, and paddle is at top right stationary, EM Down should be
activated ... so there should be at least one EM Down neuron that receives strong V1 input at top
right and middle of screen SE neuron ... if there was a topographic arrangement of EM neurons,
would that be possible? not if there are restriction of connectivity across spatially distant
neurons... but having additional recurrent connectivity in EM might still allow that encoding to emerge

tried that out briefly with some recurrent connectivity between EMUP<>EMUP and EMDOWN<>EMDOWN

gif/20may18_M0_weightmap.mp4
gif/20may18_M0_actmap.mp4
savefig('gif/20may18_M0_rast.png')

why do weights start below "EEMWghtAM":0.0000375 and only jump up at weight normalization time?
have noticed that in other simulations ... also, almost no EM activity after first two burst
until that weight norm ... 

will have to put in param to control whether to include recurrent/RL connectivity
between the EM populations ...

*20may19 - look at multistep output; other new options; setting up on falcor
** check latest from multistep -- sim with higher max weight still improving

python
import numpy as np
import pandas as pd
from pylab import *
from simdat import plotRewards,plotFollowBall,plotHitMiss

lpda = []

name = '20may15_ZN_MultiStep_A__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,5,1):
  name = '20may15_ZN_MultiStep_A__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)

lpda.append(pda)
  
name = '20may15_ZN_MultiStep_B__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,5,1):
  name = '20may15_ZN_MultiStep_B__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)
  
lpda.append(pda)

# sim A on left (lower max weight threshold), sim B on right (higher max weight threshold)
clf(); plotFollowBall(lpda[0],ax=subplot(1,2,1),msz=3); ylim((0.3,.51)); plotFollowBall(lpda[1],ax=subplot(1,2,2),msz=3); ylim((.3,.51))

savefig('gif/20may19_multistep_A_B_reward_1500s_a0.png')

the one with lower max weights seems to converge faster ... and get toward slightly higher accuracy ...
but the one with higher max weights still has a slightly upward slope

clf(); plotHitMiss(lpda[0],ax=subplot(1,2,1),msz=3); ylim((0,100)); plotHitMiss(lpda[1],ax=subplot(1,2,2),msz=3); ylim((0,100));

savefig('gif/20may19_multistep_A_B_hit_miss_1500s_a1.png')

the one with higher max weights is doing a little better in terms of hits vs misses ... 

clf(); plotRewards(lpda[0],ax=subplot(1,2,1),msz=3); plotRewards(lpda[1],ax=subplot(1,2,2),msz=3)

savefig('gif/20may19_multistep_A_B_rewards_1500s_a2.png')

sum(lpda[0].reward) # 358.09000000000003
sum(lpda[1].reward) # 369.83099999999996

higher overall reward for second sim (higher max weights) ...

finished step 6 (total of 2100 s; 35 hours <<-- minutes!) for both sims ... next steps were not completed due to crash
from missing new param in the previously made json files ... take a look at the output ... to
see whether worth continuing either

python
import numpy as np
import pandas as pd
from pylab import *
from simdat import plotRewards,plotFollowBall,plotHitMiss

lpda = []

name = '20may15_ZN_MultiStep_A__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,7,1):
  name = '20may15_ZN_MultiStep_A__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)

lpda.append(pda)
  
name = '20may15_ZN_MultiStep_B__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,7,1):
  name = '20may15_ZN_MultiStep_B__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)
  
lpda.append(pda)

# sim A on left (lower max weight threshold), sim B on right (higher max weight threshold)
clf(); plotFollowBall(lpda[0],ax=subplot(1,2,1),msz=3); ylim((0.3,.51)); plotFollowBall(lpda[1],ax=subplot(1,2,2),msz=3); ylim((.3,.51))

savefig('gif/20may19_multistep_A_B_reward_2100s_a0.png')

clf(); plotHitMiss(lpda[0],ax=subplot(1,2,1),msz=3); ylim((0,120)); plotHitMiss(lpda[1],ax=subplot(1,2,2),msz=3); ylim((0,120));

savefig('gif/20may19_multistep_A_B_hit_miss_2100s_a1.png')

the one with higher max weights is a little worse in terms of hits vs misses ... 

clf(); plotRewards(lpda[0],ax=subplot(1,2,1),msz=3); plotRewards(lpda[1],ax=subplot(1,2,2),msz=3)

savefig('gif/20may19_multistep_A_B_rewards_2100s_a2.png')

sum(lpda[0].reward) # 505.499
sum(lpda[1].reward) # 507.49799999999993

similar overall rewards ... and similar overall performance ...  looks like the learning has mostly stopped improving ...
need to figure out what's preventing improvement

could continue set B ... steps 7,8,9 ... just to check ...

will adjust multirun and make conf.py check for new option (if absent, defaults to opticflow for now since that's
what started this set of sims from)

multirun

** couple new options

"EEMProb":0.2, <<-- sets probability of connections
"EEMRecProb":0.0 <<-- sets recurrent connectivity probability between neurons in EM populations
(same command directions only)

** try new object tracker

with EEMRecProb of 0.1, EEMProb of 0.1

myrun 12

  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 17288 (0.65 Hz)
  Simulated time: 5.0 s; 12 workers
  Run time: 604.94 s

python -i simdat.py

drawraster(dspkT,dspkID)
savefig('gif/20may19_a0.png')

animSynWeights(pdf)

gif/20may19_A0_weightmap.mp4

python -i actmap.py

fig, axs, plt = animActivityMaps()

gif/20may19_A0_actmap.mp4

object-detection-based direction fields look much more refined than before from optical flow

adjust weights ... to inc firing ...

savefig('gif/20may19_a1.png')

** setting up on falcor

first need to install miniconda (to save space)

downloaded and installed for python3.7

Miniconda3-latest-Linux-x86_64.sh

in /home/samn/miniconda3

note that is uses bash and modifies .bashrc
have to modify .tcshrc to use it
or can use bash ...

falcor:~/SMARTAgent> bash
(base) samn@falcor:~/SMARTAgent$ which python
/home/samn/miniconda3/bin/python

(base) samn@falcor:~/SMARTAgent$ python
Python 3.7.6 (default, Jan  8 2020, 19:59:22) 
[GCC 7.3.0] :: Anaconda, Inc. on linux
Type "help", "copyright", "credits" or "license" for more information.
>>>

mkdir ~/neuron
cd ~/neuron/
git clone https://github.com/neuronsimulator/nrn
git clone https://github.com/neuronsimulator/iv

export IVB=~/neuron/iv; cd $IVB   
./build.sh
./configure --prefix=$PWD
make
make install

conda install numpy scipy matplotlib pandas scikit-image
pip install 'gym[atari]'

## pip install imageio-ffmpeg## ??

conda install imageio-ffmpeg -c conda-forge

export ND=~/neuron/nrn; cd $ND
./build.sh
./configure --with-iv=$IVB --prefix=$ND --with-nrnpython=dynamic --with-paranrn --with-mpi --with-pyexe=python3

hmm, no MPI installed on Falcor ...

checking for mpicc... no
checking for hcc... no
checking for mpcc... no
checking for mpcc_r... no
checking for mpxlc... no
checking for cmpicc... no
checking for MPI_Init... no
checking for MPI_Init in -lmpi... no
checking for MPI_Init in -lmpich... no
configure: error: Cannot compile MPI program

downloaded and install open-mpi

https://www.open-mpi.org/faq/?category=building

cd ~/Downloads
gunzip -c openmpi-4.0.3.tar.gz | tar xf -
cd openmpi-4.0.3
./configure --prefix=/home/samn/openmpi
make all install

then make sure that openmpi in the path so NEURON's configure can detect it ...

echo $PATH
/home/samn/miniconda3/bin:/home/samn/miniconda3/condabin:/home/samn/bin:/home/samn/.local/bin:/home/samn/bin:/home/samn/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games

export PATH="/home/samn/openmpi/bin:$PATH"

and put that into .bashrc

which mpicc
/home/samn/openmpi/bin/mpicc

export ND=~/neuron/nrn; cd $ND
./configure --with-iv=$IVB --prefix=$ND --with-nrnpython=dynamic --with-paranrn --with-mpi --with-pyexe=python3
make -j 10  # OPTIONAL  -j 10 will multithread the make and speed up ~10x

/home/samn/neuron/nrn/missing: line 81: flex: command not found
WARNING: 'flex' is missing on your system.
         You should only need it if you modified a '.l' file.
         You may want to install the Fast Lexical Analyzer package:
         <http://flex.sourceforge.net/>

https://github.com/westes/flex/releases


cd ~/Downloads
tar -xvf flex-2.6.4.tar.gz
cd flex-2.6.4
./autogen.sh

Can't exec "autopoint": No such file or directory at /usr/share/autoconf/Autom4te/FileUtils.pm line 345.
autoreconf: failed to run autopoint: No such file or directory
autoreconf: autopoint is needed because this package uses Gettext

./configure --prefix=/home/samn/bin

/bin/bash: ../build-aux/depcomp: No such file or directory
Makefile:804: recipe for target 'libmain.lo' failed
make[2]: *** [libmain.lo] Error 127
make[2]: Leaving directory '/home/samn/Downloads/flex-2.6.4/src'
Makefile:546: recipe for target 'all' failed
make[1]: *** [all] Error 2
make[1]: Leaving directory '/home/samn/Downloads/flex-2.6.4/src'
Makefile:533: recipe for target 'all-recursive' failed
make: *** [all-recursive] Error 1

make

up to here ... 

make install

echo $ND
/home/samn/neuron/nrn

echo $PYTHONPATH

Make sure that PYTHONPATH includes $ND/share/python/lib/python
Add $ND/x86_64/bin to $PATH


*20may20
** look at output from long run (20may15_ZN_MultiStep_B)

finished step 7 already ... two more steps and then 3000 s finished (backupcfg/20may15_ZN_MultiStep_B__step_6_sim.json)

instead of cumulative follow/miss should probably plot average over an interval ... cumulative value
will change very slowly

python
import numpy as np
import pandas as pd
from pylab import *
from simdat import plotRewards,plotFollowBall,plotHitMiss
  
name = '20may15_ZN_MultiStep_B__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,8,1):
  name = '20may15_ZN_MultiStep_B__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)
  
np.amax(pda.time) # 2400000.0

#
plotFollowBall(pda,ax=subplot(1,3,1),msz=3); ylim((.3,.51))
plotHitMiss(pda,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(pda,ax=subplot(1,3,3),msz=3); 

savefig('gif/20may20_B_step7_a0.png')

sum(pda.reward) # 566.635

actreward = pda

action_times = np.array(actreward.time)
actionvsproposed = np.array(actreward.action-actreward.proposed)

Hit_Missed = np.array(actreward.hit)

followact = np.where(actionvsproposed==0,1,0)
nbin = int(10e3 / (action_times[1]-action_times[0]))
avgfollow = [mean(followact[sidx:sidx+nbin]) for sidx in arange(0,len(followact),nbin)]
plot(20*arange(0,len(followact),nbin), avgfollow)
savefig('gif/20may20_B_step7_a1.png')

so that's probability of following, which does not improve past ~0.5 at peak, and then
decays a bit...

Hit_Missed = np.array(actreward.hit)
allHit = np.where(Hit_Missed==1,1,0) 
nbin = int(10e3 / (action_times[1]-action_times[0]))
avghit = [mean(allHit[sidx:sidx+nbin]) for sidx in arange(0,len(allHit),nbin)]
plot(20*arange(0,len(allHit),nbin), avghit)
savefig('gif/20may20_B_step7_a2.png')

and probability of hits is not increasing ...

in actmap movies looked like bias towards particular direction was interfering with ability of model to perform well ...

could have some smoothing function on firing rates and minimum difference in rates to generate a move

will stop multistep B from continuing for now ...

** normalize inputs to populations to avoid any bias (on average) ?

not all actions should be equal probability ... but avoiding bias on average might help ...
worth a try ...

myrun 12

python -i simdat.py

drawraster(dspkT,dspkID)
savefig('gif/20may20_b0.png')

animSynWeights(pdf)

gif/20may20_A0_weightmap.mp4

python -i actmap.py

fig, axs, plt = animActivityMaps()

gif/20may20_A0_actmap.mp4

hmm, still getting stuck at top for a while

** continue setup on falcor

ryan installed flex on falcor ... 

export ND=~/neuron/nrn; cd $ND
./configure --with-iv=$IVB --prefix=$ND --with-nrnpython=dynamic --with-paranrn --with-mpi --with-pyexe=python3
make -j 10  # OPTIONAL  -j 10 will multithread the make and speed up ~10x

yacc missing ... asked & ryan installed yac

make -j 10  # OPTIONAL  -j 10 will multithread the make and speed up ~10x

make install

echo $ND
/home/samn/neuron/nrn

echo $PYTHONPATH

Make sure that PYTHONPATH includes $ND/share/lib/python
export PYTHONPATH="$ND/share/lib/python"
Add $ND/x86_64/bin to $PATH
and put into .bashrc

hmm, neuron starts with python but from neuron import h does not work ...

(base) samn@falcor:~$ python
Python 3.7.6 (default, Jan  8 2020, 19:59:22) 
[GCC 7.3.0] :: Anaconda, Inc. on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> from neuron import h
Traceback (most recent call last):
  File "/home/samn/neuron/nrn/share/lib/python/neuron/__init__.py", line 124, in <module>
    import hoc
ModuleNotFoundError: No module named 'hoc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/samn/neuron/nrn/share/lib/python/neuron/__init__.py", line 128, in <module>
    import neuron.hoc
ModuleNotFoundError: No module named 'neuron.hoc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/samn/neuron/nrn/share/lib/python/neuron/__init__.py", line 130, in <module>
    exec("import neuron.hoc%d%d as hoc" % (sys.version_info[0], sys.version_info[1]))
  File "<string>", line 1, in <module>
ModuleNotFoundError: No module named 'neuron.hoc37'

maybe HOC_LIBRARY_PATH not set properly?

export HOC_LIBRARY_PATH="$ND/share/nrn/lib/hoc"

python
from neuron import h

no, same error ...

cd /home/samn/neuron/nrn/src/nrnpython
python setup.py install --home=$ND/share/lib/python

this is a much easier way to install neuron (without compilation): 
pip install neuron-nightly

export PYTHONPATH=''

python
from neuron import h

works now ...

which nrniv
/home/samn/miniconda3/bin/nrniv

pip install netpyne --upgrade

ok ... anything else missing? should consolidate install instructions somewhere ...

** try run on falcor

first compile model ...

nrnivmodl mod

ok, needed aux_fun.inc ... added to repo ...

then error about not finding mpi libraries and should set LD_LIBRARY_PATH

export LD_LIBRARY_PATH="/home/samn/openmpi/lib"

error about missing glibc used by scipy fft ...

conda install -c asmeurer glibc

./myrun 16

--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 0 with PID 0 on node falcor exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------

conda remove asmeurer glibc

hmm, now conda messed up ...

so did

bash ~/Downloads/Miniconda3-latest-Linux-x86_64.sh -u
to fix ...

/home/samn/Downloads/Miniconda3-latest-Linux-x86_64.sh: line 449: 42131 Segmentation fault      (core dumped) $PREFIX/bin/python -E -s "$PREFIX/pkgs/.cio-config.py" "$THIS_PATH"

hmm, better start over with conda/neuron ... !

look in install.txt for instructions ...

conda install gcc_linux-64 openmpi mpi4py

which mpicc
/home/samn/miniconda3/bin/mpicc

ok, so that's using conda's version of openmpi ... easier than compiling openmpi directly

./myrun 16

Traceback (most recent call last):
  File "sim.py", line 1, in <module>
    from netpyne import specs, sim
  File "/home/samn/miniconda3/lib/python3.7/site-packages/netpyne/sim/__init__.py", line 72, in <module>
    from .. import analysis
  File "/home/samn/miniconda3/lib/python3.7/site-packages/netpyne/analysis/__init__.py", line 39, in <module>
    from .spikes import calculateRate, plotRates, plotSyncs, plotRaster, plotSpikeHist, plotSpikeStats, plotRatePSD, plotRateSpectrogram, popAvgRates
  File "/home/samn/miniconda3/lib/python3.7/site-packages/netpyne/analysis/spikes.py", line 34, in <module>
    import scipy
  File "/home/samn/miniconda3/lib/python3.7/site-packages/scipy/__init__.py", line 156, in <module>
    from . import fft
  File "/home/samn/miniconda3/lib/python3.7/site-packages/scipy/fft/__init__.py", line 81, in <module>
    from ._helper import next_fast_len
  File "/home/samn/miniconda3/lib/python3.7/site-packages/scipy/fft/_helper.py", line 4, in <module>
    from . import _pocketfft
  File "/home/samn/miniconda3/lib/python3.7/site-packages/scipy/fft/_pocketfft/__init__.py", line 3, in <module>
    from .basic import *
  File "/home/samn/miniconda3/lib/python3.7/site-packages/scipy/fft/_pocketfft/basic.py", line 8, in <module>
    from . import pypocketfft as pfft
ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.22' not found (required by /home/samn/miniconda3/lib/python3.7/site-packages/scipy/fft/_pocketfft/pypocketfft.cpython-37m-x86_64-linux-gnu.so)

conda install cython

./myrun 16

same error ...

 strings /usr/lib/x86_64-linux-gnu/libstdc++.so.6 | grep GLIBC
GLIBCXX_3.4
GLIBCXX_3.4.1
GLIBCXX_3.4.2
GLIBCXX_3.4.3
GLIBCXX_3.4.4
GLIBCXX_3.4.5
GLIBCXX_3.4.6
GLIBCXX_3.4.7
GLIBCXX_3.4.8
GLIBCXX_3.4.9
GLIBCXX_3.4.10
GLIBCXX_3.4.11
GLIBCXX_3.4.12
GLIBCXX_3.4.13
GLIBCXX_3.4.14
GLIBCXX_3.4.15
GLIBCXX_3.4.16
GLIBCXX_3.4.17
GLIBCXX_3.4.18
GLIBCXX_3.4.19
GLIBCXX_3.4.20
GLIBCXX_3.4.21
GLIBC_2.3
GLIBC_2.2.5
GLIBC_2.14
GLIBC_2.4
GLIBC_2.18
GLIBC_2.3.4
GLIBC_2.17
GLIBC_2.3.2
GLIBCXX_DEBUG_MESSAGE_LENGTH

export LD_LIBRARY_PATH="/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH"

./myrun 16

hmm, did not help ...

ryan upgraded libc package ... try again

now get this when compile with nrnivmodl:

/bin/sh: 1: x86_64-conda_cos6-linux-gnu-c++: not found
/home/samn/miniconda3/lib/python3.7/site-packages/neuron/.data/bin/nrnmech_makefile:76: recipe for target 'x86_64/libnrnmech.0.0.so' failed
make: *** [x86_64/libnrnmech.0.0.so] Error 127

may need to redo conda install again ...

condensed commands:
bash ~/Downloads/Miniconda3-latest-Linux-x86_64.sh
conda install numpy scipy matplotlib pandas scikit-image

pip install 'gym[atari]'
conda install imageio-ffmpeg -c conda-forge

conda install gcc_linux-64 openmpi mpi4py cython
conda install openmpi mpi4py cython
## conda install gcc_linux-64

pip install neuron-nightly
pip install netpyne --upgrade
cd ~/SMARTAgent
nrnivmodl mod

*20may21
** continue with falcor install/setup -->> works now

ryan suggests:
conda install gxx_linux-64
based on https://github.com/RcppCore/Rcpp/issues/770

installed successfully ... now try compile

nrnivmodl mod

Successfully created x86_64/special
great...now let's see if it runs ...

./myrun 16

Try loading libmpi and libmpich
load_mpi: libmpich.so: cannot open shared object file: No such file or directory
Is openmpi, mpich, intel-mpi, sgi-mpt etc. installed? If not in default location, need a LD_LIBRARY_PATH.

hmm, thought openmpi already installed ...

can set LD_LIBRARY_PATH to /home/samn/miniconda3/lib

export LD_LIBRARY_PATH="/home/samn/miniconda3/lib"

** try a sim on falcor

./myrun 16

seems to be working!

it runs but even with doquit==1 does not stop ... will have to debug that
for multistep ...

check output ...

python -i simdat.py

drawraster(dspkT,dspkID)

savefig('gif/20may21_rast_a0.png')
xlim((19e3,20e3))
savefig('gif/20may21_rast_a0b.png')

animSynWeights(pdf)

python -i actmap.py

fig, axs, plt = animActivityMaps()

activity looks typical - this is with the new weight normalization that
equalizes inputs to the two M populations
even with that weight normalization the paddle gets stuck at top
and even with the weights ~equal to both sets of EM neurons ... that suggests a bug...??

try inc EEMProb ... to 0.3

./myrun 16

  Connections: 0 (0.00 per cell)
  Spikes: 37701 (3.52 Hz)
  Simulated time: 2.0 s; 16 workers
  Run time: 182.41 s
fatal: Not a git repository (or any parent up to mount point /home)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
Saving output as data/20may21_B0_simConfig.pkl ... 
Finished saving!
  Done; saving time = 1.52 s.

what's the git error ...

python -i simdat.py

drawraster(dspkT,dspkID)
savefig('gif/20may21_rast_b0.png')
hypersynch from the larger number of inputs ...

animSynWeights(pdf)
gif/20may21_B0_weightmap.mp4

python -i actmap.py
fig, axs, plt = animActivityMaps()

also reduce the weights ...

python -i simdat.py
drawraster(dspkT,dspkID)
savefig('gif/20may21_rast_b1.png')
those rates are fine

could add a margin factor to different between rates for movement directions ... otherwise hold still ...
will try longer sim first (300 s) ... (20may21_B0_)

./myrun 16

python -i simdat.py
drawraster(dspkT,dspkID)
savefig('gif/20may21_rast_b2.png')

animSynWeights(pdf) # gif/20may21_B0_weightmap.mp4

python -i actmap.py
fig, axs, plt = animActivityMaps() # gif/20may21_B0_actmap.mp4

try another sim in parallel (20may21_C0_) with different scoring ...
instead of
    "rewardcodes": {"scorePoint": 1, "losePoint": -0.01, "followBall": 0.01, "avoidBall": -0.001, "hitBall": 0.25},
try:
    "rewardcodes": {"scorePoint": 1, "losePoint": -0.1, "followBall": 0.1, "avoidBall": -0.01, "hitBall": 0.5},

hmm, right now by accident running two of 20may21_B0 ... kill one and start 20may21_C0 

*20may22
** sims on falcor still running

for some reason they didn't complete yet ... do they get stalled when pause the x2go connection?

can try running on my too ... zn over-booked

also asked ryan (nki) about availability of other machines ...

** try run with recurrent/plasticity in EM (10%) 20may22_D0_ on laptop (crashed in middle)

20may22_D0_

add in the recurrent/plastic connectivity to EM populations (~10%)
see if existing weights ok ...

myrun 12

somewhat slow ... may as well use laptop ... 

myrun 12

python -i simdat.py

drawraster(dspkT,dspkID)
savefig('gif/20may22_rast_d0.png')

animSynWeights(pdf) # 

python -i actmap.py
fig, axs, plt = animActivityMaps() # gif/20may22_D0_actmap.mp4

bug in optical flow at right side of image ... always pointing west around right paddle location ...
at least it's ~constant ... but note to fix it ...

run 100 s ...

myrun 12

pretty slow on laptop as well ... must be due to all the extra connections ...

will add a separate json file for myself to avoid conflicts with what haroon's doing ...

cp sim.json sn.json

git add sn.json snnotes.dol; git commit -m 'separate json file for self'; gpushdev

run on laptop crashed in middle ... 

** try further doubling connectivity onto EM (20may22_E0_)

and also reducing the weight to avoid epi

can try 12 cores on zn ...

"EEMProb":0.6,"EEMRecProb":0.2

myrun 12 sn.json

  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 20147 (1.88 Hz)
  Simulated time: 2.0 s; 12 workers
  Run time: 2183.28 s


"EEMWghtAM":0.0000125,"EEMWghtNM":0.00000125,"EEMWghtThreshMin":0.000025,"EEMWghtThreshMax":0.000075

same reward codes as used on laptop:
    "rewardcodes": {"scorePoint": 1, "losePoint": -0.1, "followBall": 0.1, "avoidBall": -0.01,
    "hitBall": 0.5},

python -i simdat.py backupcfg/20may22_E0_sim.json
animSynWeights(pdf) #

drawraster(dspkT,dspkID)
savefig('gif/20may22_e0_rast.png')

python -i actmap.py backupcfg/20may22_E0_sim.json
fig, axs, plt = animActivityMaps()

hmm, only ran for 2 s ...

if running with so many synapses values saved, have to limit to every 5-10 s

ok, start for 200 s ... saving weights every 10 s ...

myrun 12 sn.json

<<<<<<< HEAD
** sims on falcor did not save output properly, had memory errors

20may21_B0_sim.json
20may21_C0_sim.json

well, have some of the output (actions rewards for B0) ... may as well take a look ... and see
whether worth rerunning for more of the output...

python
#
import numpy as np
import pandas as pd
from pylab import *
from simdat import plotRewards,plotFollowBall,plotHitMiss
  
name = '20may21_B0_'; pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  
np.amax(pda.time) # 2000.0

so do not even have that output ... 

so all the output lost from those two simulations ...

** try same 20may22_D0_ on falcor, but rename sim name to 20may22_D0_falcor_

in sn.json

will use recordWeightStepSize of 500 (smaller file output and RAM use) and only use 12 cores instead of 16 ...

will also only run a single sim at a time ... see if that helps ...

here are some of the relevant params:

    "rewardcodes": {"scorePoint": 1, "losePoint": -0.1, "followBall": 0.1, "avoidBall": -0.01, "hitBall": 0.5},
    "actionsPerPlay": 1,
    "DirectionDetectionAlgo":{"CentroidTracker":0,"OpticFlow":1},

    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EMDOWN":400,"EMUP":400,"IM":200,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.000025,"EEMWghtNM":0.0000025,"EEMWghtThreshMin":0.000025,"EEMWghtThreshMax":0.000075,"EEMProb":0.3,"EEMRecProb":0.1,"EEMPopNorm":0},
    "RL":{"AMPA":
	  {"wbase":0.0000001,"wmax":0.0001,"RLon":1,"RLlenhebb":50,"RLlenanti":50,"useRLexp":1,"RLhebbwt":0.0005,"RLantiwt":-0.0,"hebbwt":0,"antiwt":0,"tauhebb":10,"RLwindhebb":50,"softthresh":0,"verbose":0},

./myrun 12 sn.json

*20may23
** sim on zn getting rates too high (~400 Hz periodically), have to lower max weight, restart as 20may23_A0_zn_

may as well stop it and set the max weight lower to avoid hyperxcit

transition to hyperexcit occurred around 55 s when weights got up to ~6.2e-5 for both EMDOWN and
EMUP:
t= 54999.99999948014 - adjusting weights based on RL critic value: -0.01
Game rewards: [-0.01]
sim.rank= 0 davg: {'EMUP': 6.192818441676834e-05, 'EMDOWN': 6.168511982260213e-05} dfctr: {'EMUP': 1.0, 'EMDOWN': 1.0}
U,D firing rates:  [0.0] [0.0]
Model actions: [1]

so set max at 6.15e-5
at t=54 s:
t= 53999.99999949469 - adjusting weights based on RL critic value: 0.1
Game rewards: [0.1]
sim.rank= 0 davg: {'EMUP': 6.159468527383135e-05, 'EMDOWN': 6.117707481808665e-05} dfctr: {'EMUP': 1.0, 'EMDOWN': 1.0}
U,D firing rates:  [7.575757575757575] [3.0303030303030303]

"EEMWghtThreshMax":0.0000615

"name":"20may23_A0_zn_"

recordWeightStepSize":250

ok, restart on zn ...

myrun 12 sn.json

** meanwhile, check output from falcor (20may22_D0_falcor_) -> did not get great result

python -i simdat.py backupcfg/20may22_D0_falcor_sim.json

animSynWeights(pdf) # gif/20may22_D0_falcor_weightmap.mp4

python -i actmap.py backupcfg/20may22_D0_falcor_sim.json

fig, axs, plt = animActivityMaps() # gif/20may22_D0_falcor_actmap.mp4

to view mp4s, first download to laptop ...
scp 'samn@falcor.rfmh.org://home/samn/SMARTAgent/gif/20may22_D0_falcor*mp4' ./gif/
scp samn@falcor.rfmh.org://home/samn/SMARTAgent/backupcfg/20may22_D0_falcor_sim.json ./backupcfg

from looking at output mp4s, looks like model reachesbest performance pretty quickly and doesn't improve much after ...
also still seeing biases with higher activation of EMUP compared to EMDOWN ...

but weights did reach ~max quicker than in prior sims ... is that a good thing?

** try another sim on falcor with longer RLlenhebb (100 ms instead of previous 50 ms; name = 20may23_A0_falcor_)

same params as backupcfg/20may22_D0_falcor_sim.json otherwise

"RLlenhebb":100

"name":"20may23_A0_falcor_"

./myrun 12 sn.json

*20may24
** sim on zn (20may23_A0_zn_) still develops hyperexcit?

or at least periods where it's firing at very high rates, not every action ... 
hyperexcit also comes much later ... let it finish since from printouts appeared to have
some decent bhavior early on ... 

** check output on falcor's latest sim (20may23_A0_falcor_)

python -i simdat.py backupcfg/20may23_A0_falcor_sim.json

animSynWeights(pdf) # gif/20may23_A0_falcor_weightmap.mp4

python -i actmap.py backupcfg/20may23_A0_falcor_sim.json

fig, axs, plt = animActivityMaps() # gif/20may23_A0_falcor_actmap.mp4

to view mp4s, first download to laptop ...
scp 'samn@falcor.rfmh.org://home/samn/SMARTAgent/gif/20may23_A0_falcor*mp4' ./gif/
scp samn@falcor.rfmh.org://home/samn/SMARTAgent/backupcfg/20may23_A0_falcor_sim.json ./backupcfg

in weightmap, there appears to be less difference between average input weights to EMDOWN and EMUP populations
suggesting possibly less bias in movement directions ... in terms of following vs not following ball, there
is not a clear difference ... in terms of hit vs miss, there appears to be a slightly higher number of hits
for the latter simulation, with the longer time constant for eligibility trace (100 ms vs previous 50 ms)

overall, follow ball probability does not pass ~50% / random level ... actually, is 50% random level?
or 33% if no move is the appropriate answer sometimes ... ?

still have to look at actmap movie to see if bias really absent ... 

** start another sim on falcor (20may24_A0_falcor_)

same as last but even longer time constant for eligibility trace (200 ms)

"RLlenhebb":200

run it a little longer too ... 400 s ...

./myrun 12 sn.json

*20may25
** sim finished on zn (20may23_A0_zn_sim.json) -->> check output, start new (20may25_A0_zn_)

python -i simdat.py backupcfg/20may23_A0_zn_sim.json

animSynWeights(pdf) # gif/20may23_A0_zn_weightmap.mp4

drawraster(dspkT,dspkID)
savefig('gif/20may25_20may23_A0_zn_rast.png')
on average, rates are not terrible ... 
savefig('gif/20may25_20may23_A0_zn_rast_b.png')
but the hypersynchronized firing pattern is a problem ... 
savefig('gif/20may25_20may23_A0_zn_rast_c.png')
should also look at membrane potential ... 

follow ball probability looks like transitions, first rises, then decays ... possibly due
to hyperactivity?

python -i actmap.py backupcfg/20may23_A0_zn_sim.json

fig, axs, plt = animActivityMaps() # 

so based on above, should have lower max weights ... and possibly lower min weights as well... 

some of the params just used in 20may23_A0_zn_ seem off:
    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EMDOWN":400,"EMUP":400,"IM":200,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.0000125,"EEMWghtNM":0.00000125,"EEMWghtThreshMin":0.000025,"EEMWghtThreshMax":0.0000615,"EEMProb":0.6,"EEMRecProb":0.2,"EEMPopNorm":0},

EEMWghtAM had lower value than EEMWghtThreshMin, so that means weights got pushed up through
normalization pretty early (and for no good reason)

"name":"20may25_A0_zn_"

set "EEMWghtThreshMin":0.0000125
and "EEMWghtThreshMax" from 0.0000615 to 0.00005

ok, start that ... for 200 s ...

myrun 16 sn.json

** sim finished on falcor (20may24_A0_falcor_sim.json) -->> check output

python -i simdat.py backupcfg/20may24_A0_falcor_sim.json

animSynWeights(pdf) #

python -i actmap.py backupcfg/20may24_A0_falcor_sim.json

fig, axs, plt = animActivityMaps() # 

scp 'samn@falcor.rfmh.org://home/samn/SMARTAgent/gif/20may24_A0_falcor*mp4' ./gif/
scp samn@falcor.rfmh.org://home/samn/SMARTAgent/backupcfg/20may24_A0_falcor_sim.json ./backupcfg

similar patternt to last simulation run on falcor seen here, with longer time constant for
eligibility trace (200 ms, compared to original 50 ms), there is less bias/difference between
weights to EMUP and EMDOWN populations. however probability of move toward/away from ball
is no better than the 100 ms eligibility trace.

for comparison, worth running a sim with shorter eligibility trace time constants ... (25 ms vs original 50 ms)

will make duration 200 s ...

"name":"20may25_A0_falcor_"

"RLlenhebb":25

./myrun 12 sn.json

** 20may23_A0_falcor_actmap.mp4 <- does not look as terrible as usual, in terms of performance
(though many of the usual biases remain)
20may23_A0_falcor_weightmap.mp4

that's with the 100 ms RL eligiblity trace ... and higher connectivity to EMUP, EMDOWN

there are some sequences where the model hits the ball back a few times in a row ... number of
hits between points could be another metric but hit vs miss is more basic and still captures that

could compare performance of the model to naive model or one with equal rewards distributed
randomly over time

other thing to note is that it's difficult for the paddle to remain still, since any difference
in firing between the two populations can lead to movement. there's no wide-margin / middle
ground allowing the paddle to stay still ... could implement that as factor higher rate
for one population to move ... would at least mean some ability to hold paddle still ... 

*20may26
** check 20may25_A0_falcor_ output (25 ms tau for rl eligibility trace)

python -i simdat.py backupcfg/20may25_A0_falcor_sim.json

animSynWeights(pdf) # gif/20may25_A0_falcor_weightmap.mp4

drawraster(dspkT,dspkID)
savefig('gif/20may26_20may25_A0_falcor_rast.png')
overall rates are ok...
savefig('gif/20may26_20may25_A0_falcor_rast_b.png')
too much hypersynch, once in a while...

python -i actmap.py backupcfg/20may25_A0_falcor_sim.json

fig, axs, plt = animActivityMaps() # 

scp 'samn@falcor.rfmh.org://home/samn/SMARTAgent/gif/20may25_A0_falcor*mp4' ./gif/
scp samn@falcor.rfmh.org://home/samn/SMARTAgent/backupcfg/20may25_A0_falcor_sim.json ./backupcfg

most of the time the weights to EMUP are higher ... so that's effect seen with the shorter time constant ... 

** some discussion with ha

10:15
samn was running different sims over the weekend ... with higher connectivity to M populations
10:15
Haroon Anwar so different sims---- any useful results
10:18
samn ran with higher connectivity to M populations, and some recurrent connectivity
sims with longer time constant for eligiliblity trace have less difference in weights to the diff pops - so that's possibly good to avoid bias
there are some sequences where the model hits the ball back a few times in a row ... number of
hits between points could be another metric but hit vs miss is more basic and still captures that
could compare performance of the model to naive model or one with equal rewards distributed
randomly over time
other thing to note is that it's difficult for the paddle to remain still, since any difference
in firing between the two populations can lead to movement. there's no wide-margin / middle
ground allowing the paddle to stay still ... could implement that as factor higher rate
for one population to move ... would at least mean some ability to hold paddle still ... or could have a population that specifically encodes "NO MOVE"
10:21
Haroon Anwar hard to say which one is better, factor high or separate pop…. probably should try both
10:21
better to try factor high firing rate first
10:23
samn which better - well, too much bias interferes with performance
10:23
even a slight average bias
10:25
Haroon Anwar do we have a quantification for that?--- i mean i am trying to understand what kind of biases are we talking about here and what are the origins of those biases
10:25
samn quantification - average weight to each  poulation
10:26
should also measure time paddle is at each location
10:26
seems clear from movies that it stays at top or bottom too much
10:26
origin - it's either the weights or a bug
10:26
yeah, would be good to look into all of that
10:27
Haroon Anwar i agree
10:27
samn you were working on the object detection?
10:28
Haroon Anwar that was done… was having some issues with movies,
10:28
and had hard time testing the accuracy of direction selective neurons
10:29
samn done with wider distribution of flow?
10:29
Haroon Anwar yes, had done that
10:29
samn can you show how it looks?
10:30
Haroon Anwar let me see if i can find a movie with wider flow
10:30
else i will have to generate one
10:31
samn probably useful if width could be a param
10:31
Haroon Anwar yes it is
10:31
oh but not in json
10:31
i can make that too
10:32
samn so rates ~same as when using optical flow?
10:32
and runtime ~same?
10:33
Haroon Anwar it was very similar…. but i was skeptical about the runtime comparison because i noticed things were slow on zn on friday…. but yes looked similar
10:33
samn ok sg
10:34
param in json - sg
10:34
other than that you had idea about topology of M
10:34
Haroon Anwar hopefully i will be satisfied with more testing today to move on to topology of M
10:35
samn ic, testing of obj detection
10:35
Haroon Anwar movies
10:35
testing movies
10:35
i feel something is off
10:35
samn ic
10:35
Haroon Anwar i added a frame in the beginning
10:35
samn actma or synweight or both
10:36
Haroon Anwar actmap
10:36
samn ic
10:36
ok
10:36
Haroon Anwar but for 10000 ms it goes till 99960 ms
10:36
samn i'll paste some fo this to games channel so interns can read later ... they're starting next week btw
10:36
99960 - ok, so might be off by 1 frame
10:37
Haroon Anwar may be — but that makes comparison impossible
10:37
samn yeah, should have everything aligned
10:38
Haroon Anwar hopefully will be a small thing
10:38
samn but single frame for display, don't think will make huge diff, yeah, good to check, thx
10:38
especially if means bug in the main sim code
10:39
Haroon Anwar everything seems good from sim
10:41
samn ic

** last sim completed on zn (20may23_A0_zn_) with hypersynchrony, has poor performance
for most of its duration and paddle gets stuck on top for majority of time (once
the hypersynchrony develops) so that's another indicator of origin of bias

** this sim (20may25_A0_zn_sim.json) on zn also has hypersynch/high rates develop & likely poor performance
so should kill that and start one with even lower max weights ...

set "EEMWghtThreshMax":0.00005
to ~1/2 that value ... "EEMWghtThreshMax":0.000025

"name":"20may26_A0_zn_"

can also try longer time constant for RL (based on sims on falcor)
set "RLlenhebb":50
to 100 ...

also lower
"EEMWghtThreshMin":0.0000125
to
"EEMWghtThreshMin":0.00000625
so weights could go down further before getting pushed back up through normalization

myrun 16 sn.json

** summary from latest sims on falcor

20may22_D0_falcor_sim.json -->> "RLlenhebb":50 <<-- original default
20may23_A0_falcor_sim.json -->> "RLlenhebb":100 <<-- has lower bias
20may24_A0_falcor_sim.json -->> "RLlenhebb":200 <<-- has lower bias
20may25_A0_falcor_sim.json -->> "RLlenhebb":25 <<-- has higher bias

can look at how much time spent at every y position ... but not saving estimated racket and ball positions ... 

try a quick sim saving the ball and racket (paddle) positions ...

may as well try the object tracker too ...

./myrun 12 sn.json

hmm, no firing for these param weights...have to adjust ... 

python -i simdat.py backupcfg/20may26_A0_falcor_sim.json

animSynWeights(pdf) # gif/20may26_A0_falcor_weightmap.mp4

drawraster(dspkT,dspkID)
savefig('gif/20may26_A0_falcor_rast.png')
not much activity for EM pops ... 

python -i actmap.py backupcfg/20may26_A0_falcor_sim.json

fig, axs, plt = animActivityMaps() # 

scp 'samn@falcor.rfmh.org://home/samn/SMARTAgent/gif/20may26_A0_falcor*mp4' ./gif/
scp samn@falcor.rfmh.org://home/samn/SMARTAgent/backupcfg/20may26_A0_falcor_sim.json ./backupcfg

and can adjust flowwidth for object tracker too

try with double the flow width (16, compared to original 8)

python -i simdat.py backupcfg/20may26_A0_falcor_sim.json

animSynWeights(pdf) # gif/20may26_A0_falcor_weightmap.mp4

drawraster(dspkT,dspkID)
savefig('gif/20may26_A0_falcor_rast_b.png')
ok, a little more activity for EM ... 

python -i actmap.py backupcfg/20may26_A0_falcor_sim.json

fig, axs, plt = animActivityMaps() # 

scp 'samn@falcor.rfmh.org://home/samn/SMARTAgent/gif/20may26_A0_falcor*mp4' ./gif/
scp samn@falcor.rfmh.org://home/samn/SMARTAgent/backupcfg/20may26_A0_falcor_sim.json ./backupcfg

ok, object detection-based flow is a little wider ... though EM rates still lower than when using optical flow algorithm

dobjpos = loadObjPos()

dobjpos['ball'] = np.array(dobjpos['ball'])
dobjpos['ball'].shape # (249, 2)

dobjpos['racket'] = np.array(dobjpos['racket'])

plot(dobjpos['ball'][:,0],dobjpos['ball'][:,1])
plot(dobjpos['racket'][:,0],dobjpos['racket'][:,1])

fig=animInput(InputImages,'testflow2.mp4',ldflow=ldflow,dobjpos=dobjpos)

fig, axs, plt = animActivityMaps(outpath='testact.mp4',dobjpos=dobjpos) # 

#
clf()
subplot(1,2,1); xlabel('Racket X position')
hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position')
hist(dobjpos['racket'][:,1])

savefig('gif/20may26_racketposhist_b1.png')

yeah, looks like racket spending more time at top or bottom ... 

try a bit longer run with slightly higher weights to see if firing ok ... 

./myrun 12 sn.json

python -i simdat.py backupcfg/20may26_A0_falcor_sim.json

drawraster(dspkT,dspkID)
savefig('gif/20may26_A0_falcor_rast_b2.png')
savefig('gif/20may26_A0_falcor_rast_b2b.png')

overall rates are ok but some hypersynch will likely emerge eventually since max weight pretty high
with 0.3 prob of conn to EM and 0.1 recurr conn in EM

animSynWeights(pdf) # gif/20may26_A0_falcor_weightmap.mp4

python -i actmap.py backupcfg/20may26_A0_falcor_sim.json

dobjpos = loadObjPos(); fig, axs, plt = animActivityMaps(dobjpos=dobjpos) # 

scp 'samn@falcor.rfmh.org://home/samn/SMARTAgent/gif/20may26_A0_falcor*mp4' ./gif/
scp samn@falcor.rfmh.org://home/samn/SMARTAgent/backupcfg/20may26_A0_falcor_sim.json ./backupcfg

looks decent ... can run longer ... 

./myrun 12 sn.json

firing rates getting too high ... should lower min and max weights ...
"name":"20may26_B0_falcor_"
"EEMWghtAM":0.00004,"EEMWghtNM":0.0000025,"EEMWghtThreshMin":0.00002,"EEMWghtThreshMax":0.00008,"EEMProb":0.3,"EEMRecProb":0.1,"EEMPopNorm":0
"wbase":0.0000001,"wmax":0.00012

./myrun 12 sn.json

** setup rule for larger firing rates (by factor, prior to movement) ?

may help stability and avoiding bias ... ?

*20may27
** make movies/check output from full 20may26_A0_falcor_ 

python -i simdat.py backupcfg/20may26_A0_falcor_sim.json

drawraster(dspkT,dspkID)
savefig('gif/20may27_20may26_A0_falcor_rast_a.png')
decent overall rates
savefig('gif/20may27_20may26_A0_falcor_rast_b.png')
but overly synchronous ... 

animSynWeights(pdf) # gif/20may26_A0_falcor_weightmap.mp4

check cells too ...

simConfig['simData'].keys()
dict_keys(['spkt', 'spkid', 'V_soma', 't', 'dminID', 'avgRate'])

simConfig['simData']['V_soma'].keys()
dict_keys(['cell_0', 'cell_900', 'cell_4359', 'cell_400', 'cell_4759', 'cell_500', 'cell_4100', 'cell_5159'])

len(simConfig['simData']['V_soma']['cell_0'])

plot(simConfig['simData']['t'],simConfig['simData']['V_soma']['cell_0'])
savefig('gif/20may27_20may26_A0_falcor_cell_0_V.png')

simConfig['net']['cells'][0]

drawcellVm(simConfig); xlim((190e3,200e3))
savefig('gif/20may27_20may26_A0_falcor_cellVm.png')

looks mostly ok, no depolarization blockade ... though a lot of synchrony between different types
and very strong osc. - that could prevent good performance...if everything time-locked into
hypersynch osc.

python -i actmap.py backupcfg/20may26_A0_falcor_sim.json

dobjpos = loadObjPos(); fig, axs, plt = animActivityMaps(dobjpos=dobjpos) # 

frame t =  199800
frame t =  199820
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "actmap.py", line 155, in animActivityMaps
    ani.save(outpath, writer=writer); print('saved animation to', outpath)
  File "/home/samn/miniconda3/lib/python3.7/site-packages/matplotlib/animation.py", line 1199, in save
    anim._draw_next_frame(d, blit=False)
  File "/home/samn/miniconda3/lib/python3.7/site-packages/matplotlib/animation.py", line 1236, in _draw_next_frame
    self._draw_frame(framedata)
  File "/home/samn/miniconda3/lib/python3.7/site-packages/matplotlib/animation.py", line 1772, in _draw_frame
    self._drawn_artists = self._func(framedata, *self._args)
  File "actmap.py", line 149, in updatefig
    lobjx,lobjy = [objfctr*dobjpos[k][t,0] for k in dobjpos.keys()], [objfctr*dobjpos[k][t,1] for k in dobjpos.keys()]
  File "actmap.py", line 149, in <listcomp>
    lobjx,lobjy = [objfctr*dobjpos[k][t,0] for k in dobjpos.keys()], [objfctr*dobjpos[k][t,1] for k in dobjpos.keys()]
IndexError: index 9991 is out of bounds for axis 0 with size 9991
>>> len(dobjpos['racket'])
9991

hmm...positions must not be recorded for every step... definitely not for first few time steps
but apparently 9 positions not recorded (9*20 + 199820) == 200000

will draw without positions for now ... 

#
clf()
subplot(1,2,1); xlabel('Racket X position')
hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position')
hist(dobjpos['racket'][:,1])

savefig('gif/20may27_20may26_A0_falcor_racketposhist_b.png') # <<-- shows a lot of bias towards one y position

fig, axs, plt = animActivityMaps(dobjpos=None) # 

** make movies/check output from 20may26_B0_falcor_ 

python -i simdat.py backupcfg/20may26_B0_falcor_sim.json

drawraster(dspkT,dspkID)
savefig('gif/20may27_20may26_B0_falcor_rast_a.png')
xlim((190e3,200e3))
not much going on in beginning of simulation
savefig('gif/20may27_20may26_B0_falcor_rast_b.png')
then becomes more synchronized, but not continuously

drawcellVm(simConfig); xlim((190e3,200e3))
savefig('gif/20may27_20may26_B0_falcor_cellVm.png')

animSynWeights(pdf) # gif/20may26_B0_falcor_weightmap.mp4

hmm, there's more of a difference between the synaptic weights to the two M populations here
not sure this model is performing better than previous with optical flow ... 

python -i actmap.py backupcfg/20may26_B0_falcor_sim.json

dobjpos = loadObjPos()

#
clf()
subplot(1,2,1); xlabel('Racket X position')
hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position')
hist(dobjpos['racket'][:,1])

savefig('gif/20may27_20may26_B0_falcor_racketposhist_b.png') # 
still bias in positions ... at both extremes ...

fig, axs, plt = animActivityMaps(dobjpos=None) # 

while making adjustments to model can continue this one ...

    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20may26_B0_falcor_synWeights.pkl"},        
"name":"20may27_B1_falcor_"

./myrun 12 sn.json

** add dconf['movefctr'] to require margin between EM pop rates for move generation

default can be 1.0 to have same activity
uses this logic:
        if F_UPs[ts]>F_DOWNs[ts] * dconf['movefctr']:
          actions.append(dconf['moves']['UP'])
        elif F_DOWNs[ts]>F_UPs[ts] * dconf['movefctr']:
          actions.append(dconf['moves']['DOWN'])
        else:
          actions.append(dconf['moves']['NOMOVE']) # No move        

start weights higher than sim on falcor to see if any moves:
"EEMWghtAM":0.00006

testing this on laptop first ... 

myrun 12 sn.json

  Done; run time = 1176.29 s; real-time ratio: 0.00.

Analyzing...
  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 32154 (1.20 Hz)
  Simulated time: 5.0 s; 12 workers
  Run time: 1176.29 s
Saving output as data/20may27_C0_laptop_simConfig.pkl ... 
Finished saving!
  Done; saving time = 1.66 s.

python -i simdat.py backupcfg/20may27_C0_laptop_sim.json

drawraster(dspkT,dspkID)
savefig('gif/20may27_C0_rast_a.png')
less firing for EM pops

drawcellVm(simConfig); 
savefig('gif/20may27_C0_laptop_cellVm.png')

animSynWeights(pdf) # 

python -i actmap.py backupcfg/20may27_C0_laptop_sim.json

dobjpos = loadObjPos()

#
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])

savefig('gif/20may27_C0_laptop_racketposhist_b.png') # 
some bias, also stuck in middle (no moves)

fig, axs, plt = animActivityMaps(dobjpos=None) # gif/20may27_C0_laptop_actmap.mp4

well, certainly less movement ... 

run longer ... 100 s ...

also adjust weights ... 

** check output from 20may26_A0_zn_

t= 199999.80000715362 - adjusting weights based on RL critic value: -0.01
Game rewards: [-0.01]
sim.rank= 0 davg: {'EMUP': 2.5309090724359646e-05, 'EMDOWN': 2.54674733529361e-05} dfctr: {'EMUP': 0.9877873635317073, 'EMDOWN': 0.9816442979459442}
  Done; run time = 105017.57 s; real-time ratio: 0.00.

Gathering data...
  Done; gather time = 5.29 s.

Analyzing...
  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 2388616 (2.23 Hz)
  Simulated time: 200.0 s; 16 workers
  Run time: 105017.57 s
Saving output as data/20may26_A0_zn_simConfig.pkl ... 
Finished saving!
  Done; saving time = 18.70 s.

python -i simdat.py backupcfg/20may26_A0_zn_sim.json

drawraster(dspkT,dspkID)
savefig('gif/20may27_20may26_A0_zn_rast_a.png')
overall, rates are ok
xlim((190e3,200e3))
savefig('gif/20may27_20may26_A0_zn_rast_b.png')
xlim((195e3,200e3))
savefig('gif/20may27_20may26_A0_zn_rast_c.png')
but do have periods of hypersynch activity ...

drawcellVm(simConfig); 
savefig('gif/20may27_20may26_A0_zn_cellVm.png')
xlim((190e3,200e3))
savefig('gif/20may27_20may26_A0_zn_cellVm_b.png')
xlim((195e3,200e3))
savefig('gif/20may27_20may26_A0_zn_cellVm_c.png')

animSynWeights(pdf) # 

python -i actmap.py  backupcfg/20may26_A0_zn_sim.json

fig, axs, plt = animActivityMaps(dobjpos=None) # gif/20may27_20may26_A0_zn_actmap.mp4

*20may28
** check output from 20may27_B1_falcor_

python -i simdat.py backupcfg/20may27_B1_falcor_sim.json

reading  backupcfg/20may27_B1_falcor_sim.json
-1
loading data from 20may27_B1_falcor_
loading input images from data/20may27_B1_falcor_InputImages.txt
loaded simulation data

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.51))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/20may28_20may27_B1_falcor_behav_a0.png')

drawraster(dspkT,dspkID)
xlim((190e3,200e3))
savefig('gif/20may28_20may27_B1_falcor_rast_a1.png')

drawcellVm(simConfig); xlim((190e3,200e3))
savefig('gif/20may28_20may27_B1_falcor_cellVm_a2.png')

everything looks ok except for performance ... 

fig, axs, plt = animActivityMaps()

#
dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])

savefig('gif/20may28_20may27_B1_falcor_racket_pos_hist_a3.png')

is there any stability to the weights over time?
can take a few synapses and see how they vary ... whether there's a similar pattern

pdf.columns
Index(['time', 'preid', 'postid', 'weight'], dtype='object')

dstartidx['EMUP'] # 4759
dendidx['EMUP'] # 5158
pdfs = pdf[pdf.postid==4759]
len(pdfs) # 23160
pdfs.at[pdfs.index[0],'preid'] # 528

dstartidx['EV1'] # 500
dendidx['EV1'] # 899

pdfs = pdf[(pdf.postid==4759) & (pdf.preid==528)]
len(pdfs) # 20

plot(pdfs.time,pdfs.weight,'k')
savefig('gif/20may28_20may27_B1_falcor_synweight_a4.png')
rises, then decays ...

postid = dstartidx['EMUP']
pdfs = pdf[(pdf.postid==postid) & (pdf.preid>dstartidx['EV1']) & (pdf.preid<=dendidx['EV1'])]
lpreid = pdfs.preid
len(lpreid) # 2400

connectLayerswithOverlap in connUtils.py
cells seem to be arranged in square with first index as row and second as column
so that gives the coordinates based on gid ... ? 

dnumc['ER'] # 400
dstartidx['ER'] # 0
dendidx['ER'] # 399

lx,ly=[],[]
for gid in range(dstartidx['ER'],dendidx['ER']+1,1):
  x,y = gid2pos(dnumc['ER'], dstartidx['ER'], gid)
  lx.append(x)
  ly.append(y)

lx
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
ly
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]
>>> 

works ok when the grid is evenly spaced and each neuron occupies a point ... so could use it to map ER, EV1, and direction
selective RFs ... all populations which have 400 neurons ... for V4 and MT and the interneurons will have to adjust scale

postid = dstartidx['EMUP']
pdfs = pdf[(pdf.postid==postid) & (pdf.preid>dstartidx['EV1']) & (pdf.preid<=dendidx['EV1'])]
lpreid = pdfs.preid

rfmap = getinputmap(pdf, pdf.time[0], 'EV1', dstartidx['EMUP'], 'EMUP', dnumc, dstartidx, dendidx)

imshow(rfmap,cmap='gray',origin='upper')
colorbar()
savefig('gif/20may28_20may27_B1_falcor_rfmap_a5.png')
ok, that EMUP neuron gets pretty broad coverage ... (white pixels where it gets input from EV1)

lrfmap = [getinputmap(pdf, pdf.time[0], 'EV1', postid, 'EMUP', dnumc, dstartidx, dendidx) for postid in range(dstartidx['EMUP'],dendidx['EMUP']+1,1)]

len(lrfmap) # 400

nprfmap = np.array(lrfmap)
nprfmap.shape # (400, 20, 20)
imshow(np.sum(nprfmap,axis=0),cmap='gray',origin='upper'); colorbar()
savefig('gif/20may28_20may27_B1_falcor_rfmap_a6.png')
hmm, one pixel always empty ... but otherwise, as a population EMUP has full coverage of visual space from EV1 inputs...

lprety = ['EV1DNW', 'EV1DN', 'EV1DNE', 'EV1DW', 'EV1','EV1DE','EV1DSW', 'EV1DS', 'EV1DSE']
drfmap = {prety:getinputmap(pdf, pdf.time[0], prety, dstartidx['EMUP'], 'EMUP', dnumc, dstartidx, dendidx) for prety in lprety}

#
for tdx,prety in enumerate(lprety):
  subplot(3,3,tdx+1)
  imshow(drfmap[prety],cmap='gray',origin='upper'); title(prety+'->EMUP0'); 

savefig('gif/20may28_20may27_B1_falcor_rfmap_a7.png')

so, somewhat broad coverage. but which locations have info about intensity and all directions? 

drfmap = plotallinputmaps(pdf, pdf.time[0], dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, lprety)
drfmap = plotallinputmaps(pdf, pdf.time[0], dstartidx['EMUP'] + 1, 'EMUP', dnumc, dstartidx, dendidx, lprety)

lmap = [drfmap[x] for x in drfmap.keys()]
mask = lmap[0]
for i in range(1,len(lmap),1): mask = np.logical_and(mask, lmap[i])
np.amax(mask) # False

lmap = np.array(lmap)
nps = np.sum(lmap,axis=0)
imshow(nps,cmap='gray',origin='upper')
colorbar()
savefig('gif/20may28_20may27_B1_falcor_rfmap_a8.png')
some locations have lot of info, others not ... 

np.amin(nps), np.amax(nps), mean(nps) # (0.0, 7.0, 2.695)
so average has ~2.7/9 of total info, which is ~1/3 ... which is around EEMProb of 0.3
so the recurrent connectivity becomes important for making decisions ... right now EEMRecProb was at 0.1
could make it higher ... 

** check output from 20may27_D0_movefctr_1.25_falcor_

python -i simdat.py backupcfg/20may27_D0_movefctr_1.25_falcor_sim.json


#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.51))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/20may28_20may27_D0_movefctr_1.25_falcor_a0.png')

drawraster(dspkT,dspkID); xlim((190e3,200e3))
savefig('gif/20may28_20may27_D0_movefctr_1.25_falcor_rast_a1.png')

drawcellVm(simConfig); xlim((190e3,200e3))
savefig('gif/20may28_20may27_D0_movefctr_1.25_falcor_cellVm_a2.png')

#
dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])

savefig('gif/20may28_20may27_D0_movefctr_1.25_falcor_racket_pos_hist_a3.png')
still a large bias in positions ... 

fig, axs, plt = animActivityMaps()

** try sim with higher recurrent conn and no (or less frequent?) weight norm (20may28_A0_falcor_)

less frequent weight norm (every 40 s)

and higher recurrent connectivity (0.3 instead of previous 0.1)

"name":"20may28_A0_falcor_"

./myrun 12 sn.json

** check input maps using weight as sim progresses

python -i simdat.py backupcfg/20may27_B1_falcor_sim.json

drfmap = plotallinputmaps(pdf, pdf.time[0], dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=False)
savefig('gif/20may28_e0.png')

drfmap = plotallinputmaps(pdf, pdf.time[0], dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True)
savefig('gif/20may28_e1.png')

hmm, when plotting as weight, only EV1 synapses have some weights lowered ... 
pdf.time[0] # 10000.000000018848
but the others do not ... why?? since nothing moved at the locations specific to those direction selective neurons yet
so those neurons did not yet fire ...

drfmap = plotallinputmaps(pdf, pdf.time[1], dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True)
savefig('gif/20may28_e2.png')

drfmap = plotallinputmaps(pdf, pdf.time[2], dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True)
savefig('gif/20may28_e3.png')

drfmap = plotallinputmaps(pdf, pdf.time[3], dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True)
savefig('gif/20may28_e4.png')
pdf.time[3] # 39999.99999969842
by that time, a lot more synapses have become depressed ... ? or some have been potentiated ... need colorbars ...

drfmap = plotallinputmaps(pdf, np.amax(pdf.time), dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True)
savefig('gif/20may28_e5.png')

drfmap = plotallinputmaps(pdf, np.amax(pdf.time), dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True,cmap='jet')
savefig('gif/20may28_e6.png')
ok, easier to compare this way ... 

clf(); drfmap = plotallinputmaps(pdf, np.amin(pdf.time), dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True,cmap='jet')
savefig('gif/20may28_e7.png')
and at first time recorded, weights from EV1 were already heightened ... 

lmap = [drfmap[x] for x in drfmap.keys()]
lmap = np.array(lmap)
nps = np.sum(lmap,axis=0)
clf(); imshow(nps,cmap='jet',origin='upper'); colorbar()
savefig('gif/20may28_e8.png')

how does pattern look when combine across postsynaptic neurons of a given population?

#
dtmp = None
for postid in range(dstartidx['EMUP'],dendidx['EMUP']+1,1):
  print(postid)
  drfmap = getallinputmaps(pdf, np.amax(pdf.time), postid, 'EMUP', dnumc, dstartidx, dendidx)
  if dtmp is None: 
    dtmp = drfmap
  else:
    for k in dtmp.keys(): dtmp[k] += drfmap[k]

clf(); drfmap = plotallinputmaps(pdf, np.amax(pdf.time), dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True,cmap='jet', dmap=dtmp)

savefig('gif/20may28_e9.png')

hmm, did not div those values properly ... and that obscures relative value in each location

*20may29
** check output from 20may28_A0_falcor_

  Cells: 5359
  Connections: 0 (0.00 per cell) <<-- that's not right, just because not saving all network info
  Spikes: 2046943 (1.91 Hz)
  Simulated time: 200.0 s; 12 workers
  Run time: 44290.63 s

python -i simdat.py backupcfg/20may28_A0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.51))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
subplot(1,3,1); plot([40e3,80e3,120e3,160e3,200e3],[0.45,.45,.45,.45,.45],'bo',markersize=10) # times of weight norm

savefig('gif/20may29_a0.png')
rises initially but then decays ... 

drawraster(dspkT,dspkID); 
xlim((20e3,30e3)); savefig('gif/20may29_a1.png')
xlim((190e3,200e3)); savefig('gif/20may29_a2.png')

activity much more synchronized at end when performance worse ... but not clear if that's the reason performance worse

drawcellVm(simConfig); 
xlim((20e3,30e3)); savefig('gif/20may29_a3.png')
xlim((190e3,200e3)); savefig('gif/20may29_a4.png')

#
dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])

savefig('gif/20may29_a5.png')

## fig, axs, plt = animActivityMaps()

drfmap = plotallinputmaps(pdf, np.amin(pdf.time), dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True,cmap='jet')
savefig('gif/20may29_a6.png')

clf(); drfmap = plotallinputmaps(pdf, np.amax(pdf.time), dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True,cmap='jet')
savefig('gif/20may29_a7.png')

drfmap = plotallinputmaps(pdf, np.amin(pdf.time), dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True,cmap='jet')
#
lmap = [drfmap[x] for x in drfmap.keys()]
lmap = np.array(lmap)
nps = np.sum(lmap,axis=0)
clf(); imshow(nps,cmap='jet',origin='upper'); colorbar()
savefig('gif/20may29_a8.png')

#
drfmap = plotallinputmaps(pdf, np.amax(pdf.time), dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True,cmap='jet')
lmap = [drfmap[x] for x in drfmap.keys()]
lmap = np.array(lmap)
nps = np.sum(lmap,axis=0)
clf(); imshow(nps,cmap='jet',origin='upper'); colorbar()
savefig('gif/20may29_a9.png')

** are weight step sizes reasonable? no, too large. try with smaller (~5% max)

seemed like optic flow did a little better ... ? 
or could be due to EEMRecProb of 0.3 ... or many other things ... 

for last sim (backupcfg/20may28_A0_falcor_sim.json):
    "rewardcodes": {"scorePoint": 1, "losePoint": -0.1, "followBall": 0.1, "avoidBall": -0.01, "hitBall": 0.5},

	  {"wbase":0.0000001,"wmax":0.00024,"RLon":1,"RLlenhebb":100,"RLlenanti":50,"useRLexp":1,"RLhebbwt":0.0005,"RLantiwt":-0.0,"hebbwt":0,"antiwt":0,"tauhebb":10,"RLwindhebb":50,"softthresh":0,"verbose":0},

"EEMWghtAM":0.00008,"EEMWghtNM":0.0000025,"EEMWghtThreshMin":0.00004,"EEMWghtThreshMax":0.00016,"EEMProb":0.3,"EEMRecProb":0.3,"EEMPopNorm":0

so starting weight is 0.00008
RLhebbwt is 0.0005 -- increment is much larger than starting weight (0.0005 / 0.00008 = 6.25)
but then it gets multiplied by reward value; for a scorePoint (1) it goes up too much
for losePoint (-0.1) it goes down 0.0005*0.1 = 0.00005 > 50% of original value; 0.0005*0.1/0.00008 (0.625)
for followball (0.1) it goes up > 50% of original value
for avoidBall (-0.01) it goes down by 6.25% of original value
for hitBall (0.5)  too much as well ... 

so none of the reward increments make sense ... they should all be relatively small ... ~5% change should be the maximum

0.00008 * 0.05 # 4.000000000000001e-06
that should be value of RLhebbwt (0.000004)
relative values for rewardcodes can be maintained ...

"name":"20may29_A0_falcor_"

ok, try that out ...

./myrun 12 sn.json

and another with less recurrent connectivity (EEMRecProb) ... at 0.1 instead of 0.3 in 20may29_A0_falcor_

"name":"20may29_B0_falcor_"



** simpler architecture?

population for opponent racket position (1D)
population for player racket position (1D)
population for ball position (2D)

it might work (even that architecture is not guaranteed) but loses generality ... 

** simpler cells?

switch to izhikevich neurons?

** other notes from neco 2013 paper

model from neco 2013 seemed to have recurrent plastic connectivity between different motor neuron command populations 
also had RL plasticity within sensory areas and feedback RL plasticity from M -> S

noise was important component of the M neurons since drove the motor system to "babble" and produce
random movements which were then reinforced/punished

so may want to incorporate some of that into the present model

*20may30
** check output from 20may29_A0_falcor_

python -i simdat.py backupcfg/20may29_A0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.51))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
subplot(1,3,1); plot([40e3,80e3,120e3,160e3,200e3],[0.45,.45,.45,.45,.45],'bo',markersize=10) # times of weight norm

savefig('gif/20may30_a0.png')

early spike, decay, then slow rise ... that's possibly a good sign if improvements continue ...

drawraster(dspkT,dspkID); 
xlim((190e3,200e3)); savefig('gif/20may30_a2.png')
low rates overall, no hypersynch

drawcellVm(simConfig); xlim((190e3,200e3)); savefig('gif/20may30_a4.png')

#
dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/20may30_a5.png')savefig('gif/20may30_a5.png')

save final output weights for continuation ...

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs) 
len(pdfs) # 990400
pickle.dump(D, open('data/20may29_A0_falcor_synWeights_final.pkl','wb')) # ~36 MB
ok, can use that to continue sim ...

** check output from 20may29_B0_falcor_

python -i simdat.py backupcfg/20may29_B0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.51))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
subplot(1,3,1); plot([40e3,80e3,120e3,160e3,200e3],[0.45,.45,.45,.45,.45],'bo',markersize=10) # times of weight norm

savefig('gif/20may30_b0.png')

similar pattern but the one with more recurrent EM connectivity seems to be doing better overall ?

clf(); drawraster(dspkT,dspkID); xlim((190e3,200e3)); savefig('gif/20may30_b2.png')

clf(); drawcellVm(simConfig);  xlim((190e3,200e3)); savefig('gif/20may30_b4.png')

save final output weights for continuation ...

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs)
len(pdfs) # 926400
pickle.dump(D, open('data/20may29_B0_falcor_synWeights_final.pkl','wb')) # ~33 MB
ok, can use that to continue sim ...

** continue 20may29_A0_falcor_ as 20may30_A1_falcor_

    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20may29_A0_falcor_synWeights_final.pkl"},        

running for 400 s ... saving weights every 10 s ... (instead of every 5 s)

./myrun 12 sn.json

** continue 20may29_B0_falcor_ as 20may30_B1_falcor_

./myrun 12 sn.json

hmm, not loading weights properly ... 
they seem to have run out of memory ... later should fix to save final weights for easier reload 
(fixed with selecting last time and then dumping output of pdf2weightsdict -- see above)

    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20may29_B0_falcor_synWeights_final.pkl"},        

./myrun 12 sn.json

running for 400 s ... saving weights every 10 s ... (instead of every 5 s)

*20jun1
** check output from 20may30_A1_falcor_ and continue as 20jun1_A2_falcor_

dfctr never increased > 1, so weight normalization never occurred (due to small weight increments)

  Simulated time: 400.0 s; 12 workers
  Run time: 117071.13 s

synweights file is ~1GB

python -i simdat.py backupcfg/20may30_A1_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.51))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
subplot(1,3,1); plot([40e3,80e3,120e3,160e3,200e3,240e3,280e3,320e3,360e3,400e3],[.45,.45,.45,.45,.45,0.45,.45,.45,.45,.45],'bo',markersize=10) # times of weight norm

savefig('gif/20jun1_a0.png')
continued to improve?, possibly, but slowly ... 

drawraster(dspkT,dspkID); xlim((390e3,400e3)); savefig('gif/20jun1_a2.png')

clf(); drawcellVm(simConfig); xlim((390e3,400e3)); savefig('gif/20jun1_a4.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/20jun1_a5.png')

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs) 
len(pdfs) # 990400
pickle.dump(D, open('data/20may30_A1_falcor_synWeights_final.pkl','wb')) # ~36 MB

continue from there ...

    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20may30_A1_falcor_synWeights_final.pkl"}, 
"name":"20jun1_A2_falcor_"

./myrun 12 sn.json

** check output from 20may30_B1_falcor_ -- mistake, the json file has the same params as 20may30_A1_falcor_ ? no, continue as 20jun1_B2_falcor_

so did not properly continue the sim with the lower recurrent connectivity ... ? but then why are the B1
output files produced ?

will leave that one out for now ...

hmm, but file output sizes are different, so different parameters were used

check if output looks different in corrected json file ...

python -i simdat.py backupcfg/20may30_B1_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.51))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
subplot(1,3,1); plot([40e3,80e3,120e3,160e3,200e3,240e3,280e3,320e3,360e3,400e3],[.45,.45,.45,.45,.45,0.45,.45,.45,.45,.45],'bo',markersize=10) # times of weight norm

savefig('gif/20jun1_b0.png') # ok that looks somewhat different from A0 above

clf(); drawraster(dspkT,dspkID); xlim((390e3,400e3)); savefig('gif/20jun1_b2.png')

clf(); drawcellVm(simConfig); xlim((390e3,400e3)); savefig('gif/20jun1_b4.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/20jun1_b5.png')

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs) 
len(pdfs) # 926400
pickle.dump(D, open('data/20may30_B1_falcor_synWeights_final.pkl','wb')) # ~33 MB

continue from there ...

    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20may30_B1_falcor_synWeights_final.pkl"}, 
"name":"20jun1_B2_falcor_"

./myrun 12 sn.json

** sim with optical flow as comparison?

optical flow may have performed a little better?, possibly due to higher noise or just a diff param regime

can use ~same params on zn ... (12-16 cores?)
but use optical flow instead of object track ... 

myrun 16 sn.json

weights too high ... have to reduce for optical flow (since more widesread activation)

python -i simdat.py backupcfg/20jun1_C0_zn_sim.json

drawraster(dspkT,dspkID); 
savefig('gif/20jun1_c0.png')

clf(); drawcellVm(simConfig)
savefig('gif/20jun1_c1.png')

last time used optic flow had these weight params:

    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EMDOWN":400,"EMUP":400,"IM":200,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.000025,"EEMWghtNM":0.0000025,"EEMWghtThreshMin":0.000025,"EEMWghtThreshMax":0.000075,"EEMProb":0.3,"EEMRecProb":0.1,"EEMPopNorm":0},
    "RL":{"AMPA":
	  {"wbase":0.0000001,"wmax":0.0001,"RLon":1,"RLlenhebb":50,"RLlenanti":50,"useRLexp":1,"RLhebbwt":0.0005,"RLantiwt":-0.0,"hebbwt":0,"antiwt":0,"tauhebb":10,"RLwindhebb":50,"softthresh":0,"verbose":0},

can use similar but have lower minthresh, smaller weight inc, and longer lenhebb

    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EMDOWN":400,"EMUP":400,"IM":200,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.000025,"EEMWghtNM":0.0000025,"EEMWghtThreshMin":0.00000625,"EEMWghtThreshMax":0.0001,"EEMProb":0.3,"EEMRecProb":0.3,"EEMPopNorm":0},
    "RL":{"AMPA":
	  {"wbase":0.0000001,"wmax":0.0001,"RLon":1,"RLlenhebb":100,"RLlenanti":50,"useRLexp":1,"RLhebbwt":0.00000125,"RLantiwt":-0.0,"hebbwt":0,"antiwt":0,"tauhebb":10,"RLwindhebb":50,"softthresh":0,"verbose":0},

weight change (RLhebbwt): 0.000025 * .05

also change usefull to off:
    "DirectionDetectionAlgo":{"CentroidTracker":0,"OpticFlow":1,"FlowWidth":16,"UseFull":0},

ok, try quick sim...

myrun 16 sn.json

python -i simdat.py backupcfg/20jun1_C0_zn_sim.json

drawraster(dspkT,dspkID); 
savefig('gif/20jun1_c2.png')

clf(); drawcellVm(simConfig); savefig('gif/20jun1_c3.png')

looks ok...

may as well run long sim for comparison ... 

running for 400 s ... 

*20jun2
** check output from 20jun1_C0_zn_ (uses optical flow)

  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 4317394 (2.01 Hz)
  Simulated time: 400.0 s; 16 workers
  Run time: 56524.00 s
Saving output as data/20jun1_C0_zn_simConfig.pkl ... 

synweights output file is ~2 GB

python -i simdat.py backupcfg/20jun1_C0_zn_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.51))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
subplot(1,3,1); plot([40e3,80e3,120e3,160e3,200e3,240e3,280e3,320e3,360e3,400e3],[.45,.45,.45,.45,.45,0.45,.45,.45,.45,.45],'bo',markersize=10) # times of weight norm

savefig('gif/20jun2_a0.png') # 
so far, this one doing worse than the others with object tracking...likely not due to object
tracking itself...but low firing rates...

clf(); drawraster(dspkT,dspkID); xlim((390e3,400e3)); savefig('gif/20jun2_a2.png')

clf(); drawcellVm(simConfig); xlim((390e3,400e3)); savefig('gif/20jun2_a4.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/20jun2_a5.png')

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs) 
len(pdfs) # 
pickle.dump(D, open('data/20jun1_C0_zn_synWeights_final.pkl','wb')) # 

can continue from there ... 

current weights are only ~20% of max and increasing slowly ... so there's room to improve
also better than hypersynch...

"name":"20jun2_C1_zn_"

    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20jun1_C0_zn_synWeights_final.pkl"}, 

** check output from 20jun1_A2_falcor_ and continue as 20jun2_A3_falcor_

python -i simdat.py backupcfg/20jun1_A2_falcor_sim.json

dstr = '20jun2_'; simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
subplot(1,3,1); plot([40e3,80e3,120e3,160e3,200e3,240e3,280e3,320e3,360e3,400e3],[.45,.45,.45,.45,.45,0.45,.45,.45,.45,.45],'bo',markersize=10) # times of weight norm

savefig('gif/'+dstr+simstr+'perf.png')
interesting ... does pass 50% probability of following ball in beginning but then decays ... should look at combined
cumulative probability ...

clf(); drawraster(dspkT,dspkID); xlim((390e3,400e3)); savefig('gif/'+dstr+simstr+'rast.png')
xlim((0,10e3)); savefig('gif/'+dstr+simstr+'rast_b.png')
looks like more firing in beginning compared to end; could too much punishment screw up performance? perhaps ...

clf(); drawcellVm(simConfig); xlim((390e3,400e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

#
sim = '20may29_A0_falcor_'
pda = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
curt = 200e3
for sim,maxdur in zip(['20may30_A1_falcor_', '20jun1_A2_falcor_'],[400e3,400e3]):
  tmp = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += curt
  curt += maxdur
  pda = pda.append(tmp)

#
clf()
plotFollowBall(pda,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(pda,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(pda,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf_total.png')

just looks like inaccuracy in measurement leading to initial overestimation of follow probability ...
but at least it does appear follow ball probability is increasing ... though fairly slowly ... and
possibly slowing down - so reached a peak ... 

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

ok, restart as ... 20jun2_A3_falcor_

"name":"20jun2_A3_falcor_"
    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20jun1_A2_falcor_synWeights_final.pkl"}, 

duration of 500 s ...

./myrun 12 sn.json
 
** check output from 20jun1_B2_falcor_ and continue as 20jun2_B3_falcor_

python -i simdat.py backupcfg/20jun1_B2_falcor_sim.json

dstr = '20jun2_'; simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
subplot(1,3,1); plot([40e3,80e3,120e3,160e3,200e3,240e3,280e3,320e3,360e3,400e3],[.45,.45,.45,.45,.45,0.45,.45,.45,.45,.45],'bo',markersize=10) # times of weight norm

savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); xlim((390e3,400e3)); savefig('gif/'+dstr+simstr+'rast.png')
rates look ok overall

clf(); drawcellVm(simConfig); xlim((390e3,400e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

#
sim = '20may29_B0_falcor_'
pda = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
curt = 200e3
for sim,maxdur in zip(['20may30_B1_falcor_', '20jun1_B2_falcor_'],[400e3,400e3]):
  tmp = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += curt
  curt += maxdur
  pda = pda.append(tmp)

#
clf()
plotFollowBall(pda,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(pda,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(pda,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf_total.png')

these cumulative probabilities look pretty clearly increasing ... so worth continuing further ... 

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) # 

ok, restart as ... 20jun2_A3_falcor_

"name":"20jun2_B3_falcor_"
    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20jun1_B2_falcor_synWeights_final.pkl"}, 

duration of 500 s ...

./myrun 12 sn.json

*20jun4
** check output from 20jun1_C0_zn_ -- still at pretty low probability of follow -->> too low firing rate?

  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 4292836 (2.00 Hz)
  Simulated time: 400.0 s; 16 workers
  Run time: 127753.46 s

python -i simdat.py backupcfg/20jun1_C0_zn_sim.json

dstr = '20jun4_'; simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

still rising, but not even approaching 50% yet ...

clf(); drawraster(dspkT,dspkID); xlim((390e3,400e3)); savefig('gif/'+dstr+simstr+'rast.png')
clf(); drawcellVm(simConfig); xlim((390e3,400e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

hmm, looks like the weights/output was overwritten since did not update the sim name properly
when started the last sim on zn

overall, looks like weights decreased from original:
2.101540571002588e-05/0.000025 == 0.8406162284010351

should start from the sims that had close to 50% probability of success? they had lower level of
recurr conn

less punishment or higher min value might help ... or higher starting value ... 

## pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) # 

** start from my

some errors on my ... 

** check output from 20jun2_A3_falcor_ and continue as 20jun4_A4_falcor_

python -i simdat.py backupcfg/20jun2_A3_falcor_sim.json

dstr = '20jun4_'; simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')
finally got close to 50% follow ball probability previously achieved, but then decays downwards ... 
and looks like starts decaying when gets more rewards ... so reward strength might be too high??

clf(); drawraster(dspkT,dspkID); xlim((90e3,100e3)); savefig('gif/'+dstr+simstr+'rast.png')
xlim((490e3,500e3)); savefig('gif/'+dstr+simstr+'rast_b.png')
already much more hypersynchrony near the end ... 

clf(); drawcellVm(simConfig); xlim((90e3,100e3)); savefig('gif/'+dstr+simstr+'Vm.png')
xlim((490e3,500e3)); savefig('gif/'+dstr+simstr+'Vm_b.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

#
sim = '20may29_A0_falcor_'
pda = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
curt = 200e3
for sim,maxdur in zip(['20may30_A1_falcor_', '20jun1_A2_falcor_','20jun2_A3_falcor_'],[400e3,400e3,500e3]):
  tmp = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += curt
  curt += maxdur
  pda = pda.append(tmp)

#
clf()
plotFollowBall(pda,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(pda,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(pda,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf_total.png')

hmm...using total cumulative, still seems to be increasing ...

clf()
actreward = pda
action_times = np.array(actreward.time)
actionvsproposed = np.array(actreward.action-actreward.proposed)
Hit_Missed = np.array(actreward.hit)
followact = np.where(actionvsproposed==0,1,0)
nbin = int(1e3 / (action_times[1]-action_times[0]))
avgfollow = [mean(followact[sidx:sidx+nbin]) for sidx in arange(0,len(followact),nbin)]
plot(20*arange(0,len(followact),nbin), avgfollow)
savefig('gif/'+dstr+simstr+'perf_follow_ball_prob.png')

probability gradually increasing but lot of variability ... 

DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration']))

savefig('gif/'+dstr+simstr+'avg_weight.png')

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

so, not clear if worth continuing this sim ... since getting towards hypersynch at end ... 
can reduce RLhebbwt ... ? so weights stop increasing as quickly ... 

this was value used up to now: "RLhebbwt":0.000004
try
"RLhebbwt":0.000002
and also increase RLlenhebb from 100 to 200 ... see if reduces some of the bias towards EMUP

ok, restart as ... 20jun4_A4_falcor_

"name":"20jun4_A4_falcor_"

duration of 200 s ...

./myrun 12 sn.json

** check output from 20jun2_B3_falcor_ and continue as 20jun4_B4_falcor_ <<-- will not continue this one

python -i simdat.py backupcfg/20jun2_B3_falcor_sim.json

dstr = '20jun4_'; simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); xlim((390e3,400e3)); savefig('gif/'+dstr+simstr+'rast.png')
xlim((0,10e3)); savefig('gif/'+dstr+simstr+'rast_b.png')

clf(); drawcellVm(simConfig); xlim((390e3,400e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

#
sim = '20may29_B0_falcor_'
pda = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
curt = 200e3
for sim,maxdur in zip(['20may30_B1_falcor_', '20jun1_B2_falcor_','20jun2_B3_falcor_'],[400e3,400e3,500e3]):
  tmp = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += curt
  curt += maxdur
  pda = pda.append(tmp)

#
clf()
plotFollowBall(pda,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(pda,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(pda,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf_total.png')

clf()
actreward = pda
action_times = np.array(actreward.time)
actionvsproposed = np.array(actreward.action-actreward.proposed)
Hit_Missed = np.array(actreward.hit)
followact = np.where(actionvsproposed==0,1,0)
nbin = int(1e3 / (action_times[1]-action_times[0]))
avgfollow = [mean(followact[sidx:sidx+nbin]) for sidx in arange(0,len(followact),nbin)]
plot(20*arange(0,len(followact),nbin), avgfollow)
savefig('gif/'+dstr+simstr+'perf_follow_ball_prob.png')

DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration']))

savefig('gif/'+dstr+simstr+'avg_weight.png')

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

ok, restart as ... 20jun4_B4_falcor_

"name":"20jun4_B4_falcor_"

duration of 500 s ...

./myrun 12 sn.json

** architecture changes?

feedback connections
plast between EM pops
bigger net?

*20jun5
** check output from 20jun4_A4_falcor_

python -i simdat.py backupcfg/20jun4_A4_falcor_sim.json

dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); xlim((190e3,200e3)); savefig('gif/'+dstr+simstr+'rast.png')
xlim((0,10e3)); savefig('gif/'+dstr+simstr+'rast_b.png')
it's not really doing better with these params ...

clf(); drawcellVm(simConfig); xlim((190e3,200e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

#
sim = '20may29_A0_falcor_'
pda = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
curt = 200e3
for sim,maxdur in zip(['20may30_A1_falcor_', '20jun1_A2_falcor_','20jun2_A3_falcor_','20jun4_A4_falcor_'],[400e3,400e3,500e3,200e3]):
  tmp = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += curt
  curt += maxdur
  pda = pda.append(tmp)

#
clf()
plotFollowBall(pda,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(pda,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(pda,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf_total.png')

clf()
actreward = pda
action_times = np.array(actreward.time)
actionvsproposed = np.array(actreward.action-actreward.proposed)
Hit_Missed = np.array(actreward.hit)
followact = np.where(actionvsproposed==0,1,0)
nbin = int(1e3 / (action_times[1]-action_times[0]))
avgfollow = [mean(followact[sidx:sidx+nbin]) for sidx in arange(0,len(followact),nbin)]
plot(20*arange(0,len(followact),nbin), avgfollow)
savefig('gif/'+dstr+simstr+'perf_follow_ball_prob.png')
not improvement

DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')
and some separation between weights, causing large bias in movement ... 

** try adjustment to recurrent connectivity between EMotor Pops

allow connectivity across the populations

also reduce the probability ... down to 0.1 ... 

for simplicity should also set the gains in file to 1.0 and adjust weights used accordingly ... 

  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 930526 (1.74 Hz)
  Simulated time: 100.0 s; 12 workers
  Run time: 14030.12 s

python -i simdat.py backupcfg/20jun5_A0_falcor_sim.json

dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); xlim((90e3,100e3)); savefig('gif/'+dstr+simstr+'rast.png')

clf(); drawcellVm(simConfig); xlim((90e3,100e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

still bias ... 

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')

ok, so that approach did not help much . . . 

** adjust rewards?

more punishment?
"rewardcodes": {"scorePoint": 1, "losePoint": -0.1, "followBall": 0.1, "avoidBall": -0.01, "hitBall": 0.5},
to
"rewardcodes": {"scorePoint": 1, "losePoint": -1, "followBall": 0.1, "avoidBall": -0.1, "hitBall": 0.5},

** bigger network?

hmm, why ... 

** plasticity within premotor areas?

add option for it dconf['net']['EEPreMProb']  
and EEPreMWghtAM, EEPreNWghtNM

ok...see if it helps ... 

./myrun 16 sn.json

python -i simdat.py backupcfg/20jun5_B0_falcor_sim.json

dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); xlim((90e3,100e3)); savefig('gif/'+dstr+simstr+'rast.png')
clf(); drawcellVm(simConfig); xlim((90e3,100e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')

firing rates seem ok ... performance not great ... so maybe did not help ...

#
lpop = ['ER', 'EV1', 'EV4', 'EMT', 'IR', 'IV1', 'IV4', 'IMT','EV1DW','EV1DNW', 'EV1DN', 'EV1DNE','EV1DE','EV1DSW', 'EV1DS', 'EV1DSE','EMDOWN','EMUP']  
dact = getdActMap(totalDur, tstepPerAction, lpop)
fig, axs, plt = animActivityMaps()

...based on results of next entry below should rerun (proposed action invalid sometimes, leading to bias in up direction)...

** use noframeskip?? -->> there was a mistake in proposed action when ball not visible -->> fixed -- always check ball position first!

is frameskip making it more difficult to train model? frameskip > 1 means same action taken several times before updating

'PongNoFrameskip-v4'

20jun5_C0_falcor_

./myrun 16 sn.json

hmm, nothing happens ... no ball visible, though reward = 0.01 throughout 

python -i simdat.py backupcfg/20jun5_C0_falcor_sim.json

lpop = ['ER', 'EV1', 'EV4', 'EMT', 'IR', 'IV1', 'IV4', 'IMT','EV1DW','EV1DNW', 'EV1DN', 'EV1DNE','EV1DE','EV1DSW', 'EV1DS', 'EV1DSE','EMDOWN','EMUP']  
dact = getdActMap(totalDur, tstepPerAction, lpop)

fig, axs, plt = animActivityMaps()

hmm: gif/20jun5_C0_falcor_actmap.mp4

in that movie there was no movement, and ball was not present at all but the punishment signal of 0.01
was almost always there ... and there were two instances of 0.1 reward ...

dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string

plotRewards(actreward,ax=gca(),msz=3); 
ylim((-0.02,0.12))
savefig('gif/'+dstr+simstr+'reward.png')

hmm, this logic in aigame.py seems incorrect?

        if ypos_Racket>ypos_Ball: #if the racket is lower than the ball the suggestion is to move up
          proposed_action = dconf['moves']['UP'] #move up
        elif ypos_Racket<ypos_Ball: #if the racket is higher than the ball the suggestion is to move down
          proposed_action = dconf['moves']['DOWN'] #move down
        elif ypos_Racket==ypos_Ball:
          proposed_action = dconf['moves']['NOMOVE'] #no move
        elif ypos_Ball==-1: #guess about proposed move can't be made because ball was not visible in the court
          proposed_action = -1 #no valid action guessed

since when ball is not found (via aigame.findobj), its coordinates are -1,-1
racket could have valid coordinates but ball could have invalid coordinates ... 

also, note that lower values in the image array are closer to top
so moving 'up' means moving towards smaller y values (top of screen)

try again with this ordering:

        if ypos_Ball==-1: #guess about proposed move can't be made because ball was not visible in the court
          proposed_action = -1 #no valid action guessed        
        elif ypos_Racket>ypos_Ball: #if the racket is lower than the ball the suggestion is to move up
          proposed_action = dconf['moves']['UP'] #move up
        elif ypos_Racket<ypos_Ball: #if the racket is higher than the ball the suggestion is to move down
          proposed_action = dconf['moves']['DOWN'] #move down
        elif ypos_Racket==ypos_Ball:
          proposed_action = dconf['moves']['NOMOVE'] #no move

20jun5_C1_falcor_

in sim.py, this seems like a mistake too? 

      for ai in range(len(actions)):
        caction = actions[ai]
        cproposed_action = proposed_actions[ai]
        if caction - cproposed_action == 0:
          critic_for_following_ball += dconf['rewardcodes']['followBall'] #follow the ball
        else:
          critic_for_following_ball += dconf['rewardcodes']['avoidBall'] # didn't follow the ball

since does not check if proposed action is valid (not equal to -1)

ok, adjusted that too to check if proposed action == -1

try that again ...

hmm, maybe the incorrect check for ball position is why biased towards up moves? since racket usually on screen
and when ball off-screen has y position of -1, leading to proposed move being up ... 

python -i simdat.py backupcfg/20jun5_C1_falcor_sim.json

#
dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string
plotRewards(actreward,ax=gca(),msz=3); 
ylim((-0.02,0.12))
savefig('gif/'+dstr+simstr+'reward.png')

ok, now has 0 rewards ... so that's correct ... but still not clear
why frameskip of 1 with noframeskip version of pong not updating frames properly ... 

** run 20jun5_PreMRecurr_falcor_ (with premotor recurrent plasticity)

running for 300 s ...

    "architecturePreMtoM": {"useProbabilistic":1,"useTopological":0},
    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EMDOWN":400,"EMUP":400,"IM":200,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.00008,"EEMWghtNM":0.0000025,"EEPreMWghtAM":0.00008,"EEPreMWghtNM":0.0000025,"EEMWghtThreshMin":0.00004,"EEMWghtThreshMax":0.00016,"EEMProb":0.3,"EEMRecProb":0.1,"EEPreMProb":0.1,"EEMPopNorm":0,"EEMRecProbCross":1},

./myrun 12 sn.json

** run 20jun5_NoPreMRecurrCross_falcor_ (no premotor recurrent plasticity, no cross-EM population plasticity)

running for 300 s ...

    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EMDOWN":400,"EMUP":400,"IM":200,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.00008,"EEMWghtNM":0.0000025,"EEPreMWghtAM":0.00008,"EEPreMWghtNM":0.0000025,"EEMWghtThreshMin":0.00004,"EEMWghtThreshMax":0.00016,"EEMProb":0.3,"EEMRecProb":0.1,"EEPreMProb":0.0,"EEMPopNorm":0,"EEMRecProbCross":0},

./myrun 12 sn.json

** still need to check how to get frameskip==0 to work
*20jun6
** check output from 20jun5_PreMRecurr_falcor_

python -i simdat.py backupcfg/20jun5_PreMRecurr_falcor_sim.json

dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r',binsz=10e3); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
savefig('gif/'+dstr+simstr+'perfB.png')

clf(); drawraster(dspkT,dspkID); xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'rast.png')
clf(); drawcellVm(simConfig); xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

still bias towards both top and bottom 

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')

slightly more towards down than up ...

worth continuing?? performance seems mostly flat ... 

hmm, is this right in plotFollowBall?
actionvsproposed = np.array(actreward.action-actreward.proposed)
is actreward.proposed ever -1?
np.amin(actreward.proposed) # -1.0
np.amin(actreward.action) # 1.0
still right for counting number of times model and proposed same, though not
for counting times model does not follow proposed since -1 a possible value for proposed and meaningless ...

** check output from 20jun5_NoPreMRecurrCross_falcor_

python -i simdat.py backupcfg/20jun5_NoPreMRecurrCross_falcor_sim.json

dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'rast.png')
clf(); drawcellVm(simConfig); xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')

this one not doing any better ... though generally less diff in weights to EMUP vs EMDOWN ...

** try same as last two but with targettedRL

worth checking in newer networks if targettedRL helps ... 

*** 20jun6_PreMRecurr_targetted_falcor_ 
*** 20jun6_NoPreMRecurrCross_targetted_falcor_
*20jun7
** check output from 20jun6_PreMRecurr_targetted_falcor_ 

python -i simdat.py backupcfg/20jun6_PreMRecurr_targetted_falcor_sim.json

dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

is that doing etter than without targetted RL? might be a little better than 20jun6_20jun5_PreMRecurr_falcor_perf.png

clf(); drawraster(dspkT,dspkID); xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'rast.png')
clf(); drawcellVm(simConfig); xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

less bias at down position ...

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')

neither population dominates throughout; that's somewhat reassuring ... can continue ... see if improves ...

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

** check output from 20jun6_NoPreMRecurrCross_targetted_falcor_

python -i simdat.py backupcfg/20jun6_NoPreMRecurrCross_targetted_falcor_sim.json

dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'rast.png')
clf(); drawcellVm(simConfig); xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

** other problem with follow ball rule

what if ball is flying away from racket? the distance between racket and ball might increase even if the racket is 'following' the ball
e.g. ball moving up and to the left and racket moving up, but ball moving faster up than racket. so that might be a punishing action
instead of rewarding. could instead consider that it's best action compared to staying still or moving down. alternatively, ignore situations
when ball is moving away from the racket.

there are some calculations for checking if ball moving towards racket in aigame.py:

      observation, reward, done, info = self.env.step(caction)
      #find position of ball after action
      xpos_Ball2, ypos_Ball2 = self.findobj(observation, courtXRng, courtYRng)        
      if xpos_Ball>0 and xpos_Ball2>0:
        if xpos_Ball2-xpos_Ball>0:
          ball_moves_towards_racket = 1 #use proposed action for reward only when the ball moves towards the racket
          current_ball_dir = 1 
        elif xpos_Ball2-xpos_Ball<0:
          ball_moves_towards_racket = 0
          current_ball_dir = -1
        else:
          ball_moves_towards_racket = 0
          current_ball_dir = 0 #direction can't be determinted  prob. because the ball didn't move in x dir.
      else:
        ball_moves_towards_racket = 0
        current_ball_dir = 0 #direction can't be determined because either current or last position of the ball is outside the court

but ball_moves_towards_racket is not used anywhere ... 

added option to set proposed_action to -1 if that value in sn.json == 1:
    "followOnlyTowards": 1,

note that similar problem can occur when ball moving towards racket. even if it's getting farther away in
y direction, the model's action may have been best possible action selected and so should not be punished for it.
so, should compare which action minimizes error, and reward model if it took that action, punish otherwise.
will note to update aigame.py logic for that ... hmm, check more carefully if aigame.py implements that
logic already ... 

one other reason that follow ball rule seems not ideal is racket should move towards where ball will be when
it hits x coord of racket, which is not always minimizing current y difference between ball and racket. this
is especially true if ball bounces off top or bottom of court.

ok, anyway, follow ball rule makes some sense, though should be improved to use
movement towards/away from predicted y location where ball crosses racket x coordinate 

** add some noise to EM populations (new option)

that might desynchronize their activity ... how does it look with E and I noise to the EMUP,EMDOWN populations?

here's how to specify in the json file:
    "Noise":{"I":{"Rate":100,"Weight":0.00001},"E":{"Rate":50,"Weight":0.00001}}

./myrun 16 sn.json

python -i simdat.py backupcfg/20jun7_A0_falcor_sim.json

dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png')
clf(); drawcellVm(simConfig); savefig('gif/'+dstr+simstr+'Vm.png')

raster looks a bit too synched at times ... but other times noisy ... 

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')
first time saw average weights go up and then down ... ?? 

note that this is also with     "followOnlyTowards" == 1
could compare in both cases ... 

try another noise test first, with E Rate of 25 ...

python -i simdat.py backupcfg/20jun7_A0_falcor_sim.json

dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
savefig('gif/'+dstr+simstr+'perf_B.png')

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast_B.png')
clf(); drawcellVm(simConfig); savefig('gif/'+dstr+simstr+'Vm_B.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight_B.png')

raster probably ok ... 

** top/bottom edge move rule?

if at top/bottom edge, prevent actuating further moves in that direction?

** feedback plasticity?
** longer run with noise to EMUP,EMDOWN and "followOnlyTowards" == 1

could have longer RLlenhebb of 200 ... since less frequent feedback about success

name: 20jun7_B0_falcor_
    "Noise":{"I":{"Rate":100,"Weight":0.00001},"E":{"Rate":25,"Weight":0.00001}}
    "followOnlyTowards": 1,

./myrun 16 sn.json

hmm, crashed at the very end with a memory error ... of course, recordWeightStepSize was 25!!
anyway, from viewing activity, did not look like model performance was too great ... 

*20jun8
** right side rule for ball

follow vs not should also only apply until ball passes model racket (on right side)

** other run

compare performance when no intermediate rewards from follow vs not follow given?
since follow ball seems problematic ... watching videos shows that racket overshoots
sometimes and does not have time to adjust ... 

lower E noise ... looks less synched?

    "Noise":{"I":{"Rate":100,"Weight":0.00001},"E":{"Rate":0,"Weight":0.00001}}

./myrun 16 sn.json

python -i simdat.py backupcfg/20jun8_A0_falcor_sim.json

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png')

EM populations are less synchronized ... but the direction selective neurons fire too synchronously ... 

try an intermediate run ... 

seemed like when ball hit racket, there was no reward ... must have introduced a bug

python -i simdat.py backupcfg/20jun8_A0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png')
xlim((19e3,20e3)); savefig('gif/'+dstr+simstr+'rastB.png')

*20jun9
** ha fixed follow ball rule

is working on updating it for calculating trajectory/intercept

** other test following ha fix

adding other options for architecture adjustments
including "EEMFeedbackProb":0.05,"VisualFeedback":0
EEMFeedbackProb <- probability of feedback connections from EM to the premotor and visual excitatory neurons (apart from ER)
VisualFeedback <- whether to have feedback from higher to lower order visual areas (EV1->ER, EV4->EV1, etc.; and inhibitory feedback too)

try it out ... when running with feedback plasticity tends towards
hyperexcitability, so have to keep the weights and probabilities low (or off)

seems like paddle is following ball to some extent but tends to overshoot and
then has trouble stabilizing ... did this with lower probability from preM
to M ... 

./myrun 16 sn.json

python -i simdat.py backupcfg/20jun9_A0_falcor_sim.json

drawraster(dspkT,dspkID); 
savefig('gif/'+dstr+simstr+'rast.png')
xlim((9e3,10e3))
savefig('gif/'+dstr+simstr+'rastB.png')

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

try longer run . . . 

