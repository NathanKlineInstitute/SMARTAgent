
* 19nov27
** trying on laptop

do not have netpyne on laptop

python3
import netpyne

pip3 install netpyne

Traceback (most recent call last):
  File "/usr/bin/pip3", line 9, in <module>
    from pip import main
ImportError: cannot import name 'main'

what's wrong with pip3?

https://stackoverflow.com/questions/49836676/error-after-upgrading-pip-cannot-import-name-main

sudo python3 -m pip uninstall pip && sudo apt install python3-pip --reinstall

pip3 install netpyne

hmm, needs newer version of python (>= 3.6 ), only have python 3.5 on laptop ...

will try on neurosim ... 

python3
import netpyne
netpyne.__version__ # '0.9.3.1'

pip3 install gym --user
pip3 install atari-py --user

compile:
nrnivmodl

for running on 1 node:
py3env
python3 trainSmartAgent.py

mpirun -n 16 python trainSmartAgent.py

was able to run with 1 core, took 2.5 GB with 500 ms interval for saving weights and 1000 ms simulation
will need to record from only a small fraction of the cells

* 20feb13
** make new branch to avoid conflict with haroon's work

git branch samn
git checkout samn
git add snnotes.dol
git commit -m 'new branch for samn test'
git push origin samn

make an alias for that: gpushsamn

** try compile and then run 

nrnivmodl

mpirun -n 16 python trainSmartAgent.py

myrun

mpirun -n 16 python trainSmartAgent.py

even after calling py3env to set the environment to use anaconda ... 
it's showing many different pong windows ... should only be 1 window  (this was run on zn)

aigame.py loads the gym environment with the pong game
where is aigame.py called from?

trainSmartAgent.py is the main sim setup
it imports SMARTAgent from aigame

hmm, not running it properly ...

mpiexec -n 16 python -mpi trainSmartAgent.py

* 20feb24
** HA fixed the MPI issues
** set env.frameskip to a constant value on environment init to avoid random frameskip in a range
** setup code for some more flexibility

can use json for config file

* 20feb25
** adjust architecture add direct V1 -> M popoulations

that way M has higher resolution visual information
and M still receives the lower resolution visual information from V2, IT as well ...

** simple test - reward for moving up, punish for moving down

does it produce expected behavior?

myrun 16

python
import numpy as np
from pylab import *
ion()
d = np.loadtxt('ActionsRewards.txt')
len(np.where(d[:,1]==3)[0]) # 232
len(np.where(d[:,1]==4)[0]) # 246
len(np.where(d[:,1]==1)[0]) # 272

plot(d[:,0],d[:,1],'ko')
hist(d[:,1])

to test if it's working just check the RL weights onto ML vs MR; weights onto ML neurons should
increase, while weights onto MR should decrease ...  if that's not happening, something is wrong ...

* 20feb26
** looking at the output weights for the fake training task

myrun 1
quit()

python3
import numpy as np
from pylab import *
ion()
awt = np.loadtxt('data/AdjustableWeights.txt')
awt.shape # (21999, 5) # columns are time, preid, postid, stdptype, weight

plot(awt[:,0],awt[:,4],'ko')
savefig('gif/20feb26_a0.png')

need to know cell types ...

import pandas as pd
pdf = pd.DataFrame(awt,columns=['time','preid','postid','stdptype','weight'])
len(pdf) # 21999

pdfs = pdf[(pdf.postid==1184) & (pdf.stdptype==1)]
len(pdfs) # 879
plot(pdfs.time,pdfs.weight,'r')
savefig('gif/20feb26_a1.png') # looks incorrect ?? does it go up and down or are those two different synapses?

min(pdfs.preid),max(pdfs.preid) # (403.0, 924.0)
yeah, two preids ... and they're differnet because different source populations ...

pdfs = pdf[(pdf.postid==1184) & (pdf.stdptype==1) & (pdf.preid==403)]
len(pdfs) # 20
plot(pdfs.time,pdfs.weight,'b')
savefig('gif/20feb26_a2.png')
ok, that weight is increasing gradually ... but is that the ML or MR output population?

ID 1159 through 1183 (inclusive) are the ML neurons? (/u/samn/SMARTAgent/trainSmartAgent.py:754)

pdfs = pdf[(pdf.postid==1159) & (pdf.stdptype==1)]
len(pdfs) # 0

pdfs = pdf[(pdf.postid==1160) & (pdf.stdptype==1)]
len(pdfs) # 0

pdfs = pdf[(pdf.postid>=1159) & (pdf.postid<=1183) & (pdf.stdptype==1)]
len(pdfs) # 0

hmm, are any of the ML weights getting saved??

note that this was run with a single core ...

ah, a bug in new code ...

fix, rerun ...

myrun 1

python3
import numpy as np
from pylab import *
ion()
awt = np.loadtxt('data/AdjustableWeights.txt')
awt.shape # (22000, 5) # columns are time, preid, postid, stdptype, weight

plot(awt[:,0],awt[:,4],'ko')

import pandas as pd
pdf = pd.DataFrame(awt,columns=['time','preid','postid','stdptype','weight'])
pdfs = pdf[(pdf.postid>=1159) & (pdf.postid<=1183) & (pdf.stdptype==1)]
len(pdfs) # 11000

should save types in the file ... 

plot(pdfs.time,pdfs.weight,'b')

myrun 1
sim.net.cells[0].tags['pop'] # 'R'

sim.net.cells[1184].tags['pop'] # 'MR'
sim.net.cells[1159].tags['pop'] # 'ML'

* 20feb27
** continue debugging

to get the network/cell info use this:
simConfig.savePickle = True            # Save params, network and sim output to pickle file

myrun 1

from pylab import *
savefig('gif/20feb27_rast_a0.png')

simConfig.filename = 'data/simConfig'
sim.saveFolder = 'data'

python3
import numpy as np
from pylab import *
ion()
awt = np.loadtxt('data/AdjustableWeights.txt')

import pandas as pd
pdf = pd.DataFrame(awt,columns=['time','preid','postid','stdptype','weight'])
pdfs = pdf[(pdf.postid>=1159) & (pdf.postid<=1183) & (pdf.stdptype==1)]

import pickle
simConfig = pickle.load(open('data/simConfig.pkl','rb'))
simConfig.keys() # dict_keys(['netpyne_version', 'netpyne_changeset', 'net', 'simConfig', 'simData'])

simConfig['net'].keys() # dict_keys(['params', 'cells', 'pops'])
simConfig['net']['pops'].keys() # odict_keys(['R', 'V1', 'V4', 'IT', 'IR', 'IV1', 'IV4', 'IIT', 'ML', 'MR'])
simConfig['net']['pops']['MR'].keys() # dict_keys(['tags', 'cellGids'])
simConfig['net']['pops']['MR']['cellGids'] # [1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208]
simConfig['net']['pops']['ML']['cellGids'] # [1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183]

ok, good ...

dstartidx = {p:simConfig['net']['pops'][p]['cellGids'][0] for p in simConfig['net']['pops'].keys()}
dendidx = {p:simConfig['net']['pops'][p]['cellGids'][-1] for p in simConfig['net']['pops'].keys()}

dstartidx # {'R': 0, 'V1': 400, 'V4': 800, 'IT': 900, 'IR': 925, 'IV1': 1025, 'IV4': 1125, 'IIT': 1150, 'ML': 1159, 'MR': 1184}
dendidx # {'R': 399, 'V1': 799, 'V4': 899, 'IT': 924, 'IR': 1024, 'IV1': 1124, 'IV4': 1149, 'IIT': 1158, 'ML': 1183, 'MR': 1208}

pdfs = pdf[(pdf.postid>=dstartidx['ML']) & (pdf.postid<=dendidx['ML']) & (pdf.preid>=dstartidx['V1']) & (pdf.preid<=dendidx['V1']) & (pdf.stdptype==1)]
len(pdfs) # 4000

plot(pdfs.time,pdfs.weight,'bo')

savefig('gif/20feb27_wghts_a1.png')

pdfs = pdf[(pdf.postid>=dstartidx['MR']) & (pdf.postid<=dendidx['MR']) & (pdf.preid>=dstartidx['V1']) & (pdf.preid<=dendidx['V1']) & (pdf.stdptype==1)]
len(pdfs) # 4000

plot(pdfs.time,pdfs.weight,'ro')

savefig('gif/20feb27_wghts_a2.png')

so both ML and MR weights are increasing - that's incorrect

checking if recording the synaptic weights into sim.simData['synweights'] will work
with netpyne gathering the info across nodes automatically ...

python3
import numpy as np
from pylab import *
import pickle

simConfig = pickle.load(open('data/simConfig.pkl','rb'))
simConfig.keys() # dict_keys(['netpyne_version', 'netpyne_changeset', 'net', 'simConfig', 'simData'])
simConfig['simData'].keys() # dict_keys(['spkt', 'spkid', 'V_soma', 't', 'synweights', 'avgRate'])
len(simConfig['simData']['synweights']) # 22000
simConfig['simData']['synweights'][0] # [99.9999999999986, 0.0025, 1184, 900, 1]

and that was when running with 1 node ... try again with > 1 to see if same

myrun 16

Traceback (most recent call last):
  File "sim.py", line 988, in <module>
    sim.gatherData() # gather data from different nodes
  File "/usr/site/python/netpyne/netpyne/sim/gather.py", line 165, in gatherData
    sim.allSimData[key].update(val)           # update simData dicts which are not Vectors
ValueError: dictionary update sequence element #0 has length 5; 2 is required

change sim.simData['synweights'] to a dict (with key 0 pointing to a list of lists)

type(sim.simData['synweights']) # <class 'dict'>
sim.simData['synweights'][0][0] # [99.9999999999986, 0.0025, 1184, 912, 1]
len(sim.simData['synweights'][0]) # 1320
len(sim.allSimData['synweights'][0]) # 1320
sim.allSimData['synweights'].keys() # dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])
len(sim.allSimData['synweights'][15]) # 1320
sum([len(sim.allSimData['synweights'][i]) for i in range(16)]) # 22000

import pickle
simConfig = pickle.load(open('data/simConfig.pkl','rb'))
len(simConfig['simData']['synweights'][0]) # 1320
simConfig['simData']['synweights'].keys() # dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15])
simConfig['simData']['synweights'][0][0] # [99.9999999999986, 0.0025, 1184, 912, 1]

ion()
awt = np.loadtxt('data/AdjustableWeights.txt')

import pandas as pd
pdf = pd.DataFrame(awt,columns=['time','preid','postid','stdptype','weight'])


ok, good ...

dstartidx = {p:simConfig['net']['pops'][p]['cellGids'][0] for p in simConfig['net']['pops'].keys()}
dendidx = {p:simConfig['net']['pops'][p]['cellGids'][-1] for p in simConfig['net']['pops'].keys()}

testing basic mechanism again , with RL exp off and fake up rule ... 

myrun 16

plw

savefig('gif/20feb27_rewards_wghts_a3.png')

seems to generally work, once separated out the population specific projections (V1->ML and V1->MR) ...
but not clear why V1->MR is getting reinforced when MR produces down moves ...

could be that MR getting reinforced since V1 projects to both MR and ML and V1->MR synapses are tagged
within the interval when V1->ML synapses are tagged for reward ...

try cutting off some of the higher connections connections and see what happens ... e.g. no V1 -> MR
and no V4, IT -> ML or -> MR; and may need to set wbase to 0 as well ...

myrun 16

now for some reason ML never firing ... ??? no, ML firing but MR not firing (that was the test)
but mostly only producing move 3 (down), instead of 4 (up) ... why?

savefig('gif/20feb27_rewards_wghts_a4.png')
savefig('gif/20feb27_rewards_wghts_a5.png')

hmm, had the rule backwards:
            if F_R1>F_L1:
                actions.append(dconf['moves']['UP']) #UP
            elif F_R1<F_L1:
                actions.append(dconf['moves']['DOWN']) # Down
            else:
            actions.append(dconf['moves']['NOMOVE']) # No move

R produces up, L produces down ...

ok, fixing that, now V->MR weights go up as they should (but now have turned off inputs to ML)
savefig('gif/20feb27_rewards_wghts_a6.png')

so, turned back on the inputs to ML to see if -> MR weights still go up with time ...

savefig('gif/20feb27_raster_a7.png')

savefig('gif/20feb27_rewards_weights_a8.png')

it does look like the V -> MR weights increase more than the V -> ML weights, which
is correct, but the V -> ML weights still seem to correlate with the V -> MR weights, and go up in parallel
perhaps, as long as overall more of the correct moves are made, it doesn't matter if the V -> ML weights
are increased too ... ?

what is the move command as a function of time? more correct moves later on compared to earlier?

pad = pd.DataFrame(actreward,columns=['time','action','reward'])

figure(); pads = pad[pad.action==3]; plot(pads.time,pads.action,'bo'); pads = pad[pad.action==4]; plot(pads.time,pads.action,'ro')

#
ldown,lup = [],[]
ltt = linspace(0,99,100)
for tt in ltt:
  pads = pad[(pad.action==3) & (pad.time>=tt*1e3) & (pad.time<=(tt+1)*1e3)]
  ldown.append(len(pads))
  pads = pad[(pad.action==4) & (pad.time>=tt*1e3) & (pad.time<=(tt+1)*1e3)]
  lup.append(len(pads))

clf(); plot(ltt,ldown,'r',linewidth=4); plot(ltt,lup,'b',linewidth=4); xlabel('Time (s)'); ylabel('Move frequency (Hz)');
import matplotlib.patches as mpatches
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','r'],['Up','Down'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/20feb27_action_freq_a9.png')

most of the time, up moves have higher rate than down moves ...

see if it's reversed when using the down fake rule ...

ok, using sim.json sim:name to specify simulation name so can save output files for different sim in data ...

also may as well adjust plotWeights to draw actions in top panel ...? suppose only useful when using fake rule ... 
otherwise up/down rates not so important ...  

sim name is 20feb27_FakeDownRule_B0_

myrun 16

  Cells: 1209
  Connections: 27879 (23.06 per cell)
  Spikes: 173390 (1.43 Hz)
  Simulated time: 100.0 s; 16 workers
  Run time: 2309.54 s

savefig('gif/20feb27_raster_b0.png')

more spikes at bottom, where they should be ... ML has higher firing rate (ML produces down move), much more than in previous example where MR had
slightly higher firing rate than ML  ... maybe a bug somewhere? why the difference?

and now check the weights and action freqs ... 

plw

savefig('gif/20feb27_rewards_weights_b1.png')

#
ldown,lup = [],[]
ltt = linspace(0,99,100)
for tt in ltt:
  actrewards = actreward[(actreward.action==3) & (actreward.time>=tt*1e3) & (actreward.time<=(tt+1)*1e3)]
  ldown.append(len(actrewards))
  actrewards = actreward[(actreward.action==4) & (actreward.time>=tt*1e3) & (actreward.time<=(tt+1)*1e3)]
  lup.append(len(actrewards))

figure(); plot(ltt,ldown,'r',linewidth=4); plot(ltt,lup,'b',linewidth=4); xlabel('Time (s)'); ylabel('Move frequency (Hz)');
import matplotlib.patches as mpatches
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','r'],['Up','Down'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/20feb27_action_freq_b2.png')

so, there are more down actions generally ..., particularly as the sim progresses ... maybe less consistent
than in previous FAKE MOVEUP test ...

not clear why would get diff results for the two fake rule tests ... one up and one down ... maybe some bug,
or some runaway effect ... 

could run another test to see if teach net to hold paddle still ... leading to suppression of ML and MR ...

ok, will try that ... with this sim name: 20feb27_FakeStayRule_C0_
and RLFakeStayRule == 1

note that any move up or down (in the 5 action block) is a penalty and any stay command is opposite (for the critic signal)... 

myrun 16

  Cells: 1209
  Connections: 27879 (23.06 per cell)
  Spikes: 173771 (1.44 Hz)
  Simulated time: 100.0 s; 16 workers
  Run time: 2286.23 s
Saving output as data/20feb27_FakeStayRule_C0_simConfig.pkl ... 
Finished saving!
Done; saving time = 11.18 s.

savefig('gif/20feb27_FakeStayRule_C0_raster.png')
lower firing rates for MR, ML ... next, look at behavior and weights...

plw

savefig('gif/20feb27_FakeStayRule_C0_rewards_weights_c0.png')

both sets of weights stay close to baseline ... 
would have expected both sets to decrease towards 0

savefig('gif/20feb27_FakeStayRule_C0_action_freq_c0.png')

well, at least neither action dominates here ...

* 20feb28
** continue 

should make it easier to load the output data ... maybe consolidate plotting funcs too ...

question about architecture - how much of the higher level areas do we need/want? and should
allow easier scaling of the simulation in case need larger-sized populations  ... 

homeostatic plasticity will likely be needed - the weights were increasing, and could push
the net to epilepsy ...

try full architecture with the fake rules ... possible that higher order connections are not a problem ...

myrun 24

looks like M population might be too small ... ML and MR neurons should receive largely overlapping inputs from V1
because of the much higher number of V1 (400) compared to ML (25) and MR (25) neurons , with the high convergence (16)
this might be reason see highly synchronous firing in ML, MR neurons and correlation between the weight changes for the
fake tasks... whether or not topography is needed for ML,MR is unclear - random inputs may allow more complex encodings.
but can at least try increasing populaion size of ML, MR.

try that out ...

also, looks like noise inputs are off ... may want to reintroduce them ...
other source of artificial synchronization is the image inputs, which arrive to the network at a fixed interval (~30 ms?)

adjusted some of the convergence/weights onto ML,MR to have same convergence from each V1,V4,IT source
and lower weights 1/2 of original to prevent too high firing ...

savefig('gif/20feb28_rast_a0.png')
savefig('gif/20feb28_reward_weights_a1.png')
some separation between them in all projections ...
savefig('gif/20feb28_action_freq_a2.png')

try same, but longer ...

125 s ...

  Cells: 1359
  Connections: 38281 (28.17 per cell)
  Spikes: 484922 (2.85 Hz)
  Simulated time: 125.0 s; 16 workers
  Run time: 2823.09 s
Saving output as data/20feb28_A0_simConfig.pkl ... 
Finished saving!
Done; saving time = 97.79 s.

savefig('gif/20feb28_rast_b0.png')
rates go up too much ... another indication that need some form of homeostasis

savefig('gif/20feb28_reward_weight_b1.png')

#
ldown,lup = [],[]
ltt = linspace(0,124,125)
for tt in ltt:
  actrewards = actreward[(actreward.action==3) & (actreward.time>=tt*1e3) & (actreward.time<=(tt+1)*1e3)]
  ldown.append(len(actrewards))
  actrewards = actreward[(actreward.action==4) & (actreward.time>=tt*1e3) & (actreward.time<=(tt+1)*1e3)]
  lup.append(len(actrewards))

figure(); plot(ltt,ldown,'r',linewidth=4); plot(ltt,lup,'b',linewidth=4); xlabel('Time (s)'); ylabel('Move frequency (Hz)');
import matplotlib.patches as mpatches
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','r'],['Up','Down'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)
xlim((0,125))

savefig('gif/20feb28_move_rate_b2.png')
ok, clearly moving up more than down after training ... (as it should)

can try training in DOWN direction as precaution or run actual game test ...

will try game test ...

ok running this with no fake rule, and duration of 250e3 ... 
"20feb28_G0_"

if there was a weaker opponent, might be easier to train as starting point?
or play against self ...
does openai allow controlling difficulty level of opponent?

well, did see the model score a point...but pretty rare so far ...
intermediate rewards after ball contacts racket might be sensible, though less generic...
can also have multidimensional error for reward/punishment, consisting of distance
between racket/ball (0.25), contact with racket (0.5), actual points (+1/-1)
or sign(current distance to ball - last distance to ball) -- but once using those
types of rules, no longer need the visual input at all ... 

separately, also need to be able to save/restore learned weights ...

stoped sim ~1/2 way through since it ends up mostly staying still, probably due to lot of punishments, as discussed before ...

openai allows easily saving mp4 videos ... added that option ...

ok, will set wbase to starting level, since starts with pretty low level of firing anyway ...

can also reduce the frequency of saving the synaptic weights ...

  Cells: 1359
  Connections: 38281 (28.17 per cell)
  Spikes: 986134 (1.45 Hz)
  Simulated time: 500.0 s; 24 workers
  Run time: 11678.73 s
  Saving output as data/20feb28_G0_simConfig.pkl ...

savefig('gif/20feb28_rast_g0.png')  

movie is useful: videos/20feb28_G0_/openaigym.video.0.24912.video000000.mp4
but only lasts a single episode  which took ~35 s, so lost viewing movie activity from most of the sim ...

simdat

savefig('gif/20feb28_reward_weights_g0.png')  

reward frequency might increase over time ... ? weights certainly have not stabilized yet
and although rewards compared to punishments are much less frequent, they still influence
the weights substantially - the weights are not at minimum ...

so, need to allow movies generated to encompass entired simulation, and to allow setting
the initial weights to the final ones generated by previous run ...

* 20feb29
** run longer - check if video saved after each episode

ran but did not save data:
Done; run time = 37584.81 s; real-time ratio: 0.04.
ran out of memory...

Gathering data...
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
[zn:32842] *** Process received signal ***
[zn:32842] Signal: Aborted (6)
[zn:32842] Signal code:  (-6)
[zn:32842] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x12890)[0x7f3ec802f890]
[zn:32842] [ 1] /lib/x86_64-linux-gnu/libc.so.6(gsignal+0xc7)[0x7f3ec7c6ae97]
[zn:32842] [ 2] /lib/x86_64-linux-gnu/libc.so.6(abort+0x141)[0x7f3ec7c6c801]
[zn:32842] [ 3] /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0x8c957)[0x7f3ec84e0957]
[zn:32842] [ 4] /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0x92ab6)[0x7f3ec84e6ab6]
[zn:32842] [ 5] /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0x92af1)[0x7f3ec84e6af1]
[zn:32842] [ 6] /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0x92d24)[0x7f3ec84e6d24]
[zn:32842] [ 7] /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0x9329c)[0x7f3ec84e729c]
[zn:32842] [ 8] /usr/site/../arch/nrn/share/nrn/../../x86_64/lib/libnrnpython3.so(+0x1bd7a)[0x7f3ea9420d7a]
[zn:32842] [ 9] /usr/site/../arch/nrn/x86_64/lib/libnrniv.so.0(+0xb4227)[0x7f3eca326227]
[zn:32842] [10] /usr/site/../arch/nrn/x86_64/lib/libnrnoc.so.0(hoc_call_ob_proc+0x23a)[0x7f3eca5f1d7a]
[zn:32842] [11] /usr/site/../arch/nrn/x86_64/lib/libnrnoc.so.0(hoc_object_component+0x51e)[0x7f3eca5f2a8e]
[zn:32842] [12] /usr/site/../arch/nrn/share/nrn/../../x86_64/lib/libnrnpython3.so(+0xef3a)[0x7f3ea9413f3a]
[zn:32842] [13] /usr/site/../arch/nrn/share/nrn/../../x86_64/lib/libnrnpython3.so(+0x141fb)[0x7f3ea94191fb]
[zn:32842] [14] /usr/site/../arch/nrn/x86_64/lib/libnrniv.so.0(_ZN10OcJumpImpl7fpycallEPFPvS0_S0_ES0_S0_+0x3e)[0x7f3eca2ff5fe]
[zn:32842] [15] /usr/site/../arch/nrn/share/nrn/../../x86_64/lib/libnrnpython3.so(+0xeb37)[0x7f3ea9413b37]
[zn:32842] [16] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(_PyObject_FastCallDict+0x8a)[0x7f3ea97d424a]
[zn:32842] [17] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(+0x2084b7)[0x7f3ea98504b7]
[zn:32842] [18] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(_PyEval_EvalFrameDefault+0x3373)[0x7f3ea97a6153]
[zn:32842] [19] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(+0x208063)[0x7f3ea9850063]
[zn:32842] [20] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(+0x208616)[0x7f3ea9850616]
[zn:32842] [21] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(_PyEval_EvalFrameDefault+0x3373)[0x7f3ea97a6153]
[zn:32842] [22] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(+0x208063)[0x7f3ea9850063]
[zn:32842] [23] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(PyEval_EvalCodeEx+0x3e)[0x7f3ea9850a6e]
[zn:32842] [24] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(PyEval_EvalCode+0x1c)[0x7f3ea97a2b2c]
[zn:32842] [25] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(PyRun_FileExFlags+0xb7)[0x7f3ea97344d7]
[zn:32842] [26] /usr/site/nrniv/local/python/anaconda3/envs/py36/lib/libpython3.6m.so(PyRun_SimpleFileExFlags+0xf4)[0x7f3ea9738734]
[zn:32842] [27] /usr/site/../arch/nrn/share/nrn/../../x86_64/lib/libnrnpython3.so(nrnpy_pyrun+0x2c)[0x7f3ea941323c]
[zn:32842] [28] /usr/site/../arch/nrn/share/nrn/../../x86_64/lib/libnrnpython3.so(nrnpython_start+0x288)[0x7f3ea9413888]
[zn:32842] [29] nrniv(ivocmain+0x5cb)[0x563f75882bfb]
[zn:32842] *** End of error message ***
--------------------------------------------------------------------------
mpiexec noticed that process rank 0 with PID 0 on node zn exited on signal 6 (Aborted).
--------------------------------------------------------------------------

so will probably have to run simulation for shorter duration ...

* 20mar1
** run 750 s again - adjust critic for punishments

can try critic with -0.1 or -0.01 so it's less pronounced compared to reward

750 s, with critic at -0.01 ...

myrun 24

* 20mar2
** continue - look at output from last sim

  Cells: 1359
  Connections: 38281 (28.17 per cell)
  Spikes: 3478200 (3.41 Hz)
  Simulated time: 750.0 s; 24 workers
  Run time: 18652.00 s
Saving output as data/20mar1_G2_simConfig.pkl ... 
Finished saving!
  Done; saving time = 83.59 s.
Plotting recorded cell traces ... cell
QStandardPaths: XDG_RUNTIME_DIR not set, defaulting to '/tmp/runtime-samn'
Plotting raster...
Saving figure data as data/20mar1_G2_RasterData.pkl ... 
  Done; plotting time = 1282.06 s

savefig('gif/20mar2_G2_Raster.png')
  
savefig('gif/20mar2_G2_reward_weights.png')

ok, weights do not have as much time to decay now ...

but still need a way to save/restore the weights, and produce videos capturing whole simulation ...

* 20mar5 - testing on laptop after conda/neurosim setup 
** conda/packages

had installed anaconda with python36 and then recompiled neuron, etc.

for ffmpeg if you're on ubuntu & have root can use sudo apt-get install ffmpeg

py3env <<-- that now sets conda to use py36
conda install numpy
conda install scipy
conda install pandas
conda install matplotlib
used new version of netpyne from github (development branch) with pip after activating the conda
env above; note that netpyne does not support latest matplotlib or latest pandas (sal mentioned
bug in those latest versions)

this is the alias in .tcshrc for setting the py env with conda:
alias py3env 'alias py3env setenv NSUF 'py3';source /usr/site/config/nrnenv.csh; setenv PYTHONPATH {$PYTHONPATH}:/usr/site/nrniv/local/python; conda activate py36'

once that env is activated can just use pip (it points to the right pip3 for that py env) and
don't have to explicitly indicate pip3

myrun 16

here's first error:

ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.22' not found
(required by
/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/site-packages/scipy/fft/_pocketfft/pypocketfft.cpython-36m-x86_64-linux-gnu.so)

according to : https://github.com/facebookresearch/detectron2/issues/609
should do:
conda update libgcc

PackageNotInstalledError: Package is not installed in prefix.
  prefix: /usr/site/nrniv/local/python/anaconda3/envs/py36
  package name: libgcc

conda install libgcc

ok, that fixed that problem ...

next error:
python
import sim
ModuleNotFoundError: No module named 'skimage'

conda install skimage

not found ...

it's scikit-image

conda install scikit-image

and also need openai gym
can install with conda as:
conda install -c akode gym

hmm, did not find it ...

ok, just use pip ...

pip install gym

pip install 'gym[atari]'

sudo add-apt-repository ppa:ubuntu-toolchain-r/test
sudo apt-get update
sudo apt-get install gcc-4.9
sudo apt-get install --only-upgrade libstdc++6

ok, that fixed error ... based on this:
 https://github.com/lhelontra/tensorflow-on-arm/issues/13#issuecomment-489296444

myrun 12

also have this in pythonpath:
 setenv PYTHONPATH {$PYTHONPATH}:$ND/share/python/lib/python:/usr/site/nrniv/local/python

* 20mar6 - long run with restarts?
** testing

since haroon implemented weight save/restore, could let it run a few times with restarts ...

may not need to save video for now ... could instead run video once run a few rounds of training
...

* 20mar8 - notes on changes
** started setting up multistepSim.py
which generates run file to call a few sims in a row, with each one reloading weights saved from
end of previous run; still testing - not working properly yet

** noticed on mar6 that the temperature was wrong (6.3 instead of 37)
changing temperature required readjusting the connection weights between cells
added the standard cfg. EEGain, EIGain, IEGain, IIGain to allow easier modulation of
these weights

this also required changing threshold for spikes - however, voltage traces do not currently
look great, so this will require some further adjustment. may want to use simple models of
PV cells nad or PYR cells ... although their dynamics with multiple ion channels will be
more costly than simpler standalone HH

** also changed population names so they'd be consistent
some populations seemd to have inconsistent names
now always using E as prefix for excitatory population and I as prefix for inhibitory population

** ran fake up rule test with new setup

produced higher weights for expected population

* 20mar8 - fix for multistepsim, run test
** multistep test - still not working properly? fixed ... 

python multistepSim.py sim.json 16 2 multirun

individual sims do not stop after plot ... ?

ok, fixed problems ... conf.py was not reading correct json, was not passing it to sim.py either, etc.

** replace cell types?

voltage traces don't look great now after temp adjustment ...

** try a multistepsim test run with game (300 s run with 12 steps = 1 hr.)

not using fake rules ...

python multistepSim.py sim.json 16 12 multirun

* 20mar9 - adjustments to cell types/architecture
** code reorg - moved mod files to mod subdir; moved cell types to cells subdir; compile script (nrnivmodl mod)
** HA added Mainen PYR2 and FS basket cells to model
this then required adjusting weights and...
** adjusted rules to have AMPA synapses of PYR on dend; AMPA of I cells on soma; GABAA for E,I on soma
** ...then had to adjust architecture slightly (new interneuron population)
to include IM interneuron population in motor area; this reduces likelihood of depolarization blockade
of the EMR and EML populations (seems to work after some adjustment to the weights)
a 10 s run shows one population of EM neurons firing faster than the other leading to paddle
staying at top of screen for much of the sim - not sure where this assymetry comes from

right now there's one interneuron population in M area providing feedback inhibition onto both EM and ER
populations; in future may want multiple interneuron populations that receive excitation from one population
and suppress the other (easy to implement in netpyne, but thought that might lead to further positive feedback
and one EMR vs EML population dominating the dynamics)

still, where does the assymetry come from?

* 20mar10 - adjustments to connectivity, thresholds, E/I balance
** using dnumc as dictionary for number of cells
** set different thresholds for E and I cells (lower for I cells) via cellRule

netParams.cellParams['PYR_Mainen_rule']['secs']['soma']['threshold'] = 0.0
netParams.cellParams['FS_BasketCell_rule']['secs']['soma']['threshold'] = -10.0

** lack of symmetry fix? use convergence instead of probability

probably due to higher/lower number of inputs from IM to EMR vs EML
can fix that via using convergence rather than random connectivity

conv = pmat[from][to] * numc[from]

ok, try that with fake up rule ... 

myrun 16

hmm, something messed up ... was getting too much dep blockade ... 

ok, after adjusting the thresholds, other connection weights and gains ...

(note that IV4 was acting differently since receives extra inhibition from the large IV1 population; reduced
the weights from IV1 -> IV4 to reduce that effect)

get more reasonable raster, with higher I than E rates ... 

savefig('gif/20mar10_rast_a0.png')

testing fake up rule for 10 s ... still stable at end ...

raster looks ok:
savefig('gif/20mar10_rast_a1.png')
cells look ok:
savefig('gif/20mar10_IM_a1.png')
savefig('gif/20mar10_EMR_a1.png')
savefig('gif/20mar10_EML_a1.png')
savefig('gif/20mar10_IIT_a1.png')
savefig('gif/20mar10_EIT_a1.png')
savefig('gif/20mar10_IV4_a1.png')
savefig('gif/20mar10_EV4_a1.png')
savefig('gif/20mar10_IV1_a1.png')
savefig('gif/20mar10_EV1_a1.png')
savefig('gif/20mar10_IR_a1.png')
savefig('gif/20mar10_ER_a1.png')

and the weights ?
simdat
savefig('gif/20mar10_reward_weights_a1.png')
weights look biased towards correct population
(note that only recording weights every 1 s here, while reward signal recorded every 0.1 s so
cannot always see correspondence closely in figure above)

** Note: should change R and L to up and down (as appropriate)!
EMR, EML population names

** meanwhile, try multistep test again

python multistepSim.py sim.json 16 12 multirun

that did not seem to work ... paddle ends up becoming stationary after a while ...
probably too much punishment suppressing EMR,EML

* 20mar11
** add noise?
** check haroon's updated intermediate reward rules

has these in sim.json:
"rewardcodes": {"scorePoint": 1, "losePoint": -0.01, "followBall": 0.001, "avoidBall": -0.001, "hitBall": 0.05},

will reward following ball and hitting ball more ... take a look to see if works, etc.

can try:
"rewardcodes": {"scorePoint": 1, "losePoint": -1, "followBall": 0.5, "avoidBall": -0.001, "hitBall": 0.75},

myrun 16

* 20mar24
** discussion on retinal circuitry, movement selectivity

14:22
samn this paper looks useful https://senselab.med.yale.edu/ModelDB/ShowModel?model=116837&file=/RM_STDP/#tabs-1
14:23
https://paperpile.com/app/p/f2db9a70-4380-0c3c-9bc0-36a1fc7402f9
14:24
haroon found this paper for motion selectivity in retina: https://paperpile.com/app/p/7b54db25-10b2-0afe-af21-4538acf0def0
14:26
not sure if that model has retina with motion selectivity
14:28
here's another: https://senselab.med.yale.edu/ModelDB/ShowModel?model=118524#tabs-1
14:28
"virtual retina"
14:28
Haroon Anwar looks very phenomenological
14:29
samn https://paperpile.com/app/p/4c5b9cb8-6eb7-00f2-b3c9-fa42ea6d2595
14:30
"Abstract We propose a new retina simulation software, called Virtual Retina, which transforms a video into spike trains. Our goal is twofold: Allow large scale simulations (up to 100,000 neurons) in reasonable processing times and keep a strong biological plausibility, taking into account implementation constraints. The underlying model includes a linear model of filtering in the Outer Plexiform Layer, a shunting feedback at the level of bipolar cells accounting for rapid contrast gain control, and a spike generation process modeling ganglion cells. We prove the pertinence of our software by reproducing several experimental measurements from single ganglion cells such as cat X and Y cells. This software will be an evolutionary tool for neuroscientists that need realistic large-scale input spike trains in subsequent treatments, and for educational purposes"
14:30
maybe worth trying that if it has motion selectivity ... or check if can replicate relevant aspects of model
14:32
Haroon Anwar doesn’t look like- as i didnt find any keyword ‘direction’
14:33
samn does it emerge from the circuitry?
14:35
that one or different one, let's see if we can find good model that has the features needed and/or whether to replicate
14:38
Haroon Anwar may be--but if we can come up with a simpler circuit to implement direction selectivity of  ganglion cells, would prefer that….seems not difficult
14:38
samn ok - if you have an idea
14:38
Haroon Anwar the difficult part is how such information is carried out along the dorsal stream
14:39
and presented in V1, IT etc
14:39
samn if you have a simple circuit that can accomplish what we need, good
14:39
Haroon Anwar at input level. should be straight forward
14:39
at later stages-not sure
14:40
samn ok, can try first stages first...then wire it to higher after
14:40
Haroon Anwar ok
14:40
thanks
14:40
samn was that figure you shared from review paper enough to produce direction selectivity?
14:41
Haroon Anwar this shows the circuitry involved ----so its part of it…not complete
14:42
Screen Shot 2020-03-24 at 2.12.16 PM.png 
Screen Shot 2020-03-24 at 2.12.16 PM.png
14:42
how we arrange Bipolar inputs is not shown here
14:43
topologically bipolar inputs
14:43
samn some of this may be relevant: some of these papers look relevant too: https://www-sop.inria.fr/members/Pierre.Kornprobst/
14:43
hmm, since you already have the temporally decaying activation ... would it be simpler to take differences between current and previous frame and calculate direction vectors then feed to another population?
14:44
to avoid additional detailed circuitry
14:45
Haroon Anwar minimally we will have to add neurons which are not only showing position but all direction
14:45
right now its only position
14:45
samn right
14:45
Haroon Anwar so need more for direction
14:45
samn just question of whether to have circuit compute directions or to estimate it ourselves from images (optic flow)
14:46
Haroon Anwar yes thats simple way, can do that
14:46
samn ok sg

WikipediaWikipedia
Optical flow
Optical flow or optic flow is the pattern of apparent motion of objects, surfaces, and edges in a visual scene caused by the relative motion between an observer and a scene. Optical flow can also be defined as the distribution of apparent velocities of movement of brightness pattern in an image. The concept of optical flow was introduced by the American psychologist James J. Gibson in the 1940s to describe the visual stimulus provided to animals moving through the world. Gibson stressed the importance of optic flow for affordance perception, the ability to discern possibilities for action within the environment.  Followers of Gibson and his ecological approach to psychology have further demon… Show more(531 kB)
https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Opticfloweg.png/1200px-Opticfloweg.png
14:46
probably some of those image processing functions you're using can calculate that for you
14:46
Haroon Anwar right
14:47
OK - so will include the direction precomputed
:+1:
1
14:47
samn sg
14:50
if anyone else saw relevant approaches, let us know

* 20mar25
** zlib error

cd ~/SM*
py3env
myrun 16

ImportError: /lib/x86_64-linux-gnu/libz.so.1: version `ZLIB_1.2.9' not found (required by
/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/site-packages/matplotlib/../../.././libpng16.so.16)

https://stackoverflow.com/questions/48306849/lib-x86-64-linux-gnu-libz-so-1-version-zlib-1-2-9-not-found

fix?

download:
https://sourceforge.net/projects/libpng/files/zlib/1.2.9/zlib-1.2.9.tar.gz/download

then:
cd ~/Downloads
tar -xvf ~/Downloads/zlib-1.2.9.tar.gz
cd zlib-1.2.9
sudo -s
./configure; make; make install
cd /lib/x86_64-linux-gnu
ln -s -f /usr/local/lib/libz.so.1.2.9/lib libz.so.1
cd ~/Downloads
rm -rf zlib-1.2.9

cd ~/SM*
myrun 16

ok, runs now without an error ...

** check dynamics
** how to implement direction selectivity

use optical flow on successive images to produce movement vectors at each coordinate.

then, need at least 4X number of pixels to represent the movement info from frame to frame?
and it has to be topographically arranged

...where does each pixel of movement selective neurons project?

* 20mar31
** back to testing

myrun 16

* 20apr1
** fixing up plotSpatioTemporalActivity.py

myrun 16

python -i plotSpatioTemporalActivity.py

seems to work now ... there weren't any loops, functions, dictionaries, etc.
really used in the file ...

* 20apr7
** sal code for animation

def animateRateVsWeight(dataFolder, batchLabel, params):
    import imageio
    from pathlib import Path
    Lvals = params[0]['values']
    Ivals = params[1]['values']
    for ipop, pop in enumerate(Lvals):
        print('Generating traces gif for pop %s ...' % (pop))
        #v22_batch1_18_98_traces.png
        images = ['%s/%s/%s_%d_%d_traces.png' % (dataFolder, batchLabel, batchLabel, ipop, iweight) for iweight in range(len(Ivals))]
        #images = list(image_path.glob())
        image_list = []
        for file_name in images:
            image_list.append(imageio.imread(file_name))
        pass
        imageio.mimwrite('%s/%s/%s_%s_traces.gif' % (dataFolder, batchLabel, batchLabel, pop), image_list)

should adapt for plotSpatioTemporalActivity.py to allow saving output
and/or for video ...

** test update

a lot more cells now (1e3 more motor cells, and 800 direction selective cells), so runs slower,
+ image processing slows it down some more ... not clear by how much

python -i plotSpatioTemporalActivity.py

fig, axs, plt = plotActivityMaps(pauset=0,gifpath='20apr7_activity.gif')

* 20apr8
** save spatiotemporal activity as movie instead (using ffmpeg)

could use imageio ffmpeg interface
https://imageio.readthedocs.io/en/stable/format_ffmpeg.html#parameters-for-saving

or ffmpeg-python https://github.com/kkroening/ffmpeg-python
though that is more comprehensive, so may not need full package installed ...

https://imageio.readthedocs.io/en/stable/examples.html#writing-videos-with-ffmpeg-and-vaapi

https://github.com/imageio/imageio-ffmpeg

pip install imageio-ffmpeg

should have used conda to install
with
conda install imageio-ffmpeg -c conda-forge
but without the ffmpeg binary

python -i plotSpatioTemporalActivity.py

lfnimage = ['/tmp/'+str(x)+'.png' for x in range(1,50,1)]
limage = [imageio.imread(fn) for fn in lfnimage]


from imageio_ffmpeg import write_frames

w = imageio.get_writer('my_video.mp4', format='FFMPEG', mode='I', fps=1,
                       codec='h264_vaapi',
                       output_params=['format=gray'],
                       pixelformat='gray')

for img in limage: w.append_data(img)                       

w.close()

gen = write_frames('test.mp4', (limage[0].shape[0],limage[0].shape[1],limage[0].shape[2]), pix_fmt_in="gray")
gen.send(None)  # seed the generator
for img in limage: gen.send(img)
gen.close()  # don't forget this

hmm, getting errors ... ffmpeg-python seems easier to use?

pip install ffmpeg-python

import ffmpeg
(
    ffmpeg
    .input('/tmp/*.png', pattern_type='glob', framerate=10)
    .output('movie.mp4')
    .run()
)

that works ... fast to run and makes small files

ok, put that into plotSpatioTemporalActivity.py ...

and added animation saving functions to anim.py

** testing network

number of IM was too low, after the increase in EMR, EML populations
so increased IM to 690, to be about 20% of IM (690) + EMR (1350) + EML (1350)

now, when run network, get too high firing rates for EMR, EML

savefig('gif/20apr8_rast_a0.png')

is same obtained with fewer IM cells?

reset IM to 50 ... 

myrun 12

hmm, now EMR,EML firing rates look better, but not clear why. no depolarization
blockade seen in EMR,EML

savefig('gif/20apr8_rast_a1.png')

check connectivity in sim.py ... something off?

might be due to using fixed convergence instead of probability ... for larger pop sizes
seems better to use probability ... had used convergence before to ensure minimum number
of inputs (more relevant with smaller populations)

try with probability of 0.25 and larger IM population of 690 ...

myrun 12

ok, rates of EMR, EML went down, and IM rates are OK
but now activity looks highly synchronized to 100 ms interval when visual inputs come in:
 gif/20apr8_rast_a2.png
 gif/20apr8_EMR_a2.png
 gif/20apr8_IM_a2.png

so, should avoid it ... probably can reduce weights between EMR->IM, EML->IM, IM->IM, IM->EMR, IM->EML

can try cutting probabilities between those populations in half (from 0.25 to 0.125)

myrun 12

savefig('gif/20apr8_rast_a3.png') 
looks ~same

try cutting down probabilities further ... 0.0625

myrun 12

little better ...

gif/20apr8_rast_a4.png
gif/20apr8_EMR_a4.png
gif/20apr8_IM_a4.png

should run longer to see if remains stable ... 
some of the other E vs I populations have wrong rates, e.g. EV4 faster than IV4, EV1 faster than IV1
EMT only a little slower than IMT
and no inhibitory populations in the direction selective cells...

run for 5 s to see if patterns similar, then may consider adjusting weights/probabilities further ...

myrun 12

ok, looks like decent rates ... less synchrony ... should be OK for now ... can adjust further as needed ... 
gif/20apr8_rast_a5.png
gif/20apr8_rast_a5b.png <- some alternation between synch and asynch state
gif/20apr8_IM_a5.png
gif/20apr8_EMR_a5.png
gif/20apr8_EML_a5.png

python -i actmap.py

made this movie: data/20april08_A0__movie.mp4

** try longer sim ("name":"20april08_B0_")

to test and watch output ...

"rewardcodes": {"scorePoint": 1, "losePoint": -0.01, "followBall": 0.01, "avoidBall": -0.001, "hitBall": 0.25},

and duration of 100 s ...

myrun 12

started ~17:32 ...

finished @ ~22:15 ...

rates ok:
 gif/20apr8_rast_b0.png
 gif/20apr8_rast_b0b.png

cells look ok?
 gif/20apr8_IM_b0.png
 gif/20apr8_EML_b0.png
 gif/20apr8_EV1DSE_b0.png
 gif/20apr8_EV1DS_b0.png
 gif/20apr8_EV1_b0.png
 yeah, most cells look ok. some populations fire much less than others.
 direction cells - many directions not firing too mcuh (E, W), could be due to the
 ball mostly moving at a diagonal; but N,S higher since paddles move up,down
 
and now to create the movie ...

python -i actmap.py

* 20apr9 - trying to speed up animation production
** continue

hmm, took > 12 hours so far to spit out the pngs up to 66 s, and hasn't even started on movie creation yet ...

should stop it and figure out how to speed up that process ...

can make movie from the frames that were produced so far

python
import anim
anim.savemp4('/tmp/*.png', 'data/20april08_B0_actmap.mp4', 10)

very slow encoding of mp4 ...

there's support in matplotlib for making animations and exporting to mp4 via ffmpeg but that's
slow too ...

imagemagick gif writing faster?

sudo apt-get install imagemagick

already have imagemagick ...

hmm, even the imagemagick gif writer is slow . . .

* 20apr13 - animation fixing
** HA fixing collision detection code since not working in all cases
algorithm relies on position, direction, score
** movie fix

would concat of smaller mp4 files together run faster than producing one giant mp4?

https://stackoverflow.com/questions/7333232/how-to-concatenate-two-mp4-files-using-ffmpeg

could try ffmpeg concat demuxer : 

"Use this method when you want to avoid a re-encode and your format does not support file level
concatenation (most files used by general users do not support file level concatenation).

$ cat mylist.txt
file '/path/to/file1'
file '/path/to/file2'
file '/path/to/file3'

$ ffmpeg -f concat -safe 0 -i mylist.txt -c copy output.mp4"

hmm, problem seems to be that matplotlib takes longer and longer to save output files
in beginning, saves 15 files per minute, then gradually decreases to 5 per minute ...

and that's particularly true when setting figsize to high resolution values ...

might be due to matplotlib slowing down with all the redrawing ... not even having to do
with file saving ...

yes, not ffmpeg issue - ffmpeg runs very quickly once all frames are available ... so that
isolates slowness to matplotlib

this related issue mentions slowing down:
https://github.com/matplotlib/matplotlib/issues/16182

https://stackoverflow.com/questions/40747181/slow-ploting-using-animation-function-in-matplotlib-python
also relevant ...

fig, axs, plt = animActivityMaps(mp4path='test.mp4', framerate=10)

* 20apr14
** HA made nice movie showing activity/dynamics/actions from random game (testPong.py)
will use it to generate similar with additional inclusion of network dynamics

** other movie fixes needed for simdat.py

first rerun sim for 10 s ... since now have a new column in ActionsRewards.txt

myrun 12

  Cells: 5349
  Connections: 1103176 (206.24 per cell)
  Synaptic contacts: 1105826 (206.74 per cell)
  Spikes: 78992 (1.48 Hz)
  Simulated time: 10.0 s; 12 workers
  Run time: 1974.00 s
Saving output as data/20april14_A0_simConfig.pkl ... 
Finished saving!
  Done; saving time = 82.23 s.
SAVING RASTER DATA
plot raster:
Plotting raster...
QApplication: invalid style override passed, ignoring it.
Saving figure data as 20april14_A0_raster.pkl ... 
Plotting recorded cell traces ... cell
Plotting raster...
Saving figure data as data/20april14_A0_RasterData.pkl ... 
  Done; plotting time = 30.80 s

Total time = 2191.62 s

End time:  2020-04-14 12:31:15.408575

output looks ok ... cells and rates in raster

20apr14_rast_a0.png
20apr14_rast_a0b.png
20apr14_EV1DN_a0.png
20apr14_EV1DS_a0.png
20apr14_EV1DSW_a0.png
20apr14_IMT_a0.png
20apr14_IV4_a0.png

let's see actmap.py ... then simdat.py

python -i actmap.py

produces
data/20april14_A0_actmap.mp4
fairly quickly...

and simdat.py ...

python -i simdat.py -1

that calls
plotSynWeightsPerTimeStep(pdf,pauset=1,mp4path='data/'+dconf['sim']['name']+'weightmap.mp4', framerate=10) #plot images

python -i simdat.py -1

** discussion on smooth direction selective RFs

13:17
samn btw, should E neurons always fire (but at a slower rate) when NE neurons fire?
13:17
since they're not orthogonal directions
13:17
Haroon Anwar no
13:17
samn why
13:18
Haroon Anwar E is between 337.5 degrees and 22.5 degrees
13:18
and NE is between 22.5 and 67.5 degrees
13:19
360 is divided into 8 angular regions
13:19
and each population is assigned that
13:19
samn understand but that means sharp cutoffs
13:19
Haroon Anwar right
13:19
samn could also have smooth fall-off and smoother receptive fields
13:19
Haroon Anwar possible
13:20
might be a good idea…
13:20
samn can put that on list for later
13:20
seems more realistic (?)
13:21
Haroon Anwar sure…more realistic
13:21
samn do all neurons of a population have exact same receptive field?
13:21
Haroon Anwar will also reduce number of neurons
13:21
because we could have directions coded using 4 pops instead of 8
13:22
NE will evoke e.g. 5 Hz in N and 5 Hz in E
13:22
if its exactly 45 degrees
13:22
samn you could have it with 1 pop probably too if you had receptive fields with some width tuning
13:22
width to the receptive field around a mean angle
13:22
Haroon Anwar that would be unrealistic
13:23
samn why?
13:23
Haroon Anwar we have neurons with very fine tuned directions
13:23
1 pop would not be able to encode all directions
13:23
samn it would be 1 pop in the model
13:23
where each neuron selects a mean angle randomly
13:23
then overall you'd have representations in all directions
13:24
Haroon Anwar ok --- yes possible that way---
13:24
implementation might be a bit tricky----but yes possible
13:25
samn tricky for how they project to other areas?
13:25
Haroon Anwar or assigning firing rates to each of the neurons in that pop
13:25
and generating connection lists
13:25
but yeah thats more realistic
13:26
samn if each one had a location in space and there were enough of the full directions in any locatin, seems ok
13:26
anyway, can put that on list of things to adjust. reducing # of neurons could help as you said
13:27
Haroon Anwar yes definitely to do list--- i need to think.. may be its not as difficult as i think right now…. but i will think about it
13:27
samn ok sg
13:28
Haroon Anwar will look at it after performance analysis---
13:28
samn sg

* 20apr15
** continue fixup of animSynWeights in simdat.py

this example animation https://matplotlib.org/gallery/animation/basic_example.html
shows how to set line data dynamically ...

and simpler way to save to mp4

animSynWeights(pdf,'data/'+dconf['sim']['name']+'weightmap.mp4', framerate=10) #plot/save images as movie

ok, works faster now ...

but some of the text is not visible ... adjust size of fig

python -i simdat.py -1
animSynWeights(pdf,'data/'+dconf['sim']['name']+'weightmap.mp4', framerate=10, figsize=(8,6)) #plot/save images as movie

animSynWeights(pdf,'data/'+dconf['sim']['name']+'weightmap.mp4', framerate=10, figsize=(7,5)) #plot/save images as movie

also turn off interactive mode during animation, goes faster...

animSynWeights(pdf,'data/'+dconf['sim']['name']+'weightmap.mp4', framerate=10, figsize=(7,4)) #plot/save images as movie

** discuss opt (image processing for direction selective neurons vs population reduction)
** looking through code for what to optimize/improve

moved some connection functions from sim.py to connUtils.py

cleaned up some of the code that calculates firing rates based on image contents
to use dictionaries and loops instead of previous code duplication ...

that cleanup will help with modifications in future ...

tested network with short run after first adjustments

myrun 12

20april15_A0_rast.png
20april15_A0_EMR.png
20april15_A0_IM.png
20april15_A0_EV4.png
20april15_A0_EV1DS.png

looks ok ...

check videos ...

python -i simdat.py -1

data/20april15_A0_weightmap.mp4

python -i actmap.py

data/20april15_A0_actmap.mp4

looks ok ... should try more thorough tests to make sure nothing broken ...

* 20apr16
** cleaning up code in aigame.py

moved motion computations to separate function in aigame.py
should move pong-specific code to separate place too

myrun 12

python -i simdat.py -1

data/20april16_A0_weightmap.mp4

python -i actmap.py

data/20april16_A0_actmap.mp4

* 20apr17
** continue adjustments/cleanup

myrun 12

hmm, getting depolarization blockade and black input images
values were between 0-1 after rgb2gray, so need to multiply by 255

try again ...

after Haroon's last fix (input firing rates re-adjusted), no dep blockade with the newer version of the code/image processing...

run a bit longer

myrun 12

10 s sim

Total time = 1888.37 s

20april17_A0_rast.png

rates look ok, as do neuron membrane potentials ...

python -i actmap.py

data/20april17_A0_actmap.mp4

python -i simdat.py -1

data/20april17_A0_weightmap.mp4

looks interesting but does not seem to improve over 10 s ... can run longer ...

try longer ...

100 s ...

myrun 12

Total time = 16952.75 s

End time:  2020-04-18 04:30:30.562465

* 20apr18
** check output from last run

20april17_A0B_EV1DN.png
20april17_A0B_EV1DW.png
20april17_A0B_EV1DS.png
20april17_A0B_EV1D4.png
20april17_A0B_IV1.png
20april17_A0B_IMT.png
20april17_A0B_EMT.png
20april17_A0B_IM.png
20april17_A0B_rast.png
20april17_A0B_rastB.png

rates and activity looks ok

some populations almost silent EV1DE (east direction sensitive; maybe get rid of them or adjust/reduce numbers?)

python -i simdat.py -1

data/20april17_A0_weightmap.mp4

python -i actmap.py
data/20april17_A0_actmap.mp4

does not improve in terms of following ball after 100 s ... can run longer ...

can continue for 100 s from there ... see if it improves at all ...

"simtype": {"ResumeSim":1,"ResumeSimFromFile":"20april17_A0_simConfig.pkl"},

"sim": {"duration": 100000, "dt": 0.2, "verbose": 0, "recordStep":0.2,"recordWeightStepSize":1,"RLFakeUpRule": 0,"RLFakeDownRule": 0,"RLFakeStayRule": 0,"name":"20april18_B0_","doquit":0,"doplot":1},

myrun 12

hmm, restore sim not working ... can run for 200 s ... see if improves ... fix resume later ...

    "simtype": {"ResumeSim":0,"ResumeSimFromFile":"20april17_A0_simConfig.pkl"},        
    "sim": {"duration": 200000, "dt": 0.2, "verbose": 0, "recordStep":0.2,"recordWeightStepSize":1,"RLFakeUpRule": 0,"RLFakeDownRule": 0,"RLFakeStayRule": 0,"name":"20april18_A0_","doquit":0,"doplot":1},

myrun 12    
* 20apr22 - RFs for direction selective neurons
** add gaussian profile to direction selective neurons

most of that can go into aigame.py where the rates for those neurons are set

may want to try other optical flow algorithm first ... might be faster to
use a standard implementation

https://scikit-image.org/docs/dev/auto_examples/registration/plot_opticalflow.html#sphx-glr-auto-examples-registration-plot-opticalflow-py

"By definition, the optical flow is the vector field (u, v) verifying image1(x+u, y+v) =
image0(x, y), where (image0, image1) is a couple of consecutive 2D frames from a sequence. This
vector field can then be used for registration by image warping."

try images saved from game ...

python

import numpy as np

Input_Images = np.loadtxt('data/20april21_A0_InputImages.txt')
New_InputImages = []
NB_Images = int(Input_Images.shape[0]/Input_Images.shape[1])
for x in range(NB_Images):
    fp = x*Input_Images.shape[1]
    cImage = Input_Images[fp:fp+20,:] # 20 is sqrt of 400 (20x20 pixels)
    New_InputImages.append(cImage)
New_InputImages = np.array(New_InputImages)

New_InputImages.shape # (10, 20, 20)

from pylab import *

ion()
imshow(New_InputImages[3,:,:],cmap='gray'); savefig('gif/20apr22_a0.png')
imshow(New_InputImages[4,:,:],cmap='gray'); savefig('gif/20apr22_a1.png')

from skimage.color import rgb2gray
from skimage.data import stereo_motorcycle
from skimage.registration import optical_flow_tvl1
# --- Convert the images to gray level: color is not supported.
image0 = New_InputImages[3,:,:]
image1 = New_InputImages[4,:,:]
flow = optical_flow_tvl1(image1, image0)

imshow(flow[0,:,:],cmap='gray'); savefig('gif/20apr22_a2.png')
imshow(flow[1,:,:],cmap='gray'); savefig('gif/20apr22_a3.png')

amin(flow[0,:,:]) # -29.32014
amax(flow[0,:,:]) # 16.496756
amin(flow[1,:,:]) # -19.863085
amax(flow[1,:,:]) # 32.638676

those colors don't have directions ... 

in the example here:
 https://scikit-image.org/docs/dev/auto_examples/registration/plot_opticalflow.html#sphx-glr-auto-examples-registration-plot-opticalflow-py

the two arrays returned by optical flow are the row and column displacements?

e.g.:
# --- Compute the optical flow
v, u = optical_flow_tvl1(image0, image1)
# --- Use the estimated optical flow for registration
nr, nc = image0.shape
row_coords, col_coords = np.meshgrid(np.arange(nr), np.arange(nc), indexing='ij')
image1_warp = warp(image1, np.array([row_coords + v, col_coords + u]), mode='nearest')

other simple code for motion detection/tracking:
 https://www.pyimagesearch.com/2015/05/25/basic-motion-detection-and-tracking-with-python-and-opencv/
more general ... uses opencv2

implemented exp decay in each direction as
           fctr = np.exp(-1.0*((theta-dAngPk[pop])**2)/AngSigma**2)
          print('updateDirSensitiveRates',pop,x,y,fctr,dAngPk[pop],motiondir[y][x])
          if fctr > 0.:
            self.dFiringRates[pop][y,x] = AngVal * fctr

with AngSigma as 45 ... (can tweak) and AngVal as 30
            
... ran a small test ... (still have to fix E direction!!)

gif/20apr22_rast_a4.png
gif/20apr22_EV1DS_a4.png

not sure what data/20april22_A0_randGameBehavior.mp4 is supposed to show but looks incomplete ... only runs
up to 50 ms ... yeah, used old files from hours ago ... should cleanup the pngs

python -i actmap.py

data/20april22_A0_actmap.mp4

looks OK but E needs to be fixed

python -i simdat.py -1

data/20april22_A0_weightmap.mp4

* 20apr23 - RFs for direction selective neurons
** RFs for direction selective neurons

right now the RFs are setup to have peaks every 45 degrees with 45 degree sigma for exp fall-off
in magnitude of firing rate ...

could randomize directions between 0-360 degrees and potentially reduce number of direction selective neurons?
8 directions for RF is also somewhat limiting. movement can occur in other directions ...

or increase spread of RFs ...

also can change size of direction selective neuron populations ...

original values:
"net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":100,"EV1DNE":100,"EV1DN":100,"EV1DNW":100,"EV1DW":100,"EV1DSW":100,"EV1DS":100,"EV1DSE":100,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EML":1350,"EMR":1350,"IM":690,"AngRFSigma":45,"DirMinRate":0.0001,"DirMaxRate":30.0}

change to:
"net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":49,"EV1DNE":49,"EV1DN":49,"EV1DNW":49,"EV1DW":49,"EV1DSW":49,"EV1DS":49,"EV1DSE":49,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EML":1350,"EMR":1350,"IM":690,"AngRFSigma":90,"DirMinRate":0.0001,"DirMaxRate":30.0}

to cut the number of dir sensitive neurons in ~1/2 and have wider RFs...

sim name ... 20april23_A0

myrun 12

Done; run time = 432.66 s; real-time ratio: 0.00.

python -i actmap.py

data/20april23_A0_actmap.mp4

python -i simdat.py -1

data/20april23_A0_weightmap.mp4

right now there are 1350 EMR and 1350 EML neurons

reduced direction selection neurons from 10x10 to 7x7
and there are 8 pops, so 51*8=408 fewer neurons
then HA mentioned number of EMR is equal to number of all other E neurons projecting to them
so can reduce those as well ...

original EMR was 400 (EV1) + 100*8 (dir sensitive) + 100 (EV4) + 25 (EMT) = 1325
but there were 1350 ... 25 extra?

was supposed to be 1325

so new number for current architecture should be

400 + 49*8 + 100 + 25  = 917

try that one ... noticeable faster?

"net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":49,"EV1DNE":49,"EV1DN":49,"EV1DNW":49,"EV1DW":49,"EV1DSW":49,"EV1DS":49,"EV1DSE":49,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EML":917,"EMR":917,"IM":690,"AngRFSigma":90,"DirMinRate":0.0001,"DirMaxRate":30.0}

20april23_A1_

myrun 12

Done; run time = 291.53 s; real-time ratio: 0.00.

yeah, noticeably faster ...

savefig('gif/20apr23_rast_a1.png')

rates and cell activity looks ok

python -i actmap.py

data/20april23_A1_actmap.mp4

python -i simdat.py -1

data/20april23_A1_weightmap.mp4

** adjust one-to-one to random connectivity

will have to reduce convergence most likely ...

20april23_B0_

myrun 12

something making this run very slowly now ... not clear why ...

also, did not adjust number of IM neurons ... should be lower

x / (917*2+x) = 0.2
0.2*(917*2+x) = x
366.8 + .2x = x
.8x = 366.8
x = 366.8/.8 = 458.5

459/(917*2+459) # 0.20017444395987788

so should have 459 IM neurons ...

but doubt that's reason for slowdown ...

there were some bugs in connectivity from visual to motor areas and from premotor to motor areas
EV1DW connected to EML and EMR two times both for AMPA and NMDA

used loops to reduce those errors ... 

* 20apr24
** debug connectivity/speed issues

myrun 12

  Done; run time = 257.86 s; real-time ratio: 0.00.
  Done; gather time = 455.45 s.

that's for 1 s of sim time ... seems a bit faster to run sim ... why is gather so slow?

getting hyperactivation/synchrony ... probably too much EE connectivity  

python -i actmap.py

data/20april24_A0_actmap.mp4

python -i simdat.py -1

got an error about wrong size in image ... 

** discuss net/motion selectivity with HA

also i think after neuron reduction in direction selective cells, motioncomputation is not capturing whole image
samn ok, i'll restore their number
but may keep EML, EMR numbers lower
Haroon Anwar yes, probably that way we can narrow down the issue…. can lower direction selective neuron nb later
samn sg
one other question i had was ...
Haroon Anwar sure
samn now we use 2 frames to compute direction
and we did that to have 1 action for each frame
could we use 5 frames for motion calculation but still have 1 action for 5 frames?
Haroon Anwar so in sim.json, we specify 1 frame….but in aigame.py, it uses last_obs to compute motion direction.
i dont think so
we could do so but back in time
so for time t, we could use t-4,t-3,t-2,t-1 and t
and use 1 action
samn so we could do 5 frames for motion, 1 action for 5 frames?
Haroon Anwar for 1 action for 1 frame
1 action for 5 frames will compromise the performance severly
samn ok, so we can keep as is.
think any problems with how you modified it to? if we have 100 neurons for each direction population
Haroon Anwar how i modified it to? — which part?
samn 1 action per 1 frame
and 2 frames for motion
Haroon Anwar no it should not effect
samn so it should be good
ok, and to follow up, 20 ms is time for 1 frame. if it's longer, will that help?
Haroon Anwar problem is with computing motion not activating neurons
samn so there is a problem of computing motion from 2 frames. and possibly optical flow algorithm will help
Haroon Anwar 20 ms for 1 frame should nicely scale, as we were using 100 ms for 5 frames. so it
means that firing rate has to be 50 Hz to have one spike per action
samn ok sg


** restore # dir selective neurons but reduce # motor neurons & debug/test

x / (400*2+x) = 0.2
0.2*(400*2+x) = x
160 + 0.2x = x
0.8x = 160
x=160/.8=200

"EML":400,"EMR":400,"IM":200

    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":100,"EV1DNE":100,"EV1DN":100,"EV1DNW":100,"EV1DW":100,"EV1DSW":100,"EV1DS":100,"EV1DSE":100,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EML":400,"EMR":400,"IM":200,"AngRFSigma":90,"DirMinRate":0.0001,"DirMaxRate":30.0}

20april24_B0_

myrun 12

Done; run time = 159.11 s; real-time ratio: 0.01.

most cells at decent rates, runs quicker than before ... but EMR,EML,IM cells fire too fast and with depolarization blockade 
20apr24_rast_a1.png
20apr24_IM_a1.png
20apr24_EML_a1.png

to remove that problem could reduce probability of inputs to EML,EMR neurons ...

python -i actmap.py

data/20april24_B0_actmap.mp4

python -i simdat.py -1

simdat.py:97: UserWarning: Attempting to set identical bottom == top == 0 results in singular transformations; automatically expanding.
  f_ax4.set_ylim((0,np.max([cumHits[-1],cumMissed[-1]])))
Traceback (most recent call last):
  File "simdat.py", line 415, in <module>
    animSynWeights(pdf,'data/'+dconf['sim']['name']+'weightmap.mp4', framerate=10) #plot/save images as movie
  File "simdat.py", line 127, in animSynWeights
    wtsL, wtsR = getwts(0, src)
  File "simdat.py", line 111, in getwts
    wtsL = np.reshape(wtsl,(int(np.sqrt(len(wtsl))),int(np.sqrt(len(wtsl))))) 
  File "<__array_function__ internals>", line 6, in reshape
  File "/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py", line 301, in reshape
    return _wrapfunc(a, 'reshape', newshape, order=order)
  File "/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py", line 61, in _wrapfunc
    return bound(*args, **kwds)
ValueError: cannot reshape array of size 15964 into shape (126,126)

hmm, keep getting those errors in animSynWeights in getwts

must happen since have probabilistic connectivity, no longer exact number of inputs specified ... ?

will fix ... also reduce weight to EML, EMR ... try that out ...

myrun 12

Run time: 156.21 s
Done; saving time = 121.36 s.

raster looks ok ...

20apr22_rast_b0.png
most cells look ok, though EML,EMR rates still a little high ...
20apr22_EMR_b0.png
20apr22_IM_b0.png
20apr22_EML_b0.png

python -i actmap.py

data/20april24_B0_actmap.mp4

directions look decent but mabe the RF angle sigma is too high ...

python -i simdat.py -1

simdat.py:97: UserWarning: Attempting to set identical bottom == top == 0 results in singular transformations; automatically expanding.
  f_ax4.set_ylim((0,np.max([cumHits[-1],cumMissed[-1]])))
Traceback (most recent call last):
  File "simdat.py", line 415, in <module>
    animSynWeights(pdf,'data/'+dconf['sim']['name']+'weightmap.mp4', framerate=10) #plot/save images as movie
  File "simdat.py", line 127, in animSynWeights
    wtsL, wtsR = getwts(0, src)
  File "simdat.py", line 111, in getwts
    wtsL = np.reshape(wtsl,(int(np.sqrt(len(wtsl))),int(np.sqrt(len(wtsl))))) 
  File "<__array_function__ internals>", line 6, in reshape
  File "/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py", line 301, in reshape
    return _wrapfunc(a, 'reshape', newshape, order=order)
  File "/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/site-packages/numpy/core/fromnumeric.py", line 61, in _wrapfunc
    return bound(*args, **kwds)
ValueError: cannot reshape array of size 15964 into shape (126,126)

have to fix simdat.py ! ! !

* 20apr27 - fixup simdat.py animation (AMPA & NMDA separate); continue tuning network
** fixup simdat.py

ok, adjusted - separating out AMPA, NMDA weights

  animSynWeights(pdf[pdf.syntype=='AMPA'],'data/'+dconf['sim']['name']+'_AMPA_weightmap.mp4', framerate=10) #plot/save images as movie
  animSynWeights(pdf[pdf.syntype=='NMDA'],'data/'+dconf['sim']['name']+'_NMDA_weightmap.mp4', framerate=10) #plot/save images as movie  

can combine AMPA and NMDA later if needed ...

though no reason to assume the two sets of weights should change at same time-scale

** continue adjusting network - reduce hyperexcit

well, EML, EMR rates were a bit high ... can adjust that ...

try cutting down E -> EML, EMR weights by 1/2

for strty,synmech,weight,plastty in zip(['','n'],['AMPA', 'NMDA'],[0.005*cfg.EEGain, 0.0005*cfg.EEGain],[STDPparamsRL1,STDPparamsRL2]):

myrun 12

Done; run time = 160.28 s; real-time ratio: 0.01.
Done; gather time = 280.91 s.
Total time = 604.62 s

rates a little better ...
20apr27_rast_a0.png

would rather have higher density and lower starting weights, so have possibility for right structure to develop

for now will continue from here ... will try longer sim ... 

python -i actmap.py

saved animation to data/20april27_A0_actmap.mp4

python -i simdat.py -1

saved animation to data/20april27_A0__AMPA_weightmap.mp4
saved animation to data/20april27_A0__NMDA_weightmap.mp4

weights to EMR increased more than EML ... and this is without fake rule

anyway, try longer sim now ...

myrun 12

* 20apr28 - adjusting network
** optical flow in python

https://nanonets.com/blog/optical-flow/
https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_video/py_lucas_kanade/py_lucas_kanade.html

** sim crashes with memory problem

occurs even for 2.5 s sim during gatherdata

what if only recorded weights every 5 steps? with "recordWeightStepSize":5

myrun 12

  Done; run time = 191.75 s; real-time ratio: 0.01.
Gathering data...
  Done; gather time = 108.16 s.
    Cells: 2959
  Connections: 299852 (101.34 per cell)
  Synaptic contacts: 405671 (137.10 per cell)
  Spikes: 30546 (4.13 Hz)
  Simulated time: 2.5 s; 12 workers
  Run time: 191.75 s
Saving output as data/20april28_A0_simConfig.pkl ...

Total time = 383.88 s

ok, good, did not crash ...

20apr28_rast_a0.png

rates and membrane potential traces look ok but EMR,EML,IM rates somewhat high ... (~5-6 Hz for
EMR,EML and ~18 Hz for IM); could reduce weights to EMR,EML further ...

python -i actmap.py

data/20april28_A0_actmap.mp4

python -i simdat.py -1

data/20april28_A0__AMPA_weightmap.mp4
data/20april28_A0__NMDA_weightmap.mp4

try again with:
 larger recordStep and comment out the connection rules for weights that are 0 (feedback connections)
 do not need to plot raster twice and to save raster data in separate file
 do not need to plot voltage traces from every direction cells, one type should be enough to see if looks ok
 also reduce weight to EMR,EML
 
does this simConfig.recordTraces = {'V_soma':{'sec':'soma','loc':0.5,'var':'v'}}  # Dict with traces to record
cause recording of all cells' membrane potential? probably do not want that ...

based on this:
"recordCells - List of cells from which to record traces. Can include cell gids (e.g. 5 or [2,
3]), population labels (e.g. 'S' to record from one cell of the ‘S’ population), or 'all', to
record from all cells. NOTE: All cells selected in the include argument of
simConfig.analysis['plotTraces'] will be automatically included in recordCells. (default: [])

recordTraces - Dict of traces to record (default: {} ; example: {‘V_soma’:{‘sec’:’soma’,’loc’:0.5,’var’:’v’}})"

... it does NOT record ALL cells; just the ones in include:
simConfig.analysis['plotTraces'] = {'include': [(pop, 0) for pop in ['ER','IR','EV1','EV1DE','IV1','EV4','IV4','EMT','IMT','EML','EMR','IM']]}

myrun 12

  Done; gather time = 108.10 s.

hmm, did not save much time or space ... must be saving a lot of other stuff in the 680 MB 20april28_A0_simConfig.pkl
also rate of EMR,EML did not decrease ...

https://www.neuron.yale.edu/phpBB/viewtopic.php?f=45&t=3770&p=16227&hilit=memory#p16122

so try with those options, see if saves time/space ...

myrun 12

Gathering data...
  Gathering only sim data...
  Done; gather time = 70.73 s.

  saved some time ...

  but got error:
  File "sim.py", line 983, in <module>
    sim.saveData() # save data to disk
  File "/u/samn/netpyne/netpyne/sim/save.py", line 127, in saveData
    pickle.dump(dataSave, fileObj)
    TypeError: HocObject: Only Vector instance can be pickled
    
  and then simConfig.pkl output was empty ...

 so will run as it was before ... but still need to adjust the weights

ok, first try with higher ->EMR, ->EML weights
for strty,synmech,weight,plastty in zip(['','n'],['AMPA', 'NMDA'],[0.00375*cfg.EEGain, 0.000375*cfg.EEGain],[STDPparamsRL1,STDPparamsRL2]):
to make sure those synapses have an impact ...

when the weights were 0.005*cfg.EEGain and 0.0005*cfg.EEGain had similar rates ... which means other inputs driving most
of the activity ... 

also see recurrent connectivity ... should adjust for EMR->EMR and EML->EML to allow some plasticity ...

python -i simdat.py

simConfig, pdf, actreward, dstartidx, dendidx = loadsimdat()
simConfig.keys() # dict_keys(['netpyne_version', 'netpyne_changeset', 'net', 'simConfig', 'simData'])
simConfig['simData'].keys() # dict_keys(['spkt', 'spkid', 'V_soma', 't', 'synweights', 'avgRate'])
len(simConfig['simData']['spkt']) # 29862
len(simConfig['simData']['spkid']) # 29862

python -i actmap.py

also see if these options make output smaller:
cfg.saveCellSecs = False     # removes all data on cell sections prior to gathering from nodes
cfg.saveCellConns = False    # removes all data on cell connections prior to gathering from nodes

myrun 12

Gathering data...
Done; gather time = 72.30 s.

ok, that reduced main output file size to ~210 MB vs ~690 MB (for 2.5 s sim)
and a shorter gather time (without a crash)

python -i actmap.py

data/20april28_A0_actmap.mp4

python -i simdat.py -1

...

can put that into option in sim.json ... in case want connectivity info at some point

** test the targetted RL rule in fake up

added option to sim.json to specify whether to use targetted rule (only rewards actions to
motor neurons responsible for the action)

first without targetted RL:
10 s sim with name 20april28_T0_
myrun 12

20apr28_rast_T0.png
20apr28_rast_T0b.png

EMR,EML get too fast  ...
IM hits depolarization blockade: 20apr28_IM_T0.png
so does EMR, EML: 20apr28_EMR_T0.png, 20apr28_EML_T0.png

python -i actmap.py

data/20april28_T0_actmap.mp4

doesn't seem like direction selective neurons activating properly ... all activity
in each population seems to go together ...

python -i simdat.py -1

data/20april28_T0__AMPA_weightmap.mp4
data/20april28_T0__NMDA_weightmap.mp4 <<-- NMDA weights look much different compared to AMPA, perhaps NMDA weights
are not helping, as the populations are not differentiated. strange pattern for NMDA, spikes and decays...similar times with AMPA
what is the cause for those spikes? high rate of rewards??

UP is 4, DOWN is 3; EMR is for UP, EML is for DOWN; so in those movies, overall
the weights to EMR are larger

and next with targetted RL:
10 s sim with name 20april28_T1_
myrun 12

Done; run time = 2946.54 s; real-time ratio: 0.00.
Gathering data...
  Done; gather time = 1267.64 s.
Analyzing...
  Cells: 2959
  Connections: 0 (0.00 per cell)
  Spikes: 598894 (20.24 Hz)
  Simulated time: 10.0 s; 12 workers
  Run time: 2946.54 s
Saving output as data/20april28_T1_simConfig.pkl ... 
Finished saving!
  Done; saving time = 436.50 s.
SAVING RASTER DATA
plot raster:
Plotting recorded cell traces ... cell
QApplication: invalid style override passed, ignoring it.
Plotting raster...
  Done; plotting time = 828.98 s

Total time = 5536.42 s
End time:  2020-04-28 17:36:51.533489

takes a surprisingly long time to save and plot the data ... 

well, there's depolarization blockade:

20apr28_IM_T1.png
20apr28_EMR_T1.png
20apr28_EML_T1.png
20apr28_rast_T1.png <<-- very high rates for EML
IM,EMR are in depolarization blockade. weights to EMR probably increased too much.
better if there was some homeostasis built in

python -i actmap.py

data/20april28_T1_actmap.mp4   <<-- paddle goes up fairly quickly but then goes way down near end of sim and stays
there, probably due to depolarization blockade of EMR cells; EML might be firing quickly since does not receive and
inhibition from IM since IM in depolarization blockade. but then why does the racket stay near top of court for most
of the simulation, until the very end. is it drawn incorrectly??

python -i simdat.py -1

data/20april28_T1__AMPA_weightmap.mp4
data/20april28_T1__NMDA_weightmap.mp4

weights diverge towards EMR population quickly, weights to EML drop quickly, and then they stay that way
same pattern with AMPA and NMDA weights ...


confused by the variable names (ts_end is end time? ts_beg is beginning time? or opposite?)
            ts_end = t-tstepPerAction*(dconf['actionsPerPlay']-ts)
            ts_beg = t-tstepPerAction*(dconf['actionsPerPlay']-ts-1)
            F_Rs.append(getFiringRatesWithInterval([ts_end,ts_beg], sim.net.pops['EMR'].cellGids))

            and
def getFiringRatesWithInterval (trange = None, neuronal_pop = None):
has
if trange[0] <= spkts[i] <= trange[1] and spkids[i] in neuronal_pop:


tstepPerAction = 20
actionsPerPlay = 1
ts_beg = t - 20*(1-0-1) = t - 0
ts_end = t - 20*(1-0) = t - 20

ok, so ts_end is smaller, so it's correct, but the names are confusing ...

anyway, getting back to why actmap.py appears incorrect ... need to check that ...

the depolarization blockade issues suggest need for homeostasis built-in to the synapse ... should also try adding that ...

* 20apr29 - debug actmap.py animations
** check actmap.py

make sure has input images / activity displayed at right times

python -i actmap.py

fig = animInput(New_InputImages, 'test.mp4')

hmm, maybe y-axis for input images should be reversed ...

fig, axs, plt = animActivityMaps('test2.mp4', framerate=10)

limg = New_InputImages = loadInputImages('data/'+dconf['sim']['name']+'InputImages.txt')

limg.shape # (500, 20, 20)
imshow(limg[0,:,:],origin='upper')
imshow(limg[7,:,:],origin='upper')

row 0 of input images is top

was using wrong timestep in actmap.py ... made a variable for it tstepPerAction, also used in sim.json
and sim.py

* 20apr30 - opt flow/quiver
** optical flow

this is what haroon tried last time:
(/u/samn/SMARTAgent/hanotes.org:1432)

see how to use it to produce direction vectors at each pixel ...

python

from pylab import *
import numpy as np
import gym
import cv2 # opencv
from skimage.color import rgb2gray
from skimage.registration import optical_flow_tvl1

env = gym.make('Pong-v0')
env.reset()
observation, reward, done, info = env.step(3)

for _ in range(30): #running 30 times, so that ball appears in the court.
  observation, reward, done, info = env.step(3)
  observation, reward, done, info = env.step(4)
  observation, reward, done, info = env.step(4)
  observation, reward, done, info = env.step(4)
  observation, reward, done, info = env.step(4)
  
o1, reward, done, info = env.step(4)
o2, reward, done, info = env.step(4)
o3, reward, done, info = env.step(4)
o4, reward, done, info = env.step(4)
o5, reward, done, info = env.step(4)

imshow(o1); savefig('gif/20apr30_a0.png')
imshow(o2); savefig('gif/20apr30_a1.png')
imshow(o3); savefig('gif/20apr30_a2.png')
imshow(o4); savefig('gif/20apr30_a3.png')
imshow(o5); savefig('gif/20apr30_a4.png')

g1 = rgb2gray(o1)
g2 = rgb2gray(o2)
g3 = rgb2gray(o3)

subplot(1,2,1); imshow(g1,cmap='gray'); subplot(1,2,2); imshow(g3,cmap='gray')
savefig('gif/20apr30_a5.png')

#
winsz = 10 # win size. flow is computed over the window....larger value is more robust to the noise.
imgscale = 1.0 # image pyramid or simple image scale
nlayer = 1 # nb of pyramidal layer. if used 1 means flow is calculated only from previous image.
niter = 3 # num iterations
polydeg = 5 # polynominal degree expansion. (recommended 5-7)
smooth = 1.2 # standard deviation used to smooth used derivatives. (recommended 1.1-1.5)
flow = cv2.calcOpticalFlowFarneback(g1,g3, None, imgscale, nlayer, winsz, niter, polydeg, smooth, 0)
flow = cv2.calcOpticalFlowFarneback(g1,g3, None, 0.5, 3, 15, 3, 5, 1.2, 0)
flow = cv2.calcOpticalFlowFarneback(g1,g3, None, 1.0, 3, 15, 3, 5, 1.2, 0)
mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])
goodInds = np.where(mag<1e-10,0,1)

#
clf()
subplot(2,2,1); imshow(g1,cmap='gray'); title('Frame1'); subplot(2,2,2); imshow(g3,cmap='gray'); title('Frame2');
subplot(2,2,3); imshow(np.multiply(mag,goodInds),cmap='gray'); title('Mag'); colorbar()
subplot(2,2,4); imshow(np.degrees(np.multiply(ang,goodInds)),cmap='gray'); title('Dir'); colorbar()

savefig('gif/20apr30_a6.png')

try quiver for directions:
https://matplotlib.org/3.1.0/api/_as_gen/matplotlib.pyplot.quiver.html
https://matplotlib.org/3.1.0/gallery/images_contours_and_fields/quiver_simple_demo.html#sphx-glr-gallery-images-contours-and-fields-quiver-simple-demo-py

figure(); quiver(flow[:,:,0],flow[:,:,1])

savefig('gif/20apr30_a7.png')

looks upside down ...

flow.shape # (210, 160, 2)

g1.shape # (210, 160)
top is row 0

what is value at x=17, y=120
flow[120][17][0],flow[120][17][1] # (1.1408521e-09, -1.1311174e-06)

figure(); plot(flow[120,:,1])
savefig('gif/20apr30_a8.png')
so that's negative, movement towards smaller y-values, which in original frame is up

so draw quiver with negated flow in y direction to make easier to visualize ...

#
clf()
subplot(2,3,1); imshow(g1,cmap='gray'); title('Frame1'); subplot(2,3,2); imshow(g3,cmap='gray'); title('Frame2');
subplot(2,3,4); imshow(np.multiply(mag,goodInds),cmap='gray'); title('Mag'); colorbar()
subplot(2,3,5); imshow(np.degrees(np.multiply(ang,goodInds)),cmap='gray'); title('Dir'); colorbar()

X, Y = np.meshgrid(np.arange(0, 160, 1), np.arange(0, 210, 1))
subplot(2,3,6); quiver(X, Y, flow[:,:,0],-flow[:,:,1], units='width')

savefig('gif/20apr30_a9.png')

looks ok ... zoom-in shows mostly pointing in right direction ... could make movie to show
and then use that for dir selective neurons; doesn't have to be completely accurate ... 

#imshow(np.degrees(np.multiply(ang,goodInds)),cmap='gray'); title('Dir'); colorbar()
#
#X,Y = np.meshgrid(flow.shape[1], -flow.shape[0])

* 20may1 - tested optical flow / integrated with sim/model
** continue optical flow

restart to make sure params correct ...

python

from pylab import *
import numpy as np
import gym
import cv2 # opencv
from skimage.color import rgb2gray
from skimage.registration import optical_flow_tvl1

env = gym.make('Pong-v0')
env.reset()
observation, reward, done, info = env.step(3)

for _ in range(30): #running 30 times, so that ball appears in the court.
  observation, reward, done, info = env.step(3)
  observation, reward, done, info = env.step(4)
  observation, reward, done, info = env.step(4)
  observation, reward, done, info = env.step(4)
  observation, reward, done, info = env.step(4)
  
o1, reward, done, info = env.step(4)
o2, reward, done, info = env.step(4)
o3, reward, done, info = env.step(4)
o4, reward, done, info = env.step(4)
o5, reward, done, info = env.step(4)

g1 = rgb2gray(o1)
g2 = rgb2gray(o2)
g3 = rgb2gray(o3)

help(calcOpticalFlowFarneback)

 calcOpticalFlowFarneback(prev, next, flow, pyr_scale, levels, winsize, iterations, poly_n, poly_sigma, flags) -> flow
    .   @brief Computes a dense optical flow using the Gunnar Farneback's algorithm.
    .   @param prev first 8-bit single-channel input image.
    .   @param next second input image of the same size and the same type as prev.
    .   @param flow computed flow image that has the same size as prev and type CV_32FC2.
    .   @param pyr_scale parameter, specifying the image scale (\<1) to build pyramids for each image;
    .   pyr_scale=0.5 means a classical pyramid, where each next layer is twice smaller than the previous
    .   one.
    .   @param levels number of pyramid layers including the initial image; levels=1 means that no extra
    .   layers are created and only the original images are used.
    .   @param winsize averaging window size; larger values increase the algorithm robustness to image
    .   noise and give more chances for fast motion detection, but yield more blurred motion field.
    .   @param iterations number of iterations the algorithm does at each pyramid level.
    .   @param poly_n size of the pixel neighborhood used to find polynomial expansion in each pixel;
    .   larger values mean that the image will be approximated with smoother surfaces, yielding more
    .   robust algorithm and more blurred motion field, typically poly_n =5 or 7.
    .   @param poly_sigma standard deviation of the Gaussian that is used to smooth derivatives used as a
    .   basis for the polynomial expansion; for poly_n=5, you can set poly_sigma=1.1, for poly_n=7, a
    .   good value would be poly_sigma=1.5.
    .   @param flags operation flags that can be a combination of the following:
    .    -   **OPTFLOW_USE_INITIAL_FLOW** uses the input flow as an initial flow approximation.
    .    -   **OPTFLOW_FARNEBACK_GAUSSIAN** uses the Gaussian \f$\texttt{winsize}\times\texttt{winsize}\f$
    .        filter instead of a box filter of the same size for optical flow estimation; usually, this
    .        option gives z more accurate flow than with a box filter, at the cost of lower speed;
    .        normally, winsize for a Gaussian window should be set to a larger value to achieve the same
    .        level of robustness.

#
winsz = 10 # win size. flow is computed over the window....larger value is more robust to the noise.
pyrscale = 0.5 # image pyramid or simple image scale
nlayer = 3 # nb of pyramidal layer. if used 1 means flow is calculated only from previous image.
niter = 3 # num iterations
polyn = 7 # polynominal degree expansion. (recommended 5-7)
polysigma = 1.5 # standard deviation used to smooth used derivatives. (recommended 1.1-1.5)
flow = cv2.calcOpticalFlowFarneback(g1,g3, None, pyrscale, nlayer, winsz, niter, polyn, polysigma, 0)
mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])
goodInds = np.where(mag<1e-10,0,1)
clf()
subplot(2,3,1); imshow(g1,cmap='gray'); title('Frame1'); subplot(2,3,2); imshow(g3,cmap='gray'); title('Frame2');
subplot(2,3,4); imshow(np.multiply(mag,goodInds),cmap='gray'); title('Mag'); colorbar()
subplot(2,3,5); imshow(np.degrees(np.multiply(ang,goodInds)),cmap='gray'); title('Dir'); colorbar()
X, Y = np.meshgrid(np.arange(0, 160, 1), np.arange(210, 0, -1))
ax=subplot(2,3,6); quiver(X, Y, flow[:,:,0],-flow[:,:,1], units='width', color='r')
ax.set_xlim((0,160)); ax.set_ylim((0,210))
ax.invert_yaxis()

savefig('gif/20may1_a0.png')

looks decent ...

ok...will try that in a movie to make sure looks ok

may not want to use the thresholding?

#
winsz = 10 # win size. flow is computed over the window....larger value is more robust to the noise.
pyrscale = 0.5 # image pyramid or simple image scale
nlayer = 3 # nb of pyramidal layer. if used 1 means flow is calculated only from previous image.
niter = 3 # num iterations
polyn = 7 # polynominal degree expansion. (recommended 5-7)
polysigma = 1.5 # standard deviation used to smooth used derivatives. (recommended 1.1-1.5)
flow = cv2.calcOpticalFlowFarneback(g1,g3, None, pyrscale, nlayer, winsz, niter, polyn, polysigma, 0)
mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])
clf()
subplot(2,3,1); imshow(g1,cmap='gray'); title('Frame1'); subplot(2,3,2); imshow(g3,cmap='gray'); title('Frame2');
subplot(2,3,4); imshow(mag,cmap='gray'); title('Mag'); colorbar()
subplot(2,3,5); imshow(np.degrees(ang),cmap='gray'); title('Dir'); colorbar()
X, Y = np.meshgrid(np.arange(0, 160, 1), np.arange(210, 0, -1))
ax=subplot(2,3,6); qdat=quiver(X, Y, flow[:,:,0],-flow[:,:,1], units='width', color='k')
ax.set_xlim((0,160)); ax.set_ylim((0,210))
ax.invert_yaxis()

savefig('gif/20may1_a1.png')

can use quiver.set_UVC from within an animation set_UVC(U, V, C=None) method of matplotlib.quiver.Quiver instance
to update its data ...

qdat.set_UVC([],[])

or follow example here ...

https://stackoverflow.com/questions/19329039/plotting-animated-quivers-in-python

fig = animInput(New_InputImages, 'test.mp4', showflow=True)

looks pretty good ...

added imgutils.py as wrapper that calculates optical flow for 2 images and for a set of frames
can put other image processing utilities there

should put the direction fields into actmap animation too ...

will make it easier to assess whether the direction selective populations are firing properly ...
after that should plugin the optical flow into aigame.py

hmm, should actually save the direction fields calculated during the simulation
so make sure calculated same way as displayed ...

** integrating optical flow with game,sim

cleaning up some of the code since have to adjust it to use different type of motion calculation ...
having AIGame save its own InputImages (ReducedImages) and Images (FullImages)
to avoid passing that info back and forth between AIGame and sim ...

based on discussion with HA could use 20x20 or even 160x160 input images to calculate motion
directions, then downsample to 10x10 direction field that is projected to the direction
selective neurons ...

* 20may4
** check opt flow integration, make sure working properly

when ran it last time, there was incorrect activity in different populations

actually, had started saving the motion fields computed so need to finish that
for display in the movies ...

run a short 2 s sim for testing ... named 20may4_A0_

myrun 12

  Cells: 2959
  Connections: 0 (0.00 per cell)
  Spikes: 79757 (13.48 Hz)
  Simulated time: 2.0 s; 12 workers
  Run time: 412.59 s
Saving output as data/20may4_A0_simConfig.pkl ... 
Finished saving!
  Done; saving time = 95.63 s.
SAVING RASTER DATA
plot raster:
Plotting recorded cell traces ... cell
QApplication: invalid style override passed, ignoring it.
Plotting raster...
  Done; plotting time = 117.68 s

Total time = 925.17 s

End time:  2020-05-04 12:45:31.363310

lot of cells go into block ...
20may4_a0_rast.png
20may4_a0_IM.png
20may4_a0_EML.png
20may4_a0_EV1DE.png

probably since direction selective cells not setup properly with the new optical flow ...

motion fields saved ... 20may4_A0_MotionFields.pkl

now check the output

python -i actmap.py

len(ldflow) # 99
99*20 # 1980 - that's amount of time covered, since first frame has no optical flow
and used 20 ms interval

first adjust animInput

fig=animInput(InputImages,'testflow.mp4',ldflow=ldflow)

something wrong with the output movie ...

same problem if calc the optflow here?

from imgutils import getoptflowframes
ldflow2 = getoptflowframes(InputImages)
fig=animInput(InputImages,'testflow.mp4',ldflow=ldflow2)

hmm, same error opening in vlc ...

opens fine in parole media player

fig=animInput(InputImages,'testflow.mp4',ldflow=ldflow)

in general it's working but probably need higher spatial resolution ...

fig, axs, plt = animActivityMaps('testact2.mp4', framerate=10)

looks interesting but hard to see what's going on in motion fields there because so small ... should reduce size/width of arrows

hmm, may need bigger figure size ... 

fig, axs, plt = animActivityMaps('testact3.mp4', framerate=10,figsize=(9,5))

well, optical flow generally follows motion with wide spread, but the direction selective populations not following
the motion directions properly ... 

also add motor pops to activity map ...

fig, axs, plt = animActivityMaps('testact4.mp4', framerate=10,figsize=(9,5))

looks interesting ... need IM too ... and the rewards, and the weights, etc.
first fixup direction selectivity ...

does activity look more clear without vmax restriction?
fig, axs, plt = animActivityMaps('testact5.mp4', framerate=10,figsize=(9,5))
looks even worse ... 

how about reducing AngRFSigma from 45 to 22.5 ... ??
since there's 45 degrees between primary directions but only 22.5 half-way in either direction ...

20may4_A1_

AngRFSigma:22.5

myrun 12

  Cells: 2959
  Connections: 0 (0.00 per cell)
  Spikes: 43011 (7.27 Hz)
  Simulated time: 2.0 s; 12 workers
  Run time: 445.23 s
Saving output as data/20may4_A1_simConfig.pkl ... 
Finished saving!
  Done; saving time = 87.67 s.
SAVING RASTER DATA
plot raster:
Plotting recorded cell traces ... cell
QApplication: invalid style override passed, ignoring it.
Plotting raster...
  Done; plotting time = 64.77 s

Total time = 894.50 s

End time:  2020-05-04 22:54:32.382426

20may4_a1_IM.png
20may4_a1_EMR.png
20may4_a1_EV1DE.png
20may4_a1_rast.png

still hyperactive, but not as much as last run ...
E, NE only directions that seem to be activated
and then too strongly activating EML, EMR?

python -i actmap.py

fig, axs, plt = animActivityMaps('data/20may4_A1_actmap.mp4', framerate=10,figsize=(9,5))

data/20may4_A1_actmap.mp4

a little better ... for some reason only E, NE cells getting activated ... and not even at right times ...
so have to debug the projections from optical flow -> direction selective populations


* 20may5
** fixing optical flow input

looks like motiondir units are in radians ...

myrun 12

sim.AIGame.ldflow[0].keys() # dict_keys(['flow', 'mag', 'ang', 'goodInds'])
np.amin(sim.AIGame.ldflow[0]['ang']),np.amax(sim.AIGame.ldflow[0]['ang']) # (5.553319e-13, 6.2265844)

so use this in imgutils.py:
  return {'flow':flow,'mag':mag,'ang':np.rad2deg(ang),'goodInds':goodInds}

ok, now rerun 2 s sim ... 
  
myrun 12

  Cells: 2959
  Connections: 0 (0.00 per cell)
  Spikes: 55939 (9.45 Hz)
  Simulated time: 2.0 s; 12 workers
  Run time: 178.73 s
Saving output as data/20may5_A0_simConfig.pkl ... 
Finished saving!
  Done; saving time = 25.08 s.
SAVING RASTER DATA
plot raster:
Plotting recorded cell traces ... cell
QApplication: invalid style override passed, ignoring it.
Plotting raster...
  Done; plotting time = 23.70 s

Total time = 315.73 s

End time:  2020-05-05 10:03:32.129322


20may5_a0_EV1DE.png
20may5_a0_IM.png
20may5_a0_EMR.png
20may5_a0_rast.png

overall better since there appears to be some direction selectivity, though the rate of direciton selective cells
remains too high ... leading to depolarization blockade of EMR,EML,IM cells ...
can reduce rate of direction selective neurons by reducing DirMaxRate from 30 down to x ...

python -i actmap.py

fig, axs, plt = animActivityMaps('data/20may5_A0_actmap.mp4', framerate=10,figsize=(9,5))

triy lower DirMaxRate ... 1 Hz ...

20may5_A1_

myrun 12

still hard to see what's going on but the rates are better ...

also do not see much activity in ER that corresponds with the input images ... ER is very subdued

fig, axs, plt = animActivityMaps('data/20may5_A1_actmap.mp4', framerate=10,figsize=(9,5))

firing rates for most populations are decent ... but don't see much direction selectivity that would expect/want to see ...
seems somewhat random ... 

20may5_a1_EV1DE.png
20may5_a1_EMR.png
20may5_a1_IM.png
20may5_a1_rast.png

fig=animInput(InputImages,'testflow.mp4',ldflow=ldflow)

should find better params to increase resolution for the optical flow ...

ldflow2 = getoptflowframes(InputImages,winsz=3, pyrscale=0.5, nlayer=3, niter=3, polyn=5, polysigma=1.1)
fig=animInput(InputImages,'testflow.mp4',ldflow=ldflow2)

ok, those param values a bit better in getting higher resolution optical flow, but then somewhat more noisy ...

will try that in sim ...

20may5_A2_

myrun 12

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may5_A2_actmap.mp4', framerate=10,figsize=(9,5))

hmm, most of the activity appears to be due to the recurrent connectivity ... getting rid of that
and the direction selective neurons do not fire any more ... and do not seem to receive any inputs (EPSPs) ...
must be a bug somewhere ...

does it have to do with 20x20 for direction image and 10x10 for each population of E dir selective neurons??

check in actmap.py animInput ...

from skimage.transform import downscale_local_mean, resize

ldflow = loadMotionFields(dconf['sim']['name'])
for dflow in ldflow:
  u = resize(dflow['flow'][:,:,0], (10,10), anti_aliasing=True)
  v = resize(dflow['flow'][:,:,1], (10,10), anti_aliasing=True)
  dflow['flow'] = np.array([u,v]).T

fig=animInput(InputImages,'testflow2.mp4',ldflow=ldflow)

yeah, looks like the resize operation is messing things up ... which means may
need to use more neurons for direction selective ... or distribute their RFs
over all angles and assign each a coordinate in 2D grid ... hmm, already have
that, so maybe need to restore 3200 neurons ... 

* 20may6
** restore each dir selective neuron as 20x20 - motion fields better?

doesnt run too slowly ...

myrun 12

has 5359 neurons ... 

fig, axs, plt = animActivityMaps('gif/20may6_A0_actmap.mp4', framerate=10,figsize=(9,5))

looks better but still very noisy ...

needs more debugging ...

would longer time windows help??

can try 50 ms tstepPerAction instead of 20 ...

200 ms needed for 5 Hz max rate ...

probably easier to see if motion field info sent/detected properly by combining activity of
all the motion selective neurons together to produce estimated direction map

maxdirX,maxdirY = getmaxdir(dact,ddir)

fig=animDetectedMotionMaps('testdetectm.mp4', framerate=10, figsize=(7,3))

estimates based on max firing of direction selective neurons looks way off

for some reason E (EV1DE) neurons are almost always firing ...

something about 0 degrees for E ... when change it to have peak at 2 degrees much less firing ...

* 20may7 - more on optical flow; some fixes
** discuss optical flow with ha

conclusion: will see if can tweak params to get example motion below to produce correct results
with existing params, detected motion didn't look great

** ha example code to test optical flow on single frame motion, fix, start testing network

python
from netpyne import specs, sim
from neuron import h
import numpy as np
import random
from conf import dconf # configuration dictionary
import pandas as pd
import pickle
from collections import OrderedDict
from connUtils import *
from matplotlib import pyplot as plt
import os
import anim
from matplotlib import animation
from aigame import AIGame
sim.AIGame = AIGame()
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[3], epCount = 0)
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[3], epCount = 0)
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[3], epCount = 0)
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[3], epCount = 0)
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[3], epCount = 0)
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[4], epCount = 0)
sim.AIGame.dFiringRates # to see the firing rates of 8 different populations
sim.AIGame.ldflow[-1]['ang'] # to see the angle computed for object motion

from pylab import *
ion()

#
fig = figure(figsize=(8,4))
cbaxes = fig.add_axes([0.92, 0.3, 0.01, 0.5])
subplot(1,3,1); imshow(sim.AIGame.FullImages[-2]); title('Frame1')
subplot(1,3,2); imshow(sim.AIGame.FullImages[-1]); title('Frame2')
subplot(1,3,3); imshow(sim.AIGame.ldflow[-1]['ang'],vmin=0, vmax=359, cmap='Dark2'); title('Angle')
c1 = colorbar(fa,cax = cbaxes)
c1.set_ticks([22,67,112,157,202,247,292,337])
c1.set_ticklabels(['E','NE','N','NW','W','SW','S','SE'])

savefig('gif/20may7_test_ha_0.png')

ha suggests thresholding by magnitude

E directions might dominate if angle 0 is default

opposite sign in y direction?


from imgutils import getoptflow

#
dflow = getoptflow(sim.AIGame.ReducedImages[-2], sim.AIGame.ReducedImages[-1],winsz=3,nlayer=3,niter=3,polyn=5,polysigma=1.1)
thflow = np.zeros(dflow['ang'].shape)
th = mean(dflow['mag']) + std(dflow['mag'])
for y in range(thflow.shape[0]):
  for x in range(thflow.shape[1]):
    if dflow['mag'][y,x] < th:
      thflow[y,x] = -100
    else:
      thflow[y,x] = dflow['ang'][y,x]

fig = figure(figsize=(8,4))

#
clf()
cbaxes = fig.add_axes([0.92, 0.3, 0.01, 0.5])
subplot(1,3,1); imshow(sim.AIGame.ReducedImages[-2]); title('Frame1')
subplot(1,3,2); imshow(sim.AIGame.ReducedImages[-1]); title('Frame2')
subplot(1,3,3); imshow(thflow,vmin=-100, vmax=359, cmap='Dark2'); title('Angle')
c1 = colorbar(fa,cax = cbaxes)
c1.set_ticks([22,67,112,157,202,247,292,337])
c1.set_ticklabels(['NONE','E','NE','N','NW','W','SW','S','SE'])

savefig('gif/20may7_test_2.png')

not terrible ...

python -i actmap.py
fig=animInput(InputImages,'testflow2.mp4',ldflow=None)

looks better than before ...

try in sim after checking for valid angles there ...

myrun 12

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may7_A0_actmap.mp4', framerate=10,figsize=(9,5))

saved animation to gif/20may7_A0_actmap.mp4

looks much better ...

20may7_a0_rast.png
most rates ok but EMR,EML fire too much and are too synchronized
possibly due to high drive from EV1DN, EV1DS which fire a lot more than the other direction selective cells (since
most motion is up and down due to paddles moving in those directions)
20may7_a0_IM.png
20may7_a0_EML.png

next will test with some angular RF spread ... also need to make sure EMR,EML fire less frequently/synchronously ...

set AngRFSigma to 22.5 and run again

name = 20may7_A1_

myrun 12

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may7_A1_actmap.mp4', framerate=10,figsize=(9,5))

saved animation to gif/20may7_A1_actmap.mp4

animation looks ok ... rates all right?

all rates decent but EML,EMR,IM rates too high ...
20may7_a1_rast.png
20may7_a1_EML.png
20may7_a1_EMR.png
20may7_a1_IM.png

so, next try decreasing the E projection weights to the EMR,EML neurons ...

20may7_A2_

set down from 0.00375, 0.000375 to 0.002, 0.0002 in this loop in sim.py to:
    for strty,synmech,weight,plastty in zip(['','n'],['AMPA', 'NMDA'],[0.0001*cfg.EEGain, 0.00001*cfg.EEGain],[STDPparamsRL1,STDPparamsRL2]):

EMR,EML still firing too much , though slightly lower ... 
    
** other discussion with ha points towards potential benefits of explicit object detection/tracking

e.g. threshold image, extract bbox, then use that to see motion

opencv supports this with efficient algorithms, though also have some code for it in OEvent

problem with this approach is some loss of generality
and may not even need image pixels as inputs if use explicit object locations as
neuronal representations

** put some object detection, bbox, image code into imgutils.py

can possibly use them for object detection/tracking, though opencv code probably more efficient

* 20may8 - continue optical flow, testing
** reduce EMR,EML,IM rates

adding these params to control from json file:
"EEMWghtAM":0.0001,"EEMWghtNM":0.0001

will continue reducing until get better rates ...

20may8_A0_

make sure no firing of EMR,EML when those values are at 0...

strange, EMR,EML still firing ... :
 20may8_test_rast_a0.png

dconf['net']['EEMWghtAM'], dconf['net']['EEMWghtNM'] # (0.0, 0.0)

so what's driving them so strongly ...

maybe it's because of the wbase param of RL STDP mechanism?

#For AMPA-faster synapses
STDPparamsRL1 = {'hebbwt': 0.0000, 'antiwt':-0.0000, 'wbase': 0.0005, 'wmax': 1, 'RLon': 1 , 'RLhebbwt': 0.001 , 'RLantiwt': -0.000,
                'tauhebb': 10, 'RLlenhebb': 50 ,'RLlenanti': 50, 'RLwindhebb': 50, 'useRLexp': 1, 'softthresh': 0, 'verbose':0}
#for NMDA (slower) synapses
STDPparamsRL2 = {'hebbwt': 0.0000, 'antiwt':-0.0000, 'wbase': 0.0005, 'wmax': 1, 'RLon': 1 , 'RLhebbwt': 0.001 , 'RLantiwt': -0.000,
                'tauhebb': 10, 'RLlenhebb': 800 ,'RLlenanti': 100, 'RLwindhebb': 50, 'useRLexp': 0, 'softthresh': 0, 'verbose':0}

wbase sets a lower limit for the weights ... try setting wbase to 0 to see if reduces the EMR,EML activity ...

myrun 12                               

20may8_test_rast_a1.png

yeah, that's reason why EMR,EML were firing so fast ... so, will have to set wbase to starting value
for those params, or even lower ...

adding these:
"RL":{"AMPA":{"WBase":0.0,"WMax":1.0,"ON":1,"lenhebb":50,"lenanti":50,"exp":1},"NMDA":{"WBase":0.0,"WMax":1.0,"ON":1,"lenhebb":800,"lenanti":100,"exp":0}}
to sim.json
can add other RL params, as needed

wbase was 0.0005 before and even that had high rates, so set the start weight much lower ...

myrun 12

  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 13277 (2.48 Hz)
  Simulated time: 1.0 s; 12 workers
  Run time: 131.85 s
Saving output as data/20may8_A0_simConfig.pkl ... 
Finished saving!
  Done; saving time = 35.32 s.
SAVING RASTER DATA
plot raster:
Plotting recorded cell traces ... cell
QApplication: invalid style override passed, ignoring it.
Plotting raster...
  Done; plotting time = 7.62 s

Total time = 298.91 s

these params seem ok:

    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EML":400,"EMR":400,"IM":200,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.0001,"EEMWghtNM":0.00001},
    "RL":{"AMPA":
	  {"WBase":0.0001,"WMax":1.0,"ON":1,"lenhebb":50,"lenanti":50,"exp":1},
	  "NMDA":
	  {"WBase":0.00001,"WMax":1.0,"ON":1,"lenhebb":800,"lenanti":100,"exp":1}
    }

there are a few initial M pop spikes but then desynchronizes ... 20may8_test_rast_a2.png
20may8_test_EMR_a3.png
20may8_test_IM_a4.png


should have WMax much lower ... maybe at 0.00075, 0.000075

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may8_actmap_a5.mp4', framerate=10,figsize=(9,5))

looks ok ...

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may8_AMPA_weightmap_a6.mp4', framerate=10) #plot/save images as movie
animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may8_NMDA_weightmap_a7.mp4', framerate=10) #plot/save images as movie

try longer run to see if activity remains reasonable ...

tried run for 10 s ... but crashed in gatherdata ... 

  Done; run time = 1413.07 s; real-time ratio: 0.01.

Gathering data...
[samndp7730:08851] *** Process received signal ***
[samndp7730:08851] Signal: Segmentation fault (11)
[samndp7730:08851] Associated errno: Unknown error 32686 (32686)
[samndp7730:08851] Signal code:  (334043992)
[samndp7730:08851] Failing at address: 0x7fff13e91b54
[samndp7730:08851] [ 0] /lib/x86_64-linux-gnu/libc.so.6(+0x354b0)[0x7fae6d8cd4b0]
[samndp7730:08851] [ 1] /lib/x86_64-linux-gnu/libc.so.6(+0x14e156)[0x7fae6d9e6156]
[samndp7730:08851] [ 2] /usr/lib/libopen-pal.so.13(opal_convertor_unpack+0xa8)[0x7fae6c4596b8]
[samndp7730:08851] [ 3] /usr/lib/openmpi/lib/openmpi/mca_pml_ob1.so(mca_pml_ob1_recv_request_progress_rndv+0x181)[0x7fae5fcdc2b1]
[samndp7730:08851] [ 4] /usr/lib/openmpi/lib/openmpi/mca_pml_ob1.so(mca_pml_ob1_recv_frag_callback_rndv+0x271)[0x7fae5fcd7cd1]
[samndp7730:08851] [ 5] /usr/lib/openmpi/lib/openmpi/mca_btl_vader.so(mca_btl_vader_poll_handle_frag+0x93)[0x7fae60523813]
[samndp7730:08851] [ 6] /usr/lib/openmpi/lib/openmpi/mca_btl_vader.so(+0x3cc3)[0x7fae60523cc3]
[samndp7730:08851] [ 7] /usr/lib/libopen-pal.so.13(opal_progress+0x4a)[0x7fae6c44d1ea]
[samndp7730:08851] [ 8] /usr/lib/libmpi.so.12(ompi_request_default_wait_all+0x315)[0x7fae6d0f4f65]
[samndp7730:08851] [ 9] /usr/lib/openmpi/lib/openmpi/mca_coll_tuned.so(ompi_coll_tuned_sendrecv_nonzero_actual+0x11a)[0x7fae5f24faca]
[samndp7730:08851] [10] /usr/lib/openmpi/lib/openmpi/mca_coll_tuned.so(ompi_coll_tuned_alltoallv_intra_pairwise+0x150)[0x7fae5f256780]
[samndp7730:08851] [11] /usr/lib/libmpi.so.12(PMPI_Alltoallv+0x1fc)[0x7fae6d105c9c]
[samndp7730:08851] [12] /usr/site/../arch/nrn/x86_64/lib/libnrnmpi.so.0(nrnmpi_char_alltoallv+0x25)[0x7fae6f7b7d35]

if network activity looks decent could run longer sims on zn ...

same problem/crash on zn?

yeah, crashes on zn in gatherdata, zn with 12 cores takes ~900s to run instead of 1413 on laptop ...

try with fewer traces recorded from ... and longer recording interval (recordStep=0.6)
only record voltage from 1 cell of these pops: ['ER','IR','EV1','EV1DE','IV1','EML','IM']

this may be where the extra data causing gather crash is coming from:
 sim.simData['synweights'][sim.rank].append([t,conn.plast.params.RLon,conn.preGid,cell.gid,float(conn['hObj'].weight[0]),conn.synMech])

probably do not need the RLon flag ...
could also use preGid, gid, synmech as index so don't have to save them each time ...
or could save to separate files for each rank and then join them together in simdat.py ...

still crashes at GatherData:
  Done; run time = 1321.29 s; real-time ratio: 0.01.

Gathering data...
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
[samndp7730:15458] *** Process received signal ***
[samndp7730:15458] Signal: Aborted (6)
[samndp7730:15458] Signal code:  (-6)
[samndp7730:15458] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x11390)[0x7fe32f7dd390]
[samndp7730:15458] [ 1] /lib/x86_64-linux-gnu/libc.so.6(gsignal+0x38)[0x7fe32f437428]

if shut off the record weights same problem?

myrun 12

Game rewards: [-0.001]
  Done; run time = 1297.58 s; real-time ratio: 0.01.

Gathering data...
  Done; gather time = 1.49 s.

Analyzing...
>>> >>> >>> >>> >>> >>> >>> >>> >>> >>> 

  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 105073 (1.96 Hz)
  Simulated time: 10.0 s; 12 workers
  Run time: 1297.58 s
>>> 
Saving output as data/20may8_A0_simConfig.pkl ... 
Finished saving!
  Done; saving time = 1.09 s.
SAVING RASTER DATA
plot raster:
Plotting recorded cell traces ... cell
QApplication: invalid style override passed, ignoring it.
Plotting raster...
  Done; plotting time = 38.63 s

Total time = 1360.35 s

ok, this time it did not crash in gatherdata ... 

may not want to gather all cell tags each time input rates updated, assuming the tags
do not change during simulation, seems ok... and there's a clear,del in there
which might cause a memory problem later on in gatherdata, which has same deletes??
https://github.com/Neurosim-lab/netpyne/blob/development/netpyne/sim/gather.py
py_alltoall

can also rewrite code to have each node save its own synaptic weight data and then at end
merge the data into a single file ...

* 20may11 - continue fixes - gatherdata issue, workaround
** debugging gatherdata issue, way to avoid it -->> save syn weights on each node, then combine

still crashes without all the extra calls to sim._gatherAllCellTags
main issue is that the plasticity data is getting saved ...

other option sal suggested:
sim.runSimWithIntervalFunc(cfg.saveInterval, sim.saveSimDataInNode)
use that instead of sim.runSim()
if already running a different interval func, would need to call sim.saveSimDataInNode()

got this error:
AttributeError: module 'netpyne.sim' has no attribute 'saveSimDataInNode'

must not have latest version of netpyne ...

netpyne.__version__ # '0.9.5'

looks like that interval saving functionality was added in version 0.9.6:
https://github.com/Neurosim-lab/netpyne/releases

pip install netpyne --upgrade

python
import netpyne
netpyne.__version__ '0.9.6'
quit()

myrun 12

seemed to work but also caused some errors ...

and did not plot properly since sim.net.allCells was not created

can use sim._gatherCells()
to get all the cells gathered ...

ok, saving as a list for now ... each node saves it and then it's merged together
at the end of the sim; takes a lot of space ~2 GB, but works pretty quickly (much
faster than gatherdata)

myrun 12

Analyzing...
  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 104487 (1.95 Hz)
  Simulated time: 10.0 s; 12 workers
  Run time: 989.55 s
fatal: No names found, cannot describe anything.
Saving output as data/20may11_A0_simConfig.pkl ... 
Finished saving!
Done; saving time = 1.34 s.

20may11_a0_rast.png

note that EML fires much less than EMR ... could be due to initial bias
in wiring from probabalistic connectivity ... could fix with convergence if that's the issue

also had targettedRL==1...that could also lead to a bias towards one population dominating..?
will retry with targettedRL off ... 

python -i actmap.py
  
fig, axs, plt = animActivityMaps('gif/20may11_actmap_a0.mp4', framerate=10,figsize=(9,5))

gif/20may11_actmap_a0.mp4

python -i simdat.py

hmm, using matplotlib 2.2.4 (newer ones not supported in netpyne) there's an error about fig.add_gridspec ...
in simdat.py animsynweights ... fixup to use matplotlib.gridspec.GridSpec

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may11_AMPA_weightmap_a0.mp4', framerate=10) #plot/save images as movie
animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may11_NMDA_weightmap_a0.mp4', framerate=10) #plot/save images as movie

compress pickle to reduce file size?

https://lucianopaz.github.io/compress_pickle/html/

pip install lz4
pip install compress_pickle

python
import pickle, compress_pickle
d = pickle.load(open('data/20may11_A0_synWeights.pkl','rb'))
compress_pickle.dump(d, 'tmp.pkl', compression="lzma", set_default_extension=False)

takes too long ...

see if reformatting weights as dict will save space ...

python
import pickle
din = pickle.load(open('data/20may11_A0_synWeights.pkl','rb'))
len(din) # 59676000
# [t,conn.preGid,cell.gid,conn.synMech,float(conn['hObj'].weight[0])]

#
dout = {}
for row in din:
  t,preID,poID,syn,w = row
  if preID not in dout:
    dout[preID] = {}
  if poID not in dout[preID]:
    dout[preID][poID] = {}
  if syn not in dout[preID][poID]:
    dout[preID][poID][syn] = []
  dout[preID][poID][syn].append([t,w])

pickle.dump(dout, open('tmp.pkl','wb'))

saves some space, but not enough:
(-rw-rw-r-- 1 samn samn 1562509212 May 11 23:06 tmp.pkl; new size is ~1.6 GB)
(original size is ~2.2GB  -rw-rw-r-- 1 samn samn 2193401415 May 11 16:26 20may11_A0_synWeights.pkl)

* 20may12 - check balanced inputs to EMR,EML, rename pops, avoid hypersynch, longer sims, targettedRL prob?
** try reducing size of output synaptic weight data

could also run for 100 s and save weights every 1 s instead of every 100 ms ...

python

import pickle
din = pickle.load(open('data/20may11_A0_synWeights.pkl','rb'))
len(din) # 59676000
# [t,conn.preGid,cell.gid,conn.synMech,float(conn['hObj'].weight[0])]

import pandas as pd
pdf = pd.DataFrame(din,columns=['time','preid','postid','syntype','weight'])

first need to run
conda install PyTables

pdf.to_hdf('tmp.hdf',key='synweight')

-rw-rw-r-- 1 samn samn 2507588016 May 12 11:57 tmp.hdf

hmm, that's too big, so not much help ... 

pdf.to_pickle('tmp.pkl',compression='bz2') # takes way too long

#
dout = {}
for row in din:
  t,preID,poID,syn,w = row
  if preID not in dout:
    dout[preID] = {}
  if poID not in dout[preID]:
    dout[preID][poID] = {}
  if syn not in dout[preID][poID]:
    dout[preID][poID][syn] = []
  dout[preID][poID][syn].append([t,w])

pickle.dump(dout, open('tmp.pkl','wb'))

will use the dictionary format since it saves ~30% of the total size ...

** other question: why were EMR weights only increasing? targettedRL seems to bias towards one population

get same when have targettedRL off?

try that with recording weights every 1 s

myrun 12

20may12_rast_a0.png
20may12_IM_a0.png
12may12_EML_a0.png
12may12_IV1_a0.png

paddle seems to get stuck at top of screen ...

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may12_actmap_a0.mp4', framerate=10,figsize=(9,5))

gif/20may12_actmap_a0.mp4

yes, paddle stuck at top and EMR fires more than EML ... then hypersynchrony develops

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may12_AMPA_weightmap_a0.mp4', framerate=10) 
animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may12_NMDA_weightmap_a0.mp4', framerate=10) 

this time weights go up for both populations ...

** make sure balanced inputs to E motor populations

all EMR, EML neurons should have same number of inputs ... use convergence instead of probability
otherwise there will be biases in relative activation of the two populations

IM -> EML, EMR has probability of 0.125

conv = int(0.5 + pij * numfrom)

could make a pmat to use ...

EML -> IM, EMR -> IM
had connection probability of 0.125/2 and 400 EML, EMR neurons ...
conv = int(0.5 + 0.125/2 * dnumc[EML]) = 25

IM -> EML, IM -> EMR
had connection probability of 0.125 and 200 IM neurons
conv = int(0.5 + 0.125 * 200) = 25

ok, put in a helper function in connUtils to get convergence from probability and num presynaptic neurons
and used it to get convergence number in the connection rules ... will see if that produces more similar
firing rates for EMR and EML ...

and try sim with the new ~equivalent convergence-based connectivity ...

20may12_B0_

myrun 12

  Cells: 5359
  Connections: 0 (0.00 per cell) <<-- that's because not saving cellconn, there are synapses in this simulation
  Spikes: 222076 (4.14 Hz)
  Simulated time: 10.0 s; 12 workers
  Run time: 1002.30 s

ok, rates for EMR, EML are more similar now:
 20may12_rast_b0.png
 20may12_EML_b0.png
 20may12_IM_b0.png

the paddle does get stuck at top for part of simulation ... seems less likely
to get stuck at bottom? 
 
the network also transitions to too much synchronous EMR,EML activity quickly ... should reduce that
maybe via different starting and max weights ... 

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may12_actmap_b0.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may12_AMPA_weightmap_b0.mp4', framerate=10, figsize=(14,8)) 
animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may12_NMDA_weightmap_b0.mp4', framerate=10, figsize=(14,8))

** change EMR -> EMUP, EML -> EMDOWN

since confusing to read code ...

ok ... adjusted in sim.py, sim.json, simdat.py, actmap.py

** get rid of hypersynch -->> ends up developing after ~10 s even with lower starting weights some improvement in performance?

can reduce "EEMWghtAM":0.0001,"EEMWghtNM":0.00001 to lower values ...

and also the RL weight increment ... which variable is that ... ?
'RLhebbwt': 0.001 , 'RLantiwt': -0.000, ??

yeah, looks like RLhebbwt ... and it's very large compared to starting weights ... so should
reduce it and add as a param for sim.json ...

note that RLhebbwt may be ok since it's multiplied by the reward/punishment value in mod/stdp.mod ...
so it only moves by a fraction anyway (when using critic values of 0.001, 0.01, etc.)
(/u/samn/SMARTAgent/mod/stdp.mod:156)

ok, try adjustments ...

myrun 12

20may12_EMDOWN_c0.png

looks better overall...but only a matter of time until epileptic/highly synchronized activity returns ...
without homeostatic plasticity that's likely to occur...unless use soft thresholding and have lower wmax values?
could also have easier homeostatic plasticity rule to check rates of all populations and increase random
inhibitory noise when cells begin to fire too fast

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may12_actmap_c0.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may12_AMPA_weightmap_c0.mp4', framerate=10, figsize=(14,8)) 
animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may12_NMDA_weightmap_c0.mp4', framerate=10, figsize=(14,8))

ok, will try a soft threshold and 10 s sim ...

not sure if want NMDA RL plasticity yet ... has very long eligibility trace (~800 ms) ...

dynamics look decent overall, but have to run longer and see if remains stable,
since rates seem to increase somewhat over time ...

20may12_rast_c1.png
20may12_IM_c1.png
20may12_EMDOWN_c1.png
20may12_IV1_C1.png

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may12_actmap_c1.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may12_AMPA_weightmap_c1.mp4', framerate=10, figsize=(14,8));animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may12_NMDA_weightmap_c1.mp4', framerate=10, figsize=(14,8))

ok, try a 100 s sim with same params ...

ran to completion & saved output but then crashed some time after display ... so did
not have chance to save raster ... can redraw from data ... looked like hypersynch
emerged eventually with fairly high rates for EMUP,EMDOWN,IM populations

synweights file is ~1.6 GB
simconfig ~540 MB

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may12_actmap_c2.mp4', framerate=10,figsize=(18,10))

that movie shows it does seem to improve by the end, though paddle gets stuck a lot ... 

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may12_AMPA_weightmap_c2.mp4', framerate=10, figsize=(14,8));animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may12_NMDA_weightmap_c2.mp4', framerate=10, figsize=(14,8))

some slight improvement in performance near the end ... looks like would need a lot longer to get anywhere reasonable, though
the hypersynchrony could cause problems far sooner ...

also worth testing the targetted RL rule keeping everything else the same ...

not sure need the NMDA RL since ball can get across screen in a few 100 ms ... can keep for now ...

can try two 300 s sims on zn and see which does better (with or without targetted RL)


** longer sims
*** 300 s same params as last (20may12_NOTARG_Z0_)

myrun 12

started ~23:29

End time:  2020-05-14 01:14:01.856790

too much time in plotting, which is not needed ... synweights ~4.6 GB
weights of EMDOWN,EMUP get too high by the end, as usual
20may12_NOTARG_Z0_rast.png
20may12_NOTARG_Z0_EMDOWN.png
20may12_NOTARG_Z0_IM.png

python -i actmap.py backupcfg/20may12_NOTARG_Z0_sim.json

fig, axs, plt = animActivityMaps('gif/20may12_NOTARG_Z0_actmap_300s.mp4', framerate=10,figsize=(18,10))

python -i simdat.py backupcfg/20may12_NOTARG_Z0_sim.json

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may12_NOTARG_Z0_AMPA_weightmap_300s.mp4', framerate=10, figsize=(14,8));animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may12_NOTARG_Z0_NMDA_weightmap_300s.mp4', framerate=10, figsize=(14,8))


*** 300 s same params as last but with targetted RL on (20may12_TARG_Z0_)

myrun 12

started ~23:31

  Run time: 82911.72 s
Total time = 86993.01 s

End time:  2020-05-13 23:41:08.873020

that's on zn with 12 cores (but many other jobs were running so took longer)

rates for EMUP,EMDOWN very unbalanced, with EMDOWN very low

20may12_TARG_Z0_rast.png
20may12_TARG_Z0_IM.png
20may12_TAG_Z0_EMDOWN.png

get rid of the 4.6GB data from this sim since did not work properly ... 

* 20may13 - longer sims; hyperexcit; read weights works with AM/NM?
** 300 s sims still running on zn ~12 hours later (~1/2 done)
** discuss object detection / optical flow

had suggestion to use object detection as a mask for optical flow to
constrain spatial resolution for the flow

** still have issue of hyperexcit

reduce the min weights for RL, use targetted RL, and run for 10 s

20may13_A0_rast.png

prevents the hyperexcit; enough M activity generated? will hyperexcit just emerge later?

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may13_A0_actmap.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may13_A0_AMPA_weightmap.mp4', framerate=10, figsize=(14,8));animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may13_A0_NMDA_weightmap.mp4', framerate=10, figsize=(14,8))

not much M activity generated ... could run for 100 s to see if emerges ... or goes overboard

myrun 12

  Done; plotting time = 284.79 s

Total time = 10613.54 s

20may13_A0_rast_1.png
2-may13_A0_IM_1.png

one of the E populations ends up dominating, so that's a problem ... due to targetted rule?
the rates are for EMUP are not terrible though...so params apart from targetted might be ok?

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may13_A0_actmap_100s.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may13_A0_AMPA_weightmap_100s.mp4', framerate=10, figsize=(14,8));animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may13_A0_NMDA_weightmap_100s.mp4', framerate=10, figsize=(14,8))

targetted rule seems not to be working properly ... ?? is it due to slight bias in beginning
that gets amplified by other M population getting suppressed through lower weights, and other
populations getting strengthened ... ? or it could occur if one population gets strengthened
for right reason a couple of times, and that strengthening increases bias towards that
action and avoiding other action, which gets suppressed if no more activation

should redo this sim but without the targetted RL , just to check if one M pop gets suppressed
...

ok, run 20may13_B0_
with targettedRL == 0  , all else same ...

myrun 12

  Spikes: 2149938 (4.01 Hz)
  Simulated time: 100.0 s; 12 workers
  Run time: 12102.82 s
Saving output as data/20may13_B0_simConfig.pkl ... 
Finished saving!
  Done; saving time = 13.08 s.
  Done; plotting time = 1262.04 s
Total time = 13866.31 s

20may13_B0_rast.png
20may13_B0_IM.png
20may13_B0_EMDOWN.png
looks like gets to hypersynch ... but at least both populations of M neurons firing

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may13_B0_actmap_100s.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may13_B0_AMPA_weightmap_100s.mp4', framerate=10, figsize=(14,8));animSynWeights(pdf[pdf.syntype=='NMDA'],'gif/20may13_B0_NMDA_weightmap_100s.mp4', framerate=10, figsize=(14,8))


** does readinweights work properly with AMPA and NMDA weights?

do not see any check for AMPA vs NMDA ...

not clear the NMDA plasticity needed ... could just have long time constant for AMPA eligibility
trace with exp decay ...

* 20may14 - no NMDAR RL plasticity; implement/test simple weight normalization
** get rid of the NMDA RL plasticity for now

ok, check the RLon option in sim.json to determine whether to use plasticity for the specific
synapse

    "RL":{"AMPA":
	  {"wbase":0.00001,"wmax":0.00075,"RLon":1,"RLlenhebb":50,"RLlenanti":50,"useRLexp":1,"RLhebbwt":0.0005,"RLantiwt":-0.0,"hebbwt":0,"antiwt":0,"tauhebb":10,"RLwindhebb":50,"softthresh":1,"verbose":0},
	  "NMDA":
	  {"wbase":0.000001,"wmax":0.000075,"RLon":0,"RLlenhebb":800,"RLlenanti":100,"useRLexp":1,"RLhebbwt":0.0005,"RLantiwt":-0.0,"hebbwt":0,"antiwt":0,"tauhebb":10,"RLwindhebb":50,"softthresh":1,"verbose":0}
	 }

there, it's specified to shut off RL for NMDA ...

may want to adjust the NMDA weights too since they're pretty low and probably just as well to leave
them off ...

try a fast sim to test with the NMDA RL off ...

myrun 12

  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 32264 (2.01 Hz)
  Simulated time: 3.0 s; 12 workers
  Run time: 300.88 s

using 100 ms resolution for the AMPA weights ...

20may14_A0_rast.png

looks ok ... did it run any faster? perhaps ...

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may14_A0_actmap_3s.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may14_A0_AMPA_weightmap_3s.mp4', framerate=10, figsize=(14,8))

looks ok ... those videos show reward after ball hit and point scored but not in the hit ball / miss ball panel ...
is that a bug? probably hit/miss code just needs a minor adjustment

** there was a bug in paddle/ball hit detection, ha fixed
** weight rescaling every so often? seems to work/prevent hyperexcit

could normalize incoming AMPA/NMDA weights of EMUP,EMDOWN populations
to have same average or sum as start with ... 

ok, implemented some of that, testing it now ...

normalizeWeightStepSize in sim.json controls how many action steps to use for normalizing the
weights; uses a mult factor for each population based on EEMWghtAM
so when average weights dip below, they're pushed towards that value, and when they're above, they are reduced
scaling as EEMWghtAM / average_weight

seems to work based on printouts ... and some short sims

tried in 10 s sim ... with weight normalization every 500 ms ...

average weights moved in both directions and were scaled up or down ... 

maybe works ... ?

at least no hyperexcit here:
20may14_T0_rast.png

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may14_T0_actmap_10s.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may14_T0_AMPA_weightmap_10s.mp4', framerate=10, figsize=(14,8))

looks like ~avg value maintained fairly well, and some hotspots with high weight emerge too ... 

next, to test in longer sim ... can use 1 s between normalizations ... 

run for 300 s ... with 12 cores ... on zn (20may14_T0_Z0_)

myrun 12

  Simulated time: 300.0 s; 12 workers
  Run time: 22489.13 s

20may14_T0_Z0_rast.png

rates are ok

python -i actmap.py backupcfg/20may14_T0_Z0_sim.json

fig, axs, plt = animActivityMaps('gif/20may14_T0_Z0_300s.mp4')

python -i simdat.py backupcfg/20may14_T0_Z0_sim.json

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may14_T0_Z0_AMPA_weightmap_300s.mp4')

myrun 12

also run same on laptop for 100 s with 12 cores

Analyzing...
  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 1076136 (2.01 Hz)
  Simulated time: 100.0 s; 12 workers
  Run time: 9454.24 s

20may14_T0_L0_rast.png
20may14_T0_L0_EMDOWN.png
20may14_T0_L0_IM.png
20may14_T0_L0_EMUP.png

activity looks ok - EMUP,EMDOWN,IM rates pretty low
  
python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may14_T0_L0_actmap_100s.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may14_T0_L0_AMPA_weightmap_100s.mp4', framerate=10, figsize=(14,8))

looks ok though seems to need a lot more time to improve, if ever ... may want to adjust normalization
rule to only scale weights down if they pass some threshold, and at a higher threshold than initial average weight

or perhaps maintaining the initial average weight would allow for sparse firing and more efficient coding??

probably need long runs with comparisons to determine ...

could have upper and lower threshold for normalizing weights; when average weight higher than upper threshold
scale down; when average weight below lower threshold scale up. lower threshold could be set to starting
average weight but upper threshold could be set to some positive multiple of starting weight. that way normalization
would push average weight to be within a reasonable range...

ok, try that rule with lower bound of original and upper bound of 5X original ... weights will likely go up
and hover around upper bound ... 

myrun 12

20may14_T0_M0_rast.png

rates look ok so far ... 

python -i actmap.py 

fig, axs, plt = animActivityMaps('gif/20may14_T0_M0_actmap_10s.mp4', framerate=10,figsize=(18,10))

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may14_T0_M0_AMPA_weightmap_10s.mp4', framerate=10, figsize=(14,8))

based on previous sims 2X original weight probably high enough and even that may produce hypersynchrony ...
can try the 2X anyway to check ... see if it does any better than the 1X original weight rule (same min
and max threshold)

will run that on zn for 300 s ... and compare to other sim currently running ...

myrun 12

  Simulated time: 300.0 s; 12 workers
  Run time: 21025.55 s
  Done; plotting time = 1867.69 s  
  Total time = 23540.60 s

20may14_Min1Max2Thresh_Z0_rast.png
rates look ok at end, only slightly higher than other sim
but the scaling factor used was 1.0 for most of simulation (after initial scaling up
of all stdp/rl weights). the 1.0 scaling means that the weights never got up to the
upper limit; so then it's surprising the network did not reach hypersynchrony ...
something seems off ...

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may14_Min1Max2Thresh_Z0_300s.mp4')

python -i simdat.py

animSynWeights(pdf[pdf.syntype=='AMPA'],'gif/20may14_Min1Max2Thresh_Z0_AMPA_weightmap_300s.mp4', framerate=10, figsize=(14,8))

* 20may15 - check weight norm, fix resumesim (multistep)
** check the weight normalization

why does hyperexcit not emerge when weights are below the max, but
continuously increasing?

due to soft thresholding? should the min,max weight thresholds be closer to the wbase, wmax params for the
STPD/RL??

if starting EEMWghtAM is at max for RL weights (0.00075) is there hyperexcit?

myrun 12

20may15_rast_a0.png

yeah, there's hyperexcit, then after weights normalized (lower) at t=500 ms, the hyperexcit
disappears

t= 500.0000000000452 - adjusting weights based on RL critic value: -0.001
sim.rank= 0 davg: {'EMUP': 0.0005615105765452703, 'EMDOWN': 0.0005615055487169171} dfctr: {'EMUP': 0.26713655319350277, 'EMDOWN': 0.2671389451854241}

then later it moves up a bit and is normalized downward some more:
t= 1000.0000000001588 - adjusting weights based on RL critic value: -0.001
sim.rank= 0 davg: {'EMUP': 0.00015004612430169018, 'EMDOWN': 0.0001500624095345771} dfctr:
{'EMUP': 0.9996925991797199, 'EMDOWN': 0.9995841094730473}

what if EEMWghtAM starts at 0.00015 ... ?

myrun 12

savefig('gif/20may15_rast_a0.png') # hmm, overwrote last file

less hypersynch and it decays anyway from the RL ... if RL was off, what would happen?

myrun 12

savefig('gif/20may15_rast_a1.png') # not much hypersynch ...

so 0.00015 would be a decent upper limit ... can it be higher?

try with "EEMWghtAM":0.000375

myrun 12

savefig('gif/20may15_rast_a2.png') # mostly ok but some periods of overly (?) synchronous firing

so, that might be ok as upper bound ... higher upper bound could allow larger set of weights ...
but could run another sim with lower upper bound for comparison ... 

** movies from zn 300 s sims -->> gradual increase in probability of following ball?

20may14_Min1Max2Thresh_Z0_AMPA_weightmap_300s.mp4 <<-- that one looks better
than 20may14_T0_Z0_AMPA_weightmap_300s.mp4

the better sim (20may14_Min1Max2Thresh_Z0_) has higher max weight before normalization, and follow ball probability is
increasing with the weights. longer duration might allow the follow ball probability to surpass the not follow ball probability

the other sim (20may14_T0_Z0_) has lower max weight before normalization, and the probability of follow and not follow seem
to have hit a plateau corresponding with the weights, or at least a lower slope compared to the other simulation

that suggests higher max weight would perform better in the long run... at least encouraging that the follow
ball probability seems to be increasing ... 

** fixup/check resumesim

also check if can run sim saving everything but not drawing the raster ... that takes a long time

first run with raster for comparison ...

savefig('gif/20may15_b0_rast.png')

ok, with doplot==0, doquit==1 it runs ok

and then should have quick func to draw raster ...

python -i simdat.py

simConfig.keys() # dict_keys(['netpyne_version', 'netpyne_changeset', 'net', 'simConfig', 'simData'])
simConfig['simData'].keys() # dict_keys(['spkt', 'spkid', 'V_soma', 't', 'dminID', 'avgRate'])
simConfig['simData']['avgRate'] # 1.9083784288113455

plot(simConfig['simData']['spkt'],simConfig['simData']['spkid'],'ko',markersize=2)

savefig('gif/20may15_rast_b1.png')

looks ok, though no color/type/rate, can add that in or see if netpyne raster func supported here ...

simConfig['simData']['V_soma'].keys() 
dict_keys(['cell_0', 'cell_900', 'cell_4359', 'cell_400', 'cell_4759', 'cell_500', 'cell_4100', 'cell_5159'])

python -i simdat.py

dspkID.keys() # dict_keys(['ER', 'IR', 'EV1', 'EV1DE', 'EV1DNE', 'EV1DN', 'EV1DNW', 'EV1DW', 'EV1DSW', 'EV1DS', 'EV1DSE', 'IV1', 'EV4', 'IV4', 'EMT', 'IMT', 'EMDOWN', 'EMUP', 'IM'])
dspkT.keys() # dict_keys(['ER', 'IR', 'EV1', 'EV1DE', 'EV1DNE', 'EV1DN', 'EV1DNW', 'EV1DW', 'EV1DSW', 'EV1DS', 'EV1DSE', 'IV1', 'EV4', 'IV4', 'EMT', 'IMT', 'EMDOWN', 'EMUP', 'IM'])

drawraster(dspkT,dspkID)

savefig('gif/20may15_rast_b2.png')

looks pretty good...

should run much longer sim with resume ... with sim duration on order of 1000 of s ...

1 reason to use resume is if sim crashes in middle, would not have any intermediate output ...

try a 2 step sim ... make sure everything working 

python multistepSim.py sim.json 12 2 multirun

got error about not being able to restore STDP weights ...

ok, fixed up ...

try 3 steps to make sure working ...

python multistepSim.py sim.json 12 3 multirun

well, no crashes, so that's good ... check rasters

python -i simdat.py backupcfg/20may15_C0__step_0_sim.json
drawraster(dspkT,dspkID)
savefig('gif/20may15_step0_b3.png')
quit()

python -i simdat.py backupcfg/20may15_C0__step_1_sim.json
drawraster(dspkT,dspkID)
savefig('gif/20may15_step1_b3.png')
quit()

python -i simdat.py backupcfg/20may15_C0__step_2_sim.json
drawraster(dspkT,dspkID)
savefig('gif/20may15_step2_b3.png')

there are some diffs in firing patterns and rates ... check the weights too ...

python -i simdat.py backupcfg/20may15_C0__step_0_sim.json
animSynWeights(pdf)
gif/20may15_C0__step_0_weightmap.mp4

python -i simdat.py backupcfg/20may15_C0__step_1_sim.json
animSynWeights(pdf)
gif/20may15_C0__step_1_weightmap.mp4

python -i simdat.py backupcfg/20may15_C0__step_2_sim.json
animSynWeights(pdf)
gif/20may15_C0__step_2_weightmap.mp4

seems like the weights are properly loaded, and sim continues from there ...

one thing that seems to recur is paddle getting stuck at top ... that bias
seems difficult to overcome, hopefully not an intrinsic bias ...e.g. in the
wiring ... 

** setup long multistep sim on zn (20may15_ZN_MultiStep_A_)

python multistepSim.py sim.json 12 10 multirun

sim base name is 20may15_ZN_MultiStep_A_

with "EEMWghtThreshMax":0.000375

started ~17:16 ... 10 steps of 300 s ... total of 3000 s ...

** other multistep sim on zn (20may15_ZN_MultiStep_B_)

with slightly higher max weight ...

with "EEMWghtThreshMax":0.0005

python multistepSim.py sim.json 12 10 multirun

started ~17:27 ...

* 20may18 - looking at output from long multistep runs, M encoding issues?
** start looking at output from latest multistep runs

each sim finished ~4 steps each for total of ~1200 s

first just look at hit/miss ball probabilities ... 

*** simA 20may15_ZN_MultiStep_A_

python
import numpy as np
import pandas as pd
from pylab import *
from simdat import plotRewards,plotFollowBall,plotHitMiss

name = '20may15_ZN_MultiStep_A__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,4,1):
  name = '20may15_ZN_MultiStep_A__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)

np.amax(pda.time) # 1200000.0
  
pda.columns # Index(['time', 'action', 'reward', 'proposed', 'hit'], dtype='object')

#
plotRewards(pda,ax=subplot(3,1,1),msz=3,xl=(0,120e3))
plotFollowBall(pda,ax=subplot(3,1,2),msz=3)
plotHitMiss(pda,ax=subplot(3,1,3),msz=3)

tight_layout()

savefig('gif/20may18_multistep_A_reward_1200s_a0.png')

in middle panel follow vs not follow might be improving, though somewhat slowly...could also just be converging towards 50/50 (random)

*** simB 20may15_ZN_MultiStep_B_

python
import numpy as np
import pandas as pd
from pylab import *
from simdat import plotRewards,plotFollowBall,plotHitMiss

name = '20may15_ZN_MultiStep_B__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,4,1):
  name = '20may15_ZN_MultiStep_B__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)

np.amax(pda.time) # 1200000.0
  
pda.columns # Index(['time', 'action', 'reward', 'proposed', 'hit'], dtype='object')

#
clf()
plotRewards(pda,ax=subplot(3,1,1),msz=3,xl=(0,120e3))
plotFollowBall(pda,ax=subplot(3,1,2),msz=3)
plotHitMiss(pda,ax=subplot(3,1,3),msz=3)

tight_layout()

savefig('gif/20may18_multistep_B_reward_1200s_b0.png')

*** compare the two

python
import numpy as np
import pandas as pd
from pylab import *
from simdat import plotRewards,plotFollowBall,plotHitMiss

lpda = []

name = '20may15_ZN_MultiStep_A__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,4,1):
  name = '20may15_ZN_MultiStep_A__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)

lpda.append(pda)
  
name = '20may15_ZN_MultiStep_B__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,4,1):
  name = '20may15_ZN_MultiStep_B__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)
  
lpda.append(pda)

# sim A on left (lower max weight threshold), sim B on right (higher max weight threshold)
plotFollowBall(lpda[0],ax=subplot(1,2,1),msz=3); plotFollowBall(lpda[1],ax=subplot(1,2,2),msz=3)

savefig('gif/20may18_multistep_A_B_reward_1200s_c0.png')

the one with lower max weights seems to converge faster ... and get toward slightly higher accuracy ... ?

plotHitMiss(lpda[0],ax=subplot(1,2,1),msz=3); plotHitMiss(lpda[1],ax=subplot(1,2,2),msz=3)

savefig('gif/20may18_multistep_A_B_hit_miss_1200s_c1.png')

for hit,miss the one with higher max weights gets slightly higher number of hits

plotRewards(lpda[0],ax=subplot(1,2,1),msz=3); plotRewards(lpda[1],ax=subplot(1,2,2),msz=3)

savefig('gif/20may18_multistep_A_B_rewards_1200s_c2.png')

can't see diffs from reward fig ...

sum(lpda[0].reward) # 290.6
sum(lpda[1].reward) # 289.36
so, almost identical total reward ...

may as well let those sims run some more to see if they improve further ... possible that
learning is taking place, just at a slow rate ...

make movies to see how weights changing ... use last available step

python -i simdat.py backupcfg/20may15_ZN_MultiStep_A__step_4_sim.json
animSynWeights(pdf)

python -i simdat.py backupcfg/20may15_ZN_MultiStep_B__step_4_sim.json
animSynWeights(pdf)



** build a map of which info received by each/all M neurons

otherwise will not know if architecture supports proper decision making

** try higher conn probability for inputs to M populations

that will increase likelihood that M populations have enough info to make decisions

can make a param to control it ... EEMProb, and as scale up prob, scale down the incoming weights ...

EEMProb ... original was 0.1 ... try at double probability ... and 1/2 weight ... 

change "EEMWghtAM":0.000075,"EEMWghtNM":0.0000075
to
"EEMWghtAM":0.0000375,"EEMWghtNM":0.00000375

also change "EEMWghtThreshMin":0.000075,"EEMWghtThreshMax":0.0005
to
"EEMWghtThreshMin":0.0000375,"EEMWghtThreshMax":0.0005

myrun 12

ok...

python -i simdat.py

drawraster(dspkT,dspkID)
savefig('gif/20may18_d0.png')

rates are ok ... 

animSynWeights(pdf,'gif/20may18_d0_weightmap.mp4')

python -i actmap.py

fig, axs, plt = animActivityMaps('gif/20may18_d0_actmap.mp4')

well, activity not epileptic ... could run a long sim to compare to how others performing ...

even 100 s worth trying ...

20may18_L0_

myrun 12

hmm, laptop got closed in middle of run ... 

** info

right now, convergence onto any EM neuron is from 10% of presynaptic neurons
so that's 40 neurons of each direction selective class ... 40 x 8 = 320
40 from EV1, 10 from EV4, 2.5 from EMT, ... most of the inputs are from direction selective
neurons . . . is that reasonable?

when 20%, 80 neurons ...

** do M neurons need topography? recurrent connectivity with RL synapses? 

any E M neuron could receive information from spatially separated locations ...

if no topography, then should have recurrent connectivity in EM neurons with RL synapses ...

topographic arrangement of M neurons might allow better prediction on when to move ... for
example if ball is far away but moving in a certain direction, might want to initiate movement
in advance of the ball getting to the paddle ...

so while there's some spatial information with random connectivity, it's less organized/useful if
receiving random (from spatial perspective) inputs?

if ball in middle of screen moving SE, and paddle is at top right stationary, EM Down should be
activated ... so there should be at least one EM Down neuron that receives strong V1 input at top
right and middle of screen SE neuron ... if there was a topographic arrangement of EM neurons,
would that be possible? not if there are restriction of connectivity across spatially distant
neurons... but having additional recurrent connectivity in EM might still allow that encoding to emerge

tried that out briefly with some recurrent connectivity between EMUP<>EMUP and EMDOWN<>EMDOWN

gif/20may18_M0_weightmap.mp4
gif/20may18_M0_actmap.mp4
savefig('gif/20may18_M0_rast.png')

why do weights start below "EEMWghtAM":0.0000375 and only jump up at weight normalization time?
have noticed that in other simulations ... also, almost no EM activity after first two burst
until that weight norm ... 

will have to put in param to control whether to include recurrent/RL connectivity
between the EM populations ...

* 20may19 - look at multistep output; other new options; setting up on falcor
** check latest from multistep -- sim with higher max weight still improving

python
import numpy as np
import pandas as pd
from pylab import *
from simdat import plotRewards,plotFollowBall,plotHitMiss

lpda = []

name = '20may15_ZN_MultiStep_A__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,5,1):
  name = '20may15_ZN_MultiStep_A__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)

lpda.append(pda)
  
name = '20may15_ZN_MultiStep_B__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,5,1):
  name = '20may15_ZN_MultiStep_B__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)
  
lpda.append(pda)

# sim A on left (lower max weight threshold), sim B on right (higher max weight threshold)
clf(); plotFollowBall(lpda[0],ax=subplot(1,2,1),msz=3); ylim((0.3,.51)); plotFollowBall(lpda[1],ax=subplot(1,2,2),msz=3); ylim((.3,.51))

savefig('gif/20may19_multistep_A_B_reward_1500s_a0.png')

the one with lower max weights seems to converge faster ... and get toward slightly higher accuracy ...
but the one with higher max weights still has a slightly upward slope

clf(); plotHitMiss(lpda[0],ax=subplot(1,2,1),msz=3); ylim((0,100)); plotHitMiss(lpda[1],ax=subplot(1,2,2),msz=3); ylim((0,100));

savefig('gif/20may19_multistep_A_B_hit_miss_1500s_a1.png')

the one with higher max weights is doing a little better in terms of hits vs misses ... 

clf(); plotRewards(lpda[0],ax=subplot(1,2,1),msz=3); plotRewards(lpda[1],ax=subplot(1,2,2),msz=3)

savefig('gif/20may19_multistep_A_B_rewards_1500s_a2.png')

sum(lpda[0].reward) # 358.09000000000003
sum(lpda[1].reward) # 369.83099999999996

higher overall reward for second sim (higher max weights) ...

finished step 6 (total of 2100 s; 35 hours <<-- minutes!) for both sims ... next steps were not completed due to crash
from missing new param in the previously made json files ... take a look at the output ... to
see whether worth continuing either

python
import numpy as np
import pandas as pd
from pylab import *
from simdat import plotRewards,plotFollowBall,plotHitMiss

lpda = []

name = '20may15_ZN_MultiStep_A__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,7,1):
  name = '20may15_ZN_MultiStep_A__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)

lpda.append(pda)
  
name = '20may15_ZN_MultiStep_B__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,7,1):
  name = '20may15_ZN_MultiStep_B__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)
  
lpda.append(pda)

# sim A on left (lower max weight threshold), sim B on right (higher max weight threshold)
clf(); plotFollowBall(lpda[0],ax=subplot(1,2,1),msz=3); ylim((0.3,.51)); plotFollowBall(lpda[1],ax=subplot(1,2,2),msz=3); ylim((.3,.51))

savefig('gif/20may19_multistep_A_B_reward_2100s_a0.png')

clf(); plotHitMiss(lpda[0],ax=subplot(1,2,1),msz=3); ylim((0,120)); plotHitMiss(lpda[1],ax=subplot(1,2,2),msz=3); ylim((0,120));

savefig('gif/20may19_multistep_A_B_hit_miss_2100s_a1.png')

the one with higher max weights is a little worse in terms of hits vs misses ... 

clf(); plotRewards(lpda[0],ax=subplot(1,2,1),msz=3); plotRewards(lpda[1],ax=subplot(1,2,2),msz=3)

savefig('gif/20may19_multistep_A_B_rewards_2100s_a2.png')

sum(lpda[0].reward) # 505.499
sum(lpda[1].reward) # 507.49799999999993

similar overall rewards ... and similar overall performance ...  looks like the learning has mostly stopped improving ...
need to figure out what's preventing improvement

could continue set B ... steps 7,8,9 ... just to check ...

will adjust multirun and make conf.py check for new option (if absent, defaults to opticflow for now since that's
what started this set of sims from)

multirun

** couple new options

"EEMProb":0.2, <<-- sets probability of connections
"EEMRecProb":0.0 <<-- sets recurrent connectivity probability between neurons in EM populations
(same command directions only)

** try new object tracker

with EEMRecProb of 0.1, EEMProb of 0.1

myrun 12

  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 17288 (0.65 Hz)
  Simulated time: 5.0 s; 12 workers
  Run time: 604.94 s

python -i simdat.py

drawraster(dspkT,dspkID)
savefig('gif/20may19_a0.png')

animSynWeights(pdf)

gif/20may19_A0_weightmap.mp4

python -i actmap.py

fig, axs, plt = animActivityMaps()

gif/20may19_A0_actmap.mp4

object-detection-based direction fields look much more refined than before from optical flow

adjust weights ... to inc firing ...

savefig('gif/20may19_a1.png')

** setting up on falcor

first need to install miniconda (to save space)

downloaded and installed for python3.7

Miniconda3-latest-Linux-x86_64.sh

in /home/samn/miniconda3

note that is uses bash and modifies .bashrc
have to modify .tcshrc to use it
or can use bash ...

falcor:~/SMARTAgent> bash
(base) samn@falcor:~/SMARTAgent$ which python
/home/samn/miniconda3/bin/python

(base) samn@falcor:~/SMARTAgent$ python
Python 3.7.6 (default, Jan  8 2020, 19:59:22) 
[GCC 7.3.0] :: Anaconda, Inc. on linux
Type "help", "copyright", "credits" or "license" for more information.
>>>

mkdir ~/neuron
cd ~/neuron/
git clone https://github.com/neuronsimulator/nrn
git clone https://github.com/neuronsimulator/iv

export IVB=~/neuron/iv; cd $IVB   
./build.sh
./configure --prefix=$PWD
make
make install

conda install numpy scipy matplotlib pandas scikit-image
pip install 'gym[atari]'

## pip install imageio-ffmpeg## ??

conda install imageio-ffmpeg -c conda-forge

export ND=~/neuron/nrn; cd $ND
./build.sh
./configure --with-iv=$IVB --prefix=$ND --with-nrnpython=dynamic --with-paranrn --with-mpi --with-pyexe=python3

hmm, no MPI installed on Falcor ...

checking for mpicc... no
checking for hcc... no
checking for mpcc... no
checking for mpcc_r... no
checking for mpxlc... no
checking for cmpicc... no
checking for MPI_Init... no
checking for MPI_Init in -lmpi... no
checking for MPI_Init in -lmpich... no
configure: error: Cannot compile MPI program

downloaded and install open-mpi

https://www.open-mpi.org/faq/?category=building

cd ~/Downloads
gunzip -c openmpi-4.0.3.tar.gz | tar xf -
cd openmpi-4.0.3
./configure --prefix=/home/samn/openmpi
make all install

then make sure that openmpi in the path so NEURON's configure can detect it ...

echo $PATH
/home/samn/miniconda3/bin:/home/samn/miniconda3/condabin:/home/samn/bin:/home/samn/.local/bin:/home/samn/bin:/home/samn/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games

export PATH="/home/samn/openmpi/bin:$PATH"

and put that into .bashrc

which mpicc
/home/samn/openmpi/bin/mpicc

export ND=~/neuron/nrn; cd $ND
./configure --with-iv=$IVB --prefix=$ND --with-nrnpython=dynamic --with-paranrn --with-mpi --with-pyexe=python3
make -j 10  # OPTIONAL  -j 10 will multithread the make and speed up ~10x

/home/samn/neuron/nrn/missing: line 81: flex: command not found
WARNING: 'flex' is missing on your system.
         You should only need it if you modified a '.l' file.
         You may want to install the Fast Lexical Analyzer package:
         <http://flex.sourceforge.net/>

https://github.com/westes/flex/releases


cd ~/Downloads
tar -xvf flex-2.6.4.tar.gz
cd flex-2.6.4
./autogen.sh

Can't exec "autopoint": No such file or directory at /usr/share/autoconf/Autom4te/FileUtils.pm line 345.
autoreconf: failed to run autopoint: No such file or directory
autoreconf: autopoint is needed because this package uses Gettext

./configure --prefix=/home/samn/bin

/bin/bash: ../build-aux/depcomp: No such file or directory
Makefile:804: recipe for target 'libmain.lo' failed
make[2]: *** [libmain.lo] Error 127
make[2]: Leaving directory '/home/samn/Downloads/flex-2.6.4/src'
Makefile:546: recipe for target 'all' failed
make[1]: *** [all] Error 2
make[1]: Leaving directory '/home/samn/Downloads/flex-2.6.4/src'
Makefile:533: recipe for target 'all-recursive' failed
make: *** [all-recursive] Error 1

make

up to here ... 

make install

echo $ND
/home/samn/neuron/nrn

echo $PYTHONPATH

Make sure that PYTHONPATH includes $ND/share/python/lib/python
Add $ND/x86_64/bin to $PATH


* 20may20
** look at output from long run (20may15_ZN_MultiStep_B)

finished step 7 already ... two more steps and then 3000 s finished (backupcfg/20may15_ZN_MultiStep_B__step_6_sim.json)

instead of cumulative follow/miss should probably plot average over an interval ... cumulative value
will change very slowly

python
import numpy as np
import pandas as pd
from pylab import *
from simdat import plotRewards,plotFollowBall,plotHitMiss
  
name = '20may15_ZN_MultiStep_B__step_0_'
pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

for i in range(1,8,1):
  name = '20may15_ZN_MultiStep_B__step_'+str(i)+'_'
  tmp = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += i*300e3
  pda = pda.append(tmp)
  
np.amax(pda.time) # 2400000.0

#
plotFollowBall(pda,ax=subplot(1,3,1),msz=3); ylim((.3,.51))
plotHitMiss(pda,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(pda,ax=subplot(1,3,3),msz=3); 

savefig('gif/20may20_B_step7_a0.png')

sum(pda.reward) # 566.635

actreward = pda

action_times = np.array(actreward.time)
actionvsproposed = np.array(actreward.action-actreward.proposed)

Hit_Missed = np.array(actreward.hit)

followact = np.where(actionvsproposed==0,1,0)
nbin = int(10e3 / (action_times[1]-action_times[0]))
avgfollow = [mean(followact[sidx:sidx+nbin]) for sidx in arange(0,len(followact),nbin)]
plot(20*arange(0,len(followact),nbin), avgfollow)
savefig('gif/20may20_B_step7_a1.png')

so that's probability of following, which does not improve past ~0.5 at peak, and then
decays a bit...

Hit_Missed = np.array(actreward.hit)
allHit = np.where(Hit_Missed==1,1,0) 
nbin = int(10e3 / (action_times[1]-action_times[0]))
avghit = [mean(allHit[sidx:sidx+nbin]) for sidx in arange(0,len(allHit),nbin)]
plot(20*arange(0,len(allHit),nbin), avghit)
savefig('gif/20may20_B_step7_a2.png')

and probability of hits is not increasing ...

in actmap movies looked like bias towards particular direction was interfering with ability of model to perform well ...

could have some smoothing function on firing rates and minimum difference in rates to generate a move

will stop multistep B from continuing for now ...

** normalize inputs to populations to avoid any bias (on average) ?

not all actions should be equal probability ... but avoiding bias on average might help ...
worth a try ...

myrun 12

python -i simdat.py

drawraster(dspkT,dspkID)
savefig('gif/20may20_b0.png')

animSynWeights(pdf)

gif/20may20_A0_weightmap.mp4

python -i actmap.py

fig, axs, plt = animActivityMaps()

gif/20may20_A0_actmap.mp4

hmm, still getting stuck at top for a while

** continue setup on falcor

ryan installed flex on falcor ... 

export ND=~/neuron/nrn; cd $ND
./configure --with-iv=$IVB --prefix=$ND --with-nrnpython=dynamic --with-paranrn --with-mpi --with-pyexe=python3
make -j 10  # OPTIONAL  -j 10 will multithread the make and speed up ~10x

yacc missing ... asked & ryan installed yac

make -j 10  # OPTIONAL  -j 10 will multithread the make and speed up ~10x

make install

echo $ND
/home/samn/neuron/nrn

echo $PYTHONPATH

Make sure that PYTHONPATH includes $ND/share/lib/python
export PYTHONPATH="$ND/share/lib/python"
Add $ND/x86_64/bin to $PATH
and put into .bashrc

hmm, neuron starts with python but from neuron import h does not work ...

(base) samn@falcor:~$ python
Python 3.7.6 (default, Jan  8 2020, 19:59:22) 
[GCC 7.3.0] :: Anaconda, Inc. on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> from neuron import h
Traceback (most recent call last):
  File "/home/samn/neuron/nrn/share/lib/python/neuron/__init__.py", line 124, in <module>
    import hoc
ModuleNotFoundError: No module named 'hoc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/samn/neuron/nrn/share/lib/python/neuron/__init__.py", line 128, in <module>
    import neuron.hoc
ModuleNotFoundError: No module named 'neuron.hoc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/samn/neuron/nrn/share/lib/python/neuron/__init__.py", line 130, in <module>
    exec("import neuron.hoc%d%d as hoc" % (sys.version_info[0], sys.version_info[1]))
  File "<string>", line 1, in <module>
ModuleNotFoundError: No module named 'neuron.hoc37'

maybe HOC_LIBRARY_PATH not set properly?

export HOC_LIBRARY_PATH="$ND/share/nrn/lib/hoc"

python
from neuron import h

no, same error ...

cd /home/samn/neuron/nrn/src/nrnpython
python setup.py install --home=$ND/share/lib/python

this is a much easier way to install neuron (without compilation): 
pip install neuron-nightly

export PYTHONPATH=''

python
from neuron import h

works now ...

which nrniv
/home/samn/miniconda3/bin/nrniv

pip install netpyne --upgrade

ok ... anything else missing? should consolidate install instructions somewhere ...

** try run on falcor

first compile model ...

nrnivmodl mod

ok, needed aux_fun.inc ... added to repo ...

then error about not finding mpi libraries and should set LD_LIBRARY_PATH

export LD_LIBRARY_PATH="/home/samn/openmpi/lib"

error about missing glibc used by scipy fft ...

conda install -c asmeurer glibc

./myrun 16

--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 0 with PID 0 on node falcor exited on signal 11 (Segmentation fault).
--------------------------------------------------------------------------

conda remove asmeurer glibc

hmm, now conda messed up ...

so did

bash ~/Downloads/Miniconda3-latest-Linux-x86_64.sh -u
to fix ...

/home/samn/Downloads/Miniconda3-latest-Linux-x86_64.sh: line 449: 42131 Segmentation fault      (core dumped) $PREFIX/bin/python -E -s "$PREFIX/pkgs/.cio-config.py" "$THIS_PATH"

hmm, better start over with conda/neuron ... !

look in install.txt for instructions ...

conda install gcc_linux-64 openmpi mpi4py

which mpicc
/home/samn/miniconda3/bin/mpicc

ok, so that's using conda's version of openmpi ... easier than compiling openmpi directly

./myrun 16

Traceback (most recent call last):
  File "sim.py", line 1, in <module>
    from netpyne import specs, sim
  File "/home/samn/miniconda3/lib/python3.7/site-packages/netpyne/sim/__init__.py", line 72, in <module>
    from .. import analysis
  File "/home/samn/miniconda3/lib/python3.7/site-packages/netpyne/analysis/__init__.py", line 39, in <module>
    from .spikes import calculateRate, plotRates, plotSyncs, plotRaster, plotSpikeHist, plotSpikeStats, plotRatePSD, plotRateSpectrogram, popAvgRates
  File "/home/samn/miniconda3/lib/python3.7/site-packages/netpyne/analysis/spikes.py", line 34, in <module>
    import scipy
  File "/home/samn/miniconda3/lib/python3.7/site-packages/scipy/__init__.py", line 156, in <module>
    from . import fft
  File "/home/samn/miniconda3/lib/python3.7/site-packages/scipy/fft/__init__.py", line 81, in <module>
    from ._helper import next_fast_len
  File "/home/samn/miniconda3/lib/python3.7/site-packages/scipy/fft/_helper.py", line 4, in <module>
    from . import _pocketfft
  File "/home/samn/miniconda3/lib/python3.7/site-packages/scipy/fft/_pocketfft/__init__.py", line 3, in <module>
    from .basic import *
  File "/home/samn/miniconda3/lib/python3.7/site-packages/scipy/fft/_pocketfft/basic.py", line 8, in <module>
    from . import pypocketfft as pfft
ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.22' not found (required by /home/samn/miniconda3/lib/python3.7/site-packages/scipy/fft/_pocketfft/pypocketfft.cpython-37m-x86_64-linux-gnu.so)

conda install cython

./myrun 16

same error ...

 strings /usr/lib/x86_64-linux-gnu/libstdc++.so.6 | grep GLIBC
GLIBCXX_3.4
GLIBCXX_3.4.1
GLIBCXX_3.4.2
GLIBCXX_3.4.3
GLIBCXX_3.4.4
GLIBCXX_3.4.5
GLIBCXX_3.4.6
GLIBCXX_3.4.7
GLIBCXX_3.4.8
GLIBCXX_3.4.9
GLIBCXX_3.4.10
GLIBCXX_3.4.11
GLIBCXX_3.4.12
GLIBCXX_3.4.13
GLIBCXX_3.4.14
GLIBCXX_3.4.15
GLIBCXX_3.4.16
GLIBCXX_3.4.17
GLIBCXX_3.4.18
GLIBCXX_3.4.19
GLIBCXX_3.4.20
GLIBCXX_3.4.21
GLIBC_2.3
GLIBC_2.2.5
GLIBC_2.14
GLIBC_2.4
GLIBC_2.18
GLIBC_2.3.4
GLIBC_2.17
GLIBC_2.3.2
GLIBCXX_DEBUG_MESSAGE_LENGTH

export LD_LIBRARY_PATH="/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH"

./myrun 16

hmm, did not help ...

ryan upgraded libc package ... try again

now get this when compile with nrnivmodl:

/bin/sh: 1: x86_64-conda_cos6-linux-gnu-c++: not found
/home/samn/miniconda3/lib/python3.7/site-packages/neuron/.data/bin/nrnmech_makefile:76: recipe for target 'x86_64/libnrnmech.0.0.so' failed
make: *** [x86_64/libnrnmech.0.0.so] Error 127

may need to redo conda install again ...

condensed commands:
bash ~/Downloads/Miniconda3-latest-Linux-x86_64.sh
conda install numpy scipy matplotlib pandas scikit-image

pip install 'gym[atari]'
conda install imageio-ffmpeg -c conda-forge

conda install gcc_linux-64 openmpi mpi4py cython
conda install openmpi mpi4py cython
## conda install gcc_linux-64

pip install neuron-nightly
pip install netpyne --upgrade
cd ~/SMARTAgent
nrnivmodl mod

* 20may21
** continue with falcor install/setup -->> works now

ryan suggests:
conda install gxx_linux-64
based on https://github.com/RcppCore/Rcpp/issues/770

installed successfully ... now try compile

nrnivmodl mod

Successfully created x86_64/special
great...now let's see if it runs ...

./myrun 16

Try loading libmpi and libmpich
load_mpi: libmpich.so: cannot open shared object file: No such file or directory
Is openmpi, mpich, intel-mpi, sgi-mpt etc. installed? If not in default location, need a LD_LIBRARY_PATH.

hmm, thought openmpi already installed ...

can set LD_LIBRARY_PATH to /home/samn/miniconda3/lib

export LD_LIBRARY_PATH="/home/samn/miniconda3/lib"

** try a sim on falcor

./myrun 16

seems to be working!

it runs but even with doquit==1 does not stop ... will have to debug that
for multistep ...

check output ...

python -i simdat.py

drawraster(dspkT,dspkID)

savefig('gif/20may21_rast_a0.png')
xlim((19e3,20e3))
savefig('gif/20may21_rast_a0b.png')

animSynWeights(pdf)

python -i actmap.py

fig, axs, plt = animActivityMaps()

activity looks typical - this is with the new weight normalization that
equalizes inputs to the two M populations
even with that weight normalization the paddle gets stuck at top
and even with the weights ~equal to both sets of EM neurons ... that suggests a bug...??

try inc EEMProb ... to 0.3

./myrun 16

  Connections: 0 (0.00 per cell)
  Spikes: 37701 (3.52 Hz)
  Simulated time: 2.0 s; 16 workers
  Run time: 182.41 s
fatal: Not a git repository (or any parent up to mount point /home)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
Saving output as data/20may21_B0_simConfig.pkl ... 
Finished saving!
  Done; saving time = 1.52 s.

what's the git error ...

python -i simdat.py

drawraster(dspkT,dspkID)
savefig('gif/20may21_rast_b0.png')
hypersynch from the larger number of inputs ...

animSynWeights(pdf)
gif/20may21_B0_weightmap.mp4

python -i actmap.py
fig, axs, plt = animActivityMaps()

also reduce the weights ...

python -i simdat.py
drawraster(dspkT,dspkID)
savefig('gif/20may21_rast_b1.png')
those rates are fine

could add a margin factor to different between rates for movement directions ... otherwise hold still ...
will try longer sim first (300 s) ... (20may21_B0_)

./myrun 16

python -i simdat.py
drawraster(dspkT,dspkID)
savefig('gif/20may21_rast_b2.png')

animSynWeights(pdf) # gif/20may21_B0_weightmap.mp4

python -i actmap.py
fig, axs, plt = animActivityMaps() # gif/20may21_B0_actmap.mp4

try another sim in parallel (20may21_C0_) with different scoring ...
instead of
    "rewardcodes": {"scorePoint": 1, "losePoint": -0.01, "followBall": 0.01, "avoidBall": -0.001, "hitBall": 0.25},
try:
    "rewardcodes": {"scorePoint": 1, "losePoint": -0.1, "followBall": 0.1, "avoidBall": -0.01, "hitBall": 0.5},

hmm, right now by accident running two of 20may21_B0 ... kill one and start 20may21_C0 

* 20may22
** sims on falcor still running

for some reason they didn't complete yet ... do they get stalled when pause the x2go connection?

can try running on my too ... zn over-booked

also asked ryan (nki) about availability of other machines ...

** try run with recurrent/plasticity in EM (10%) 20may22_D0_ on laptop (crashed in middle)

20may22_D0_

add in the recurrent/plastic connectivity to EM populations (~10%)
see if existing weights ok ...

myrun 12

somewhat slow ... may as well use laptop ... 

myrun 12

python -i simdat.py

drawraster(dspkT,dspkID)
savefig('gif/20may22_rast_d0.png')

animSynWeights(pdf) # 

python -i actmap.py
fig, axs, plt = animActivityMaps() # gif/20may22_D0_actmap.mp4

bug in optical flow at right side of image ... always pointing west around right paddle location ...
at least it's ~constant ... but note to fix it ...

run 100 s ...

myrun 12

pretty slow on laptop as well ... must be due to all the extra connections ...

will add a separate json file for myself to avoid conflicts with what haroon's doing ...

cp sim.json sn.json

git add sn.json snnotes.dol; git commit -m 'separate json file for self'; gpushdev

run on laptop crashed in middle ... 

** try further doubling connectivity onto EM (20may22_E0_)

and also reducing the weight to avoid epi

can try 12 cores on zn ...

"EEMProb":0.6,"EEMRecProb":0.2

myrun 12 sn.json

  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 20147 (1.88 Hz)
  Simulated time: 2.0 s; 12 workers
  Run time: 2183.28 s


"EEMWghtAM":0.0000125,"EEMWghtNM":0.00000125,"EEMWghtThreshMin":0.000025,"EEMWghtThreshMax":0.000075

same reward codes as used on laptop:
    "rewardcodes": {"scorePoint": 1, "losePoint": -0.1, "followBall": 0.1, "avoidBall": -0.01,
    "hitBall": 0.5},

python -i simdat.py backupcfg/20may22_E0_sim.json
animSynWeights(pdf) #

drawraster(dspkT,dspkID)
savefig('gif/20may22_e0_rast.png')

python -i actmap.py backupcfg/20may22_E0_sim.json
fig, axs, plt = animActivityMaps()

hmm, only ran for 2 s ...

if running with so many synapses values saved, have to limit to every 5-10 s

ok, start for 200 s ... saving weights every 10 s ...

myrun 12 sn.json

<<<<<<< HEAD
** sims on falcor did not save output properly, had memory errors

20may21_B0_sim.json
20may21_C0_sim.json

well, have some of the output (actions rewards for B0) ... may as well take a look ... and see
whether worth rerunning for more of the output...

python
#
import numpy as np
import pandas as pd
from pylab import *
from simdat import plotRewards,plotFollowBall,plotHitMiss
  
name = '20may21_B0_'; pda = pd.DataFrame(np.loadtxt('data/'+name+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  
np.amax(pda.time) # 2000.0

so do not even have that output ... 

so all the output lost from those two simulations ...

** try same 20may22_D0_ on falcor, but rename sim name to 20may22_D0_falcor_

in sn.json

will use recordWeightStepSize of 500 (smaller file output and RAM use) and only use 12 cores instead of 16 ...

will also only run a single sim at a time ... see if that helps ...

here are some of the relevant params:

    "rewardcodes": {"scorePoint": 1, "losePoint": -0.1, "followBall": 0.1, "avoidBall": -0.01, "hitBall": 0.5},
    "actionsPerPlay": 1,
    "DirectionDetectionAlgo":{"CentroidTracker":0,"OpticFlow":1},

    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EMDOWN":400,"EMUP":400,"IM":200,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.000025,"EEMWghtNM":0.0000025,"EEMWghtThreshMin":0.000025,"EEMWghtThreshMax":0.000075,"EEMProb":0.3,"EEMRecProb":0.1,"EEMPopNorm":0},
    "RL":{"AMPA":
	  {"wbase":0.0000001,"wmax":0.0001,"RLon":1,"RLlenhebb":50,"RLlenanti":50,"useRLexp":1,"RLhebbwt":0.0005,"RLantiwt":-0.0,"hebbwt":0,"antiwt":0,"tauhebb":10,"RLwindhebb":50,"softthresh":0,"verbose":0},

./myrun 12 sn.json

* 20may23
** sim on zn getting rates too high (~400 Hz periodically), have to lower max weight, restart as 20may23_A0_zn_

may as well stop it and set the max weight lower to avoid hyperxcit

transition to hyperexcit occurred around 55 s when weights got up to ~6.2e-5 for both EMDOWN and
EMUP:
t= 54999.99999948014 - adjusting weights based on RL critic value: -0.01
Game rewards: [-0.01]
sim.rank= 0 davg: {'EMUP': 6.192818441676834e-05, 'EMDOWN': 6.168511982260213e-05} dfctr: {'EMUP': 1.0, 'EMDOWN': 1.0}
U,D firing rates:  [0.0] [0.0]
Model actions: [1]

so set max at 6.15e-5
at t=54 s:
t= 53999.99999949469 - adjusting weights based on RL critic value: 0.1
Game rewards: [0.1]
sim.rank= 0 davg: {'EMUP': 6.159468527383135e-05, 'EMDOWN': 6.117707481808665e-05} dfctr: {'EMUP': 1.0, 'EMDOWN': 1.0}
U,D firing rates:  [7.575757575757575] [3.0303030303030303]

"EEMWghtThreshMax":0.0000615

"name":"20may23_A0_zn_"

recordWeightStepSize":250

ok, restart on zn ...

myrun 12 sn.json

** meanwhile, check output from falcor (20may22_D0_falcor_) -> did not get great result

python -i simdat.py backupcfg/20may22_D0_falcor_sim.json

animSynWeights(pdf) # gif/20may22_D0_falcor_weightmap.mp4

python -i actmap.py backupcfg/20may22_D0_falcor_sim.json

fig, axs, plt = animActivityMaps() # gif/20may22_D0_falcor_actmap.mp4

to view mp4s, first download to laptop ...
scp 'samn@falcor.rfmh.org://home/samn/SMARTAgent/gif/20may22_D0_falcor*mp4' ./gif/
scp samn@falcor.rfmh.org://home/samn/SMARTAgent/backupcfg/20may22_D0_falcor_sim.json ./backupcfg

from looking at output mp4s, looks like model reachesbest performance pretty quickly and doesn't improve much after ...
also still seeing biases with higher activation of EMUP compared to EMDOWN ...

but weights did reach ~max quicker than in prior sims ... is that a good thing?

** try another sim on falcor with longer RLlenhebb (100 ms instead of previous 50 ms; name = 20may23_A0_falcor_)

same params as backupcfg/20may22_D0_falcor_sim.json otherwise

"RLlenhebb":100

"name":"20may23_A0_falcor_"

./myrun 12 sn.json

* 20may24
** sim on zn (20may23_A0_zn_) still develops hyperexcit?

or at least periods where it's firing at very high rates, not every action ... 
hyperexcit also comes much later ... let it finish since from printouts appeared to have
some decent bhavior early on ... 

** check output on falcor's latest sim (20may23_A0_falcor_)

python -i simdat.py backupcfg/20may23_A0_falcor_sim.json

animSynWeights(pdf) # gif/20may23_A0_falcor_weightmap.mp4

python -i actmap.py backupcfg/20may23_A0_falcor_sim.json

fig, axs, plt = animActivityMaps() # gif/20may23_A0_falcor_actmap.mp4

to view mp4s, first download to laptop ...
scp 'samn@falcor.rfmh.org://home/samn/SMARTAgent/gif/20may23_A0_falcor*mp4' ./gif/
scp samn@falcor.rfmh.org://home/samn/SMARTAgent/backupcfg/20may23_A0_falcor_sim.json ./backupcfg

in weightmap, there appears to be less difference between average input weights to EMDOWN and EMUP populations
suggesting possibly less bias in movement directions ... in terms of following vs not following ball, there
is not a clear difference ... in terms of hit vs miss, there appears to be a slightly higher number of hits
for the latter simulation, with the longer time constant for eligibility trace (100 ms vs previous 50 ms)

overall, follow ball probability does not pass ~50% / random level ... actually, is 50% random level?
or 33% if no move is the appropriate answer sometimes ... ?

still have to look at actmap movie to see if bias really absent ... 

** start another sim on falcor (20may24_A0_falcor_)

same as last but even longer time constant for eligibility trace (200 ms)

"RLlenhebb":200

run it a little longer too ... 400 s ...

./myrun 12 sn.json

* 20may25
** sim finished on zn (20may23_A0_zn_sim.json) -->> check output, start new (20may25_A0_zn_)

python -i simdat.py backupcfg/20may23_A0_zn_sim.json

animSynWeights(pdf) # gif/20may23_A0_zn_weightmap.mp4

drawraster(dspkT,dspkID)
savefig('gif/20may25_20may23_A0_zn_rast.png')
on average, rates are not terrible ... 
savefig('gif/20may25_20may23_A0_zn_rast_b.png')
but the hypersynchronized firing pattern is a problem ... 
savefig('gif/20may25_20may23_A0_zn_rast_c.png')
should also look at membrane potential ... 

follow ball probability looks like transitions, first rises, then decays ... possibly due
to hyperactivity?

python -i actmap.py backupcfg/20may23_A0_zn_sim.json

fig, axs, plt = animActivityMaps() # 

so based on above, should have lower max weights ... and possibly lower min weights as well... 

some of the params just used in 20may23_A0_zn_ seem off:
    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EMDOWN":400,"EMUP":400,"IM":200,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.0000125,"EEMWghtNM":0.00000125,"EEMWghtThreshMin":0.000025,"EEMWghtThreshMax":0.0000615,"EEMProb":0.6,"EEMRecProb":0.2,"EEMPopNorm":0},

EEMWghtAM had lower value than EEMWghtThreshMin, so that means weights got pushed up through
normalization pretty early (and for no good reason)

"name":"20may25_A0_zn_"

set "EEMWghtThreshMin":0.0000125
and "EEMWghtThreshMax" from 0.0000615 to 0.00005

ok, start that ... for 200 s ...

myrun 16 sn.json

** sim finished on falcor (20may24_A0_falcor_sim.json) -->> check output

python -i simdat.py backupcfg/20may24_A0_falcor_sim.json

animSynWeights(pdf) #

python -i actmap.py backupcfg/20may24_A0_falcor_sim.json

fig, axs, plt = animActivityMaps() # 

scp 'samn@falcor.rfmh.org://home/samn/SMARTAgent/gif/20may24_A0_falcor*mp4' ./gif/
scp samn@falcor.rfmh.org://home/samn/SMARTAgent/backupcfg/20may24_A0_falcor_sim.json ./backupcfg

similar patternt to last simulation run on falcor seen here, with longer time constant for
eligibility trace (200 ms, compared to original 50 ms), there is less bias/difference between
weights to EMUP and EMDOWN populations. however probability of move toward/away from ball
is no better than the 100 ms eligibility trace.

for comparison, worth running a sim with shorter eligibility trace time constants ... (25 ms vs original 50 ms)

will make duration 200 s ...

"name":"20may25_A0_falcor_"

"RLlenhebb":25

./myrun 12 sn.json

** 20may23_A0_falcor_actmap.mp4 <- does not look as terrible as usual, in terms of performance
(though many of the usual biases remain)
20may23_A0_falcor_weightmap.mp4

that's with the 100 ms RL eligiblity trace ... and higher connectivity to EMUP, EMDOWN

there are some sequences where the model hits the ball back a few times in a row ... number of
hits between points could be another metric but hit vs miss is more basic and still captures that

could compare performance of the model to naive model or one with equal rewards distributed
randomly over time

other thing to note is that it's difficult for the paddle to remain still, since any difference
in firing between the two populations can lead to movement. there's no wide-margin / middle
ground allowing the paddle to stay still ... could implement that as factor higher rate
for one population to move ... would at least mean some ability to hold paddle still ... 

* 20may26
** check 20may25_A0_falcor_ output (25 ms tau for rl eligibility trace)

python -i simdat.py backupcfg/20may25_A0_falcor_sim.json

animSynWeights(pdf) # gif/20may25_A0_falcor_weightmap.mp4

drawraster(dspkT,dspkID)
savefig('gif/20may26_20may25_A0_falcor_rast.png')
overall rates are ok...
savefig('gif/20may26_20may25_A0_falcor_rast_b.png')
too much hypersynch, once in a while...

python -i actmap.py backupcfg/20may25_A0_falcor_sim.json

fig, axs, plt = animActivityMaps() # 

scp 'samn@falcor.rfmh.org://home/samn/SMARTAgent/gif/20may25_A0_falcor*mp4' ./gif/
scp samn@falcor.rfmh.org://home/samn/SMARTAgent/backupcfg/20may25_A0_falcor_sim.json ./backupcfg

most of the time the weights to EMUP are higher ... so that's effect seen with the shorter time constant ... 

** some discussion with ha

10:15
samn was running different sims over the weekend ... with higher connectivity to M populations
10:15
Haroon Anwar so different sims---- any useful results
10:18
samn ran with higher connectivity to M populations, and some recurrent connectivity
sims with longer time constant for eligiliblity trace have less difference in weights to the diff pops - so that's possibly good to avoid bias
there are some sequences where the model hits the ball back a few times in a row ... number of
hits between points could be another metric but hit vs miss is more basic and still captures that
could compare performance of the model to naive model or one with equal rewards distributed
randomly over time
other thing to note is that it's difficult for the paddle to remain still, since any difference
in firing between the two populations can lead to movement. there's no wide-margin / middle
ground allowing the paddle to stay still ... could implement that as factor higher rate
for one population to move ... would at least mean some ability to hold paddle still ... or could have a population that specifically encodes "NO MOVE"
10:21
Haroon Anwar hard to say which one is better, factor high or separate pop…. probably should try both
10:21
better to try factor high firing rate first
10:23
samn which better - well, too much bias interferes with performance
10:23
even a slight average bias
10:25
Haroon Anwar do we have a quantification for that?--- i mean i am trying to understand what kind of biases are we talking about here and what are the origins of those biases
10:25
samn quantification - average weight to each  poulation
10:26
should also measure time paddle is at each location
10:26
seems clear from movies that it stays at top or bottom too much
10:26
origin - it's either the weights or a bug
10:26
yeah, would be good to look into all of that
10:27
Haroon Anwar i agree
10:27
samn you were working on the object detection?
10:28
Haroon Anwar that was done… was having some issues with movies,
10:28
and had hard time testing the accuracy of direction selective neurons
10:29
samn done with wider distribution of flow?
10:29
Haroon Anwar yes, had done that
10:29
samn can you show how it looks?
10:30
Haroon Anwar let me see if i can find a movie with wider flow
10:30
else i will have to generate one
10:31
samn probably useful if width could be a param
10:31
Haroon Anwar yes it is
10:31
oh but not in json
10:31
i can make that too
10:32
samn so rates ~same as when using optical flow?
10:32
and runtime ~same?
10:33
Haroon Anwar it was very similar…. but i was skeptical about the runtime comparison because i noticed things were slow on zn on friday…. but yes looked similar
10:33
samn ok sg
10:34
param in json - sg
10:34
other than that you had idea about topology of M
10:34
Haroon Anwar hopefully i will be satisfied with more testing today to move on to topology of M
10:35
samn ic, testing of obj detection
10:35
Haroon Anwar movies
10:35
testing movies
10:35
i feel something is off
10:35
samn ic
10:35
Haroon Anwar i added a frame in the beginning
10:35
samn actma or synweight or both
10:36
Haroon Anwar actmap
10:36
samn ic
10:36
ok
10:36
Haroon Anwar but for 10000 ms it goes till 99960 ms
10:36
samn i'll paste some fo this to games channel so interns can read later ... they're starting next week btw
10:36
99960 - ok, so might be off by 1 frame
10:37
Haroon Anwar may be — but that makes comparison impossible
10:37
samn yeah, should have everything aligned
10:38
Haroon Anwar hopefully will be a small thing
10:38
samn but single frame for display, don't think will make huge diff, yeah, good to check, thx
10:38
especially if means bug in the main sim code
10:39
Haroon Anwar everything seems good from sim
10:41
samn ic

** last sim completed on zn (20may23_A0_zn_) with hypersynchrony, has poor performance
for most of its duration and paddle gets stuck on top for majority of time (once
the hypersynchrony develops) so that's another indicator of origin of bias

** this sim (20may25_A0_zn_sim.json) on zn also has hypersynch/high rates develop & likely poor performance
so should kill that and start one with even lower max weights ...

set "EEMWghtThreshMax":0.00005
to ~1/2 that value ... "EEMWghtThreshMax":0.000025

"name":"20may26_A0_zn_"

can also try longer time constant for RL (based on sims on falcor)
set "RLlenhebb":50
to 100 ...

also lower
"EEMWghtThreshMin":0.0000125
to
"EEMWghtThreshMin":0.00000625
so weights could go down further before getting pushed back up through normalization

myrun 16 sn.json

** summary from latest sims on falcor

20may22_D0_falcor_sim.json -->> "RLlenhebb":50 <<-- original default
20may23_A0_falcor_sim.json -->> "RLlenhebb":100 <<-- has lower bias
20may24_A0_falcor_sim.json -->> "RLlenhebb":200 <<-- has lower bias
20may25_A0_falcor_sim.json -->> "RLlenhebb":25 <<-- has higher bias

can look at how much time spent at every y position ... but not saving estimated racket and ball positions ... 

try a quick sim saving the ball and racket (paddle) positions ...

may as well try the object tracker too ...

./myrun 12 sn.json

hmm, no firing for these param weights...have to adjust ... 

python -i simdat.py backupcfg/20may26_A0_falcor_sim.json

animSynWeights(pdf) # gif/20may26_A0_falcor_weightmap.mp4

drawraster(dspkT,dspkID)
savefig('gif/20may26_A0_falcor_rast.png')
not much activity for EM pops ... 

python -i actmap.py backupcfg/20may26_A0_falcor_sim.json

fig, axs, plt = animActivityMaps() # 

scp 'samn@falcor.rfmh.org://home/samn/SMARTAgent/gif/20may26_A0_falcor*mp4' ./gif/
scp samn@falcor.rfmh.org://home/samn/SMARTAgent/backupcfg/20may26_A0_falcor_sim.json ./backupcfg

and can adjust flowwidth for object tracker too

try with double the flow width (16, compared to original 8)

python -i simdat.py backupcfg/20may26_A0_falcor_sim.json

animSynWeights(pdf) # gif/20may26_A0_falcor_weightmap.mp4

drawraster(dspkT,dspkID)
savefig('gif/20may26_A0_falcor_rast_b.png')
ok, a little more activity for EM ... 

python -i actmap.py backupcfg/20may26_A0_falcor_sim.json

fig, axs, plt = animActivityMaps() # 

scp 'samn@falcor.rfmh.org://home/samn/SMARTAgent/gif/20may26_A0_falcor*mp4' ./gif/
scp samn@falcor.rfmh.org://home/samn/SMARTAgent/backupcfg/20may26_A0_falcor_sim.json ./backupcfg

ok, object detection-based flow is a little wider ... though EM rates still lower than when using optical flow algorithm

dobjpos = loadObjPos()

dobjpos['ball'] = np.array(dobjpos['ball'])
dobjpos['ball'].shape # (249, 2)

dobjpos['racket'] = np.array(dobjpos['racket'])

plot(dobjpos['ball'][:,0],dobjpos['ball'][:,1])
plot(dobjpos['racket'][:,0],dobjpos['racket'][:,1])

fig=animInput(InputImages,'testflow2.mp4',ldflow=ldflow,dobjpos=dobjpos)

fig, axs, plt = animActivityMaps(outpath='testact.mp4',dobjpos=dobjpos) # 

#
clf()
subplot(1,2,1); xlabel('Racket X position')
hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position')
hist(dobjpos['racket'][:,1])

savefig('gif/20may26_racketposhist_b1.png')

yeah, looks like racket spending more time at top or bottom ... 

try a bit longer run with slightly higher weights to see if firing ok ... 

./myrun 12 sn.json

python -i simdat.py backupcfg/20may26_A0_falcor_sim.json

drawraster(dspkT,dspkID)
savefig('gif/20may26_A0_falcor_rast_b2.png')
savefig('gif/20may26_A0_falcor_rast_b2b.png')

overall rates are ok but some hypersynch will likely emerge eventually since max weight pretty high
with 0.3 prob of conn to EM and 0.1 recurr conn in EM

animSynWeights(pdf) # gif/20may26_A0_falcor_weightmap.mp4

python -i actmap.py backupcfg/20may26_A0_falcor_sim.json

dobjpos = loadObjPos(); fig, axs, plt = animActivityMaps(dobjpos=dobjpos) # 

scp 'samn@falcor.rfmh.org://home/samn/SMARTAgent/gif/20may26_A0_falcor*mp4' ./gif/
scp samn@falcor.rfmh.org://home/samn/SMARTAgent/backupcfg/20may26_A0_falcor_sim.json ./backupcfg

looks decent ... can run longer ... 

./myrun 12 sn.json

firing rates getting too high ... should lower min and max weights ...
"name":"20may26_B0_falcor_"
"EEMWghtAM":0.00004,"EEMWghtNM":0.0000025,"EEMWghtThreshMin":0.00002,"EEMWghtThreshMax":0.00008,"EEMProb":0.3,"EEMRecProb":0.1,"EEMPopNorm":0
"wbase":0.0000001,"wmax":0.00012

./myrun 12 sn.json

** setup rule for larger firing rates (by factor, prior to movement) ?

may help stability and avoiding bias ... ?

* 20may27
** make movies/check output from full 20may26_A0_falcor_ 

python -i simdat.py backupcfg/20may26_A0_falcor_sim.json

drawraster(dspkT,dspkID)
savefig('gif/20may27_20may26_A0_falcor_rast_a.png')
decent overall rates
savefig('gif/20may27_20may26_A0_falcor_rast_b.png')
but overly synchronous ... 

animSynWeights(pdf) # gif/20may26_A0_falcor_weightmap.mp4

check cells too ...

simConfig['simData'].keys()
dict_keys(['spkt', 'spkid', 'V_soma', 't', 'dminID', 'avgRate'])

simConfig['simData']['V_soma'].keys()
dict_keys(['cell_0', 'cell_900', 'cell_4359', 'cell_400', 'cell_4759', 'cell_500', 'cell_4100', 'cell_5159'])

len(simConfig['simData']['V_soma']['cell_0'])

plot(simConfig['simData']['t'],simConfig['simData']['V_soma']['cell_0'])
savefig('gif/20may27_20may26_A0_falcor_cell_0_V.png')

simConfig['net']['cells'][0]

drawcellVm(simConfig); xlim((190e3,200e3))
savefig('gif/20may27_20may26_A0_falcor_cellVm.png')

looks mostly ok, no depolarization blockade ... though a lot of synchrony between different types
and very strong osc. - that could prevent good performance...if everything time-locked into
hypersynch osc.

python -i actmap.py backupcfg/20may26_A0_falcor_sim.json

dobjpos = loadObjPos(); fig, axs, plt = animActivityMaps(dobjpos=dobjpos) # 

frame t =  199800
frame t =  199820
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "actmap.py", line 155, in animActivityMaps
    ani.save(outpath, writer=writer); print('saved animation to', outpath)
  File "/home/samn/miniconda3/lib/python3.7/site-packages/matplotlib/animation.py", line 1199, in save
    anim._draw_next_frame(d, blit=False)
  File "/home/samn/miniconda3/lib/python3.7/site-packages/matplotlib/animation.py", line 1236, in _draw_next_frame
    self._draw_frame(framedata)
  File "/home/samn/miniconda3/lib/python3.7/site-packages/matplotlib/animation.py", line 1772, in _draw_frame
    self._drawn_artists = self._func(framedata, *self._args)
  File "actmap.py", line 149, in updatefig
    lobjx,lobjy = [objfctr*dobjpos[k][t,0] for k in dobjpos.keys()], [objfctr*dobjpos[k][t,1] for k in dobjpos.keys()]
  File "actmap.py", line 149, in <listcomp>
    lobjx,lobjy = [objfctr*dobjpos[k][t,0] for k in dobjpos.keys()], [objfctr*dobjpos[k][t,1] for k in dobjpos.keys()]
IndexError: index 9991 is out of bounds for axis 0 with size 9991
>>> len(dobjpos['racket'])
9991

hmm...positions must not be recorded for every step... definitely not for first few time steps
but apparently 9 positions not recorded (9*20 + 199820) == 200000

will draw without positions for now ... 

#
clf()
subplot(1,2,1); xlabel('Racket X position')
hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position')
hist(dobjpos['racket'][:,1])

savefig('gif/20may27_20may26_A0_falcor_racketposhist_b.png') # <<-- shows a lot of bias towards one y position

fig, axs, plt = animActivityMaps(dobjpos=None) # 

** make movies/check output from 20may26_B0_falcor_ 

python -i simdat.py backupcfg/20may26_B0_falcor_sim.json

drawraster(dspkT,dspkID)
savefig('gif/20may27_20may26_B0_falcor_rast_a.png')
xlim((190e3,200e3))
not much going on in beginning of simulation
savefig('gif/20may27_20may26_B0_falcor_rast_b.png')
then becomes more synchronized, but not continuously

drawcellVm(simConfig); xlim((190e3,200e3))
savefig('gif/20may27_20may26_B0_falcor_cellVm.png')

animSynWeights(pdf) # gif/20may26_B0_falcor_weightmap.mp4

hmm, there's more of a difference between the synaptic weights to the two M populations here
not sure this model is performing better than previous with optical flow ... 

python -i actmap.py backupcfg/20may26_B0_falcor_sim.json

dobjpos = loadObjPos()

#
clf()
subplot(1,2,1); xlabel('Racket X position')
hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position')
hist(dobjpos['racket'][:,1])

savefig('gif/20may27_20may26_B0_falcor_racketposhist_b.png') # 
still bias in positions ... at both extremes ...

fig, axs, plt = animActivityMaps(dobjpos=None) # 

while making adjustments to model can continue this one ...

    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20may26_B0_falcor_synWeights.pkl"},        
"name":"20may27_B1_falcor_"

./myrun 12 sn.json

** add dconf['movefctr'] to require margin between EM pop rates for move generation

default can be 1.0 to have same activity
uses this logic:
        if F_UPs[ts]>F_DOWNs[ts] * dconf['movefctr']:
          actions.append(dconf['moves']['UP'])
        elif F_DOWNs[ts]>F_UPs[ts] * dconf['movefctr']:
          actions.append(dconf['moves']['DOWN'])
        else:
          actions.append(dconf['moves']['NOMOVE']) # No move        

start weights higher than sim on falcor to see if any moves:
"EEMWghtAM":0.00006

testing this on laptop first ... 

myrun 12 sn.json

  Done; run time = 1176.29 s; real-time ratio: 0.00.

Analyzing...
  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 32154 (1.20 Hz)
  Simulated time: 5.0 s; 12 workers
  Run time: 1176.29 s
Saving output as data/20may27_C0_laptop_simConfig.pkl ... 
Finished saving!
  Done; saving time = 1.66 s.

python -i simdat.py backupcfg/20may27_C0_laptop_sim.json

drawraster(dspkT,dspkID)
savefig('gif/20may27_C0_rast_a.png')
less firing for EM pops

drawcellVm(simConfig); 
savefig('gif/20may27_C0_laptop_cellVm.png')

animSynWeights(pdf) # 

python -i actmap.py backupcfg/20may27_C0_laptop_sim.json

dobjpos = loadObjPos()

#
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])

savefig('gif/20may27_C0_laptop_racketposhist_b.png') # 
some bias, also stuck in middle (no moves)

fig, axs, plt = animActivityMaps(dobjpos=None) # gif/20may27_C0_laptop_actmap.mp4

well, certainly less movement ... 

run longer ... 100 s ...

also adjust weights ... 

** check output from 20may26_A0_zn_

t= 199999.80000715362 - adjusting weights based on RL critic value: -0.01
Game rewards: [-0.01]
sim.rank= 0 davg: {'EMUP': 2.5309090724359646e-05, 'EMDOWN': 2.54674733529361e-05} dfctr: {'EMUP': 0.9877873635317073, 'EMDOWN': 0.9816442979459442}
  Done; run time = 105017.57 s; real-time ratio: 0.00.

Gathering data...
  Done; gather time = 5.29 s.

Analyzing...
  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 2388616 (2.23 Hz)
  Simulated time: 200.0 s; 16 workers
  Run time: 105017.57 s
Saving output as data/20may26_A0_zn_simConfig.pkl ... 
Finished saving!
  Done; saving time = 18.70 s.

python -i simdat.py backupcfg/20may26_A0_zn_sim.json

drawraster(dspkT,dspkID)
savefig('gif/20may27_20may26_A0_zn_rast_a.png')
overall, rates are ok
xlim((190e3,200e3))
savefig('gif/20may27_20may26_A0_zn_rast_b.png')
xlim((195e3,200e3))
savefig('gif/20may27_20may26_A0_zn_rast_c.png')
but do have periods of hypersynch activity ...

drawcellVm(simConfig); 
savefig('gif/20may27_20may26_A0_zn_cellVm.png')
xlim((190e3,200e3))
savefig('gif/20may27_20may26_A0_zn_cellVm_b.png')
xlim((195e3,200e3))
savefig('gif/20may27_20may26_A0_zn_cellVm_c.png')

animSynWeights(pdf) # 

python -i actmap.py  backupcfg/20may26_A0_zn_sim.json

fig, axs, plt = animActivityMaps(dobjpos=None) # gif/20may27_20may26_A0_zn_actmap.mp4

* 20may28
** check output from 20may27_B1_falcor_

python -i simdat.py backupcfg/20may27_B1_falcor_sim.json

reading  backupcfg/20may27_B1_falcor_sim.json
-1
loading data from 20may27_B1_falcor_
loading input images from data/20may27_B1_falcor_InputImages.txt
loaded simulation data

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.51))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/20may28_20may27_B1_falcor_behav_a0.png')

drawraster(dspkT,dspkID)
xlim((190e3,200e3))
savefig('gif/20may28_20may27_B1_falcor_rast_a1.png')

drawcellVm(simConfig); xlim((190e3,200e3))
savefig('gif/20may28_20may27_B1_falcor_cellVm_a2.png')

everything looks ok except for performance ... 

fig, axs, plt = animActivityMaps()

#
dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])

savefig('gif/20may28_20may27_B1_falcor_racket_pos_hist_a3.png')

is there any stability to the weights over time?
can take a few synapses and see how they vary ... whether there's a similar pattern

pdf.columns
Index(['time', 'preid', 'postid', 'weight'], dtype='object')

dstartidx['EMUP'] # 4759
dendidx['EMUP'] # 5158
pdfs = pdf[pdf.postid==4759]
len(pdfs) # 23160
pdfs.at[pdfs.index[0],'preid'] # 528

dstartidx['EV1'] # 500
dendidx['EV1'] # 899

pdfs = pdf[(pdf.postid==4759) & (pdf.preid==528)]
len(pdfs) # 20

plot(pdfs.time,pdfs.weight,'k')
savefig('gif/20may28_20may27_B1_falcor_synweight_a4.png')
rises, then decays ...

postid = dstartidx['EMUP']
pdfs = pdf[(pdf.postid==postid) & (pdf.preid>dstartidx['EV1']) & (pdf.preid<=dendidx['EV1'])]
lpreid = pdfs.preid
len(lpreid) # 2400

connectLayerswithOverlap in connUtils.py
cells seem to be arranged in square with first index as row and second as column
so that gives the coordinates based on gid ... ? 

dnumc['ER'] # 400
dstartidx['ER'] # 0
dendidx['ER'] # 399

lx,ly=[],[]
for gid in range(dstartidx['ER'],dendidx['ER']+1,1):
  x,y = gid2pos(dnumc['ER'], dstartidx['ER'], gid)
  lx.append(x)
  ly.append(y)

lx
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
ly
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]
>>> 

works ok when the grid is evenly spaced and each neuron occupies a point ... so could use it to map ER, EV1, and direction
selective RFs ... all populations which have 400 neurons ... for V4 and MT and the interneurons will have to adjust scale

postid = dstartidx['EMUP']
pdfs = pdf[(pdf.postid==postid) & (pdf.preid>dstartidx['EV1']) & (pdf.preid<=dendidx['EV1'])]
lpreid = pdfs.preid

rfmap = getinputmap(pdf, pdf.time[0], 'EV1', dstartidx['EMUP'], 'EMUP', dnumc, dstartidx, dendidx)

imshow(rfmap,cmap='gray',origin='upper')
colorbar()
savefig('gif/20may28_20may27_B1_falcor_rfmap_a5.png')
ok, that EMUP neuron gets pretty broad coverage ... (white pixels where it gets input from EV1)

lrfmap = [getinputmap(pdf, pdf.time[0], 'EV1', postid, 'EMUP', dnumc, dstartidx, dendidx) for postid in range(dstartidx['EMUP'],dendidx['EMUP']+1,1)]

len(lrfmap) # 400

nprfmap = np.array(lrfmap)
nprfmap.shape # (400, 20, 20)
imshow(np.sum(nprfmap,axis=0),cmap='gray',origin='upper'); colorbar()
savefig('gif/20may28_20may27_B1_falcor_rfmap_a6.png')
hmm, one pixel always empty ... but otherwise, as a population EMUP has full coverage of visual space from EV1 inputs...

lprety = ['EV1DNW', 'EV1DN', 'EV1DNE', 'EV1DW', 'EV1','EV1DE','EV1DSW', 'EV1DS', 'EV1DSE']
drfmap = {prety:getinputmap(pdf, pdf.time[0], prety, dstartidx['EMUP'], 'EMUP', dnumc, dstartidx, dendidx) for prety in lprety}

#
for tdx,prety in enumerate(lprety):
  subplot(3,3,tdx+1)
  imshow(drfmap[prety],cmap='gray',origin='upper'); title(prety+'->EMUP0'); 

savefig('gif/20may28_20may27_B1_falcor_rfmap_a7.png')

so, somewhat broad coverage. but which locations have info about intensity and all directions? 

drfmap = plotallinputmaps(pdf, pdf.time[0], dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, lprety)
drfmap = plotallinputmaps(pdf, pdf.time[0], dstartidx['EMUP'] + 1, 'EMUP', dnumc, dstartidx, dendidx, lprety)

lmap = [drfmap[x] for x in drfmap.keys()]
mask = lmap[0]
for i in range(1,len(lmap),1): mask = np.logical_and(mask, lmap[i])
np.amax(mask) # False

lmap = np.array(lmap)
nps = np.sum(lmap,axis=0)
imshow(nps,cmap='gray',origin='upper')
colorbar()
savefig('gif/20may28_20may27_B1_falcor_rfmap_a8.png')
some locations have lot of info, others not ... 

np.amin(nps), np.amax(nps), mean(nps) # (0.0, 7.0, 2.695)
so average has ~2.7/9 of total info, which is ~1/3 ... which is around EEMProb of 0.3
so the recurrent connectivity becomes important for making decisions ... right now EEMRecProb was at 0.1
could make it higher ... 

** check output from 20may27_D0_movefctr_1.25_falcor_

python -i simdat.py backupcfg/20may27_D0_movefctr_1.25_falcor_sim.json


#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.51))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/20may28_20may27_D0_movefctr_1.25_falcor_a0.png')

drawraster(dspkT,dspkID); xlim((190e3,200e3))
savefig('gif/20may28_20may27_D0_movefctr_1.25_falcor_rast_a1.png')

drawcellVm(simConfig); xlim((190e3,200e3))
savefig('gif/20may28_20may27_D0_movefctr_1.25_falcor_cellVm_a2.png')

#
dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])

savefig('gif/20may28_20may27_D0_movefctr_1.25_falcor_racket_pos_hist_a3.png')
still a large bias in positions ... 

fig, axs, plt = animActivityMaps()

** try sim with higher recurrent conn and no (or less frequent?) weight norm (20may28_A0_falcor_)

less frequent weight norm (every 40 s)

and higher recurrent connectivity (0.3 instead of previous 0.1)

"name":"20may28_A0_falcor_"

./myrun 12 sn.json

** check input maps using weight as sim progresses

python -i simdat.py backupcfg/20may27_B1_falcor_sim.json

drfmap = plotallinputmaps(pdf, pdf.time[0], dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=False)
savefig('gif/20may28_e0.png')

drfmap = plotallinputmaps(pdf, pdf.time[0], dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True)
savefig('gif/20may28_e1.png')

hmm, when plotting as weight, only EV1 synapses have some weights lowered ... 
pdf.time[0] # 10000.000000018848
but the others do not ... why?? since nothing moved at the locations specific to those direction selective neurons yet
so those neurons did not yet fire ...

drfmap = plotallinputmaps(pdf, pdf.time[1], dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True)
savefig('gif/20may28_e2.png')

drfmap = plotallinputmaps(pdf, pdf.time[2], dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True)
savefig('gif/20may28_e3.png')

drfmap = plotallinputmaps(pdf, pdf.time[3], dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True)
savefig('gif/20may28_e4.png')
pdf.time[3] # 39999.99999969842
by that time, a lot more synapses have become depressed ... ? or some have been potentiated ... need colorbars ...

drfmap = plotallinputmaps(pdf, np.amax(pdf.time), dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True)
savefig('gif/20may28_e5.png')

drfmap = plotallinputmaps(pdf, np.amax(pdf.time), dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True,cmap='jet')
savefig('gif/20may28_e6.png')
ok, easier to compare this way ... 

clf(); drfmap = plotallinputmaps(pdf, np.amin(pdf.time), dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True,cmap='jet')
savefig('gif/20may28_e7.png')
and at first time recorded, weights from EV1 were already heightened ... 

lmap = [drfmap[x] for x in drfmap.keys()]
lmap = np.array(lmap)
nps = np.sum(lmap,axis=0)
clf(); imshow(nps,cmap='jet',origin='upper'); colorbar()
savefig('gif/20may28_e8.png')

how does pattern look when combine across postsynaptic neurons of a given population?

#
dtmp = None
for postid in range(dstartidx['EMUP'],dendidx['EMUP']+1,1):
  print(postid)
  drfmap = getallinputmaps(pdf, np.amax(pdf.time), postid, 'EMUP', dnumc, dstartidx, dendidx)
  if dtmp is None: 
    dtmp = drfmap
  else:
    for k in dtmp.keys(): dtmp[k] += drfmap[k]

clf(); drfmap = plotallinputmaps(pdf, np.amax(pdf.time), dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True,cmap='jet', dmap=dtmp)

savefig('gif/20may28_e9.png')

hmm, did not div those values properly ... and that obscures relative value in each location

* 20may29
** check output from 20may28_A0_falcor_

  Cells: 5359
  Connections: 0 (0.00 per cell) <<-- that's not right, just because not saving all network info
  Spikes: 2046943 (1.91 Hz)
  Simulated time: 200.0 s; 12 workers
  Run time: 44290.63 s

python -i simdat.py backupcfg/20may28_A0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.51))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
subplot(1,3,1); plot([40e3,80e3,120e3,160e3,200e3],[0.45,.45,.45,.45,.45],'bo',markersize=10) # times of weight norm

savefig('gif/20may29_a0.png')
rises initially but then decays ... 

drawraster(dspkT,dspkID); 
xlim((20e3,30e3)); savefig('gif/20may29_a1.png')
xlim((190e3,200e3)); savefig('gif/20may29_a2.png')

activity much more synchronized at end when performance worse ... but not clear if that's the reason performance worse

drawcellVm(simConfig); 
xlim((20e3,30e3)); savefig('gif/20may29_a3.png')
xlim((190e3,200e3)); savefig('gif/20may29_a4.png')

#
dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])

savefig('gif/20may29_a5.png')

## fig, axs, plt = animActivityMaps()

drfmap = plotallinputmaps(pdf, np.amin(pdf.time), dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True,cmap='jet')
savefig('gif/20may29_a6.png')

clf(); drfmap = plotallinputmaps(pdf, np.amax(pdf.time), dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True,cmap='jet')
savefig('gif/20may29_a7.png')

drfmap = plotallinputmaps(pdf, np.amin(pdf.time), dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True,cmap='jet')
#
lmap = [drfmap[x] for x in drfmap.keys()]
lmap = np.array(lmap)
nps = np.sum(lmap,axis=0)
clf(); imshow(nps,cmap='jet',origin='upper'); colorbar()
savefig('gif/20may29_a8.png')

#
drfmap = plotallinputmaps(pdf, np.amax(pdf.time), dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, asweight=True,cmap='jet')
lmap = [drfmap[x] for x in drfmap.keys()]
lmap = np.array(lmap)
nps = np.sum(lmap,axis=0)
clf(); imshow(nps,cmap='jet',origin='upper'); colorbar()
savefig('gif/20may29_a9.png')

** are weight step sizes reasonable? no, too large. try with smaller (~5% max)

seemed like optic flow did a little better ... ? 
or could be due to EEMRecProb of 0.3 ... or many other things ... 

for last sim (backupcfg/20may28_A0_falcor_sim.json):
    "rewardcodes": {"scorePoint": 1, "losePoint": -0.1, "followBall": 0.1, "avoidBall": -0.01, "hitBall": 0.5},

	  {"wbase":0.0000001,"wmax":0.00024,"RLon":1,"RLlenhebb":100,"RLlenanti":50,"useRLexp":1,"RLhebbwt":0.0005,"RLantiwt":-0.0,"hebbwt":0,"antiwt":0,"tauhebb":10,"RLwindhebb":50,"softthresh":0,"verbose":0},

"EEMWghtAM":0.00008,"EEMWghtNM":0.0000025,"EEMWghtThreshMin":0.00004,"EEMWghtThreshMax":0.00016,"EEMProb":0.3,"EEMRecProb":0.3,"EEMPopNorm":0

so starting weight is 0.00008
RLhebbwt is 0.0005 -- increment is much larger than starting weight (0.0005 / 0.00008 = 6.25)
but then it gets multiplied by reward value; for a scorePoint (1) it goes up too much
for losePoint (-0.1) it goes down 0.0005*0.1 = 0.00005 > 50% of original value; 0.0005*0.1/0.00008 (0.625)
for followball (0.1) it goes up > 50% of original value
for avoidBall (-0.01) it goes down by 6.25% of original value
for hitBall (0.5)  too much as well ... 

so none of the reward increments make sense ... they should all be relatively small ... ~5% change should be the maximum

0.00008 * 0.05 # 4.000000000000001e-06
that should be value of RLhebbwt (0.000004)
relative values for rewardcodes can be maintained ...

"name":"20may29_A0_falcor_"

ok, try that out ...

./myrun 12 sn.json

and another with less recurrent connectivity (EEMRecProb) ... at 0.1 instead of 0.3 in 20may29_A0_falcor_

"name":"20may29_B0_falcor_"



** simpler architecture?

population for opponent racket position (1D)
population for player racket position (1D)
population for ball position (2D)

it might work (even that architecture is not guaranteed) but loses generality ... 

** simpler cells?

switch to izhikevich neurons?

** other notes from neco 2013 paper

model from neco 2013 seemed to have recurrent plastic connectivity between different motor neuron command populations 
also had RL plasticity within sensory areas and feedback RL plasticity from M -> S

noise was important component of the M neurons since drove the motor system to "babble" and produce
random movements which were then reinforced/punished

so may want to incorporate some of that into the present model

* 20may30
** check output from 20may29_A0_falcor_

python -i simdat.py backupcfg/20may29_A0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.51))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
subplot(1,3,1); plot([40e3,80e3,120e3,160e3,200e3],[0.45,.45,.45,.45,.45],'bo',markersize=10) # times of weight norm

savefig('gif/20may30_a0.png')

early spike, decay, then slow rise ... that's possibly a good sign if improvements continue ...

drawraster(dspkT,dspkID); 
xlim((190e3,200e3)); savefig('gif/20may30_a2.png')
low rates overall, no hypersynch

drawcellVm(simConfig); xlim((190e3,200e3)); savefig('gif/20may30_a4.png')

#
dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/20may30_a5.png')savefig('gif/20may30_a5.png')

save final output weights for continuation ...

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs) 
len(pdfs) # 990400
pickle.dump(D, open('data/20may29_A0_falcor_synWeights_final.pkl','wb')) # ~36 MB
ok, can use that to continue sim ...

** check output from 20may29_B0_falcor_

python -i simdat.py backupcfg/20may29_B0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.51))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
subplot(1,3,1); plot([40e3,80e3,120e3,160e3,200e3],[0.45,.45,.45,.45,.45],'bo',markersize=10) # times of weight norm

savefig('gif/20may30_b0.png')

similar pattern but the one with more recurrent EM connectivity seems to be doing better overall ?

clf(); drawraster(dspkT,dspkID); xlim((190e3,200e3)); savefig('gif/20may30_b2.png')

clf(); drawcellVm(simConfig);  xlim((190e3,200e3)); savefig('gif/20may30_b4.png')

save final output weights for continuation ...

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs)
len(pdfs) # 926400
pickle.dump(D, open('data/20may29_B0_falcor_synWeights_final.pkl','wb')) # ~33 MB
ok, can use that to continue sim ...

** continue 20may29_A0_falcor_ as 20may30_A1_falcor_

    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20may29_A0_falcor_synWeights_final.pkl"},        

running for 400 s ... saving weights every 10 s ... (instead of every 5 s)

./myrun 12 sn.json

** continue 20may29_B0_falcor_ as 20may30_B1_falcor_

./myrun 12 sn.json

hmm, not loading weights properly ... 
they seem to have run out of memory ... later should fix to save final weights for easier reload 
(fixed with selecting last time and then dumping output of pdf2weightsdict -- see above)

    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20may29_B0_falcor_synWeights_final.pkl"},        

./myrun 12 sn.json

running for 400 s ... saving weights every 10 s ... (instead of every 5 s)

* 20jun1
** check output from 20may30_A1_falcor_ and continue as 20jun1_A2_falcor_

dfctr never increased > 1, so weight normalization never occurred (due to small weight increments)

  Simulated time: 400.0 s; 12 workers
  Run time: 117071.13 s

synweights file is ~1GB

python -i simdat.py backupcfg/20may30_A1_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.51))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
subplot(1,3,1); plot([40e3,80e3,120e3,160e3,200e3,240e3,280e3,320e3,360e3,400e3],[.45,.45,.45,.45,.45,0.45,.45,.45,.45,.45],'bo',markersize=10) # times of weight norm

savefig('gif/20jun1_a0.png')
continued to improve?, possibly, but slowly ... 

drawraster(dspkT,dspkID); xlim((390e3,400e3)); savefig('gif/20jun1_a2.png')

clf(); drawcellVm(simConfig); xlim((390e3,400e3)); savefig('gif/20jun1_a4.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/20jun1_a5.png')

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs) 
len(pdfs) # 990400
pickle.dump(D, open('data/20may30_A1_falcor_synWeights_final.pkl','wb')) # ~36 MB

continue from there ...

    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20may30_A1_falcor_synWeights_final.pkl"}, 
"name":"20jun1_A2_falcor_"

./myrun 12 sn.json

** check output from 20may30_B1_falcor_ -- mistake, the json file has the same params as 20may30_A1_falcor_ ? no, continue as 20jun1_B2_falcor_

so did not properly continue the sim with the lower recurrent connectivity ... ? but then why are the B1
output files produced ?

will leave that one out for now ...

hmm, but file output sizes are different, so different parameters were used

check if output looks different in corrected json file ...

python -i simdat.py backupcfg/20may30_B1_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.51))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
subplot(1,3,1); plot([40e3,80e3,120e3,160e3,200e3,240e3,280e3,320e3,360e3,400e3],[.45,.45,.45,.45,.45,0.45,.45,.45,.45,.45],'bo',markersize=10) # times of weight norm

savefig('gif/20jun1_b0.png') # ok that looks somewhat different from A0 above

clf(); drawraster(dspkT,dspkID); xlim((390e3,400e3)); savefig('gif/20jun1_b2.png')

clf(); drawcellVm(simConfig); xlim((390e3,400e3)); savefig('gif/20jun1_b4.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/20jun1_b5.png')

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs) 
len(pdfs) # 926400
pickle.dump(D, open('data/20may30_B1_falcor_synWeights_final.pkl','wb')) # ~33 MB

continue from there ...

    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20may30_B1_falcor_synWeights_final.pkl"}, 
"name":"20jun1_B2_falcor_"

./myrun 12 sn.json

** sim with optical flow as comparison?

optical flow may have performed a little better?, possibly due to higher noise or just a diff param regime

can use ~same params on zn ... (12-16 cores?)
but use optical flow instead of object track ... 

myrun 16 sn.json

weights too high ... have to reduce for optical flow (since more widesread activation)

python -i simdat.py backupcfg/20jun1_C0_zn_sim.json

drawraster(dspkT,dspkID); 
savefig('gif/20jun1_c0.png')

clf(); drawcellVm(simConfig)
savefig('gif/20jun1_c1.png')

last time used optic flow had these weight params:

    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EMDOWN":400,"EMUP":400,"IM":200,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.000025,"EEMWghtNM":0.0000025,"EEMWghtThreshMin":0.000025,"EEMWghtThreshMax":0.000075,"EEMProb":0.3,"EEMRecProb":0.1,"EEMPopNorm":0},
    "RL":{"AMPA":
	  {"wbase":0.0000001,"wmax":0.0001,"RLon":1,"RLlenhebb":50,"RLlenanti":50,"useRLexp":1,"RLhebbwt":0.0005,"RLantiwt":-0.0,"hebbwt":0,"antiwt":0,"tauhebb":10,"RLwindhebb":50,"softthresh":0,"verbose":0},

can use similar but have lower minthresh, smaller weight inc, and longer lenhebb

    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EMDOWN":400,"EMUP":400,"IM":200,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.000025,"EEMWghtNM":0.0000025,"EEMWghtThreshMin":0.00000625,"EEMWghtThreshMax":0.0001,"EEMProb":0.3,"EEMRecProb":0.3,"EEMPopNorm":0},
    "RL":{"AMPA":
	  {"wbase":0.0000001,"wmax":0.0001,"RLon":1,"RLlenhebb":100,"RLlenanti":50,"useRLexp":1,"RLhebbwt":0.00000125,"RLantiwt":-0.0,"hebbwt":0,"antiwt":0,"tauhebb":10,"RLwindhebb":50,"softthresh":0,"verbose":0},

weight change (RLhebbwt): 0.000025 * .05

also change usefull to off:
    "DirectionDetectionAlgo":{"CentroidTracker":0,"OpticFlow":1,"FlowWidth":16,"UseFull":0},

ok, try quick sim...

myrun 16 sn.json

python -i simdat.py backupcfg/20jun1_C0_zn_sim.json

drawraster(dspkT,dspkID); 
savefig('gif/20jun1_c2.png')

clf(); drawcellVm(simConfig); savefig('gif/20jun1_c3.png')

looks ok...

may as well run long sim for comparison ... 

running for 400 s ... 

* 20jun2
** check output from 20jun1_C0_zn_ (uses optical flow)

  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 4317394 (2.01 Hz)
  Simulated time: 400.0 s; 16 workers
  Run time: 56524.00 s
Saving output as data/20jun1_C0_zn_simConfig.pkl ... 

synweights output file is ~2 GB

python -i simdat.py backupcfg/20jun1_C0_zn_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.51))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
subplot(1,3,1); plot([40e3,80e3,120e3,160e3,200e3,240e3,280e3,320e3,360e3,400e3],[.45,.45,.45,.45,.45,0.45,.45,.45,.45,.45],'bo',markersize=10) # times of weight norm

savefig('gif/20jun2_a0.png') # 
so far, this one doing worse than the others with object tracking...likely not due to object
tracking itself...but low firing rates...

clf(); drawraster(dspkT,dspkID); xlim((390e3,400e3)); savefig('gif/20jun2_a2.png')

clf(); drawcellVm(simConfig); xlim((390e3,400e3)); savefig('gif/20jun2_a4.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/20jun2_a5.png')

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs) 
len(pdfs) # 
pickle.dump(D, open('data/20jun1_C0_zn_synWeights_final.pkl','wb')) # 

can continue from there ... 

current weights are only ~20% of max and increasing slowly ... so there's room to improve
also better than hypersynch...

"name":"20jun2_C1_zn_"

    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20jun1_C0_zn_synWeights_final.pkl"}, 

** check output from 20jun1_A2_falcor_ and continue as 20jun2_A3_falcor_

python -i simdat.py backupcfg/20jun1_A2_falcor_sim.json

dstr = '20jun2_'; simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
subplot(1,3,1); plot([40e3,80e3,120e3,160e3,200e3,240e3,280e3,320e3,360e3,400e3],[.45,.45,.45,.45,.45,0.45,.45,.45,.45,.45],'bo',markersize=10) # times of weight norm

savefig('gif/'+dstr+simstr+'perf.png')
interesting ... does pass 50% probability of following ball in beginning but then decays ... should look at combined
cumulative probability ...

clf(); drawraster(dspkT,dspkID); xlim((390e3,400e3)); savefig('gif/'+dstr+simstr+'rast.png')
xlim((0,10e3)); savefig('gif/'+dstr+simstr+'rast_b.png')
looks like more firing in beginning compared to end; could too much punishment screw up performance? perhaps ...

clf(); drawcellVm(simConfig); xlim((390e3,400e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

#
sim = '20may29_A0_falcor_'
pda = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
curt = 200e3
for sim,maxdur in zip(['20may30_A1_falcor_', '20jun1_A2_falcor_'],[400e3,400e3]):
  tmp = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += curt
  curt += maxdur
  pda = pda.append(tmp)

#
clf()
plotFollowBall(pda,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(pda,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(pda,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf_total.png')

just looks like inaccuracy in measurement leading to initial overestimation of follow probability ...
but at least it does appear follow ball probability is increasing ... though fairly slowly ... and
possibly slowing down - so reached a peak ... 

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

ok, restart as ... 20jun2_A3_falcor_

"name":"20jun2_A3_falcor_"
    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20jun1_A2_falcor_synWeights_final.pkl"}, 

duration of 500 s ...

./myrun 12 sn.json
 
** check output from 20jun1_B2_falcor_ and continue as 20jun2_B3_falcor_

python -i simdat.py backupcfg/20jun1_B2_falcor_sim.json

dstr = '20jun2_'; simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
subplot(1,3,1); plot([40e3,80e3,120e3,160e3,200e3,240e3,280e3,320e3,360e3,400e3],[.45,.45,.45,.45,.45,0.45,.45,.45,.45,.45],'bo',markersize=10) # times of weight norm

savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); xlim((390e3,400e3)); savefig('gif/'+dstr+simstr+'rast.png')
rates look ok overall

clf(); drawcellVm(simConfig); xlim((390e3,400e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

#
sim = '20may29_B0_falcor_'
pda = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
curt = 200e3
for sim,maxdur in zip(['20may30_B1_falcor_', '20jun1_B2_falcor_'],[400e3,400e3]):
  tmp = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += curt
  curt += maxdur
  pda = pda.append(tmp)

#
clf()
plotFollowBall(pda,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(pda,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(pda,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf_total.png')

these cumulative probabilities look pretty clearly increasing ... so worth continuing further ... 

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) # 

ok, restart as ... 20jun2_A3_falcor_

"name":"20jun2_B3_falcor_"
    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20jun1_B2_falcor_synWeights_final.pkl"}, 

duration of 500 s ...

./myrun 12 sn.json

* 20jun4
** check output from 20jun1_C0_zn_ -- still at pretty low probability of follow -->> too low firing rate?

  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 4292836 (2.00 Hz)
  Simulated time: 400.0 s; 16 workers
  Run time: 127753.46 s

python -i simdat.py backupcfg/20jun1_C0_zn_sim.json

dstr = '20jun4_'; simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

still rising, but not even approaching 50% yet ...

clf(); drawraster(dspkT,dspkID); xlim((390e3,400e3)); savefig('gif/'+dstr+simstr+'rast.png')
clf(); drawcellVm(simConfig); xlim((390e3,400e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

hmm, looks like the weights/output was overwritten since did not update the sim name properly
when started the last sim on zn

overall, looks like weights decreased from original:
2.101540571002588e-05/0.000025 == 0.8406162284010351

should start from the sims that had close to 50% probability of success? they had lower level of
recurr conn

less punishment or higher min value might help ... or higher starting value ... 

## pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) # 

** start from my

some errors on my ... 

** check output from 20jun2_A3_falcor_ and continue as 20jun4_A4_falcor_

python -i simdat.py backupcfg/20jun2_A3_falcor_sim.json

dstr = '20jun4_'; simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')
finally got close to 50% follow ball probability previously achieved, but then decays downwards ... 
and looks like starts decaying when gets more rewards ... so reward strength might be too high??

clf(); drawraster(dspkT,dspkID); xlim((90e3,100e3)); savefig('gif/'+dstr+simstr+'rast.png')
xlim((490e3,500e3)); savefig('gif/'+dstr+simstr+'rast_b.png')
already much more hypersynchrony near the end ... 

clf(); drawcellVm(simConfig); xlim((90e3,100e3)); savefig('gif/'+dstr+simstr+'Vm.png')
xlim((490e3,500e3)); savefig('gif/'+dstr+simstr+'Vm_b.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

#
sim = '20may29_A0_falcor_'
pda = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
curt = 200e3
for sim,maxdur in zip(['20may30_A1_falcor_', '20jun1_A2_falcor_','20jun2_A3_falcor_'],[400e3,400e3,500e3]):
  tmp = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += curt
  curt += maxdur
  pda = pda.append(tmp)

#
clf()
plotFollowBall(pda,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(pda,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(pda,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf_total.png')

hmm...using total cumulative, still seems to be increasing ...

clf()
actreward = pda
action_times = np.array(actreward.time)
actionvsproposed = np.array(actreward.action-actreward.proposed)
Hit_Missed = np.array(actreward.hit)
followact = np.where(actionvsproposed==0,1,0)
nbin = int(1e3 / (action_times[1]-action_times[0]))
avgfollow = [mean(followact[sidx:sidx+nbin]) for sidx in arange(0,len(followact),nbin)]
plot(20*arange(0,len(followact),nbin), avgfollow)
savefig('gif/'+dstr+simstr+'perf_follow_ball_prob.png')

probability gradually increasing but lot of variability ... 

DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration']))

savefig('gif/'+dstr+simstr+'avg_weight.png')

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

so, not clear if worth continuing this sim ... since getting towards hypersynch at end ... 
can reduce RLhebbwt ... ? so weights stop increasing as quickly ... 

this was value used up to now: "RLhebbwt":0.000004
try
"RLhebbwt":0.000002
and also increase RLlenhebb from 100 to 200 ... see if reduces some of the bias towards EMUP

ok, restart as ... 20jun4_A4_falcor_

"name":"20jun4_A4_falcor_"

duration of 200 s ...

./myrun 12 sn.json

** check output from 20jun2_B3_falcor_ and continue as 20jun4_B4_falcor_ <<-- will not continue this one

python -i simdat.py backupcfg/20jun2_B3_falcor_sim.json

dstr = '20jun4_'; simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); xlim((390e3,400e3)); savefig('gif/'+dstr+simstr+'rast.png')
xlim((0,10e3)); savefig('gif/'+dstr+simstr+'rast_b.png')

clf(); drawcellVm(simConfig); xlim((390e3,400e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

#
sim = '20may29_B0_falcor_'
pda = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
curt = 200e3
for sim,maxdur in zip(['20may30_B1_falcor_', '20jun1_B2_falcor_','20jun2_B3_falcor_'],[400e3,400e3,500e3]):
  tmp = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += curt
  curt += maxdur
  pda = pda.append(tmp)

#
clf()
plotFollowBall(pda,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(pda,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(pda,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf_total.png')

clf()
actreward = pda
action_times = np.array(actreward.time)
actionvsproposed = np.array(actreward.action-actreward.proposed)
Hit_Missed = np.array(actreward.hit)
followact = np.where(actionvsproposed==0,1,0)
nbin = int(1e3 / (action_times[1]-action_times[0]))
avgfollow = [mean(followact[sidx:sidx+nbin]) for sidx in arange(0,len(followact),nbin)]
plot(20*arange(0,len(followact),nbin), avgfollow)
savefig('gif/'+dstr+simstr+'perf_follow_ball_prob.png')

DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration']))

savefig('gif/'+dstr+simstr+'avg_weight.png')

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

ok, restart as ... 20jun4_B4_falcor_

"name":"20jun4_B4_falcor_"

duration of 500 s ...

./myrun 12 sn.json

** architecture changes?

feedback connections
plast between EM pops
bigger net?

* 20jun5
** check output from 20jun4_A4_falcor_

python -i simdat.py backupcfg/20jun4_A4_falcor_sim.json

dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); xlim((190e3,200e3)); savefig('gif/'+dstr+simstr+'rast.png')
xlim((0,10e3)); savefig('gif/'+dstr+simstr+'rast_b.png')
it's not really doing better with these params ...

clf(); drawcellVm(simConfig); xlim((190e3,200e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

#
sim = '20may29_A0_falcor_'
pda = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
curt = 200e3
for sim,maxdur in zip(['20may30_A1_falcor_', '20jun1_A2_falcor_','20jun2_A3_falcor_','20jun4_A4_falcor_'],[400e3,400e3,500e3,200e3]):
  tmp = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += curt
  curt += maxdur
  pda = pda.append(tmp)

#
clf()
plotFollowBall(pda,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(pda,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(pda,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf_total.png')

clf()
actreward = pda
action_times = np.array(actreward.time)
actionvsproposed = np.array(actreward.action-actreward.proposed)
Hit_Missed = np.array(actreward.hit)
followact = np.where(actionvsproposed==0,1,0)
nbin = int(1e3 / (action_times[1]-action_times[0]))
avgfollow = [mean(followact[sidx:sidx+nbin]) for sidx in arange(0,len(followact),nbin)]
plot(20*arange(0,len(followact),nbin), avgfollow)
savefig('gif/'+dstr+simstr+'perf_follow_ball_prob.png')
not improvement

DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')
and some separation between weights, causing large bias in movement ... 

** try adjustment to recurrent connectivity between EMotor Pops

allow connectivity across the populations

also reduce the probability ... down to 0.1 ... 

for simplicity should also set the gains in file to 1.0 and adjust weights used accordingly ... 

  Cells: 5359
  Connections: 0 (0.00 per cell)
  Spikes: 930526 (1.74 Hz)
  Simulated time: 100.0 s; 12 workers
  Run time: 14030.12 s

python -i simdat.py backupcfg/20jun5_A0_falcor_sim.json

dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); xlim((90e3,100e3)); savefig('gif/'+dstr+simstr+'rast.png')

clf(); drawcellVm(simConfig); xlim((90e3,100e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

still bias ... 

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')

ok, so that approach did not help much . . . 

** adjust rewards?

more punishment?
"rewardcodes": {"scorePoint": 1, "losePoint": -0.1, "followBall": 0.1, "avoidBall": -0.01, "hitBall": 0.5},
to
"rewardcodes": {"scorePoint": 1, "losePoint": -1, "followBall": 0.1, "avoidBall": -0.1, "hitBall": 0.5},

** bigger network?

hmm, why ... 

** plasticity within premotor areas?

add option for it dconf['net']['EEPreMProb']  
and EEPreMWghtAM, EEPreNWghtNM

ok...see if it helps ... 

./myrun 16 sn.json

python -i simdat.py backupcfg/20jun5_B0_falcor_sim.json

dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); xlim((90e3,100e3)); savefig('gif/'+dstr+simstr+'rast.png')
clf(); drawcellVm(simConfig); xlim((90e3,100e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')

firing rates seem ok ... performance not great ... so maybe did not help ...

#
lpop = ['ER', 'EV1', 'EV4', 'EMT', 'IR', 'IV1', 'IV4', 'IMT','EV1DW','EV1DNW', 'EV1DN', 'EV1DNE','EV1DE','EV1DSW', 'EV1DS', 'EV1DSE','EMDOWN','EMUP']  
dact = getdActMap(totalDur, tstepPerAction, lpop)
fig, axs, plt = animActivityMaps()

...based on results of next entry below should rerun (proposed action invalid sometimes, leading to bias in up direction)...

** use noframeskip?? -->> there was a mistake in proposed action when ball not visible -->> fixed -- always check ball position first!

is frameskip making it more difficult to train model? frameskip > 1 means same action taken several times before updating

'PongNoFrameskip-v4'

20jun5_C0_falcor_

./myrun 16 sn.json

hmm, nothing happens ... no ball visible, though reward = 0.01 throughout 

python -i simdat.py backupcfg/20jun5_C0_falcor_sim.json

lpop = ['ER', 'EV1', 'EV4', 'EMT', 'IR', 'IV1', 'IV4', 'IMT','EV1DW','EV1DNW', 'EV1DN', 'EV1DNE','EV1DE','EV1DSW', 'EV1DS', 'EV1DSE','EMDOWN','EMUP']  
dact = getdActMap(totalDur, tstepPerAction, lpop)

fig, axs, plt = animActivityMaps()

hmm: gif/20jun5_C0_falcor_actmap.mp4

in that movie there was no movement, and ball was not present at all but the punishment signal of 0.01
was almost always there ... and there were two instances of 0.1 reward ...

dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string

plotRewards(actreward,ax=gca(),msz=3); 
ylim((-0.02,0.12))
savefig('gif/'+dstr+simstr+'reward.png')

hmm, this logic in aigame.py seems incorrect?

        if ypos_Racket>ypos_Ball: #if the racket is lower than the ball the suggestion is to move up
          proposed_action = dconf['moves']['UP'] #move up
        elif ypos_Racket<ypos_Ball: #if the racket is higher than the ball the suggestion is to move down
          proposed_action = dconf['moves']['DOWN'] #move down
        elif ypos_Racket==ypos_Ball:
          proposed_action = dconf['moves']['NOMOVE'] #no move
        elif ypos_Ball==-1: #guess about proposed move can't be made because ball was not visible in the court
          proposed_action = -1 #no valid action guessed

since when ball is not found (via aigame.findobj), its coordinates are -1,-1
racket could have valid coordinates but ball could have invalid coordinates ... 

also, note that lower values in the image array are closer to top
so moving 'up' means moving towards smaller y values (top of screen)

try again with this ordering:

        if ypos_Ball==-1: #guess about proposed move can't be made because ball was not visible in the court
          proposed_action = -1 #no valid action guessed        
        elif ypos_Racket>ypos_Ball: #if the racket is lower than the ball the suggestion is to move up
          proposed_action = dconf['moves']['UP'] #move up
        elif ypos_Racket<ypos_Ball: #if the racket is higher than the ball the suggestion is to move down
          proposed_action = dconf['moves']['DOWN'] #move down
        elif ypos_Racket==ypos_Ball:
          proposed_action = dconf['moves']['NOMOVE'] #no move

20jun5_C1_falcor_

in sim.py, this seems like a mistake too? 

      for ai in range(len(actions)):
        caction = actions[ai]
        cproposed_action = proposed_actions[ai]
        if caction - cproposed_action == 0:
          critic_for_following_ball += dconf['rewardcodes']['followBall'] #follow the ball
        else:
          critic_for_following_ball += dconf['rewardcodes']['avoidBall'] # didn't follow the ball

since does not check if proposed action is valid (not equal to -1)

ok, adjusted that too to check if proposed action == -1

try that again ...

hmm, maybe the incorrect check for ball position is why biased towards up moves? since racket usually on screen
and when ball off-screen has y position of -1, leading to proposed move being up ... 

python -i simdat.py backupcfg/20jun5_C1_falcor_sim.json

#
dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string
plotRewards(actreward,ax=gca(),msz=3); 
ylim((-0.02,0.12))
savefig('gif/'+dstr+simstr+'reward.png')

ok, now has 0 rewards ... so that's correct ... but still not clear
why frameskip of 1 with noframeskip version of pong not updating frames properly ... 

** run 20jun5_PreMRecurr_falcor_ (with premotor recurrent plasticity)

running for 300 s ...

    "architecturePreMtoM": {"useProbabilistic":1,"useTopological":0},
    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EMDOWN":400,"EMUP":400,"IM":200,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.00008,"EEMWghtNM":0.0000025,"EEPreMWghtAM":0.00008,"EEPreMWghtNM":0.0000025,"EEMWghtThreshMin":0.00004,"EEMWghtThreshMax":0.00016,"EEMProb":0.3,"EEMRecProb":0.1,"EEPreMProb":0.1,"EEMPopNorm":0,"EEMRecProbCross":1},

./myrun 12 sn.json

** run 20jun5_NoPreMRecurrCross_falcor_ (no premotor recurrent plasticity, no cross-EM population plasticity)

running for 300 s ...

    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EMDOWN":400,"EMUP":400,"IM":200,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.00008,"EEMWghtNM":0.0000025,"EEPreMWghtAM":0.00008,"EEPreMWghtNM":0.0000025,"EEMWghtThreshMin":0.00004,"EEMWghtThreshMax":0.00016,"EEMProb":0.3,"EEMRecProb":0.1,"EEPreMProb":0.0,"EEMPopNorm":0,"EEMRecProbCross":0},

./myrun 12 sn.json

** still need to check how to get frameskip==0 to work
* 20jun6
** check output from 20jun5_PreMRecurr_falcor_

python -i simdat.py backupcfg/20jun5_PreMRecurr_falcor_sim.json

dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r',binsz=10e3); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
savefig('gif/'+dstr+simstr+'perfB.png')

clf(); drawraster(dspkT,dspkID); xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'rast.png')
clf(); drawcellVm(simConfig); xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

still bias towards both top and bottom 

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')

slightly more towards down than up ...

worth continuing?? performance seems mostly flat ... 

hmm, is this right in plotFollowBall?
actionvsproposed = np.array(actreward.action-actreward.proposed)
is actreward.proposed ever -1?
np.amin(actreward.proposed) # -1.0
np.amin(actreward.action) # 1.0
still right for counting number of times model and proposed same, though not
for counting times model does not follow proposed since -1 a possible value for proposed and meaningless ...

** check output from 20jun5_NoPreMRecurrCross_falcor_

python -i simdat.py backupcfg/20jun5_NoPreMRecurrCross_falcor_sim.json

dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'rast.png')
clf(); drawcellVm(simConfig); xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')

this one not doing any better ... though generally less diff in weights to EMUP vs EMDOWN ...

** try same as last two but with targettedRL

worth checking in newer networks if targettedRL helps ... 

*** 20jun6_PreMRecurr_targetted_falcor_ 
*** 20jun6_NoPreMRecurrCross_targetted_falcor_
* 20jun7
** check output from 20jun6_PreMRecurr_targetted_falcor_ 

python -i simdat.py backupcfg/20jun6_PreMRecurr_targetted_falcor_sim.json

dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

is that doing etter than without targetted RL? might be a little better than 20jun6_20jun5_PreMRecurr_falcor_perf.png

clf(); drawraster(dspkT,dspkID); xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'rast.png')
clf(); drawcellVm(simConfig); xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

less bias at down position ...

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')

neither population dominates throughout; that's somewhat reassuring ... can continue ... see if improves ...

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

** check output from 20jun6_NoPreMRecurrCross_targetted_falcor_

python -i simdat.py backupcfg/20jun6_NoPreMRecurrCross_targetted_falcor_sim.json

dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'rast.png')
clf(); drawcellVm(simConfig); xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

** other problem with follow ball rule

what if ball is flying away from racket? the distance between racket and ball might increase even if the racket is 'following' the ball
e.g. ball moving up and to the left and racket moving up, but ball moving faster up than racket. so that might be a punishing action
instead of rewarding. could instead consider that it's best action compared to staying still or moving down. alternatively, ignore situations
when ball is moving away from the racket.

there are some calculations for checking if ball moving towards racket in aigame.py:

      observation, reward, done, info = self.env.step(caction)
      #find position of ball after action
      xpos_Ball2, ypos_Ball2 = self.findobj(observation, courtXRng, courtYRng)        
      if xpos_Ball>0 and xpos_Ball2>0:
        if xpos_Ball2-xpos_Ball>0:
          ball_moves_towards_racket = 1 #use proposed action for reward only when the ball moves towards the racket
          current_ball_dir = 1 
        elif xpos_Ball2-xpos_Ball<0:
          ball_moves_towards_racket = 0
          current_ball_dir = -1
        else:
          ball_moves_towards_racket = 0
          current_ball_dir = 0 #direction can't be determinted  prob. because the ball didn't move in x dir.
      else:
        ball_moves_towards_racket = 0
        current_ball_dir = 0 #direction can't be determined because either current or last position of the ball is outside the court

but ball_moves_towards_racket is not used anywhere ... 

added option to set proposed_action to -1 if that value in sn.json == 1:
    "followOnlyTowards": 1,

note that similar problem can occur when ball moving towards racket. even if it's getting farther away in
y direction, the model's action may have been best possible action selected and so should not be punished for it.
so, should compare which action minimizes error, and reward model if it took that action, punish otherwise.
will note to update aigame.py logic for that ... hmm, check more carefully if aigame.py implements that
logic already ... 

one other reason that follow ball rule seems not ideal is racket should move towards where ball will be when
it hits x coord of racket, which is not always minimizing current y difference between ball and racket. this
is especially true if ball bounces off top or bottom of court.

ok, anyway, follow ball rule makes some sense, though should be improved to use
movement towards/away from predicted y location where ball crosses racket x coordinate 

** add some noise to EM populations (new option)

that might desynchronize their activity ... how does it look with E and I noise to the EMUP,EMDOWN populations?

here's how to specify in the json file:
    "Noise":{"I":{"Rate":100,"Weight":0.00001},"E":{"Rate":50,"Weight":0.00001}}

./myrun 16 sn.json

python -i simdat.py backupcfg/20jun7_A0_falcor_sim.json

dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png')
clf(); drawcellVm(simConfig); savefig('gif/'+dstr+simstr+'Vm.png')

raster looks a bit too synched at times ... but other times noisy ... 

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')
first time saw average weights go up and then down ... ?? 

note that this is also with     "followOnlyTowards" == 1
could compare in both cases ... 

try another noise test first, with E Rate of 25 ...

python -i simdat.py backupcfg/20jun7_A0_falcor_sim.json

dstr = getdatestr(); simstr = dconf['sim']['name'] # date and sim string

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 
savefig('gif/'+dstr+simstr+'perf_B.png')

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast_B.png')
clf(); drawcellVm(simConfig); savefig('gif/'+dstr+simstr+'Vm_B.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight_B.png')

raster probably ok ... 

** top/bottom edge move rule?

if at top/bottom edge, prevent actuating further moves in that direction?

** feedback plasticity?
** longer run with noise to EMUP,EMDOWN and "followOnlyTowards" == 1

could have longer RLlenhebb of 200 ... since less frequent feedback about success

name: 20jun7_B0_falcor_
    "Noise":{"I":{"Rate":100,"Weight":0.00001},"E":{"Rate":25,"Weight":0.00001}}
    "followOnlyTowards": 1,

./myrun 16 sn.json

hmm, crashed at the very end with a memory error ... of course, recordWeightStepSize was 25!!
anyway, from viewing activity, did not look like model performance was too great ... 

* 20jun8
** right side rule for ball

follow vs not should also only apply until ball passes model racket (on right side)

** other run

compare performance when no intermediate rewards from follow vs not follow given?
since follow ball seems problematic ... watching videos shows that racket overshoots
sometimes and does not have time to adjust ... 

lower E noise ... looks less synched?

    "Noise":{"I":{"Rate":100,"Weight":0.00001},"E":{"Rate":0,"Weight":0.00001}}

./myrun 16 sn.json

python -i simdat.py backupcfg/20jun8_A0_falcor_sim.json

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png')

EM populations are less synchronized ... but the direction selective neurons fire too synchronously ... 

try an intermediate run ... 

seemed like when ball hit racket, there was no reward ... must have introduced a bug

python -i simdat.py backupcfg/20jun8_A0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png')
xlim((19e3,20e3)); savefig('gif/'+dstr+simstr+'rastB.png')

* 20jun9
** ha fixed follow ball rule

is working on updating it for calculating trajectory/intercept

** other test following ha fix -- paddle follows ball sometimes but over/under-shoots and gets stuck sometimes (20jun9_A0_falcor_)

adding other options for architecture adjustments
including "EEMFeedbackProb":0.05,"VisualFeedback":0
EEMFeedbackProb <- probability of feedback connections from EM to the premotor and visual excitatory neurons (apart from ER)
VisualFeedback <- whether to have feedback from higher to lower order visual areas (EV1->ER, EV4->EV1, etc.; and inhibitory feedback too)

try it out ... when running with feedback plasticity tends towards
hyperexcitability, so have to keep the weights and probabilities low (or off)

seems like paddle is following ball to some extent but tends to overshoot and
then has trouble stabilizing ... did this with lower probability from preM
to M ... 

./myrun 16 sn.json

python -i simdat.py backupcfg/20jun9_A0_falcor_sim.json

drawraster(dspkT,dspkID); 
savefig('gif/'+dstr+simstr+'rast.png')
xlim((9e3,10e3))
savefig('gif/'+dstr+simstr+'rastB.png')

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')

try longer run . . . 

similar pattern seen in much of the activity 
sometimes takes a while for racket to move to the right place but when it does the
ball has already changed location in vertical axis relative to paddle, so model
does not have time to reverse its course 
predicting intercept rule could avoid that problem
alternatively, it's possible equal reward/punishment for follow/not-follow might
allow model to respond faster ... ? or smaller weight chnages?

similarly, seeing racket oscillate around the ball moving above and then below but
often too late ... 

** same params but with smaller weight increments (RLhebbwt of 0.000001) (20jun9_B0_falcor_)

to see if avoids overshoots

./myrun 16 sn.json

* 20jun10
** check output from 20jun9_A0_falcor_ -->> continue as 20jun10_A1_falcor_

python -i simdat.py backupcfg/20jun9_A0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')
savefig('gif/'+dstr+simstr+'perfB.png')

clf(); drawraster(dspkT,dspkID); 
savefig('gif/'+dstr+simstr+'rast.png')
xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'rastB.png')
xlim((299e3,300e3)); savefig('gif/'+dstr+simstr+'rastC.png')

clf(); drawcellVm(simConfig); 
savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); 
savefig('gif/'+dstr+simstr+'avg_weight.png')

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

lpop = ['ER', 'EV1', 'EV4', 'EMT', 'IR', 'IV1', 'IV4', 'IMT','EV1DW','EV1DNW', 'EV1DN', 'EV1DNE','EV1DE','EV1DSW', 'EV1DS', 'EV1DSE','EMDOWN','EMUP']  
dact = getdActMap(totalDur, tstepPerAction, lpop)

fig, axs, plt = animActivityMaps() # gif/20jun9_A0_falcor_actmap.mp4

animSynWeights(pdf) # gif/20jun9_A0_falcor_weightmap.mp4

continue as 20jun10_A1_falcor_

./myrun 16 sn.json

** check output from 20jun9_B0_falcor_ (lower weight increments) -->> not as good as 20jun9_A0_falcor_

python -i simdat.py backupcfg/20jun9_B0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')
savefig('gif/'+dstr+simstr+'perfB.png')

this sim 20jun9_B0_falcor_ has not as many hits as 20jun9_A0_falcor_ and has lower follow ball probability

clf(); drawraster(dspkT,dspkID); 
savefig('gif/'+dstr+simstr+'rast.png')
xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'rastB.png')
xlim((299e3,300e3)); savefig('gif/'+dstr+simstr+'rastC.png')

clf(); drawcellVm(simConfig); 
savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')

will not continue this sim (20jun9_B0_falcor_) since not as good as 20jun9_A0_falcor_ ...



** try sim with no follow ball rewards? (20jun10_B0_falcor_)

and longer time constant for RL ... 

ok
    "rewardcodes": {"scorePoint": 1, "losePoint": -0.1, "followBall": 0.0, "avoidBall": 0.0, "hitBall": 0.5},    

"RLlenhebb":800

./myrun 16 sn.json

* 20jun11
** check output of 20jun10_A1_falcor_ and continue as 20jun11_A2_falcor_

python -i simdat.py backupcfg/20jun10_A1_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')
savefig('gif/'+dstr+simstr+'perfB.png') # improved slightly from 20jun10_20jun9_A0_falcor_perfB.png

clf(); drawraster(dspkT,dspkID); 
savefig('gif/'+dstr+simstr+'rast.png')
xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'rastB.png')
xlim((299e3,300e3)); savefig('gif/'+dstr+simstr+'rastC.png')

clf(); drawcellVm(simConfig); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
subplot(1,2,1); xlabel('Racket X position'); hist(dobjpos['racket'][:,0])
subplot(1,2,2); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

#
lpop = ['ER', 'EV1', 'EV4', 'EMT', 'IR', 'IV1', 'IV4', 'IMT','EV1DW','EV1DNW', 'EV1DN', 'EV1DNE','EV1DE','EV1DSW', 'EV1DS', 'EV1DSE','EMDOWN','EMUP']  
dact = getdActMap(totalDur, tstepPerAction, lpop)
fig, axs, plt = animActivityMaps() # 
animSynWeights(pdf) # 

continue as 20jun11_A2_falcor_

./myrun 16 sn.json

** check output from 20jun10_B0_falcor_ (sim with no follow ball rewards)

python -i simdat.py backupcfg/20jun10_B0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')
savefig('gif/'+dstr+simstr+'perfB.png') # 

seems to be performing similar to the model with follow ball rule ... similar number of
points, hits, and follow ball probability ... should draw cumulative of score/lose points too

plotScoreLoss(actreward,msz=3)
savefig('gif/'+dstr+simstr+'score.png') # 16 to 238

should combine with the hit miss plot instead ... hit is greater than score
since some hits are returned ... but miss ball is same as loss since any miss
results in point for opponent

plotHitMiss(actreward)
savefig('gif/'+dstr+simstr+'scorehitmiss.png') # 16 55 238

clf(); drawraster(dspkT,dspkID); 
savefig('gif/'+dstr+simstr+'rast.png')
xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'rastB.png')
xlim((299e3,300e3)); savefig('gif/'+dstr+simstr+'rastC.png')

clf(); drawcellVm(simConfig); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

#
lpop = ['ER', 'EV1', 'EV4', 'EMT', 'IR', 'IV1', 'IV4', 'IMT','EV1DW','EV1DNW', 'EV1DN', 'EV1DNE','EV1DE','EV1DSW', 'EV1DS', 'EV1DSE','EMDOWN','EMUP']  
dact = getdActMap(totalDur, tstepPerAction, lpop)
fig, axs, plt = animActivityMaps() # 
animSynWeights(pdf) # 

continue as 20jun11_B1_falcor_

./myrun 16 sn.json

** check performance for model w/o learning (RL off) (20jun11_C0_laptop_ , 20jun11_NORL_falcor_)

./myrun 12 sn.json

too slow on laptop ... try on falcor ...

./myrun 16 sn.json

python -i simdat.py backupcfg/20jun11_NORL_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3)
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')


clf(); drawraster(dspkT,dspkID); 
savefig('gif/'+dstr+simstr+'rast.png')

#
clf(); dobjpos = loadObjPos()
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')


** check output of 20jun11_A2_falcor_ and continue as 20jun11_A3_falcor_

python -i simdat.py backupcfg/20jun11_A2_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,msz=3,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,msz=3,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120)); 
plotRewards(actreward,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf.png')
savefig('gif/'+dstr+simstr+'perfB.png') # 

a little better than last run ... 

clf(); drawraster(dspkT,dspkID); 
savefig('gif/'+dstr+simstr+'rast.png')
xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'rastB.png')
xlim((299e3,300e3)); savefig('gif/'+dstr+simstr+'rastC.png')

#
clf(); dobjpos = loadObjPos()
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

#
#lpop = ['ER', 'EV1', 'EV4', 'EMT', 'IR', 'IV1', 'IV4', 'IMT','EV1DW','EV1DNW', 'EV1DN', 'EV1DNE','EV1DE','EV1DSW', 'EV1DS', 'EV1DSE','EMDOWN','EMUP']  
#dact = getdActMap(totalDur, tstepPerAction, lpop)
#fig, axs, plt = animActivityMaps() # 
#animSynWeights(pdf) # 

check all activity from past few A series sims ... 

#
sim = '20jun9_A0_falcor_'
pda = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
curt = 300e3
for sim,maxdur in zip(['20jun10_A1_falcor_','20jun11_A2_falcor_'],[300e3,300e3]):
  tmp = pd.DataFrame(np.loadtxt('data/'+sim+'ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
  tmp.time += curt
  curt += maxdur
  pda = pda.append(tmp)

#
clf()
plotFollowBall(pda,ax=subplot(1,3,1),msz=3); ylim((0.1,.16))
plotHitMiss(pda,ax=subplot(1,3,2),msz=3); 
plotRewards(pda,ax=subplot(1,3,3),msz=3); 

savefig('gif/'+dstr+simstr+'perf_tot.png')

it's increasing slightly 

could use a different metric based on positions - y-distance between ball and racket when ball
in right half, over time ... probability that racket and ball are within a tolerance given that
the ball is in right half of court, and see how that changes over time...

clf(); plot(np.sqrt((dobjpos['ball'][:,1]-dobjpos['racket'][:,1])**2))

continue as 20jun11_A3A_falcor_

but with 1/2 the I noise rate, to see if improves faster ... 
    "Noise":{"I":{"Rate":50,"Weight":0.00001},"E":{"Rate":0,"Weight":0.00001}}

./myrun 16 sn.json

stopped this one for now ... since running too many jobs on falcor ... may restart it later ... 

** check activity with somewhat lower I noise (20jun11_lowerI_laptop_)

myrun 12 sn.json

python -i simdat.py backupcfg/20jun11_lowerI_laptop_sim.json

drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png') # 20jun11_20jun11_lowerI_laptop_rast.png

seems like a bit too much synch ~1500 ms...

try intermediate - 75 Hz I instead (just tried 50 Hz now ... )

myrun 12 sn.json

python -i simdat.py backupcfg/20jun11_lowerI_laptop_sim.json

drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rastB.png') # 20jun11_20jun11_lowerI_laptop_rastB.png

looks decent ... no longer see hypersynch ~1500 ms (initial transient between 0-250 ms is ok)

try longer ...

./myrun 12 sn.json

would noise in other E populations help too ... ???

python -i simdat.py backupcfg/20jun11_lowerI_laptop_sim.json

drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rastC.png') # 20jun11_20jun11_lowerI_laptop_rastC.png

looks decent overall ...

** check output from 20jun11_B1_falcor_ (no follow ball rule, only score/loss and hit racket) -->> did not improve in hits,score

this one continued from 20jun10_B0_falcor_

python -i simdat.py backupcfg/20jun11_B1_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

(17, 56, 239) # score, hit, miss
17 to 239 and 56 hits; last sim (20jun10_B0_falcor_) had total of 16 to 238 and 55 hits ... so it did not improve 
but it does seem to be doing better than the one with intermediate rewards for follow/not-follow (20jun11_20jun11_A2_falcor_perf_tot.png)

savefig('gif/'+dstr+simstr+'perf.png')

subplot(1,3,1); ylim((0.1,0.16)); savefig('gif/'+dstr+simstr+'perfB.png') # 

clf(); drawraster(dspkT,dspkID); 
savefig('gif/'+dstr+simstr+'rast.png')
xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'rastB.png')
xlim((299e3,300e3)); savefig('gif/'+dstr+simstr+'rastC.png')

clf(); drawcellVm(simConfig); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

#
lpop = ['ER', 'EV1', 'EV4', 'EMT', 'IR', 'IV1', 'IV4', 'IMT','EV1DW','EV1DNW', 'EV1DN', 'EV1DNE','EV1DE','EV1DSW', 'EV1DS', 'EV1DSE','EMDOWN','EMUP']  
dact = getdActMap(totalDur, tstepPerAction, lpop)
fig, axs, plt = animActivityMaps() # 
animSynWeights(pdf) # 
quit()

probably no point continuing with the current parameters ... 

* 20jun12
** back to adjusting parameters (20jun12_A0_falcor_)

try with: "EEMFeedbackProb":0.05,"EEMFeedbackWghtAM":0.00001,"EEMFeedbackWghtNM":0.000001,"VisualFeedback":0
I Noise Rate of 75 (instead of previous 100)...
    "rewardcodes": {"scorePoint": 1, "losePoint": -0.1, "followBall": 0.0, "avoidBall": 0.0, "hitBall": 0.5},    
and longer RLlenhebb of 1600 ... 

20jun12_A0_falcor_

./myrun 16 sn.json

python -i simdat.py backupcfg/20jun12_A0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

savefig('gif/'+dstr+simstr+'perf.png')

no better than naive ... 

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png')
xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'rastB.png')
xlim((299e3,300e3)); savefig('gif/'+dstr+simstr+'rastC.png')

activity (raster) looks ok

** restarted NORL sim (control) (name=20jun12_NORL_falcor)

python -i simdat.py backupcfg/20jun12_NORL_falcorsim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

savefig('gif/'+dstr+simstr+'perf.png')

subplot(1,3,1); ylim((0.1,0.16)); savefig('gif/'+dstr+simstr+'perfB.png') # 

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png')
xlim((99e3,100e3)); savefig('gif/'+dstr+simstr+'rastB.png')

ok, so the naive NORL sim performs similarly to the sim with RL ... 

#
lpop = ['ER', 'EV1', 'EV4', 'EMT', 'IR', 'IV1', 'IV4', 'IMT','EV1DW','EV1DNW', 'EV1DN', 'EV1DNE','EV1DE','EV1DSW', 'EV1DS', 'EV1DSE','EMDOWN','EMUP']  
dact = getdActMap(totalDur, tstepPerAction, lpop)
fig, axs, plt = animActivityMaps() # 
quit()

** ddonofrio found PongNoFrameskip-v4 do not have to set frameskip

but should set repeat_action_probability == 0 
will have those as defaults

** less noise help?? (20jun12_B0_falcor_)

how about 0 I noise?

20jun12_B0_falcor_

python -i simdat.py backupcfg/20jun12_B0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png')
savefig('gif/'+dstr+simstr+'rast.png')

even without noise has very low activity levels ...

./myrun 16 sn.json

python -i simdat.py backupcfg/20jun12_C0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png')
savefig('gif/'+dstr+simstr+'rast.png')

clf(); drawcellVm(simConfig); savefig('gif/'+dstr+simstr+'Vm.png')

** ha added new target tracking rule

instead of ball following rule

new rewardcodes are followTarget and avoidTarget
when     "useRacketPredictedPos": 1, uses the new rule, otherwise uses the old followball rule

** still adjusting params 

20jun12_E0_falcor_

./myrun 16 sn.json

stopped in middle - cannot tell if U,D firing rates correctly controlling racket ... 
some cases when racket was supposed to move one way based on U,D rates and get certain
reward, looked like it moved in opposite direction ... 

try simple test of only allowing up moves ... ok, worked ... hmm ... 
adjust tau to 200, equal follow avoid reward (.25, -.25) ... 

    "rewardcodes": {"scorePoint": 1.0, "losePoint": -1.0, "followTarget": 0.25, "avoidTarget": -0.25, "hitBall": 0.5},    

and increased some of the connectivity ... 10 s sim had decent rates ... avg for EMUP,EMDOWN was ~1 Hz ...

    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EMDOWN":400,"EMUP":400,"IM":200,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.00016,"EEMWghtNM":0.0000050,"EEPreMWghtAM":0.00008,"EEPreMWghtNM":0.0000025,"EEMWghtThreshMin":0.00004,"EEMWghtThreshMax":0.00032,"EEMProb":0.2,"EEMRecProb":0.125,"EEPreMProb":0.0625,"EEMPopNorm":0,"EEMRecProbCross":0,"EEMFeedbackProb":0.125,"EEMFeedbackWghtAM":0.000025,"EEMFeedbackWghtNM":0.0000025,"VisualFeedback":0},

ok, try 300 s sim ... 

./myrun 16 sn.json

python -i simdat.py backupcfg/20jun12_E0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k'); ylim((0,.6))
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=False,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png')
savefig('gif/'+dstr+simstr+'rast.png')

clf(); drawcellVm(simConfig); savefig('gif/'+dstr+simstr+'Vm.png')

** decaying integrated spike rates?

to control moves more smoothly ... ?

so integrate weights and have discounting factor, then compare totals to decide movement ...
but that would make it difficult to hold still ... unless have difference margin 

* 20jun13
** wrong normalization in plotFollowBall 

noticed that had wrong normalization in plotFollowBall leading to incorrect probability
estimate in plotFollowBall

was dividing by all actions regardless of whether an action could be suggested/proposed (which leads
to reward vs punishment); instead should only count correct actions normalized to the subset of
validly suggested actions ... that means the plotFollowBall figures above were all incorrect ...
shape could be correct but value was an underestimate of model accuracy, particularly since
introduction of proposed actions only when ball on screen and when ball moving towards target

** check output from 20jun12_E0_falcor_ -->> with fix for probabilities looks better but doesnt seem to improve over time

python -i simdat.py backupcfg/20jun12_E0_falcor_sim.json


#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

savefig('gif/'+dstr+simstr+'perf.png')

still does not seem to improve ... 

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png')
do rates differ from what started with?
xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'rast.png')
xlim((299e3,300e3)); savefig('gif/'+dstr+simstr+'rastC.png')
xlim((9e3,10e3)); savefig('gif/'+dstr+simstr+'rastD.png')

clf(); drawcellVm(simConfig); savefig('gif/'+dstr+simstr+'Vm.png')

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')

average weights decreasing, haven't seen that trend before ... 

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

worth looking at the activity ... 

#
lpop = ['ER', 'EV1', 'EV4', 'EMT', 'IR', 'IV1', 'IV4', 'IMT','EV1DW','EV1DNW', 'EV1DN', 'EV1DNE','EV1DE','EV1DSW', 'EV1DS', 'EV1DSE','EMDOWN','EMUP']  
dact = getdActMap(totalDur, tstepPerAction, lpop)
fig, axs, plt = animActivityMaps() # 
animSynWeights(pdf) # 
quit()

and maybe continuing the simulation ... 

continue as ... 
    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20jun12_E0_falcor_synWeights_final.pkl"}, 
20jun13_E1_falcor_

* 20jun14
** check output from 20jun13_E1_falcor_

python -i simdat.py backupcfg/20jun13_E1_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

savefig('gif/'+dstr+simstr+'perf.png') # 'gif/20jun14_20jun13_E1_falcor_perf.png' (4, 15, 81)

looks like it's doing worse than last run: 20jun13_20jun12_E0_falcor_perf.png (6, 20, 74)

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png') # 'gif/20jun14_20jun13_E1_falcor_rast.png'
now firing rates much lower than last run: 20jun13_20jun12_E0_falcor_rast.png ... so that means too much punishment ... ? 

xlim((290e3,300e3)); savefig('gif/'+dstr+simstr+'rast.png')
xlim((299e3,300e3)); savefig('gif/'+dstr+simstr+'rastC.png')

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')

average weights continued decreasing

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

may as well start a different simulation ... with different reward scores ... less punishment ... 

** sensitivity analysis

is there incremental improvement in scores, following target when varying specific connectivity parameters? checking that would at least 
provide ~simple test of performance and narrowing in on what might matter ... 

** differnet simulation with same architecture as 20jun13_E1_falcor_ but lower punishment values/scores (20jun14_A0_falcor_)

try these values:
    "rewardcodes": {"scorePoint": 1.0, "losePoint": -0.1, "followTarget": 0.25, "avoidTarget": -0.01, "hitBall": 0.5},    

    "followOnlyTowards": 1,
    "useRacketPredictedPos": 1,

can run for 150 s ... see if it's improving compared to previous sim at same times ... 

./myrun 16 sn.json

** control simulation for 20jun14_A0_falcor_ (20jun14_A0_control_falcor_)

everything the same but saveweight==0 and RLon==0

* 20jun15
** check output from 20jun14_A0_control_falcor_

python -i simdat.py backupcfg/20jun14_A0_control_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

over 150 s score, hit, miss: 1, 9, 42

savefig('gif/'+dstr+simstr+'perf.png') # 20jun15_20jun14_A0_control_falcor_perf.png

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png') # 20jun15_20jun14_A0_control_falcor_rast.png

xlim((140e3,150e3)); savefig('gif/'+dstr+simstr+'rastB.png')
xlim((149e3,150e3)); savefig('gif/'+dstr+simstr+'rastC.png')
xlim((9e3,10e3)); savefig('gif/'+dstr+simstr+'rastD.png')

even without RL gets ~hypersynchronized with decent overall firing rates

** check output from 20jun14_A0_falcor_

python -i simdat.py backupcfg/20jun14_A0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

savefig('gif/'+dstr+simstr+'perf.png') # 20jun15_20jun14_A0_falcor_perf.png

over 150 s score, hit, miss: 3, 9, 41

so it's very different from the control sim, has slightly better performance and very different
trajectory of follow target probabilities ... but may need to adjust params so don't get the dip 
in performance

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png') # 20jun15_20jun14_A0_falcor_rast.png
xlim((140e3,150e3)); savefig('gif/'+dstr+simstr+'rastB.png')
xlim((149e3,150e3)); savefig('gif/'+dstr+simstr+'rastC.png')
xlim((9e3,10e3)); savefig('gif/'+dstr+simstr+'rastD.png')
xlim((29e3,30e3)); savefig('gif/'+dstr+simstr+'rastE.png')

ok, might not be learning properly - could just be due to hypersynchrony and then recovery from hypersynchrony ... 

clf(); DOWNwts,UPwts = plotMeanWeights(pdf, gca(), xl=(0,simConfig['simConfig']['duration'])); savefig('gif/'+dstr+simstr+'avg_weight.png')

performance follows weights ... so if the weights increase too much, will probably lead to hypersynch again ... 

and at least part of that is likely due to feedback plasticity ... 

## pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

actcontrol = pd.DataFrame(np.loadtxt('data/20jun14_A0_control_falcor_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

#
clf()
plotFollowBall(actreward,ax=gca(),cumulative=True,color='r'); ylim((0.1,.4)); plotFollowBall(actcontrol,ax=gca(),cumulative=True,color='b'); ylim((0.1,.4));

savefig('gif/20jun15_20jun14_A0_falcor_compare_RLhypersynch_control_perf_a0.png')

good to know that the control sim moves towards ~0.33 probability which makes sense given 3 actions and it's behaving randomly ...

clf(); popwts = plotMeanWeights(pdf,gca(),msz=3,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EV1','EV4','EMT'],lclr=['r','b','g','c','m'])

savefig('gif/'+dstr+simstr+'avg_weightB.png')

ok, so the EM weights highest, others in V areas and preM lower; most of the average weights follow same pattern of rise then decay then rise ...

for next sim could reduce feedback weights

** adjust sim parameters (20jun15_A0_falcor_)

reduce the feedback connectivity probability and weight...

    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EMDOWN":400,"EMUP":400,"IM":200,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.00016,"EEMWghtNM":0.0000050,"EEPreMWghtAM":0.00008,"EEPreMWghtNM":0.0000025,"EEMWghtThreshMin":0.00000625,"EEMWghtThreshMax":0.00032,"EEMProb":0.15,"EEMRecProb":0.1,"EEPreMProb":0.05,"EEMPopNorm":0,"EEMRecProbCross":0,"EEMFeedbackProb":0.05,"EEMFeedbackWghtAM":0.0000125,"EEMFeedbackWghtNM":0.00000125,"VisualFeedback":0},

adjust reward values:
    "rewardcodes": {"scorePoint": 1.0, "losePoint": -0.1, "followTarget": 0.1, "avoidTarget": -0.01, "hitBall": 0.5},    

first will run 50 s sim to make sure doesn't get epileptic ... 

./myrun 16 sn.json

python -i simdat.py backupcfg/20jun15_A0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

savefig('gif/'+dstr+simstr+'perf.png') # 

so it's very different from the control sim, has slightly better performance and very different
trajectory of follow target probabilities ... but may need to adjust params so don't get the dip 
in performance

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png') # 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=3,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EV1','EV4','EMT'],lclr=['r','b','g','c','m'])
savefig('gif/'+dstr+simstr+'avg_weight.png')


** control sim (20jun15_A0_control_falcor_)

python -i simdat.py backupcfg/20jun15_A0_control_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

savefig('gif/'+dstr+simstr+'perf.png') # 20jun15_20jun15_A0_control_falcor_perf.png

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png') # 20jun15_20jun15_A0_control_falcor_rast.png

even without RL, there's a big spike ~10 s ... and the EMUP,EMDOWN rate is higher ... 

compare perf against the model with learning ...

actcontrol = pd.DataFrame(np.loadtxt('data/20jun15_A0_control_falcor_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn = pd.DataFrame(np.loadtxt('data/20jun15_A0_falcor_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

clf(); plotFollowBall(actlearn,ax=gca(),cumulative=True,color='r'); ylim((0.2,.4)); plotFollowBall(actcontrol,ax=gca(),cumulative=True,color='b'); ylim((0.2,.4));
savefig('gif/20jun15_20jun15_A0_falcor_compare_learn_control_perf_a0.png')
learn and control look pretty similar ... learn slightly higher prob of following target in period around 10 s ... 

#
clf()
plotHitMiss(actlearn,ax=subplot(1,2,1)); ylim((0,14));
plotHitMiss(actcontrol,ax=subplot(1,2,2)); ylim((0,14));
savefig('gif/20jun15_20jun15_A0_falcor_compare_learn_control_hitmiss_a1.png')
looks pretty similar too ... control might be a little 'better' in lower number of misses and higher number
of hits , though learning model has higher score (could be random)... 

** continue model (20jun15_A0_falcor_ as 20jun15_A1_falcor_) to see if improves at all

python -i simdat.py backupcfg/20jun15_A0_falcor_sim.json 

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

* 20jun16
** check output from 20jun15_A1_falcor_

python -i simdat.py backupcfg/20jun15_A1_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

savefig('gif/'+dstr+simstr+'perf.png') # 'gif/20jun16_20jun15_A1_falcor_perf.png'

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png') # 

#
actcontrol = pd.DataFrame(np.loadtxt('data/20jun15_A0_control_falcor_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn0 = pd.DataFrame(np.loadtxt('data/20jun15_A0_falcor_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn1 = pd.DataFrame(np.loadtxt('data/20jun15_A1_falcor_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn1.time += 50e3
pda = actlearn0; pda = pda.append(actlearn1)
                                         
clf(); plotFollowBall(pda,ax=gca(),cumulative=True,color='r'); ylim((0.2,.4)); plotFollowBall(actcontrol,ax=gca(),cumulative=True,color='b'); ylim((0.2,.4));
xlim((0,250e3))
savefig('gif/20jun16_compare_learn_control_perf_a0.png')

looks mostly random ...

#
clf()
plotHitMiss(pda,ax=subplot(1,2,1)); ylim((0,70));
plotHitMiss(actcontrol,ax=subplot(1,2,2)); ylim((0,70));

savefig('gif/20jun16_compare_learn_control_hitmiss_a1.png')

ok, not doing too well

** discussion with ha to make plan

1. test reduced architecture (get rid of V4, MT)
2. test increased connection to EMDOWN,EMUP (closer to full connectivity - to make sure motor neurons receiving right information)
3. test specific image input sequences after learning - to test whether neurons learned properly
4. is our stdp.mod testing sufficiently? could it be improved/adjusted?

** option to get rid of V4, MT

can just set number of those neurons to 0?

    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":100,"IV4":25,"EMT":25,"IMT":9,"EMDOWN":400,"EMUP":400,"IM":200,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.00016,"EEMWghtNM":0.0000050,"EEPreMWghtAM":0.00008,"EEPreMWghtNM":0.0000025,"EEMWghtThreshMin":0.00000625,"EEMWghtThreshMax":0.00032,"EEMProb":0.15,"EEMRecProb":0.1,"EEPreMProb":0.05,"EEMPopNorm":0,"EEMRecProbCross":0,"EEMFeedbackProb":0.05,"EEMFeedbackWghtAM":0.0000125,"EEMFeedbackWghtNM":0.00000125,"VisualFeedback":0},

see if that works ... seems to work after fix to connUtils.py functions checking for 0 number of pre,post neurons

ok ... 

** try higher connectivity to EM (100%) only 2 neurons, one per direction; 20jun16_B0_falcor_

since using high connectivity (100%) do not need many EM neurons (all receive same inputs)
try 16 of each ... or even 1 of each (that produces error in run), so 16 for now ... fast to run ...
can get down to 1 of each EM (and 1 IM) after fix to getfiringrateinterval checking for 0 cells of a type...
also have to fixup simdat.py ... to check for 0 pop size ... 

after watching it for a while, seems to get stuck not being able to move up ... problem with
1 neuron per direction is can't fire as rapidly or have as diverse output encoding ... only
4 possibilities at each timestep with 2 total EM neurons ... 

python -i simdat.py backupcfg/20jun16_B0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

savefig('gif/'+dstr+simstr+'perf.png') # 

clf(); drawraster(dspkT,dspkID); 
savefig('gif/'+dstr+simstr+'rast.png') # 

clf(); drawcellVm(simConfig); 
savefig('gif/'+dstr+simstr+'Vm.png')

** high connectivity to EM (100%); 16 neurons per direction - some I noise; 20jun16_C0_falcor_

some minor I noise may allow the 16 neurons to learn slightly differently ... 

run for 200 s ...

* 20jun17
** check output from 20jun16_C0_falcor_

python -i simdat.py backupcfg/20jun16_C0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

savefig('gif/'+dstr+simstr+'perf.png') # 

looks like probability jumps up around 25 s ... after that stays mostly flat

clf(); drawraster(dspkT,dspkID); 
savefig('gif/'+dstr+simstr+'rast.png') # 
all M cells firing together...
xlim((5e3,15e3))
savefig('gif/'+dstr+simstr+'rastB.png') # 
xlim((8e3,12e3))
savefig('gif/'+dstr+simstr+'rastC.png') # 
well, not exactly at same time...

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN']); 
xlim((0,10e3))
savefig('gif/'+dstr+simstr+'Vm.png')
xlim((190e3,200e3))
savefig('gif/'+dstr+simstr+'VmB.png')
by end of simulation there's less correlation between those two cell spike times ... 
that's a measure that we should track to make sure the populations differ ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=3,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b','g','c','m'])
savefig('gif/'+dstr+simstr+'avg_weight.png')

EMDOWN winning by a lot, which is why racket stays at bottom ... worth comparing to the targetted RL rule ...

np.amax

#
clf()
for pdx,pop in enumerate(['EMDOWN','EMUP']):
  subplot(2,1,pdx+1); title('->'+pop)
  pdfs = pdf[(pdf.postid>=dstartidx[pop])&(pdf.postid<=dendidx[pop])]
  ncol = np.unique(pdfs['time']).shape[0]
  nrow = int(pdfs['weight'].shape[0] / ncol)
  imshow(np.reshape(np.array(pdfs['weight']),(nrow,ncol)),extent=(0,200e3,0,nrow),interpolation='None',cmap='jet')
  colorbar()

savefig('gif/'+dstr+simstr+'_allwght.png')

look somewhat similar overall, though difficult to tell ... 

#
clf()
gdx=1
for pdx,pop in enumerate(['EMDOWN','EMUP']):
  for idx in range(dstartidx[pop],dendidx[pop]+1,1):
    subplot(8,4,gdx); title('->'+pop)
    pdfs = pdf[(pdf.postid>=idx)&(pdf.postid<=idx)]
    ncol = np.unique(pdfs['time']).shape[0]
    nrow = int(pdfs['weight'].shape[0] / ncol)
    imshow(np.reshape(np.array(pdfs['weight']),(nrow,ncol)),extent=(0,200e3,0,nrow),interpolation='None',cmap='jet')
    colorbar()
    gdx+=1
  
#
dw={}
for pdx,pop in enumerate(['EMDOWN','EMUP']):
  dw[pop]=[]
  for idx in range(dstartidx[pop],dendidx[pop]+1,1):
    pdfs = pdf[(pdf.postid>=idx)&(pdf.postid<=idx)]
    ncol = np.unique(pdfs['time']).shape[0]
    nrow = int(pdfs['weight'].shape[0] / ncol)
    dw[pop].append(np.array(pdfs.weight))

from scipy.stats import pearsonr

#
dR = {}
for pop in ['EMDOWN','EMUP']:
  dR[pop]=[]
  for idx,idf in enumerate(dw[pop]):
    for jdx,jdf in enumerate(dw[pop]):
      if jdx>idx:
        dR[pop].append(pearsonr(idf,jdf)[0])

mean(dR['EMDOWN']) # 0.7449948387935842 
mean(dR['EMUP']) # 0.6385154461653857

so there's some variability in the weights ... 

#
for pop1 in ['EMDOWN']:
  for pop2 in ['EMUP']:
    dR[pop1+'->'+pop2]=[]
    for idx,idf in enumerate(dw[pop1]):
      for jdx,jdf in enumerate(dw[pop2]):
        dR[pop1+'->'+pop2].append(pearsonr(idf,jdf)[0])

mean(dR['EMDOWN->EMUP']) # 0.6902693693719086

so that's pretty high similarity across the populations, compared to similarity within EMUP population

would probably want the two populations to have some divergence in the information emphasized ... 

does that highlight benefit of targetted rule?

lpop = ['ER', 'EV1', 'EV4', 'EMT', 'IR', 'IV1', 'IV4', 'IMT','EV1DW','EV1DNW', 'EV1DN', 'EV1DNE','EV1DE','EV1DSW', 'EV1DS', 'EV1DSE','EMDOWN','EMUP']  
dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4')

#fig, axs, plt = animActivityMaps() # 
#animSynWeights(pdf) # 

** compare last sim (20jun16_C0_falcor_) with targetted RL (20jun17_C0_targetted_falcor_) , continue as 20jun17_C1_targetted_falcor

python -i simdat.py backupcfg/20jun17_C0_targetted_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

savefig('gif/'+dstr+simstr+'perf.png') # 

(1, 4, 62)

interesting ... that seems a lot better - rises in beginning, but then drops from 75 - 125 ... 

clf(); drawraster(dspkT,dspkID); 
savefig('gif/'+dstr+simstr+'rast.png') # 
xlim((70e3,80e3))
savefig('gif/'+dstr+simstr+'rastB.png') # 
xlim((135e3,145e3))
savefig('gif/'+dstr+simstr+'rastC.png') # 

probably because weights went down, and neurons stopped firing ...

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN']); 
savefig('gif/'+dstr+simstr+'Vm.png')

clf(); popwts = plotMeanWeights(pdf,gca(),msz=3,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'])
savefig('gif/'+dstr+simstr+'avg_weight.png')
weights diverge even more ... probably too much?

#
clf()
for pdx,pop in enumerate(['EMDOWN','EMUP']):
  subplot(2,1,pdx+1); title('->'+pop)
  pdfs = pdf[(pdf.postid>=dstartidx[pop])&(pdf.postid<=dendidx[pop])]
  ncol = np.unique(pdfs['time']).shape[0]
  nrow = int(pdfs['weight'].shape[0] / ncol)
  imshow(np.reshape(np.array(pdfs['weight']),(nrow,ncol)),extent=(0,200e3,0,nrow),interpolation='None',cmap='jet')
  colorbar()

savefig('gif/'+dstr+simstr+'_allwght.png')

  
#
dw={}
for pdx,pop in enumerate(['EMDOWN','EMUP']):
  dw[pop]=[]
  for idx in range(dstartidx[pop],dendidx[pop]+1,1):
    pdfs = pdf[(pdf.postid>=idx)&(pdf.postid<=idx)]
    ncol = np.unique(pdfs['time']).shape[0]
    nrow = int(pdfs['weight'].shape[0] / ncol)
    dw[pop].append(np.array(pdfs.weight))

from scipy.stats import pearsonr

#
dR = {}
for pop in ['EMDOWN','EMUP']:
  dR[pop]=[]
  for idx,idf in enumerate(dw[pop]):
    for jdx,jdf in enumerate(dw[pop]):
      if jdx>idx:
        dR[pop].append(pearsonr(idf,jdf)[0])

mean(dR['EMDOWN']) # 0.8013999327206577
mean(dR['EMUP']) # 0.6545299428996271

#
for pop1 in ['EMDOWN']:
  for pop2 in ['EMUP']:
    dR[pop1+'->'+pop2]=[]
    for idx,idf in enumerate(dw[pop1]):
      for jdx,jdf in enumerate(dw[pop2]):
        dR[pop1+'->'+pop2].append(pearsonr(idf,jdf)[0])

mean(dR['EMDOWN->EMUP']) # 0.10102358520733701

much less similar now ... 

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

can continue ... as 20jun17_C1_targetted_falcor ... hmm, no point probably ... 

** check output from sim with 1 EM neuron of each type (20jun16_B0_falcor_sim.json)

python -i simdat.py backupcfg/20jun16_B0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

(6, 17, 251)

savefig('gif/'+dstr+simstr+'perf.png') # 

looks like probability gradually increases up to t=200e3 ... after that stays mostly flat
looks similar to other sim with 16 EM neurons of each type

clf(); drawraster(dspkT,dspkID); 
savefig('gif/'+dstr+simstr+'rast.png') # 
xlim((5e3,15e3)); savefig('gif/'+dstr+simstr+'rastB.png') # 
xlim((8e3,12e3)); savefig('gif/'+dstr+simstr+'rastC.png') # 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN']); 
xlim((0,10e3)); savefig('gif/'+dstr+simstr+'Vm.png')
xlim((790e3,800e3)); savefig('gif/'+dstr+simstr+'VmB.png')

clf(); popwts = plotMeanWeights(pdf,gca(),msz=3,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b','g','c','m'])
savefig('gif/'+dstr+simstr+'avg_weight.png')

same pattern as other model ... early initial bias sets stage for rest of simulation ... 

how do the weights correlate?

#
dw={}
for pdx,pop in enumerate(['EMDOWN','EMUP']):
  dw[pop]=[]
  for idx in range(dstartidx[pop],dendidx[pop]+1,1):
    pdfs = pdf[(pdf.postid>=idx)&(pdf.postid<=idx)]
    ncol = np.unique(pdfs['time']).shape[0]
    nrow = int(pdfs['weight'].shape[0] / ncol)
    dw[pop].append(np.array(pdfs.weight))

from scipy.stats import pearsonr

dR = {}
#
for pop1 in ['EMDOWN']:
  for pop2 in ['EMUP']:
    dR[pop1+'->'+pop2]=[]
    for idx,idf in enumerate(dw[pop1]):
      for jdx,jdf in enumerate(dw[pop2]):
        dR[pop1+'->'+pop2].append(pearsonr(idf,jdf)[0])

mean(dR['EMDOWN->EMUP']) # {'EMDOWN->EMUP': [0.1665834150590529]}

that's much different from other sim ... here there's a much different pattern of weights ...

#
clf()
gdx=1
for pdx,pop in enumerate(['EMDOWN','EMUP']):
  for idx in range(dstartidx[pop],dendidx[pop]+1,1):
    figure(); title('->'+pop)
    pdfs = pdf[(pdf.postid>=idx)&(pdf.postid<=idx)]
    ncol = np.unique(pdfs['time']).shape[0]
    nrow = int(pdfs['weight'].shape[0] / ncol)
    imshow(np.reshape(np.array(pdfs['weight']),(nrow,ncol)),extent=(0,800e3,0,nrow),interpolation='None',cmap='jet')
    #colorbar()
    gdx+=1

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4')

** try single EM neuron of each pop but with targetted RL

20jun17_B0_targetted_falcor_

only run for 200 s ...

python -i simdat.py backupcfg/20jun17_B0_targetted_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

(3, 5, 60)

savefig('gif/'+dstr+simstr+'perf.png') # 

similar to without targetted ... but worse than sim with 16 neurons ... 

clf(); drawraster(dspkT,dspkID); 
savefig('gif/'+dstr+simstr+'rast.png') # 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN']); 
savefig('gif/'+dstr+simstr+'Vm.png')

follow target mostly seems random and just a question of firing rate ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=3,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b','g','c','m'])
savefig('gif/'+dstr+simstr+'avg_weight.png')

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)

** do 32 EM (X2) neurons perform better than 16?

    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":0,"IV4":0,"EMT":0,"IMT":0,"EMDOWN":32,"EMUP":32,"IM":16,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.0000075,"EEMWghtNM":0.000001,"EEPreMWghtAM":0.00008,"EEPreMWghtNM":0.0000025,"EEMWghtThreshMin":0.00000625,"EEMWghtThreshMax":0.00032,"EEMProb":1.0,"EEMRecProb":0.0,"EEPreMProb":0.0,"EEMPopNorm":0,"EEMRecProbCross":0,"EEMFeedbackProb":0.0,"EEMFeedbackWghtAM":0.0000125,"EEMFeedbackWghtNM":0.00000125,"VisualFeedback":0},

well, so far no evidence that even the 16 can perform past chance/noise levels ... 

*** targetted: 20jun17_D0_targetted_falcor_
*** non-targetted: 20jun17_D0_falcor_
** remove the I noise, introduce other minor variability (20jun17_E0_falcor_)

can have < 100% connectivity - 75%, remove the I noise, and have some recurrent conn too (75%)...

20jun17_E0_falcor_

    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":0,"IV4":0,"EMT":0,"IMT":0,"EMDOWN":16,"EMUP":16,"IM":8,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.000012,"EEMWghtNM":0.0000012,"EEPreMWghtAM":0.00008,"EEPreMWghtNM":0.0000025,"EEMWghtThreshMin":0.00000625,"EEMWghtThreshMax":0.00032,"EEMProb":0.75,"EEMRecProb":0.75,"EEPreMProb":0.0,"EEMPopNorm":0,"EEMRecProbCross":0,"EEMFeedbackProb":0.0,"EEMFeedbackWghtAM":0.0000125,"EEMFeedbackWghtNM":0.00000125,"VisualFeedback":0},

python -i simdat.py backupcfg/20jun17_E0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

savefig('gif/'+dstr+simstr+'perf.png') # 

clf(); drawraster(dspkT,dspkID); 
savefig('gif/'+dstr+simstr+'rast.png') # 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN']); 
savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)

** and same thing but targetted (20jun17_E0_targetted_falcor_)

python -i simdat.py backupcfg/20jun17_E0_targetted_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

savefig('gif/'+dstr+simstr+'perf.png') # 

clf(); drawraster(dspkT,dspkID); 
savefig('gif/'+dstr+simstr+'rast.png') # 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN']); 
savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)


* 20jun18
** check output from 20jun17_E0_targetted_falcor_ (seems to be improcing; continue as 20jun18_E1_targetted_falcor_)

python -i simdat.py backupcfg/20jun17_E0_targetted_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

savefig('gif/'+dstr+simstr+'perf.png') # 

looks like improving - but will it go beyond 0.33 chance if continues?

score,hit,miss: (13, 36, 217)

clf(); drawraster(dspkT,dspkID); 
savefig('gif/'+dstr+simstr+'rast.png') # 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN']); 
savefig('gif/'+dstr+simstr+'Vm.png')

drops in tracking appear when lower rates occur ... 

#
clf(); dobjpos = loadObjPos()
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

less bias than have seen in other sims ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=3,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'])
savefig('gif/'+dstr+simstr+'avg_weight.png')
and there is divergence between the weights to the two EM populations ... 

for pop,clr in zip(['EMUP','EMDOWN'],['b','r']):
  for idx in range(dstartidx[pop],dendidx[pop]+1,1):
    plotMeanNeuronWeight(pdf,idx,clr=clr)

popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'])
xlabel('Time (ms)')
some variability within and across populations ... overlap in average weights of individual neurons tends to occur more as time progresses
there's also more spread between average weights, even within a population, as simulation progresses...

savefig('gif/'+dstr+simstr+'all_avg_weight.png')

will be interesting/useful to also look at full weight maps ... 

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)

worth continuing this one ... 

continue as 20jun18_E1_targetted_falcor_

    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20jun17_E0_targetted_falcor_synWeights_final.pkl"}, 

./myrun 16 sn.json

started ~16:09 ... 

** check output from 20jun17_E0_falcor_

python -i simdat.py backupcfg/20jun17_E0_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

savefig('gif/'+dstr+simstr+'perf.png') # 

score, hit, miss: (1, 1, 272)
not improving much, well a bit, but pretty slowly ... why so much worse than targetted (above)?

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png') # 
well, firing rates of the two populations are very different - is it due to chance in the evolution
of weights or specific to differences between targetted vs non-targetted RL?
xlim((790e3,800e3))
savefig('gif/'+dstr+simstr+'rastB.png') # 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN']); 
savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

and of course, spent whole time in one spot ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); savefig('gif/'+dstr+simstr+'all_avg_weight.png')

interesting how much closer the weights are together but even that small bias with UP having higher weights means paddle
stays at top of screen for most of the simulation ... 

probably no point continuing this simulation ... but seems problematic that it could enter such a bad state ... where no longer moves...

## pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb')) 

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)

** meanwhile, try a control sim (20jun18_E0_control_falcor_)

started ~16:55 ... 

* 20jun19
** check output from next step of targetted RL sim (20jun18_E1_targetted_falcor_)

python -i simdat.py backupcfg/20jun18_E1_targetted_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

score, hit, miss: (17, 48, 209)

so that improved from first step of the sim: score,hit,miss: (13, 36, 217)

improved a lot for hits ...

savefig('gif/'+dstr+simstr+'perf.png') # 

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png') # 
xlim((790e3,800e3)); savefig('gif/'+dstr+simstr+'rastB.png') # 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN']); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')
still biased ... but overall seems to be improving in performance

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png')

lot of overlap ... 

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb'))
 data/20jun18_E1_targetted_falcor_synWeights_final.pkl

and should concat the performance to see how cumulative changes ... 

#
actlearn0 = pd.DataFrame(np.loadtxt('data/20jun17_E0_targetted_falcor_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn1 = pd.DataFrame(np.loadtxt('data/20jun18_E1_targetted_falcor_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn1.time += 800e3
pda = actlearn0; pda = pda.append(actlearn1)

#
plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(pda,ax=subplot(1,3,2)); 
plotRewards(pda,ax=subplot(1,3,3)); 

score, hit, miss: (30, 84, 426)

savefig('gif/'+dstr+simstr+'perf_step0_step1.png') # 

yeah, looks like it's continuing to improve ... the restart may have caused slight downturn ... 

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)

continue as ... 20jun19_E2_targetted_falcor_

    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20jun18_E1_targetted_falcor_synWeights_final.pkl"}, 

started @ ~13:00 ... 

** check control (20jun18_E0_control_falcor_) -->> did not move for most of simulation, even w/o learning (some initial bias there, why?)

python -i simdat.py backupcfg/20jun18_E0_control_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); ylim((-0.1,1))

score, hit, miss: (0, 0, 274)

savefig('gif/'+dstr+simstr+'perf.png') # 

0 score, 0 hit, ...

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png') # 
xlim((790e3,800e3)); savefig('gif/'+dstr+simstr+'rastB.png') # 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN']); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos()
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

must be some bias in the wiring leading to EMUP population dominating, even without learning. the learning
model also has to overcome that bias ...

** other control via randomized learned weights (20jun19_E2_targetted_control_falcor_)

take learned weights, shuffle their final values, then use them to resume a control sim ... will it work
if control sim has no RL weights? could just set rl learning weight to 0 ... so weights stay fixed (check that it works)

python -i simdat.py backupcfg/20jun18_E1_targetted_falcor_sim.json

https://stackoverflow.com/questions/15772009/shuffling-permutating-a-dataframe-in-pandas

pdfs = pdf[pdf.time==np.amax(pdf.time)]; 

np.mean(pdfs.weight)
np.mean(pdfs.weight) # 1.828570798265547e-05

pdfs.index[0] # 159
pdfs.loc[159]
time      799999.999886
preid        512.000000
postid      4224.000000
weight         0.000012

pdfshuf = pdfs.reindex(np.random.permutation(pdfs.index))

pdfshuf.index[0] # 11384479
pdfshuf.loc[11384479]
time      799999.999886
preid       2018.000000
postid      4201.000000
weight         0.000022

D = pdf2weightsdict(pdfshuf); 
pickle.dump(D, open('data/'+simstr+'synWeights_final_shuffled.pkl','wb'))

data/20jun18_E1_targetted_falcor_synWeights_final_shuffled.pkl

ok, use that weight in a control sim ... have RLon but set the weight increment to 0

    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20jun18_E1_targetted_falcor_synWeights_final_shuffled.pkl"}, 
	  {"wbase":0.0000001,"wmax":0.00048,"RLon":1,"RLlenhebb":200,"RLlenanti":50,"useRLexp":1,"RLhebbwt":0.0,"RLantiwt":-0.0,"hebbwt":0,"antiwt":0,"tauhebb":10,"RLwindhebb":50,"softthresh":0,"verbose":0},

20jun19_E2_targetted_control_falcor_

first try 10 s and make sure weights stay same as initially loaded

./myrun 16 sn.json

python -i simdat.py backupcfg/20jun19_E2_targetted_control_falcor_sim.json

popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight_test.png')
ok, weights are flat ... but running this simulation will likely show bias too ... 

can check for 100 s ... 

./myrun 16 sn.json

python -i simdat.py backupcfg/20jun19_E2_targetted_control_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); ylim((-0.1,1))


** are there initial biases in the connectivity?

and that's why control model has paddle stuck at top?

had thought biases would not occur since using convergence to wire the network

** other way to vary EM activity

could have 100% connectivity to EM but randomize the starting weights to each EM neuron ... 
that way would make sure each neuron receives all the information ... 
but would allow each neuron to have a different representation and hopefully more robust response

http://www.netpyne.org/reference.html#function-string

weight = '%f * normal(%f,%f)' % (mean,stdev)

try discunif instead ...

for example:
weight = 'discunif(%f,%f)' % (mean*.9,mean*1.1)

default weightvar will be 0 ... that way can have it shut off by default ... 

have this now in sim.py :
# weight variance -- check if need to vary the initial weights (note, they're over-written if resumeSim==1)
if 'weightVar' in dconf['sim']:
  cfg.weightVar = dconf['sim']['weightVar']
else:
  cfg.weightVar = 0.

def getInitWeight (weight)
  """get initial weight for a connection
     checks if weightVar is non-zero, if so will use a uniform distribution 
     with range on interval: (1-var)*weight, (1+var)*weight
  """
  if cfg.weightVar == 0.0:
    return weight
  else:
    return 'discunif(%f,%f)' % (weight*(1.0-cfg.weightVar),weight*(1.0+cfg.weightVar))

and everywhere weight is specified for a connection using
getInitWeight(weight)
where weight is the original weight used 

note that cfg.seeds['conn'] is used seed for random number
generator, and that handles RNG initialization, etc. so do
not have to do anything additional to get same results each time

* 20jun20
** try sim with weight var

fixed weightvar to use uniform - had discunif before but that's only for discrete numbers!

will have weightVar of 0.1, run for 800 s, with 100% connectivity onto EM (EEMProb of 1.0, and EEMRecProb of 0.0)

the weight variance will apply to EMUP, EMDOWN on the inputs they receive...so they all get full sensory
info but there will be variability in how it's weighted ... 

"name":"20jun20_F0_targetted_tank_"

    "rewardcodes": {"scorePoint": 1.0, "losePoint": -0.1, "followTarget": 0.1, "avoidTarget": -0.01, "hitBall": 0.5},    
    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":0,"IV4":0,"EMT":0,"IMT":0,"EMDOWN":16,"EMUP":16,"IM":8,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.000012,"EEMWghtNM":0.0000012,"EEPreMWghtAM":0.00008,"EEPreMWghtNM":0.0000025,"EEMWghtThreshMin":0.00000625,"EEMWghtThreshMax":0.00032,"EEMProb":1.0,"EEMRecProb":0.0,"EEPreMProb":0.0,"EEMPopNorm":0,"EEMRecProbCross":0,"EEMFeedbackProb":0.0,"EEMFeedbackWghtAM":0.0000125,"EEMFeedbackWghtNM":0.00000125,"VisualFeedback":0,"weightVar":0.1},
    "RL":{"AMPA":
	  {"wbase":0.0000001,"wmax":0.00048,"RLon":1,"RLlenhebb":200,"RLlenanti":50,"useRLexp":1,"RLhebbwt":0.0000002,"RLantiwt":-0.0,"hebbwt":0,"antiwt":0,"tauhebb":10,"RLwindhebb":50,"softthresh":0,"verbose":0},

otherwise, same params as recent sims on falcor ... 

20jun20_F0_targetted_tank_

started ~00:15 ...

** check output from 20jun19_E2_targetted_falcor_

(took ~11 hours to run, while falcor was already pretty heavily in use)

python -i simdat.py backupcfg/20jun19_E2_targetted_falcor_sim.json

from previous step sim: ## score, hit, miss: (17, 48, 209)

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

from this sim score, hit, miss: (13, 36, 229)
hmm, fewer scores and hits...
but follow target probability seems better overall ?
savefig('gif/'+dstr+simstr+'perf.png') # 

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png') # 
xlim((790e3,800e3)); savefig('gif/'+dstr+simstr+'rastB.png') # 

are the EMUP,EMDOWN rates getting too high?

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN']); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos() ## hmm, did not save objpos?? got error ... 
##xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
##savefig('gif/'+dstr+simstr+'poshist.png')

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png')
very big spread in weights - suppose that's good, if it allows selectivity ... 

#
actlearn0 = pd.DataFrame(np.loadtxt('data/20jun17_E0_targetted_falcor_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn1 = pd.DataFrame(np.loadtxt('data/20jun18_E1_targetted_falcor_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn1.time += 800e3
actlearn2 = pd.DataFrame(np.loadtxt('data/20jun19_E2_targetted_falcor_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn2.time += 1600e3
pda = actlearn0; pda = pda.append(actlearn1); pda = pda.append(actlearn2)

#
plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(pda,ax=subplot(1,3,2)); 
plotRewards(pda,ax=subplot(1,3,3)); 

score, hit, miss: (43, 120, 655)

savefig('gif/'+dstr+simstr+'perf_step0_step1_step2.png') # 

seems to have improved further? at least in target following ... 

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb'))
# data/20jun19_E2_targetted_falcor_synWeights_final.pkl

continue as ... 20jun20_E3_targetted_falcor_

continue it for 1600 s ... 

meanwhile, animate the activity . . . 

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) # 20jun19_20jun19_E2_targetted_falcor__input.mp4
(in that movie model is moving in right direction a lot but most of the time it misses points is when opponent hits ball to
bottom right or top right corner and model stays all the way at bottom or top , so overshoots . . .so that's another clear
sign that learning is taking place, just needs some tweaking ... 

./myrun 16 sn.json

started ~00:41 ...

** check output from control sim (20jun19_E2_targetted_control_falcor_)

python -i simdat.py backupcfg/20jun19_E2_targetted_control_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); ylim((-0.1,1))

score, hit, miss: (9, 32, 226)

so, not as good as the simulation with correct learning in terms of score, hit -
follow target probability is random but higher than sim with learning ... is learning
sim not following due to mixed rewards (hit, score, loss, target follow vs not?)  or
some systematic bias ... 

savefig('gif/'+dstr+simstr+'perf.png') # 

should check weights for the control sim ... see how balanced they are ... 
assuming the target is ~fixed on each hit towards the paddle, random
and balanced weights would produce moves ~50% towards vs away from target
but with learning, there are some biases in weights created, so may not
expect ~50% towards/away from target even with better performance overall?

pdf.columns # Index(['time', 'preid', 'postid', 'weight'], dtype='object')

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png')

hmm, the up and down are pretty different, would not expect that from the shuffle procedure ... is it really shuffled??

via pdfshuf = pdfs.reindex(np.random.permutation(pdfs.index))
perhaps the order of the index was changed but the contents were the same?

pdfshuf = pdf.reindex(np.random.permutation(pdf.index))

clf(); popwts = plotMeanWeights(pdfshuf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight_shuffle_test_A.png')

that looks like same values as finished from 20jun19_20jun18_E1_targetted_falcor_all_avg_weight.png
so that means it wasn't a good control simulation either - it was using the learned weights
and keeping them fixed from when learning ended ... 

that's a useful demonstration that learning took place and remained in place ... but still need a control

len(pdf['weight'])

pdfs = pdf[pdf.time==np.amax(pdf.time)]; 

npwt = np.array(pdfs.weight)
len(npwt) # 86784

npwt[0],npwt[-1], mean(npwt) # (1.2421595668381792e-05, 4.670336697494599e-05, 1.828570798265547e-05)

np.random.shuffle(npwt)

npwt[0],npwt[-1], mean(npwt) # (1.2665998463950697e-05, 1.339615989324337e-05, 1.828570798265547e-05)
len(npwt) # 86784


A = np.array([pdfs.time,pdfs.preid,pdfs.postid,npwt]).T
pdfshuf = pd.DataFrame(A,columns=['time','preid','postid','weight'])

clf(); popwts = plotMeanWeights(pdfshuf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)

xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight_shuffle_test_B.png')

ok, now values more close together ... should be properly shuffled ... now can rerun the control test ... 

D = pdf2weightsdict(pdfshuf); 
pickle.dump(D, open('data/20jun20_20jun18_E1_targetted_falcor_synWeights_final_shuffled.pkl','wb'))

name:
20jun20_20jun19_E2_targetted_control_falcor_

will just run this for 100 s ... no point wasting 800 s of sim time if this is a real control ... 

* 20jun21
** check control 20jun20_20jun19_E2_targetted_control_falcor_

python -i simdat.py backupcfg/20jun20_20jun19_E2_targetted_control_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); ylim((-0.1,1))

score, hit, miss: (0, 0, 34)

savefig('gif/'+dstr+simstr+'perf.png') # 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png')

#
clf(); dobjpos = loadObjPos() ## hmm, did not save objpos?? got error ... 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

ok, so stuck at top whole time again ... 

having difficulty getting these control simulations to do anything remotely similar to learning model ... 

as control could instead just generate arbitrary/random moves ... and see what kind of performance
that produces ...

** try control with ranodom moves (20jun21_randmove_control_falcor_)

to turn on random move generation just have 'randmove' = 1 set in the json file

simulation itself isn't useful here - just generation of moves

** other simulation - only use target tracking rewards

let everything else come about through that intermediate learning rule ... 

20jun21_A0_targetted_only_track_falcor_

* 20jun22
** check new control with random moves (20jun21_randmove_control_falcor_)

python -i simdat.py backupcfg/20jun21_randmove_control_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); ylim((-0.1,1))

score, hit, miss: (0, 4, 63)

savefig('gif/'+dstr+simstr+'perf.png') # 20jun22_20jun21_randmove_control_falcor_perf.png

ok, so that's ~0.33 for target follow and 0 score, only 4 hits in 200 s (so ~16 in 800 s ... )

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) # 20jun22_20jun21_randmove_control_falcor__input.mp4
 
** check output from the 1600 s continuation sim 

python -i simdat.py backupcfg/20jun20_E3_targetted_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

from this sim score, hit, miss: (41, 140, 362)

savefig('gif/'+dstr+simstr+'perf.png') # 20jun22_20jun20_E3_targetted_falcor_perf.png

up until ~400 s the follow target probability was increasing, but then started to decrease slightly
when watching activity, looked like it was doing worse at the end ... systematically - going in opposite
direction for many moves right when ball was about to hit the racket

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png') # 
firing rates are probably too high now ... so probably should have normalized the weights ... ? 
xlim((390e3,400e3)); savefig('gif/'+dstr+simstr+'rastB.png') # 
xlim((1590e3,1600e3)); savefig('gif/'+dstr+simstr+'rastC.png') # 

rcParams['agg.path.chunksize'] = 100000000000

clf(); 
drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN']); 
savefig('gif/'+dstr+simstr+'Vm.png')

was getting this error on draw:
OverflowError: Exceeded cell block limit (set 'agg.path.chunksize' rcparam)
so had to call this rcParams['agg.path.chunksize'] = 100000000000

xlim((390e3,400e3)); savefig('gif/'+dstr+simstr+'VmB.png')
xlim((1590e3,1600e3)); savefig('gif/'+dstr+simstr+'VmC.png')

apart from those gian hyperpolarizations dont see much unusual ... how does IM look?

drawcellVm(simConfig,ldrawpop=['IM']); 
savefig('gif/'+dstr+simstr+'VmD.png')

xlim((300e3,400e3));
savefig('gif/'+dstr+simstr+'VmE.png')
do not see anything unusual about the IM neuron displayed... 

#
clf(); dobjpos = loadObjPos() ## hmm, did not save objpos?? got error ... 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png')

#
actlearn0 = pd.DataFrame(np.loadtxt('data/20jun17_E0_targetted_falcor_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn1 = pd.DataFrame(np.loadtxt('data/20jun18_E1_targetted_falcor_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn1.time += 800e3
actlearn2 = pd.DataFrame(np.loadtxt('data/20jun19_E2_targetted_falcor_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn2.time += 1600e3
actlearn3 = pd.DataFrame(np.loadtxt('data/20jun20_E3_targetted_falcor_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn3.time += 2400e3
pda = actlearn0; pda = pda.append(actlearn1); pda = pda.append(actlearn2); pda = pda.append(actlearn3)

#
clf()
plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(pda,ax=subplot(1,3,2)); 
plotRewards(pda,ax=subplot(1,3,3)); 

score, hit, miss: (84, 260, 1017)

savefig('gif/'+dstr+simstr+'perf_step0_step1_step2_step3.png') # 

looks like follow target prob decreasing slightly in last sim's period ... 1600 s ... 

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) # 

not sure worth continuing this one

** discuss with ha

re stability, add population of hold EM neurons since although looks like average position
to target is decreasing over time the paddle is hovering up/down and has difficulty holding still

** check output from 20jun21_A0_targetted_only_track_falcor_

python -i simdat.py backupcfg/20jun21_A0_targetted_only_track_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

wrong score count: (5718, 4, 64)
but right hit (4) count and miss (64) count ... 

savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png') # 


clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN']); savefig('gif/'+dstr+simstr+'Vm.png')

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) # 

* 20jun23
** check output from 20jun20_F0_targetted_tank_ -->> continue on falcor as 20jun23_F1_targetted_tank_

this one has 100% connectivity to the EM populations
with 0.1 weightVar:
    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":0,"IV4":0,"EMT":0,"IMT":0,"EMDOWN":16,"EMUP":16,"IM":8,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.000012,"EEMWghtNM":0.0000012,"EEPreMWghtAM":0.00008,"EEPreMWghtNM":0.0000025,"EEMWghtThreshMin":0.00000625,"EEMWghtThreshMax":0.00032,"EEMProb":1.0,"EEMRecProb":0.0,"EEPreMProb":0.0,"EEMPopNorm":0,"EEMRecProbCross":0,"EEMFeedbackProb":0.0,"EEMFeedbackWghtAM":0.0000125,"EEMFeedbackWghtNM":0.00000125,"VisualFeedback":0,"weightVar":0.1},

and these reward codes:
    "rewardcodes": {"scorePoint": 1.0, "losePoint": -0.1, "followTarget": 0.1, "avoidTarget": -0.01, "hitBall": 0.5},    

ran for 800 s ...

python -i simdat.py backupcfg/20jun20_F0_targetted_tank_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); ylim((-0.1,1))

score,hit,miss (12, 40, 219)

(a few more hits than 20jun17_E0_targetted_falcor_ which had 13, 36, 217)
so may want to use full conn...

savefig('gif/'+dstr+simstr+'perf.png') # 

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png') # 
xlim((790e3,800e3)); savefig('gif/'+dstr+simstr+'rastB.png') # 

clf(); 
drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN']); 
savefig('gif/'+dstr+simstr+'Vm.png')
xlim((790e3,800e3)); savefig('gif/'+dstr+simstr+'VmB.png')

#
clf(); dobjpos = loadObjPos() ## hmm, did not save objpos?? got error ... 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png')

hmm, average weights are higher to EMDOWN but the paddle goes up more - so what accounts for this??
is it depolarization blockade of the EMDOWN neurons??

is the firing threshold of 0 for pyr cells problematic? should it be even lower?

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) #

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb'))

use
20jun20_F0_targetted_tank_synWeights_final.pkl
to continue on falcor as 20jun23_F1_targetted_tank_

./myrun 16 sn.json

started @ ~22:23 ...

** continue 20jun20_E3_targetted_falcor_ as 20jun23_E4_targetted_falcor_

this movie: gif/20jun22_20jun20_E3_targetted_falcor__input.mp4
makes clear that it is learning, but still has a lot of screwups; one problem is it's hard
for stability to emerge when have two competing directions of movement and no explicit representation
of staying still; since have to move very quickly to get to an exact target location there's some
benefit to moving quickly, which is a tradeoff with precision of movement? 

first make the final weights ...

python -i simdat.py backupcfg/20jun20_E3_targetted_falcor_sim.json

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb'))

started @ 17:28 ...


* 20jun24
** check output from 20jun23_F1_targetted_tank_ continue as 20jun24_F2_targetted_tank_

backupcfg/20jun20_F0_targetted_tank_sim.json

python -i simdat.py backupcfg/20jun23_F1_targetted_tank_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); ylim((-0.1,1))

score,hit,miss (12, 40, 219) <<-- previous step
score,hit,miss (15, 49, 207) <<-- this step, a little better

savefig('gif/'+dstr+simstr+'perf.png') # 

mostly flat probability...though rises early and then decays, then rises again to flatness...

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png') # 
xlim((790e3,800e3)); savefig('gif/'+dstr+simstr+'rastB.png') # 
rates getting too high?

clf(); 
drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN']); 
savefig('gif/'+dstr+simstr+'Vm.png')

xlim((790e3,800e3)); savefig('gif/'+dstr+simstr+'VmB.png')

#
clf(); dobjpos = loadObjPos() ## hmm, did not save objpos?? got error ... 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png')

this seems buggy - weights to EMDOWN are higher but paddle gets stuck at top ... ??

pdfs = pdf[pdf.time==np.amax(pdf.time)]
pdfsUP = pdfs[(pdfs.postid>=dstartidx['EMUP'])&(pdfs.postid<=dendidx['EMUP'])]
pdfsDOWN = pdfs[(pdfs.postid>=dstartidx['EMDOWN'])&(pdfs.postid<=dendidx['EMDOWN'])]

np.mean(pdfsUP.weight),np.mean(pdfsDOWN.weight) # (1.6342212432719612e-05, 1.8452168483336483e-05)

also strange that EMDOWN has a slightly higher average firing rate (14.98 Hz) than EMUP average firing rate (14.88 Hz)
if EMDOWN is firing more would expect bias on the other side (bottom)

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb'))
# data/20jun23_F1_targetted_tank_synWeights_final.pkl

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) #
# gif/20jun24_20jun23_F1_targetted_tank__input.mp4
does look like it's learning ... has the usual screwups ... worth continuing ... 

#
actlearn0 = pd.DataFrame(np.loadtxt('data/20jun20_F0_targetted_tank_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn1 = pd.DataFrame(np.loadtxt('data/20jun23_F1_targetted_tank_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn1.time += 800e3
pda = actlearn0; pda = pda.append(actlearn1); 

#
clf()
plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(pda,ax=subplot(1,3,2)); 
plotRewards(pda,ax=subplot(1,3,3)); 

score, hit, miss: (27, 89, 426)

savefig('gif/'+dstr+simstr+'perf_step0_step1.png') # 

./myrun 16 sn.json

started ~21:47 ...

** check output from 20jun23_E4_targetted_falcor_ continue as 20jun24_E5_targetted_falcor_

python -i simdat.py backupcfg/20jun23_E4_targetted_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

from the last sim score, hit, miss: (41, 140, 362)
from this sim score, hit, miss: (17, 58, 466)
performing a lot worse now??

savefig('gif/'+dstr+simstr+'perf.png') # 20jun24_20jun23_E4_targetted_falcor_perf.png

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png') # 
xlim((1590e3,1600e3)); savefig('gif/'+dstr+simstr+'rastC.png') # 

rcParams['agg.path.chunksize'] = 100000000000

clf(); 
drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN']); 
savefig('gif/'+dstr+simstr+'Vm.png')
xlim((1590e3,1600e3)); savefig('gif/'+dstr+simstr+'VmC.png')

drawcellVm(simConfig,ldrawpop=['IM']); 
savefig('gif/'+dstr+simstr+'VmD.png')

#
clf(); dobjpos = loadObjPos() ## hmm, did not save objpos?? got error ... 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')
interesting, much less bias towards position 0 overall now...sign of progress?

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png')

interesting - some neuron average weights are staying nearly flat (thought not completely), while others are rising much more quickly ... 
maybe not enough weight variability? should track those neurons' weights from beginning to see if start off ~equal and why stay low ... could
be due to the creation of bias via RL targetting ... 

#
actlearn0 = pd.DataFrame(np.loadtxt('data/20jun17_E0_targetted_falcor_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn1 = pd.DataFrame(np.loadtxt('data/20jun18_E1_targetted_falcor_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn1.time += 800e3
actlearn2 = pd.DataFrame(np.loadtxt('data/20jun19_E2_targetted_falcor_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn2.time += 1600e3
actlearn3 = pd.DataFrame(np.loadtxt('data/20jun20_E3_targetted_falcor_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn3.time += 2400e3
actlearn4 = pd.DataFrame(np.loadtxt('data/20jun23_E4_targetted_falcor_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn4.time += 4000e3
pda = actlearn0; pda = pda.append(actlearn1); pda = pda.append(actlearn2); pda = pda.append(actlearn3); pda = pda.append(actlearn4)

#
clf()
plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(pda,ax=subplot(1,3,2)); 
plotRewards(pda,ax=subplot(1,3,3)); 

score, hit, miss: (101, 318, 1483)

savefig('gif/'+dstr+simstr+'perf_step0_step1_step2_step3_step4.png') # 

to better track progress, should look at ratio of hits/misses and scores/misses rather than cumulative counts ... ?

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb'))
# data/20jun23_E4_targetted_falcor_synWeights_final.pkl

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) # gif/20jun24_20jun23_E4_targetted_falcor__input.mp4

continue as 20jun24_E5_targetted_falcor_

will run for 800 s and check progress ... 

./myrun 16 sn.json

started ~22:18 ... 

** other rule to prevent paddle positioned at far top/bottom 

could prevent paddle from moving so far to bottom or top of screen that only part of paddle is vislbe
that would cnvert many of the misses into hits ... but ideally model should figure out never to do that...

hmm, one reason racket might move up or down all the way when ball flying to top right or bottom right
is that the model does not know the position of the racket as well as it knows the movement of the ball?
so usually moving up when ball flying to top right will minimize chance of error ... 
hmm, but model still hits ball when it's at intermediate position , so must have some
accurate info about position of racket ... 

* 20jun25
** use actmap to check if net looks epileptic -- this does still happen

discussed with ha need for using normalization; still have to test that weight normalization
does not interfere with function

** check output from 20jun24_F2_targetted_tank_

python -i simdat.py backupcfg/20jun24_F2_targetted_tank_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); ylim((-0.1,1))

score,hit,miss (12, 40, 219) <<-- previous previous step
score,hit,miss (15, 49, 207) <<-- previous step
score,hit,miss (18, 62, 189) <<-- this step, increased performance

savefig('gif/'+dstr+simstr+'perf.png') # 
savefig('gif/'+dstr+simstr+'perfB.png') # 

follow target probability rises early and then decays
hit greater than miss early on when probability of following target highest ... 

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png') # 
xlim((65e3,75e3)); savefig('gif/'+dstr+simstr+'rastB.png') # 
xlim((790e3,800e3)); savefig('gif/'+dstr+simstr+'rastB.png') # 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN']); savefig('gif/'+dstr+simstr+'Vm.png')

#
clf(); dobjpos = loadObjPos() ## hmm, did not save objpos?? got error ... 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png')

initial EEMWghtAM was 0.000012 now it's risen by > 50% ... 
could multiply all weights by 0.75 before continuing, since that might be issue with further improvement ... 

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb'))
# data/20jun24_F2_targetted_tank_synWeights_final.pkl

np.amax(pdf.weight) # 0.00010486205304156363

0.00010486205304156363 / 0.000012 # 8.738504420130303

pdf.weight *= 0.75
clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight_reduced.png')

np.mean(pdfs.weight) # 2.0353749694156496e-05
avgfinalw = np.mean(pdfs.weight)
initw = 0.000012 # initial weight
avgfinalw / initw # 1.6961458078463747
fctr = initw / avgfinalw # 0.5895719550607015

pdf.weight *= fctr
clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight_reduced.png')

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final_reduced.pkl','wb'))
# data/20jun24_F2_targetted_tank_synWeights_final_reduced.pkl
np.min(pdfs.weight) # 2.0263158815486595e-06
can try using these normalized/reduced weights for continuation ... but will have to reduce "EEMWghtThreshMin":0.00000625
try 0.000001
and for "EEMWghtThreshMax":use 0.00016 instead of 0.00032
will continue that way as 20jun25_F3_targetted_reduced_tank_ , and a comparison without the reduction

#
actlearn0 = pd.DataFrame(np.loadtxt('data/20jun20_F0_targetted_tank_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn1 = pd.DataFrame(np.loadtxt('data/20jun23_F1_targetted_tank_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn1.time += 800e3
actlearn2 = pd.DataFrame(np.loadtxt('data/20jun24_F2_targetted_tank_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])
actlearn2.time += 1600e3
pda = actlearn0; pda = pda.append(actlearn1); pda = pda.append(actlearn2); 

#
clf()
plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(pda,ax=subplot(1,3,2)); 
plotRewards(pda,ax=subplot(1,3,3)); 

score, hit, miss: (27, 89, 426)
score, hit, miss: (45, 151, 615) <<-- slightly improved ratio of hit/miss and score/miss
(45-27.)/(615-426.) # 0.09523809523809523
27/426. # 0.06338028169014084

savefig('gif/'+dstr+simstr+'perf_step0_step1_step2.png') # 

lpop = ['ER', 'EV1', 'EV4', 'EMT', 'IR', 'IV1', 'IV4', 'IMT','EV1DW','EV1DNW', 'EV1DN', 'EV1DNE','EV1DE','EV1DSW', 'EV1DS', 'EV1DSE','EMDOWN','EMUP']  
dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
fig, axs, plt = animActivityMaps() # 

./myrun 16 sn.json
started @ 16:45 ... (20jun25_F3_targetted_reduced_tank_)

and the other one without weight reduction using 
data/20jun24_F2_targetted_tank_synWeights_final.pkl
as 20jun25_F3_targetted_tank_
./myrun 16 sn.json
started @ 16:49 ... 

** check output from 20jun24_E5_targetted_falcor_ -->> need to look more closely

python -i simdat.py backupcfg/20jun24_E5_targetted_falcor_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2)); 
plotRewards(actreward,ax=subplot(1,3,3)); 

from the last last sim score, hit, miss: (41, 140, 362)
from the last sim score, hit, miss: (17, 58, 466)
from this sim score, hit, miss: (10, 39, 224)

10/224. # 0.044642857142857144
39/224. # 0.17410714285714285

savefig('gif/'+dstr+simstr+'perf.png') # 20jun25_20jun24_E5_targetted_falcor_perf.png

maybe improving but not as good as sim with weightvar and two steps ago
had much better performance (140/362 compared to 39/224, though the other sim ran for 2X duration) - 

ax=subplot(1,3,2); cla(); plotHitMiss(actreward,ax=subplot(1,3,2),asratio=True); ax.set_ylim((0,0.2))
score/miss, hit/miss = (0.044642857142857144, 0.17410714285714285)

savefig('gif/'+dstr+simstr+'perfB.png') # 20jun25_20jun24_E5_targetted_falcor_perfB.png
hit/miss ratio looks like slowly improving...

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png') # 
xlim((790e3,800e3)); savefig('gif/'+dstr+simstr+'rastC.png') # 

rcParams['agg.path.chunksize'] = 100000000000
clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM']); xlim((790e3,800e3)); savefig('gif/'+dstr+simstr+'Vm.png'); 

#
clf(); dobjpos = loadObjPos() ## hmm, did not save objpos?? got error ... 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')
don't see bias at extrema...

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png')

lfn = ['20jun17_E0_targetted_falcor_ActionsRewards.txt','20jun18_E1_targetted_falcor_ActionsRewards.txt','20jun19_E2_targetted_falcor_ActionsRewards.txt','20jun20_E3_targetted_falcor_ActionsRewards.txt','20jun23_E4_targetted_falcor_ActionsRewards.txt','20jun24_E5_targetted_falcor_ActionsRewards.txt']
lfn = ['data/'+x for x in lfn]
pda = getconcatactionreward(lfn)

#
clf()
plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(pda,ax=subplot(1,3,2),asratio=True); 
plotRewards(pda,ax=subplot(1,3,3)); 

final score/miss, hit/miss ratio: (0.06502636203866433, 0.20913884007029876)

savefig('gif/'+dstr+simstr+'perf_step0_step1_step2_step3_step4_step5.png') # 

so the performance increases, decreases, etc. . . in general may be increasing in terms
of hits and score to miss ratios ... 

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb'))
# data/20jun24_E5_targetted_falcor_synWeights_final.pkl

in case want to continue with reduced weights ... can do that if activity looks epileptic ... and should do within sim itself ... 
via EEMPopNorm set to True/1 so that would normalize both populations' synapses by same amount ...

lpop = ['ER', 'EV1', 'EV4', 'EMT', 'IR', 'IV1', 'IV4', 'IMT','EV1DW','EV1DNW', 'EV1DN', 'EV1DNE','EV1DE','EV1DSW', 'EV1DS', 'EV1DSE','EMDOWN','EMUP']  
dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
fig, axs, plt = animActivityMaps() # 

** actmap movie labels need to be adjusted for reduced architecture (no V4, MT)

should also potentially include rewards(hit,miss,score) and weights in the movie
so can see full (moving) picture ... 

* 20jun26
** setting up on cycle
** compare output from two runs on falcor - similar though reduced weights drops then increases in performance to slightly higher level
*** without reduced weights (20jun25_F3_targetted_tank_)

python -i simdat.py backupcfg/20jun25_F3_targetted_tank_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),asratio=True); 
plotRewards(actreward,ax=subplot(1,3,3)); 

score/miss, hit/miss = (0.044642857142857144, 0.17410714285714285) <<-- previous step
score/miss, hit/miss = (0.0663265306122449, 0.30612244897959184) <<-- this sim

savefig('gif/'+dstr+simstr+'perf.png') # 20jun26_20jun25_F3_targetted_tank_perf.png

so that's better on average ... though lots of variability in the performance ... 

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png') # 
xlim((790e3,800e3)); savefig('gif/'+dstr+simstr+'rastC.png') # 

rcParams['agg.path.chunksize'] = 100000000000
clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM']); xlim((790e3,800e3)); savefig('gif/'+dstr+simstr+'Vm.png'); 
xlim((790e3,792e3)); savefig('gif/'+dstr+simstr+'VmB.png'); 
might be recording artifact but seems like the EMDOWN are firing below the 0 mV threshold ... may want to lower it 
and see if improves performance -- since higher weights could have pushed AP lower ...  due to dep blockade emerging?
if that's case, would expect weight normalization to improve performance 

#
clf(); dobjpos = loadObjPos() ## hmm, did not save objpos?? got error ... 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')
bias towards top (EMUP moves)

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png')
well, most of the EMDOWN weights are lower but average EMDOWN weights are higher (?)

lfn = ['20jun20_F0_targetted_tank_ActionsRewards.txt','20jun23_F1_targetted_tank_ActionsRewards.txt','20jun24_F2_targetted_tank_ActionsRewards.txt','20jun25_F3_targetted_tank_ActionsRewards.txt']
lfn = ['data/'+x for x in lfn]
pda = getconcatactionreward(lfn)

#
clf()
plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(pda,ax=subplot(1,3,2),asratio=True); 
plotRewards(pda,ax=subplot(1,3,3)); 

final score/miss, hit/miss ratio: (0.07151664611590629, 0.2601726263871763)

savefig('gif/'+dstr+simstr+'perf_step0_step1_step2_step3.png') # 

generally increasing for hit/miss and score/miss, and p(follow) slightly...

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb'))
# data/20jun25_F3_targetted_tank_synWeights_final.pkl

can continue, depending on how compares with sim below ... 

lpop = ['ER', 'EV1', 'EV4', 'EMT', 'IR', 'IV1', 'IV4', 'IMT','EV1DW','EV1DNW', 'EV1DN', 'EV1DNE','EV1DE','EV1DSW', 'EV1DS', 'EV1DSE','EMDOWN','EMUP','IM']  
dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN']  
fig, axs, plt = animActivityMaps(lpop=lpop) # 

continuing as 20jun26_F4_targetted_tank_
for 1600 s ... 
    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20jun25_F3_targetted_tank_synWeights_final.pkl"}, 
20jun26_F4_targetted_tank_

*** with reduced weights (20jun25_F3_targetted_reduced_tank_) -->> seems much better than above (well, a little better at end)

python -i simdat.py backupcfg/20jun25_F3_targetted_reduced_tank_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),asratio=True); 
plotRewards(actreward,ax=subplot(1,3,3)); 

score/miss, hit/miss = (0.044642857142857144, 0.17410714285714285) <<-- previous step
score/miss, hit/miss = (0.09090909090909091, 0.3689839572192513) <<-- this sim (better final values than without weight reduction above)
however, this sim starts with low performance and gradually increases; low performance could be due to the normalization procedure...the
other sim stays around same level ... would periodic normalization help??

savefig('gif/'+dstr+simstr+'perf.png') # 20jun26_20jun25_F3_targetted_reduced_tank_perf.png

clf(); drawraster(dspkT,dspkID); savefig('gif/'+dstr+simstr+'rast.png') # rates lower than sim above, as expected
xlim((790e3,800e3)); savefig('gif/'+dstr+simstr+'rastC.png') # 

rcParams['agg.path.chunksize'] = 100000000000
clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM']); xlim((790e3,800e3)); savefig('gif/'+dstr+simstr+'Vm.png'); 
xlim((790e3,792e3)); savefig('gif/'+dstr+simstr+'VmB.png'); 

#
clf(); dobjpos = loadObjPos() ## hmm, did not save objpos?? got error ... 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')
still has bias towards top (EMUP moves)

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png') # 20jun26_20jun25_F3_targetted_reduced_tank_all_avg_weight.png

lfn = ['20jun20_F0_targetted_tank_ActionsRewards.txt','20jun23_F1_targetted_tank_ActionsRewards.txt','20jun24_F2_targetted_tank_ActionsRewards.txt','20jun25_F3_targetted_reduced_tank_ActionsRewards.txt']
lfn = ['data/'+x for x in lfn]
pda = getconcatactionreward(lfn)

#
clf()
plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(pda,ax=subplot(1,3,2),asratio=True); 
plotRewards(pda,ax=subplot(1,3,3)); 

final score/miss, hit/miss ratio without weight reduction: (0.07151664611590629, 0.2601726263871763)
THIS final score/miss, hit/miss ratio WITH weight reduction: (0.0773067331670823, 0.2743142144638404)
so with weight reduction final performance is slightly higher than without weight reduction ... 

savefig('gif/'+dstr+simstr+'perf_step0_step1_step2_step3.png') # 20jun26_20jun25_F3_targetted_reduced_tank_perf_step0_step1_step2_step3.png

generally increasing for hit/miss and score/miss, and p(follow) slightly...

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb'))
# data/20jun25_F3_targetted_reduced_tank_synWeights_final.pkl

lpop = ['ER', 'EV1', 'EV4', 'EMT', 'IR', 'IV1', 'IV4', 'IMT','EV1DW','EV1DNW', 'EV1DN', 'EV1DNE','EV1DE','EV1DSW', 'EV1DS', 'EV1DSE','EMDOWN','EMUP','IM']  
dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN']  
fig, axs, plt = animActivityMaps(lpop=lpop) # 

continuing as 20jun26_F4_targetted_reduced_tank_
for 1600 s ... 
    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20jun25_F3_targetted_reduced_tank_synWeights_final.pkl"}, 
20jun26_F4_targetted_reduced_tank_

"EEMPopNorm":1
can normalize/reduce the weights every 400 s ? 
that's "normalizeWeightStepSize":20000
since 20 ms per step
and set EEMWghtThreshMax to 0.000012
so that goes back to mean initial weight ... 

** test on cycle -- more EMUP,EMDOWN,IM neurons -->> better performance?

can scale up network and see if improves performance

20jun26_G0_cycle_

double number of EMDOWN, EMUP, IM to 32, 32, 16

can try run of 3200 s ... 

apparently have to configure to allow > 48 cores (64 complained)

./myrun 64 sn.json

Either request fewer slots for your application, or make more slots
available for use.

A "slot" is the Open MPI term for an allocatable unit where we can
launch a process.  The number of slots available are defined by the
environment in which Open MPI processes are run:

  1. Hostfile, via "slots=N" clauses (N defaults to number of
     processor cores if not provided)
  2. The --host command line parameter, via a ":N" suffix on the
     hostname (N defaults to 1 if not provided)
  3. Resource manager (e.g., SLURM, PBS/Torque, LSF, etc.)
  4. If none of a hostfile, the --host command line parameter, or an
     RM is present, Open MPI defaults to the number of processor cores

In all the above cases, if you want Open MPI to default to the number
of hardware threads instead of the number of processor cores, use the
--use-hwthread-cpus option.

Alternatively, you can use the --oversubscribe option to ignore the
number of available slots when deciding the number of processes to
launch.

./myrun 32 sn.json

hmm, much faster than falcor...even with the larger network 

also with 48 cores? yes, fast, but sensors indicating getting hot (close to 90C, high is 94C
crit is 104C) ... can stick with 32 for first tests ...
to make sure system does not overheat ... 

ok, will run for 3200 s ... with 32 cores ... not using weight norm for now ... 

./myrun 32 sn.json

* 20jun27
** check run from cycle (20jun26_G0_cycle_sim.json) -- better performance -- continue as 20jun27_G1_cycle_

this sim has 32 neurons of each M pop and ran for 3200 s ... took < 24 hrs with 32 cores running on cycle

Gathering data...
  Done; gather time = 68.48 s.
Analyzing...
  Cells: 4280
  Connections: 0 (0.00 per cell)
  Spikes: 24956526 (1.82 Hz)
  Simulated time: 3200.0 s; 32 workers
  Run time: 78963.26 s

python -i simdat.py backupcfg/20jun26_G0_cycle_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),asratio=True); 
plotRewards(actreward,ax=subplot(1,3,3)); 

score/miss, hit/miss ratio: (0.09251700680272108, 0.36054421768707484)
looks good - improving, and follow target prob is increasing up to ~0.43

savefig('gif/'+dstr+simstr+'perf.png') # 20jun27_20jun26_G0_cycle_perf.png

clf(); drawraster(dspkT,dspkID); xlim((3190e3,3200e3)); savefig('gif/'+dstr+simstr+'rastB.png') # 
overall rates are ok

rcParams['agg.path.chunksize'] = 100000000000
clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM']); xlim((3190e3,3200e3)); savefig('gif/'+dstr+simstr+'Vm.png'); 
looks ok, those IM neurons firing very fast with giant bursts...

#
clf(); dobjpos = loadObjPos() ## hmm, did not save objpos?? got error ... 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png') # 
same pattern as other recent sims - EMDOWN has higher weights, EMUP has lower; though bias
towards UP positions is higher ... still seems like a bug somewhere, or is it just due to initial
moves leading to the difference??

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb'))
# data/20jun26_G0_cycle_synWeights_final.pkl

lpop = ['ER', 'EV1', 'EV4', 'EMT', 'IR', 'IV1', 'IV4', 'IMT','EV1DW','EV1DNW', 'EV1DN', 'EV1DNE','EV1DE','EV1DSW', 'EV1DS', 'EV1DSE','EMDOWN','EMUP','IM']  
dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN']  
fig, axs, plt = animActivityMaps(lpop=lpop) # <<-- getting error on cycle
  File "<stdin>", line 1, in <module>
  File "simdat.py", line 199, in animActivityMaps
    ani.save(outpath, writer=writer); print('saved animation to', outpath)
  File "/opt/anaconda3/lib/python3.7/site-packages/matplotlib/animation.py", line 1200, in save
    writer.grab_frame(**savefig_kwargs)
  File "/opt/anaconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/anaconda3/lib/python3.7/site-packages/matplotlib/animation.py", line 241, in saving
    self.finish()
  File "/opt/anaconda3/lib/python3.7/site-packages/matplotlib/animation.py", line 367, in finish
    self.cleanup()
  File "/opt/anaconda3/lib/python3.7/site-packages/matplotlib/animation.py", line 405, in cleanup
    out, err = self._proc.communicate()
  File "/opt/anaconda3/lib/python3.7/subprocess.py", line 964, in communicate
    stdout, stderr = self._communicate(input, endtime, timeout)
  File "/opt/anaconda3/lib/python3.7/subprocess.py", line 1701, in _communicate
    selector.register(self.stdout, selectors.EVENT_READ)
  File "/opt/anaconda3/lib/python3.7/selectors.py", line 352, in register
    key = super().register(fileobj, events, data)
  File "/opt/anaconda3/lib/python3.7/selectors.py", line 238, in register
    key = SelectorKey(fileobj, self._fileobj_lookup(fileobj), events, data)
  File "/opt/anaconda3/lib/python3.7/selectors.py", line 225, in _fileobj_lookup
    return _fileobj_to_fd(fileobj)
  File "/opt/anaconda3/lib/python3.7/selectors.py", line 40, in _fileobj_to_fd
    "{!r}".format(fileobj)) from None
ValueError: Invalid file object: <_io.BufferedReader name=12>

this help for animation problem?
https://stackoverflow.com/questions/53198609/trying-to-save-an-animated-of-graph-with-matplotlib-in-python-invalid-file-ob/54263809#54263809

which ffmpeg
/opt/anaconda3/bin/ffmpeg

plt.rcParams['animation.ffmpeg_path'] # 'ffmpeg'

plt.rcParams['animation.ffmpeg_path'] = '/opt/anaconda3/bin/ffmpeg' # Add the path of ffmpeg here!!

fig, axs, plt = animActivityMaps(lpop=lpop) # <<-- still getting error on cycle

https://github.com/matplotlib/matplotlib/issues/12769

will check activity ... meanwhile, can either continue ... or run larger population of EM neurons and see if
its performance improves further

may as well continue first and if doesn't improve substantially can increase pop size ... 

continue as 20jun27_G1_cycle_
    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20jun26_G0_cycle_synWeights_final.pkl"}, 

./myrun 32 sn.json

started 23:02 ...

* 20jun28
** continue on cycle -- sim finished but gatherdata produced a memory error -->> rerun for 1/2 duration (1600 s)

  Done; run time = 73606.97 s; real-time ratio: 0.04.

Gathering data...
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
[cycle:678494] Process received signal
[cycle:678494] Signal: Aborted (6)
[cycle:678494] Signal code:  (-6)
[cycle:678494] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x153c0)[0x7f3012d463c0]
[cycle:678494] [ 1] /lib/x86_64-linux-gnu/libc.so.6(gsignal+0xcb)[0x7f3012b8518b]
[cycle:678494] [ 2] /lib/x86_64-linux-gnu/libc.so.6(abort+0x12b)[0x7f3012b64859]
[cycle:678494] [ 3] /opt/anaconda3/lib/libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xbc)[0x7f3012f6684a]
[cycle:678494] [ 4] /opt/anaconda3/lib/libstdc++.so.6(+0xabf47)[0x7f3012f64f47]
[cycle:678494] [ 5] /opt/anaconda3/lib/libstdc++.so.6(+0xabf7d)[0x7f3012f64f7d]
[cycle:678494] [ 6] /opt/anaconda3/lib/libstdc++.so.6(__cxa_rethrow+0x0)[0x7f3012f6515a]
[cycle:678494] [ 7] /opt/anaconda3/lib/libstdc++.so.6(_Znwm+0x52)[0x7f3012f65522]
[cycle:678494] [ 8] /opt/anaconda3/lib/python3.7/site-packages/neuron/.data/share/nrn/../../lib/libnrnpython3.so(+0x1d751)[0x7f2fffdc5751]
[cycle:678494] [ 9] /opt/anaconda3/lib/python3.7/site-packages/neuron/.data/bin/../lib/libnrniv.so(+0x273405)[0x7f30132bb405]
[cycle:678494] [10] /opt/anaconda3/lib/python3.7/site-packages/neuron/.data/bin/../lib/libnrniv.so(hoc_call_ob_proc+0x2ab)[0x7f30132f5d3b]
[cycle:678494] [11] /opt/anaconda3/lib/python3.7/site-packages/neuron/.data/bin/../lib/libnrniv.so(hoc_object_component+0x5c7)[0x7f30132f6a47]
[cycle:678494] [12] /opt/anaconda3/lib/python3.7/site-packages/neuron/.data/share/nrn/../../lib/libnrnpython3.so(+0xf93b)[0x7f2fffdb793b]
[cycle:678494] [13] /opt/anaconda3/lib/python3.7/site-packages/neuron/.data/share/nrn/../../lib/libnrnpython3.so(+0x12b74)[0x7f2fffdbab74]
[cycle:678494] [14] /opt/anaconda3/lib/python3.7/site-packages/neuron/.data/bin/../lib/libnrniv.so(_ZN10OcJumpImpl7fpycallEPFPvS0_S0_ES0_S0_+0x3e)[0x7f30132c133e]
[cycle:678494] [15] /opt/anaconda3/lib/python3.7/site-packages/neuron/.data/share/nrn/../../lib/libnrnpython3.so(+0x12fce)[0x7f2fffdbafce]
[cycle:678494] [16] /opt/anaconda3/lib/./libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0xc5)[0x7f30081ce945]
[cycle:678494] [17] /opt/anaconda3/lib/./libpython3.7m.so.1.0(+0x6f091)[0x7f30080f7091]
[cycle:678494] [18] /opt/anaconda3/lib/./libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x710a)[0x7f30080f510a]
[cycle:678494] [19] /opt/anaconda3/lib/./libpython3.7m.so.1.0(_PyEval_EvalCodeWithName+0xade)[0x7f30082a7fae]
[cycle:678494] [20] /opt/anaconda3/lib/./libpython3.7m.so.1.0(_PyFunction_FastCallKeywords+0x90)[0x7f30081cdfc0]
[cycle:678494] [21] /opt/anaconda3/lib/./libpython3.7m.so.1.0(+0x6f116)[0x7f30080f7116]
[cycle:678494] [22] /opt/anaconda3/lib/./libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x710a)[0x7f30080f510a]
[cycle:678494] [23] /opt/anaconda3/lib/./libpython3.7m.so.1.0(_PyEval_EvalCodeWithName+0xade)[0x7f30082a7fae]
[cycle:678494] [24] /opt/anaconda3/lib/./libpython3.7m.so.1.0(PyEval_EvalCodeEx+0x3f)[0x7f30082a809f]
[cycle:678494] [25] /opt/anaconda3/lib/./libpython3.7m.so.1.0(PyEval_EvalCode+0x1c)[0x7f30081970cc]
[cycle:678494] [26] /opt/anaconda3/lib/./libpython3.7m.so.1.0(PyRun_FileExFlags+0xb7)[0x7f30081867d7]
[cycle:678494] [27] /opt/anaconda3/lib/./libpython3.7m.so.1.0(PyRun_SimpleFileExFlags+0xf4)[0x7f30081fcd64]
[cycle:678494] [28] /opt/anaconda3/lib/python3.7/site-packages/neuron/.data/share/nrn/../../lib/libnrnpython3.so(nrnpy_pyrun+0x2c)[0x7f2fffdb70ac]
[cycle:678494] [29] /opt/anaconda3/lib/python3.7/site-packages/neuron/.data/share/nrn/../../lib/libnrnpython3.so(nrnpython_start+0x278)[0x7f2fffdb7638]
[cycle:678494]  End of error message 
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpiexec noticed that process rank 0 with PID 0 on node cycle exited on signal 6 (Aborted).
--------------------------------------------------------------------------

will run same sim but for 1600 s instead of 3200 s ... hopefully will not have a memory error in gatherdata ... 

./myrun 32 sn.json 

started ~22:35 ... finished ~10 hours later (including save)

t= 1599999.8  game rewards: [0]
  Done; run time = 33818.91 s; real-time ratio: 0.05.

Gathering data...
  Done; gather time = 34.85 s.

Analyzing...
  Cells: 4280
  Connections: 0 (0.00 per cell)
  Spikes: 13510421 (1.97 Hz)
  Simulated time: 1600.0 s; 32 workers
  Run time: 33818.91 s
fatal: not a git repository (or any of the parent directories): .git
Saving output as data/20jun27_G1_cycle_simConfig.pkl ... 
Finished saving!
  Done; saving time = 26.95 s.

* 20jun29
** check output from 20jun27_G1_cycle_

python -i simdat.py backupcfg/20jun27_G1_cycle_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),asratio=True); 
plotRewards(actreward,ax=subplot(1,3,3)); 

score/miss, hit/miss ratio: (0.09251700680272108, 0.36054421768707484) <<-- last sim (follow target prob is increasing up to ~0.43)
score/miss, hit/miss ratio: (0.08238636363636363, 0.4375)
score/miss goes up and down a little but hit/miss has risen substantially
follow target has increased a bit too (ends near 0.46)

savefig('gif/'+dstr+simstr+'perf.png') # 20jun29_20jun27_G1_cycle_perf.png

clf(); drawraster(dspkT,dspkID); xlim((1590e3,1600e3)); savefig('gif/'+dstr+simstr+'rastB.png') # 
rates getting higher ... 

rcParams['agg.path.chunksize'] = 100000000000
clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM']); xlim((1590e3,1600e3)); savefig('gif/'+dstr+simstr+'Vm.png'); 

#
clf(); dobjpos = loadObjPos() ## hmm, did not save objpos?? got error ... 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png') # 

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb'))
# data/20jun27_G1_cycle_synWeights_final.pkl

lfn = ['20jun26_G0_cycle_ActionsRewards.txt','20jun27_G1_cycle_ActionsRewards.txt']
lfn = ['data/'+x for x in lfn]
pda = getconcatactionreward(lfn)

#
clf()
plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(pda,ax=subplot(1,3,2),asratio=True); 
plotRewards(pda,ax=subplot(1,3,3)); 

final score/miss, hit/miss ratios: (0.08923643054277829, 0.38546458141674333)

savefig('gif/'+dstr+simstr+'perf_step0_step1.png') # 20jun29_20jun27_G1_cycle_perf_step0_step1.png

lpda = getindivactionreward(lfn)

#
clf()
plotFollowBall(lpda[0],ax=subplot(1,2,1),cumulative=True,color='g'); ylim((0,.6))
plotFollowBall(lpda[1],ax=subplot(1,2,1),cumulative=True,color='r'); ylim((0,.6))
plotHitMiss(lpda[0],ax=subplot(1,2,2),asratio=True,lclr=['c','m']); 
plotHitMiss(lpda[1],ax=subplot(1,2,2),asratio=True,lclr=['r','g']); 

#
clf()
plotFollowBall(lpda[0],ax=subplot(1,3,1),cumulative=True,color='b'); ylim((0,.6)); xlim((0,3200e3));
plotFollowBall(lpda[1],ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6)); xlim((0,3200e3));
plotHitMiss(lpda[0],ax=subplot(1,3,2),lclr=['b'],asratio=True); ylim((0,.6)); xlim((0,3200e3));
plotHitMiss(lpda[1],ax=subplot(1,3,2),lclr=['r'],asratio=True); ylim((0,.6)); xlim((0,3200e3));
plotScoreMiss(lpda[0],ax=subplot(1,3,3),clr='b',asratio=True); ylim((0,.6)); xlim((0,3200e3));
plotScoreMiss(lpda[1],ax=subplot(1,3,3),clr='r',asratio=True); ylim((0,.6)); xlim((0,3200e3));

savefig('gif/'+dstr+simstr+'perf_compare_step0_step1.png') # 20jun29_20jun27_G1_cycle_perf_compare_step0_step1.png

so overlay shows that second step is an improvement over first ... but score/miss ratio does not improve much
and follow target prob seems to be decreasing in second step ... 

and how does it compare to the smaller population of EM neurons?

lfn = ['20jun20_F0_targetted_tank_ActionsRewards.txt','20jun26_G0_cycle_ActionsRewards.txt']
lfn = ['data/'+x for x in lfn]
lpda = getindivactionreward(lfn)

#
clf()
plotFollowBall(lpda[0],ax=subplot(1,3,1),cumulative=True,color='b'); ylim((0,.6)); xlim((0,800e3));
plotFollowBall(lpda[1],ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6)); xlim((0,800e3));
plotHitMiss(lpda[0],ax=subplot(1,3,2),lclr=['b'],asratio=True); ylim((0,.6)); xlim((0,800e3));
plotHitMiss(lpda[1],ax=subplot(1,3,2),lclr=['r'],asratio=True); ylim((0,.6)); xlim((0,800e3));
plotScoreMiss(lpda[0],ax=subplot(1,3,3),clr='b',asratio=True); ylim((0,.6)); xlim((0,800e3));
plotScoreMiss(lpda[1],ax=subplot(1,3,3),clr='r',asratio=True); ylim((0,.6)); xlim((0,800e3));

savefig('gif/'+dstr+simstr+'perf_compare_16x16_32x32.png') # 20jun29_20jun27_G1_cycle_perf_compare_16x16_32x32.png

so larger population of EM seems to help only for follow target probability, otherwise over same
interval, everything else looks ~same

so may want a larger network ... though won't fix everything ... 

still have to fix movie generation on cycle... 

lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN']  
dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)

import logging
logger = logging.getLogger('matplotlib')
logger.setLevel(logging.INFO)
print(animation._log.getEffectiveLevel() > logging.DEBUG) # prints True

hmm, does not help

ffmpeg from terminal reports missing openh264 library

conda remove imageio-ffmpeg
sudo apt-get install ffmpeg

this: export LD_LIBRARY_PATH="/opt/anaconda3/lib"
in .bashrc seems to be causing the problem; getting rid
of it seems to fix the problem with missing libtinfo...but still have a ffmpeg problem...

did conda upgrade ffmpeg
and seems to work now ... 

#plt.rcParams['animation.ffmpeg_path'] = '/opt/anaconda3/bin/ffmpeg' # Add the path of ffmpeg here!!
#plt.rcParams['animation.ffmpeg_path'] = '/usr/bin/ffmpeg' # Add the path of ffmpeg here!!
fig, axs, plt = animActivityMaps(lpop=lpop) # <<-- WAS getting error on cycle

** try larger EM population (EMDOWN, EMUP, IM: 64,64,32) ; name = 20jun29_64_H0_cycle_

    "net":{"scale":1,"ER":400,"IR":100,"EV1":400,"EV1DE":400,"EV1DNE":400,"EV1DN":400,"EV1DNW":400,"EV1DW":400,"EV1DSW":400,"EV1DS":400,"EV1DSE":400,"IV1":100,"EV4":0,"IV4":0,"EMT":0,"IMT":0,"EMDOWN":64,"EMUP":64,"IM":32,"AngRFSigma":22.5,"DirMinRate":0.0,"DirMaxRate":50.0,"EEMWghtAM":0.000012,"EEMWghtNM":0.0000012,"EEPreMWghtAM":0.00008,"EEPreMWghtNM":0.0000025,"EEMWghtThreshMin":0.00000625,"EEMWghtThreshMax":0.00032,"EEMProb":1.0,"EEMRecProb":0.0,"EEPreMProb":0.0,"EEMPopNorm":0,"EEMRecProbCross":0,"EEMFeedbackProb":0.0,"EEMFeedbackWghtAM":0.0000125,"EEMFeedbackWghtNM":0.00000125,"VisualFeedback":0,"weightVar":0.1},

20jun29_64_H0_cycle_

run for 1600 s ... 

./myrun 32 sn.json

started ~noon

finished ~23:05

check output ...

python -i simdat.py backupcfg/20jun29_64_H0_cycle_sim.json

lfn = ['20jun20_F0_targetted_tank_ActionsRewards.txt','20jun26_G0_cycle_ActionsRewards.txt','20jun29_64_H0_cycle_ActionsRewards.txt']
lfn = ['data/'+x for x in lfn]
lpda = getindivactionreward(lfn)

#
plotFollowBall(lpda[0],ax=subplot(1,3,1),cumulative=True,color='b'); ylim((0,.6)); 
plotFollowBall(lpda[1],ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6)); 
plotFollowBall(lpda[2],ax=subplot(1,3,1),cumulative=True,color='g'); ylim((0,.6)); xlim((0,1600e3));
plotHitMiss(lpda[0],ax=subplot(1,3,2),lclr=['b'],asratio=True); ylim((0,.6)); 
plotHitMiss(lpda[1],ax=subplot(1,3,2),lclr=['r'],asratio=True); ylim((0,.6)); 
plotHitMiss(lpda[2],ax=subplot(1,3,2),lclr=['g'],asratio=True); ylim((0,.6)); xlim((0,1600e3));
plotScoreMiss(lpda[0],ax=subplot(1,3,3),clr='b',asratio=True); ylim((0,.6)); 
plotScoreMiss(lpda[1],ax=subplot(1,3,3),clr='r',asratio=True); ylim((0,.6)); 
plotScoreMiss(lpda[2],ax=subplot(1,3,3),clr='g',asratio=True); ylim((0,.6)); xlim((0,1600e3))

savefig('gif/'+dstr+simstr+'perf_compare_16_32_64.png') # 

based on that it looks like the network with 32 EMDOWN, 32 EMUP, 16 IM has the best performance
(green) 64,64,32 seems to perform slightly worse...perhaps higher weightvar would help the
64,64,32?

clf(); drawraster(dspkT,dspkID); xlim((1590e3,1600e3)); savefig('gif/'+dstr+simstr+'rastB.png') # 
# 20jun29_20jun29_64_H0_cycle_rastB.png
xlim((1590e3,1592e3)); savefig('gif/'+dstr+simstr+'rastC.png') # 
20jun29_20jun29_64_H0_cycle_rastC.png

performance could be degraded due to hypersynch and/or low rates of EMUP, EMDOWN ... may need
more time to develop ... 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM']); xlim((1590e3,1600e3)); savefig('gif/'+dstr+simstr+'Vm.png'); 
20jun29_20jun29_64_H0_cycle_Vm.png

#
clf(); dobjpos = loadObjPos() #
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')
plenty of the initial bias ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png') # 
20jun29_20jun29_64_H0_cycle_all_avg_weight.png
much more diversity in weights ... probably worth continuing this one later on ... 

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb'))
data/20jun29_64_H0_cycle_synWeights_final.pkl

** compare and check output/performance from 20jun26_F4_targetted_reduced_tank_ and 20jun26_F4_targetted_tank_

reduced has the weight norm every 400 s ... 

python -i simdat.py backupcfg/20jun26_F4_targetted_tank_sim.json

lfn = ['20jun26_F4_targetted_tank_ActionsRewards.txt','20jun26_F4_targetted_reduced_tank_ActionsRewards.txt']
lfn = ['data/'+x for x in lfn]
lpda = getindivactionreward(lfn)

#
clf()
plotFollowBall(lpda[0],ax=subplot(1,3,1),cumulative=True,color='b'); ylim((0,.6)); xlim((0,1600e3));
plotFollowBall(lpda[1],ax=subplot(1,3,1),cumulative=True,color='r'); ylim((0,.6)); xlim((0,1600e3));
plotHitMiss(lpda[0],ax=subplot(1,3,2),lclr=['b'],asratio=True); ylim((0,.7)); xlim((0,1600e3));
plotHitMiss(lpda[1],ax=subplot(1,3,2),lclr=['r'],asratio=True); ylim((0,.7)); xlim((0,1600e3));
plotScoreMiss(lpda[0],ax=subplot(1,3,3),clr='b',asratio=True); ylim((0,.6)); xlim((0,1600e3));
plotScoreMiss(lpda[1],ax=subplot(1,3,3),clr='r',asratio=True); ylim((0,.6)); xlim((0,1600e3));

savefig('gif/'+dstr+simstr+'perf_compare_norm_red_no_norm_blue.png') # (red is with normalization, blue is without)

interesting ... normalization during sim (at 400, 800, 1200, 1600 s) does not seem to help and
even harms - is it due to wrong time interval between normalization or the normalization itself
interferes with performance and retainment of memory? more interesting is that sim wit
normalization (but before first normalization) has pretty high hit/miss ratio pre 400 s ...
higher than have seen in other sims; sim without normalization also has pretty good
performance close to 50% level for hit/miss ratio ... 

should make movies of both and make sure activity looks ok, determine whether to continue them ...

clf(); drawraster(dspkT,dspkID); xlim((1590e3,1600e3)); savefig('gif/'+dstr+simstr+'rastB.png') # 
very high rates (~27 Hz for EMUP,EMDOWN; IM ~69 Hz)

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM']); xlim((1590e3,1600e3)); savefig('gif/'+dstr+simstr+'Vm.png'); 
cells not really in dep block so seems ok if they have high firing rates...
xlim((1590e3,1591e3)); savefig('gif/'+dstr+simstr+'VmB.png'); 

#
clf(); dobjpos = loadObjPos() ## hmm, did not save objpos?? got error ... 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')
very little bias for position 0 left ...

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png') # 

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb'))
# data/20jun26_F4_targetted_tank_synWeights_final.pkl

code right below is what used for weight norm that seemed to have a more positive impact ... ? or did it ... ? it had a drop and
then ramped up ... so might have nothing to do with the weight norm ... 
"""np.mean(pdfs.weight) # 2.0353749694156496e-05
avgfinalw = np.mean(pdfs.weight)
initw = 0.000012 # initial weight
avgfinalw / initw # 1.6961458078463747
fctr = initw / avgfinalw # 0.5895719550607015
pdf.weight *= fctr
pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final_reduced.pkl','wb'))"""
so that reduction is using average final weight to both populations, not same as done in the sim code ... 
which normalizes based on max weight to a population

lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN']  
dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
fig, axs, plt = animActivityMaps(lpop=lpop)

and check the reduced model's activity ... to make a movie ... see how it looks when performing well ... 

python -i simdat.py backupcfg/20jun26_F4_targetted_reduced_tank_sim.json

clf(); drawraster(dspkT,dspkID); xlim((1590e3,1600e3)); savefig('gif/'+dstr+simstr+'rastB.png') # 

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png')
lot of bias towards top there

lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN']  
dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
fig, axs, plt = animActivityMaps(lpop=lpop)

** start next two on falcor

    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20jun26_F4_targetted_tank_synWeights_final.pkl"}, 

*** first without weight norm (20jun29_F5_targetted_tank_)

./myrun 16 sn.json

started ~22:24 ... 

*** second with new weight norm in sim (20jun29_F5_targetted_norm_tank_)

    # normalize weights across populations to avoid bias 
    if dconf['net']['EEMPopNorm']:
      curravgw = np.mean([davg[k] for k in lpop])
      for k in lpop: dfctr[k] = initw / curravgw

this way also do not have to deal with min and max thresh for the normalization and
use the same norm for both populations maintaining the relative weights (which are biased, but
that's not a problem, is it? since based on learning appropriate responses) 

all params same as 20jun29_F5_targetted_tank_ except that has "normalizeWeightStepSize":20000  <<-- that means weight norm every 400 ms ... 
and "EEMPopNorm":1 <<-- that means use average weight to rescale both populations' weights to initial weight, but preserving relative values

./myrun 16 sn.json

started ~22:45 ...

** continue 20jun27_G1_cycle_ (EMDOWN,EMUP,IM: 32,32,16) as 20jun29_G2_cycle_

    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20jun27_G1_cycle_synWeights_final.pkl"}, 

./myrun 32 sn.json

started ~23:45 ...

finished @ 9:39 next morning ...

* 20jun30
** check output from last sim on cycle (20jun29_G2_cycle_) has (EMDOWN,EMUP,IM: 32,32,16)

python -i simdat.py backupcfg/20jun29_G2_cycle_sim.json

lfn = ['20jun26_G0_cycle_ActionsRewards.txt','20jun27_G1_cycle_ActionsRewards.txt','20jun29_G2_cycle_ActionsRewards.txt']
lfn = ['data/'+x for x in lfn]
lpda = getindivactionreward(lfn)

#
for pda,clr in zip(lpda,['b','g','r']):
  plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color=clr);  
  plotHitMiss(pda,ax=subplot(1,3,2),lclr=[clr],asratio=True); 
  plotScoreMiss(pda,ax=subplot(1,3,3),clr=clr,asratio=True); 

savefig('gif/'+dstr+simstr+'perf_compare_steps.png') # 20jun30_20jun29_G2_cycle_perf_compare_steps.png

looks like some improvement but mostly stuck for the last step
interesting that there's a large spike in performance at beginning of step 3 (red) but then after 200 s
it drops to step 2 performance levels (green). is that just an accident of which location the ball was hit to?
will have to check in movie ... 

pdac = getconcatactionreward(lfn)
plotFollowBall(pdac,ax=subplot(1,3,1),cumulative=True,color='k');  
plotHitMiss(pdac,ax=subplot(1,3,2),lclr=['k'],asratio=True); 
plotScoreMiss(pdac,ax=subplot(1,3,3),clr='k',asratio=True); 

final hit/miss ratio 0.38392857142857145
final score/miss ratio 0.08585164835164835

savefig('gif/'+dstr+simstr+'perf_compare_steps_and_cumulative.png')

clf(); drawraster(dspkT,dspkID); 
xlim((0e3,10e3)); savefig('gif/'+dstr+simstr+'rastA.png') # 
xlim((10e3,20e3)); savefig('gif/'+dstr+simstr+'rastB.png') # 
xlim((190e3,200e3)); savefig('gif/'+dstr+simstr+'rastC.png') # 
xlim((200e3,210e3)); savefig('gif/'+dstr+simstr+'rastD.png') # 

drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=(0,10e3)); tl(); savefig('gif/'+dstr+simstr+'Vm.png'); 
drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=(10e3,20e3)); tl(); savefig('gif/'+dstr+simstr+'VmB.png'); 
drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=(190e3,200e3)); tl(); savefig('gif/'+dstr+simstr+'VmC.png'); 
drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=(200e3,210e3)); tl(); savefig('gif/'+dstr+simstr+'VmD.png'); 

20jun30_20jun29_G2_cycle_Vm.png
20jun30_20jun29_G2_cycle_VmB.png
20jun30_20jun29_G2_cycle_VmC.png
20jun30_20jun29_G2_cycle_VmD.png

activity looks ok in general ... do not see anything strange around when performance drops

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # 20jun30_20jun29_G2_cycle_poshist.png

some bias ... not terrible ...

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png') # 

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb'))
# data/20jun29_G2_cycle_synWeights_final.pkl
can continue or run a multistep sim ... maybe more benefit to that so do not have to keep restarting manually ... 

lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN']  
dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
fig, axs, plt = animActivityMaps(lpop=lpop)

may as well continue as a multistep sim ... see if improves further with longer runs;
easier than restarting each time ...

first setup the base sn.json ... 

hmm, problem with multistep sim is that it does not use the final weights, uses full weights, so that
will likely lead to a memory error if 32 cores all using large amount of RAM ... well, 2 GB x 32 = 64 GB,
within system limits ... 

could have multistep auto-create final weights ... sim.py can do that too ... 

ok, sim.py will do that ... that way won't have to create each time 

try it out ...
20jun30_G3_cycle_
    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20jun29_G2_cycle_synWeights_final.pkl"}, 

run for 10 s ... 

seems to have worked ...

now try multistepSim.py ... will make it for 2 10 s steps and make sure works

python multistepSim.py sn.json 32 2 multirun

ok, seemed to work ... will run 10 1600 s sims ... 

will take a couple of days ... 

python multistepSim.py sn.json 32 10 multirun

base name is 20jun30_G3_cycle_

started ~12:33 ... 

check how it's doing ... 

** the dqn models

https://github.com/ykteh93/Deep_Reinforcement_Learning-Atari
https://github.com/araina2/Deep-Reinforcement-Learning
https://github.com/brendanator/atari-rl
https://github.com/kuz/DeepMind-Atari-Deep-Q-Learner
https://github.com/Nasdin/ReinforcementLearning-AtariGame

some of these stack 4 frames together to get motion
information and use the 4 frames to decide a single action

would that help with momentum issue?

also would be better if model did not use object detection
and flow calculations ... nor intermediate rewards ... otherwise,
not exactly a fair comparison against dqn ...

** quick test of tstepPerAction":100 (20jun30_H0_cycle_)

initialized weights from data/20jun29_G2_cycle_synWeights_final.pkl

* 20jul1
** check output from 20jun30_H0_cycle_

python -i simdat.py backupcfg/20jun30_H0_cycle_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k');  
plotHitMiss(actreward,ax=subplot(1,3,2),lclr=['k'],asratio=True); 
plotScoreMiss(actreward,ax=subplot(1,3,3),clr='k',asratio=True);

hit/miss and score/miss ratios: 0.7241379310344828, 0.13793103448275862
pretty high ratios - surprising...

savefig('gif/'+dstr+simstr+'perf.png') # 20jul1_20jun30_H0_cycle_perf.png

clf(); drawraster(dspkT,dspkID); xlim((790e3,800e3));
savefig('gif/'+dstr+simstr+'rast.png') # 20jul1_20jun30_H0_cycle_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=(790e3,800e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # 20jul1_20jun30_H0_cycle_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # 20jul1_20jun30_H0_cycle_poshist.png
not much bias

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png') #
hmm, looks like weights did not change ... did not intend that ... 

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb'))
#

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)
gif/20jul1_20jun30_H0_cycle__input.mp4

looked like paddle was trying to stay still when ball coming head on but had difficulty since
no explicit stay population was used ... 

** adjust EMstay and targetted rule

right now if two populations are tied, it picks randomly between them for action -- can make it default to stay
to help with momentum issue, later can make random ... or keep random - either could help
if no populations fire it still picks randomly -->> that should be adjusted to do nothing (stay/nomove)
but in targetted rl if two populations/actions are tied it should not reward/punish either one of them

also adjusted targetted rule - only apply RL when there's a clear winner; any ties in the larger
two populations and still no RL will be applied

** try with EMstay population

32 of them same as EMDOWN, EMUP
IM -->> 24

20jun30_S0_cycle_

run for 100 s ... see how looks, 20 ms window for actions

./myrun 32 sn.json

python -i simdat.py backupcfg/20jun30_S0_cycle_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k');  
plotHitMiss(actreward,ax=subplot(1,3,2),lclr=['k'],asratio=True); 
plotScoreMiss(actreward,ax=subplot(1,3,3),clr='k',asratio=True);

savefig('gif/'+dstr+simstr+'perf.png') 

clf(); drawraster(dspkT,dspkID); xlim((90e3,100e3));
savefig('gif/'+dstr+simstr+'rast.png') 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(90e3,100e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # 

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # 20jul1_20jun30_S0_cycle_poshist.png

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png') #
more complicated pattern ... 

pdfs = pdf[pdf.time==np.amax(pdf.time)]; D = pdf2weightsdict(pdfs); pickle.dump(D, open('data/'+simstr+'synWeights_final.pkl','wb'))
# data/20jun30_S0_cycle_synWeights_final.pkl

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)

sits a lot more still than the other models ... can continue run longer to see if improves ...

    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20jun30_S0_cycle_synWeights_final.pkl"}, 
20jun30_S1_cycle_

started ~13:31, finished ~19:46 ...

python -i simdat.py backupcfg/20jun30_S1_cycle_sim.json

#
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k');  
plotHitMiss(actreward,ax=subplot(1,3,2),lclr=['k'],asratio=True); 
plotScoreMiss(actreward,ax=subplot(1,3,3),clr='k',asratio=True);

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul1_20jun30_S1_cycle_perf.png

looks like increasing but slowly and from lower values than other recent sims ... 

hit/miss and score/miss ratios: 0.145, 0.045

clf(); drawraster(dspkT,dspkID); xlim((690e3,700e3));
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul1_20jun30_S1_cycle_rast.png

EMSTAY has slightly lower rates here ... 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(690e3,700e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul1_20jun30_S1_cycle_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul1_20jun30_S1_cycle_poshist.png
still lot of time at edges

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul1_20jun30_S1_cycle_all_avg_weight.png
more complicated pattern ... but clear the EMSTAY weights are decreasing ... while others increasing ...

hmm, since each neuron of a pop gets same inputs, all the synapses go in same direction at same time ... that
seems too redundant, even though weights start with some variability ...  

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) # gif/20jul1_20jun30_S1_cycle__input.mp4

since values still increasing can run another continuation ...

    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20jun30_S1_cycle_synWeights_final.pkl"},
"name":"20jun30_S2_cycle_"

will run longer ... (1600 s)

./myrun 32 sn.json

started ~21:42 ...

** meanwhile check output from multistep sim

python -i simdat.py backupcfg/20jun30_G3_cycle__step_2_sim.json

lfn = ['20jun26_G0_cycle_ActionsRewards.txt','20jun27_G1_cycle_ActionsRewards.txt','20jun29_G2_cycle_ActionsRewards.txt','20jun30_G3_cycle__step_0_ActionsRewards.txt','20jun30_G3_cycle__step_1_ActionsRewards.txt','20jun30_G3_cycle__step_2_ActionsRewards.txt']
lfn = ['data/'+x for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.5))
plotHitMiss(pdac,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.5))
plotScoreMiss(pdac,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.5))

hit/miss and score/miss ratios: 0.39151130503768344, 0.09401031336771122

looks pretty flat ... though follow target slowly decaying? can let multistep run continue but might be pointless ... 

savefig('gif/'+dstr+simstr+'perf_multistep.png') # 'gif/20jul1_20jun30_G3_cycle__step_2_perf_multistep.png'

* 20jul2
** check next output from multistep sim

python -i simdat.py backupcfg/20jun30_G3_cycle__step_3_sim.json

lfn = ['20jun26_G0_cycle_ActionsRewards.txt','20jun27_G1_cycle_ActionsRewards.txt','20jun29_G2_cycle_ActionsRewards.txt','20jun30_G3_cycle__step_0_ActionsRewards.txt','20jun30_G3_cycle__step_1_ActionsRewards.txt','20jun30_G3_cycle__step_2_ActionsRewards.txt','20jun30_G3_cycle__step_3_ActionsRewards.txt']
lfn = ['data/'+x for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.5))
plotHitMiss(pdac,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.5))
plotScoreMiss(pdac,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.5))

last hit/miss and score/miss ratios: 0.39151130503768344, 0.09401031336771122
this hit/miss and score/miss ratios: 0.38453572661373836, 0.09423541594753193

savefig('gif/'+dstr+simstr+'perf_multistepB.png') # gif/20jul2_20jun30_G3_cycle__step_3_perf_multistepB.png

#
clf()
aout = plotFollowBall(pdac,ax=gca(),binsz=5e3,cumulative=False,color='r');  ylim((0,.65))
plotFollowBall(pdac,ax=gca(),cumulative=True,color='k');  ylim((0,.65))

savefig('gif/'+dstr+simstr+'perf_multistep_pfollow_C.png') # gif/20jul2_20jun30_G3_cycle__step_3_perf_multistep_pfollow_C.png

looks like probability of follow target decreasing gradually ... should probably stop
this multistep sim ... ok stopped it ... 

** check output from 20jun30_S2_cycle_

python -i simdat.py backupcfg/20jun30_S2_cycle_sim.json

plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.5))
plotHitMiss(actreward,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.5))
plotScoreMiss(actreward,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.5))

0.26683291770573564, 0.0798004987531172

clear improvement ...

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul2_20jun30_S2_cycle_perf.png

should continue ...

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)

name:
20jul2_S3_cycle_
    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20jun30_S2_cycle_synWeights_final.pkl"},


started

** also start simpler test (20jul2_T0_cycle_), no score/loss, shorter RL tau

same architecture but only reward for follow / not follow target and hit
and shorten RL tau ...

20jul2_T0_cycle_

    "rewardcodes": {"scorePoint": 0.0, "losePoint": 0.0, "followTarget": 0.1, "avoidTarget": -0.01, "hitBall": 0.5},

"RLlenhebb":40

./myrun 32 sn.json

started ~15:02 ...

* 20jul3
** check output from simpler test (20jul2_T0_cycle_) -->> not as good perf

python -i simdat.py backupcfg/20jul2_T0_cycle_sim.json

plotFollowBall(actreward,ax=subplot(1,2,1),cumulative=True,color='k');  ylim((0,.5))
plotHitMiss(actreward,ax=subplot(1,2,2),lclr=['k'],asratio=True); ylim((0,.5))

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul3_20jul2_T0_cycle_perf.png

seems mostly flat...not as good as other sim so far ... not sure if it's to
do with the shorter time constant or the rewards ... could run a comparison
with a longer time constant ... (200 ms), with rewards same

clf(); drawraster(dspkT,dspkID); xlim((1590e3,1600e3));
savefig('gif/'+dstr+simstr+'rast.png') # 

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png') #

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)

** run simpler test (20jul3_T0_cycle), reward only move to target and hit, but with longer RL tau

"RLlenhebb":200
"name":"20jul3_T0_cycle_"
"duration": 500000

./myrun 32 sn.json

started ~11:10 ...

finished ~ 15:13

python -i simdat.py backupcfg/20jul3_T0_cycle_sim.json

plotFollowBall(actreward,ax=subplot(1,2,1),cumulative=True,color='k');  ylim((0,.5))
plotHitMiss(actreward,ax=subplot(1,2,2),lclr=['k'],asratio=True); ylim((0,.5))

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul3_20jul3_T0_cycle_perf.png

lfn = ['20jul2_T0_cycle_','20jul3_T0_cycle_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
lpda = getindivactionreward(lfn)

#
for pda,clr in zip(lpda,['b','r']):
  plotFollowBall(pda,ax=subplot(1,2,1),cumulative=True,color=clr);  
  plotHitMiss(pda,ax=subplot(1,2,2),lclr=[clr],asratio=True); 

savefig('gif/'+dstr+simstr+'perf_compare_tau.png') # gif/20jul3_20jul3_T0_cycle_perf_compare_tau.png

lfn = ['20jul2_T0_cycle_','20jul3_T0_cycle_', '20jun30_S1_cycle_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
lpda = getindivactionreward(lfn)

#
for pda,clr in zip(lpda,['b','r','g']):
  plotFollowBall(pda,ax=subplot(1,2,1),cumulative=True,color=clr);  xlim((0,500e3));
  plotHitMiss(pda,ax=subplot(1,2,2),lclr=[clr],asratio=True); xlim((0,500e3))

probably need to run longer ...

will continue the 200 ms tau sim ... to leave that out as a factor ...

20jul3_T1_cycle_
    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20jul3_T0_cycle_synWeights_final.pkl"}, 
each step will run for 800 s ... use 16 cores to save 16 others if needed ...

python multistepSim.py sn.json 16 4 multirunT

started ~15:51 ... 

** check output from 20jul2_S3_cycle_ -->> looked to be improving; continue as multistep

python -i simdat.py backupcfg/20jul2_S3_cycle_sim.json

plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.5))
plotHitMiss(actreward,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.5))
plotScoreMiss(actreward,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.5))

0.26683291770573564, 0.0798004987531172 <<-- last time
0.4746268656716418, 0.13432835820895522 <<-- this time

clear improvement ...

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul3_20jul2_S3_cycle_perf.png

lfn = ['20jun30_S0_cycle_', '20jun30_S1_cycle_', '20jun30_S2_cycle_', '20jul2_S3_cycle_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.5))
plotHitMiss(pdac,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.5))
plotScoreMiss(pdac,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.5))

savefig('gif/'+dstr+simstr+'perf_tot.png') # 20jul3_20jul2_S3_cycle_perf_tot.png

seems like improving ... so worth continuing ... 


clf(); drawraster(dspkT,dspkID); xlim((1590e3,1600e3));
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul3_20jul2_S3_cycle_rast.png
interesting, EMSTAY is firing much less than EMUP and EMDOWN

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1590e3,1600e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul3_20jul2_S3_cycle_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul3_20jul2_S3_cycle_poshist.png

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png') # 20jul3_20jul2_S3_cycle_all_avg_weight.png

EMSTAY input weights are much lower than input weights to EMDOWN and EMUP
though EMSTAY input weights still rising slowly now ...
savefig('gif/'+dstr+simstr+'all_avg_weightB.png') # 20jul3_20jul2_S3_cycle_all_avg_weightB.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)

meanwhile, setup for continue - could use multistep ...

    "simtype": {"ResumeSim":1,"ResumeSimFromFile":"data/20jul2_S3_cycle_synWeights_final.pkl"},
20jul3_S4_cycle_

will run ~4 steps to start ... to see how it progresses ...

python multistepSim.py sn.json 32 4 multirun

started ~12:02 ...

** sim with only score/loss and longer RL tau? (20jul3_NO_INTERMR_cycle_)

to avoid any intermediate rewards ... see if it improves at all ... 

"name":"20jul3_NO_INTERMR_cycle_"
"RLlenhebb":2000
    "rewardcodes": {"scorePoint": 1.0, "losePoint": -0.1, "followTarget": 0.0, "avoidTarget": 0.0, "hitBall": 0.0},

duration of 800 s ...

python multistepSim.py sn.json 16 4 multirunNOINTERM

* 20jul4
** check 20jul3_NO_INTERMR_cycle__step_1_

this is the sim with no intermediate rewards, and the long RL time constants ... 

python -i simdat.py backupcfg/20jul3_NO_INTERMR_cycle__step_1_sim.json

plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.5))
plotHitMiss(actreward,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.5))
plotScoreMiss(actreward,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.5))

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul4_20jul3_NO_INTERMR_cycle__step_1_perf.png

lower values than other recent sims on cycle, but does seem to be improving somewhat ... 

lfn = ['20jul3_NO_INTERMR_cycle__step_0_','20jul3_NO_INTERMR_cycle__step_1_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.5))
plotHitMiss(pdac,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.5))
plotScoreMiss(pdac,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.5))

savefig('gif/'+dstr+simstr+'perf_step0_step1.png') # 

or maybe not improving much ...

clf(); drawraster(dspkT,dspkID); xlim((790e3,800e3));
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul4_20jul3_NO_INTERMR_cycle__step_1_rast.png
as usual, EMSTAY rates lower than EMUP,EMDOWN

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(790e3,800e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul4_20jul3_NO_INTERMR_cycle__step_1_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul4_20jul3_NO_INTERMR_cycle__step_1_poshist.png
plenty of bias in position...(towards top)

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)
gif/20jul4_20jul3_NO_INTERMR_cycle__step_1__input.mp4

* 20jul5
** check 20jul3_NO_INTERMR_cycle__step_2_

this is the sim with no intermediate rewards, and the long RL time constants ... 

python -i simdat.py backupcfg/20jul3_NO_INTERMR_cycle__step_2_sim.json

plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.5))
plotHitMiss(actreward,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.5))
plotScoreMiss(actreward,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.5))

savefig('gif/'+dstr+simstr+'perf.png') # if/20jul5_20jul3_NO_INTERMR_cycle__step_2_perf.png
is it better than last step? seems a little better ... 

lfn = ['20jul3_NO_INTERMR_cycle__step_0_','20jul3_NO_INTERMR_cycle__step_1_','20jul3_NO_INTERMR_cycle__step_2_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.5))
plotHitMiss(pdac,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.5))
plotScoreMiss(pdac,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.5))

savefig('gif/'+dstr+simstr+'perf_step0_step1_step2.png') # gif/20jul5_20jul3_NO_INTERMR_cycle__step_2_perf_step0_step1_step2.png

clf(); drawraster(dspkT,dspkID); xlim((790e3,800e3));
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul5_20jul3_NO_INTERMR_cycle__step_2_rast.png
just slight increase to EMDOWN,EMUP rates from last one ... 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(790e3,800e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul5_20jul3_NO_INTERMR_cycle__step_2_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul5_20jul3_NO_INTERMR_cycle__step_2_poshist.png
still lot of bias

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)
gif/20jul5_20jul3_NO_INTERMR_cycle__step_2__input.mp4

* 20jul6
** check 20jul3_NO_INTERMR_cycle__step_3_ -->> stopped multistep since momentum issue fixed

this is the sim with no intermediate rewards, and the long RL time constants ... 

python -i simdat.py backupcfg/20jul3_NO_INTERMR_cycle__step_3_sim.json

plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.5))
plotHitMiss(actreward,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.5))
plotScoreMiss(actreward,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.5))

savefig('gif/'+dstr+simstr+'perf.png') # if/20jul5_20jul3_NO_INTERMR_cycle__step_3_perf.png

lfn = ['20jul3_NO_INTERMR_cycle__step_0_','20jul3_NO_INTERMR_cycle__step_1_','20jul3_NO_INTERMR_cycle__step_2_','20jul3_NO_INTERMR_cycle__step_3_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.25))
plotHitMiss(pdac,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.25))
plotScoreMiss(pdac,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.25))

savefig('gif/'+dstr+simstr+'perf_step0_step1_step2_step3.png') # gif/20jul6_20jul3_NO_INTERMR_cycle__step_3_perf_step0_step1_step2_step3.png

follow target rising slowly . . . seems worth continuing ... 

clf(); drawraster(dspkT,dspkID); xlim((790e3,800e3)); # emstay rates went down a lot
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul6_20jul3_NO_INTERMR_cycle__step_3_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(790e3,800e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul6_20jul3_NO_INTERMR_cycle__step_3_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul6_20jul3_NO_INTERMR_cycle__step_3_poshist.png

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul6_20jul3_NO_INTERMR_cycle__step_3_all_avg_weight.png'
all the weights are decreasing but EMSTAY weights are lower and decreasing faster

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)
gif/20jul5_20jul3_NO_INTERMR_cycle__step_3_input.mp4

continue? may as well . . .

20jul6_NO_INTERMR_cycle_
    "simtype": {"ResumeSim": 1, "ResumeSimFromFile": "data/20jul3_NO_INTERMR_cycle__step_3_synWeights_final.pkl"},
    "rewardcodes": {"scorePoint": 1.0, "losePoint": -0.1, "followTarget": 0.0, "avoidTarget": 0.0, "hitBall": 0.0},

will continue with multistep ...

python multistepSim.py sn.json 16 8 multirunNOINTERM2

** check output from sims with only target follow rewards -->> stopped next multistep since momentum issue fixed

python -i simdat.py backupcfg/20jul3_T1_cycle__step_3_sim.json

plotFollowBall(actreward,ax=subplot(1,2,1),cumulative=True,color='k');  ylim((0,.5))
plotHitMiss(actreward,ax=subplot(1,2,2),lclr=['k'],asratio=True); ylim((0,.5))

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul6_20jul3_T1_cycle__step_3_perf.png

follow target ~0.4 inc then decaying a bit; hit/miss increasing slightly...

lfn = ['20jul3_T0_cycle_', '20jul3_T1_cycle__step_0_', '20jul3_T1_cycle__step_1_', '20jul3_T1_cycle__step_2_', '20jul3_T1_cycle__step_3_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,2,1),cumulative=True,color='k');  ylim((0,.5))
plotHitMiss(pdac,ax=subplot(1,2,2),lclr=['k'],asratio=True); ylim((0,.5))

savefig('gif/'+dstr+simstr+'perf_step0_step1_step2_step3.png') # gif/20jul6_20jul3_T1_cycle__step_3_perf_step0_step1_step2_step3.png
follow target rising, same with hit/miss; worth continuing too. . .

clf(); drawraster(dspkT,dspkID); xlim((790e3,800e3)); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul6_20jul3_T1_cycle__step_3_rast.png
just as in other sim, EMSTAY rate much lower

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(790e3,800e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul6_20jul3_T1_cycle__step_3_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul6_20jul3_T1_cycle__step_3_poshist.png
some bias at top/bottom

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl(); savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul6_20jul3_T1_cycle__step_3_all_avg_weight.png

similar pattern with EMSTAY lower - in future, could start their weights lower to begin with

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)

can continue this set too ... 

 "simtype": {"ResumeSim": 1, "ResumeSimFromFile": "data/20jul3_T1_cycle__step_3_synWeights_final.pkl"},
 "name": "20jul6_T1_cycle_"
  "rewardcodes": {"scorePoint": 0.0, "losePoint": 0.0, "followTarget": 0.1, "avoidTarget": -0.01, "hitBall": 0.5},

python multistepSim.py sn.json 16 8 multirunT2

started ~10:36 ...

** DD fixed momentum issue

this is the main code for fix in aigame.py :

        observation, reward, done, info = self.env.step(caction) # Re-Initializes reward before if statement
        # To eliminate momentum
        # print('Here is caction: ' , caction)
        if caction in [dconf['moves']['DOWN'], dconf['moves']['UP'], dconf['moves']['NOMOVE']]:
          # Follow down/up/stay with stay to prevent momentum problem (Pong-specific)
          stay_step = 0 # initialize
          while not done and stay_step < 6:
            # Takes 6 stays instead of 3 because it seems every other input is ignored (check dad_notes.txt for details)
            observation, interreward, done, info = env.step(dconf['moves']['NOMOVE']) # Stay motion
            reward = reward + interreward  # Uses summation so no reinforcement/punishment is missed
            stay_step += 1
            #print(stay_step)
          env.render() # Renders the game after the stay steps

** try momentum fix

"name": "20jul6_A0_cycle_"
100 s sim ...

./myrun 32 sn.json

python -i simdat.py backupcfg/20jul6_A0_cycle_sim.json

plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.5))
plotHitMiss(actreward,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.5))
plotScoreMiss(actreward,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.5))

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul6_20jul6_A0_cycle_perf.png

clf(); drawraster(dspkT,dspkID); xlim((90e3,100e3)); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul6_20jul6_A0_cycle_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(90e3,100e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul6_20jul6_A0_cycle_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # 
not much bias...

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)
gif/20jul6_20jul6_A0_cycle__input.mp4

looks like improving and less bias ... will continue with multistep to see
how it fares with longer durations ... but seems like ball is moving too fast ...

"simtype": {"ResumeSim": 1, "ResumeSimFromFile": "data/20jul6_A0_cycle_synWeights_final.pkl"},
"name": "20jul6_A1_cycle_"

python multistepSim.py sn.json 32 4 20jul6_MultiTestA

started 16:39 ...

** other test with only follow,hit target

for 800 s
 "rewardcodes": {"scorePoint": 0.0, "losePoint": 0.0, "followTarget": 0.1, "avoidTarget": -0.01, "hitBall": 0.5},
 "name": "20jul6_TM0_cycle_"

python multistepSim.py sn.json 16 4 20jul6_MultiTestTM

started 16:42 ...

** other test with no intermediate rewards 

for 800 s
 "rewardcodes": {"scorePoint": 1.0, "losePoint": -0.1, "followTarget": 0.0, "avoidTarget": 0.0, "hitBall": 0.0},
"name": "20jul6_NOINTERM0_cycle_"

python multistepSim.py sn.json 16 4 20jul6_MultiTestNoIntermM

started 16:47 ...

** check output from 20jul3_S4_cycle__step_3_

python -i simdat.py backupcfg/20jul3_S4_cycle__step_3_sim.json

plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.75))
plotHitMiss(actreward,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.75))
plotScoreMiss(actreward,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.75))

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul6_20jul3_S4_cycle__step_3_perf.png

pretty good values except for score/miss

lfn = ['20jun30_S0_cycle_', '20jun30_S1_cycle_', '20jun30_S2_cycle_', '20jul2_S3_cycle_', '20jul3_S4_cycle__step_0_','20jul3_S4_cycle__step_1_','20jul3_S4_cycle__step_2_','20jul3_S4_cycle__step_3_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.5))
plotHitMiss(pdac,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.5))
plotScoreMiss(pdac,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.5))

savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20jul6_20jul3_S4_cycle__step_3_perf_all_steps_so_far.png

clf(); drawraster(dspkT,dspkID); xlim((1590e3,1600e3)); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul6_20jul3_S4_cycle__step_3_rast.png

EMSTAY rates (~3 Hz) much lower than EMUP, EMDOWN (~17 Hz)

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1590e3,1600e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul6_20jul3_S4_cycle__step_3_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul6_20jul3_S4_cycle__step_3_poshist.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)

* 20jul7
** stopped all sims on cycle, since seems like there's a bug in command encoding

here's main code for rate calculation:

    F_UPs = []
    F_DOWNs = []
    F_STAYs = []
    for ts in range(int(dconf['actionsPerPlay'])):
      ts_beg = t-tstepPerAction*(dconf['actionsPerPlay']-ts-1) 
      ts_end = t-tstepPerAction*(dconf['actionsPerPlay']-ts)
      F_UPs.append(getFiringRatesWithInterval([ts_end,ts_beg], sim.net.pops['EMUP'].cellGids))
      F_DOWNs.append(getFiringRatesWithInterval([ts_end,ts_beg], sim.net.pops['EMDOWN'].cellGids))
      if 'EMSTAY' in dconf['net']:
        F_STAYs.append(getFiringRatesWithInterval([ts_end,ts_beg], sim.net.pops['EMSTAY'].cellGids))
    sim.pc.allreduce(vec.from_python(F_UPs),1) #sum
    F_UPs = vec.to_python()
    sim.pc.allreduce(vec.from_python(F_DOWNs),1) #sum
    F_DOWNs = vec.to_python()
    if 'EMSTAY' in dconf['net']:
      sim.pc.allreduce(vec.from_python(F_STAYs),1) #sum
      F_STAYs = vec.to_python()

and code for broadcast of actions:
    sim.pc.broadcast(vec.from_python([critic]), 0) # convert python list to hoc vector to broadcast critic value to other nodes
    UPactions = np.sum(np.where(np.array(actions)==dconf['moves']['UP'],1,0))
    DOWNactions = np.sum(np.where(np.array(actions)==dconf['moves']['DOWN'],1,0))
    sim.pc.broadcast(vec2.from_python([UPactions]),0)
    sim.pc.broadcast(vec3.from_python([DOWNactions]),0)
    if 'EMSTAY' in dconf['net']:
      STAYactions = np.sum(np.where(np.array(actions)==dconf['moves']['NOMOVE'],1,0))
      sim.pc.broadcast(vec4.from_python([STAYactions]),0)
  else: # other workers
    sim.pc.broadcast(vec, 0) # receive critic value from master node
    critic = vec.to_python()[0] # critic is first element of the array
    sim.pc.broadcast(vec2, 0)
    UPactions = vec2.to_python()[0]
    sim.pc.broadcast(vec3, 0)
    DOWNactions = vec3.to_python()[0]
    if 'EMSTAY' in dconf['net']:
      sim.pc.broadcast(vec4, 0)
      STAYactions = vec4.to_python()[0]

not sure if there's a bug; HA checking

** where were the sims?

python -i simdat.py backupcfg/20jul6_TM0_cycle__step_0_sim.json

plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.75))
plotHitMiss(actreward,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.75))
plotScoreMiss(actreward,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.75))

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul7_20jul6_TM0_cycle__step_0_perf.png
probabilities increasing slowly ...

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)
gif/20jul7_20jul6_TM0_cycle__step_0__input.mp4

looks like improving but paddle moves too slowly compared to the ball ...

** HA found that higher weightVar (0.4 compared to 0.1) performed better
** other test

"name": "20jul7_B0_cycle_"

./myrun 32 sn.json

python -i simdat.py backupcfg/20jul7_B0_cycle_sim.json

plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.75))
plotHitMiss(actreward,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.75))
plotScoreMiss(actreward,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.75))

savefig('gif/'+dstr+simstr+'noEMSTAY_noTARGETTED_stayStepLim6_perf.png')
savefig('gif/'+dstr+simstr+'noEMSTAY_yesTARGETTED_stayStepLim6_perf.png') # <- slightly better

tried a few options - to compare targetted vs not (targetted did a little better in 100 s)
had EMSTAY off since seemed to slow movement down, now will try with it on for longer run overnight...

* 20jul8
** added option to control how many stay steps in between moves

 "stayStepLim": 6,
 default is 6 (value DD determined for removing momentum)
 but if ball moves too fast, may want to reduce the value (tradeoff between momentum problem and
 speed of game play)

** continue test from above

now put EMSTAY back will run overnihgt ... can use 64 cores on cycle if use this
flag with mpiexec : --use-hwthread-cpus
put that into myrun
96 cores is slower than 64 on cycle ... 

20jul8_A0_cycle_ ... 

./myrun 64 sn.json

python -i simdat.py backupcfg/20jul8_A0_cycle_sim.json

plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.75))
plotHitMiss(actreward,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.75))
plotScoreMiss(actreward,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.75))

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul8_20jul8_A0_cycle_perf.png
hit/miss low, score low, follow target probability increasing ... 

clf(); drawraster(dspkT,dspkID)
xlim((1590e3,1600e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul8_20jul8_A0_cycle_rast.png
emstay rates lower, emup rates lower than emdown rates

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl();
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul8_20jul8_A0_cycle_all_avg_weight.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1590e3,1600e3)); 
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20jul8_20jul8_A0_cycle_Vm.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)
gif/20jul8_20jul8_A0_cycle__input.mp4

looks like paddle movement speeding up near end ... 

can continue for shorter duration ...

20jul8_A1_cycle_
 "simtype": {"ResumeSim": 1, "ResumeSimFromFile": "data/20jul8_A0_cycle_synWeights_final.pkl"},

./myrun 64 sn.json

hmm, ball seems to move too fast ... will stop this one

** other motor command encoding

could have move to y coordinate
then a set of motor neurons each which represent a single y coordinate
winner is where paddle should move to
might allow smoother movement since higher level command
but would not generalize to all games

** compare diff levels of stayStepLim -->> no clear diff in short sims

100 s ... 
20jul8_B0_cycle_
 "stayStepLim": 3,

20jul8_B1_cycle_
 "stayStepLim": 2,

20jul8_B2_cycle_
 "stayStepLim": 1,

20jul8_B3_cycle_
 "stayStepLim": 0,

20jul8_B4_cycle_
 "stayStepLim": 4,

./myrun 64 sn.json

python -i simdat.py

lfn = ['20jul8_B3_cycle_', '20jul8_B2_cycle_', '20jul8_B1_cycle_', '20jul8_B0_cycle_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
lpda = getindivactionreward(lfn)

#
for pda,clr in zip(lpda,['b','r','g','c']):
  plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color=clr); ylim((0,0.5))
  plotHitMiss(pda,ax=subplot(1,3,2),lclr=[clr],asratio=True); ylim((0,0.5))
  plotScoreMiss(pda,ax=subplot(1,3,3),clr=clr,asratio=True); ylim((0,0.5))

lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','r','g','c'],['Stay0','Stay1','Stay2','Stay3'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/20jul8_B_cycle_perf_compare_stay0_1_2_3.png')

do not see much difference ... maybe stay0 doing best??

** fewer EMSTAY & other EM neurons?

./myrun 48 sn.json

python -i simdat.py backupcfg/20jul8_C0_cycle_sim.json

plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.75))
plotHitMiss(actreward,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.75))
plotScoreMiss(actreward,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.75))

clf(); drawraster(dspkT,dspkID)

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'])

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)

clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])

** 24 cores for 16x16x16x12 (EMUP,EMDWON,EMDSTAY,IM) was faster than 16 & 48 cores but same as 32 cores
** longer sim with stayStepLim of 0 (20jul8_D0_stayStepLim0_cycle_)

"duration": 2000000

./myrun 24 sn.json

** and comparison with stayStepLim of 1 (20jul8_D0_stayStepLim1_cycle_)

./myrun 24 sn.json

** and comparison with stayStepLim of 2 (20jul8_D0_stayStepLim2_cycle_)

./myrun 24 sn.json

* 20jul9
** and comparison with stayStepLim of 3 (20jul9_D0_stayStepLim3_falcor_)

./myrun 24 sn.json

** one neuron of each EM type??

20jul9_E0_1111_falcor_

tried that before...

./myrun 16 sn.json

python -i simdat.py backupcfg/20jul9_E0_1111_falcor_sim.json

* 20jul10
** compare outputs for different number of stayStepLim

python -i simdat.py

lfn = ['20jul8_D0_stayStepLim0_cycle_', '20jul8_D0_stayStepLim1_cycle_', '20jul8_D0_stayStepLim2_cycle_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
lpda = getindivactionreward(lfn)

#
for pda,clr in zip(lpda,['b','r','g']):
  plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color=clr); ylim((0,0.5))
  plotHitMiss(pda,ax=subplot(1,3,2),lclr=[clr],asratio=True); ylim((0,0.5))
  plotScoreMiss(pda,ax=subplot(1,3,3),clr=clr,asratio=True); ylim((0,0.5))

lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','r','g'],['Stay0','Stay1','Stay2','Stay3'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/20jul10_compare_stay0_stay1_stay2_a0.png')

stay of 2 follows target a little better but stay of 0,1 hit ball more often

** HA discussion

Pong-v0 performs better than PongNoFrameskip-v4

so will use it by default

** discuss with HA re RLwindhebb

and only change in RL parameters would be:
12:22
--change “RLlenhebb”: 200 to “RLlenhebb”: 50
(Length of the eligibility Hebbian and anti-Hebbian eligibility traces, or the decay time constants if the traces are decaying exponentials.)
-- change “RLwindhebb”: 50 to “RLwindhebb”: 20
(Maximum interval between pre- and post-synaptic events for an starting an eligibility trace.)
12:23
samn 50 ms for latter - didn't realize it was that high
12:23
Haroon Anwar yes
12:23
samn that's what sal used?
12:24
Haroon Anwar dont remember, i think so…. but could check
12:24
samn ic, np
12:24
even 10 seems reasonable for that
12:24
but def 20 sg

** so now have to test stayStepLim 0,1,2 in Pong-v0

 "stayStepLim": 0,
"name": "20jul10_A0_stay0_cycle_"

./myrun 32 sn.json

started ~13:07 ...

 "stayStepLim": 1,
"name": "20jul10_A0_stay1_cycle_"

./myrun 32 sn.json

started ~13:10 ...

using 32, 32, 32, 24 for EM and IM populations

weightVar of 0.3 ...
some recurrent and feedback connectivity and RLwindhebb of 20

check output ...

python -i simdat.py backupcfg/20jul10_A0_stay0_cycle_sim.json

lfn  = ['20jul10_A0_stay0_cycle_', '20jul10_A0_stay1_cycle_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
lpda = getindivactionreward(lfn)

#
for pda,clr in zip(lpda,['b','r']):
  plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color=clr); ylim((0,0.35))
  plotHitMiss(pda,ax=subplot(1,3,2),lclr=[clr],asratio=True); ylim((0,0.35))
  plotScoreMiss(pda,ax=subplot(1,3,3),clr=clr,asratio=True); ylim((0,0.35))

lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','r'],['Stay0','Stay1'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/20jul10_compare_stay0_stay1_b0.png')

stay1 looks better for all perf measures ...

so check its activity ...

python -i simdat.py backupcfg/20jul10_A0_stay1_cycle_sim.json

clf(); drawraster(dspkT,dspkID)
xlim((790e3,800e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul10_20jul10_A0_stay1_cycle_rast.png

EMSTAY rates lower, as usual ... 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(790e3,800e3)); 
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20jul10_20jul10_A0_stay1_cycle_Vm.png

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl();
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul10_20jul10_A0_stay1_cycle_all_avg_weight.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul10_20jul10_A0_stay1_cycle_poshist.png

#lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN', 'EMSTAY']  
#dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
#fig, axs, plt = animActivityMaps(lpop=lpop)

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)

continue this using multistep ...

"name": "20jul10_A1_stay1_cycle_"
 "simtype": {"ResumeSim": 1, "ResumeSimFromFile": "data/20jul10_A0_stay1_cycle_synWeights_final.pkl"},

each one is 800 s ... 

python multistepSim.py sn.json 32 9 20jul10_MultiTestAllRewards_

started ~22:10 ... 

** and another with stayStepLim==1 and no intermediate rewards

also did not use RLantiwt ... probably should so allows adjusting weights when post fires before pre ...
should compare sim with/without that separately ... 

"name": "20jul10_B0_stay1_NOINTERMR_cycle_"
"RLlenhebb": 2000
"duration": 800000

python multistepSim.py sn.json 32 10 20jul10_MultiTestNoIntermRewards_

started ~22:54 ...

** and another with stayStepLim==1, intermediate rewards, but RLantiwt too

running on falcor...

20jul10_C0_stay1_RLantitoo_falcor_

 "RL": {"AMPA": {"wbase": 1e-08, "wmax": 0.00048, "RLon": 1, "RLlenhebb": 2000, "RLlenanti": 2000, "useRLexp": 1, "RLhebbwt": 2e-07, "RLantiwt": -2e-07, "hebbwt": 0, "antiwt": 0, "tauhebb": 10, "RLwindhebb": 20, "softthresh": 0, "verbose": 0},

./myrun 16 sn.json

started ~22:58 ...

* 20jul13
** check output from run on falcor

python -i simdat.py backupcfg/20jul10_C0_stay1_RLantitoo_falcor_sim.json

plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.75))
plotHitMiss(actreward,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.75))
plotScoreMiss(actreward,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.75))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul13_20jul10_C0_stay1_RLantitoo_falcor_perf.png
not improving much...but should compare to same sim without the antihebbRL ...


clf(); drawraster(dspkT,dspkID)
xlim((790e3,800e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul13_20jul10_C0_stay1_RLantitoo_falcor_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(790e3,800e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20jul13_20jul10_C0_stay1_RLantitoo_falcor_Vm.png

#clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)

clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul13_20jul10_C0_stay1_RLantitoo_falcor_poshist.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) # gif/20jul13_20jul10_C0_stay1_RLantitoo_falcor__input.mp4

ok, will compare to data on cycle ...

scp samn@falcor://home/samn/SMARTAgent/backupcfg/20jul10_C0_stay1_RLantitoo_falcor_sim.json ./backupcfg
scp samn@falcor://home/samn/SMARTAgent/data/20jul10_C0_stay1_RLantitoo_falcor*.txt ./data
scp samn@falcor://home/samn/SMARTAgent/gif/*20jul10_C0_stay1_RLantitoo_falcor*png ./gif/

ok, compare these two:

python -i simdat.py backupcfg/20jul10_A0_stay1_cycle_sim.json

lfn = ['20jul10_A0_stay1_cycle_', '20jul10_C0_stay1_RLantitoo_falcor_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
lpda = getindivactionreward(lfn)

#
for pda,clr in zip(lpda,['b','r']):
  plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color=clr); ylim((0,0.35))
  plotHitMiss(pda,ax=subplot(1,3,2),lclr=[clr],asratio=True); ylim((0,0.35))
  plotScoreMiss(pda,ax=subplot(1,3,3),clr=clr,asratio=True); ylim((0,0.35))

lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','r'],['Stay1 No Anti','Stay1 Yes Anti'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/20jul13_compare_no_anti_yes_anti_a0.png')

pretty similar performance ... for target follow, no antiRL does a little better
for hit/miss and score/miss with antiRL does a litlte better, except for at the end ...
would need a longer comparison ...

** check output from multistep sims -- with intermediate reward/punishment

python -i simdat.py backupcfg/20jul10_A1_stay1_cycle__step_4_sim.json

lfn = ['20jul10_A0_stay1_cycle_', '20jul10_A1_stay1_cycle__step_0_', '20jul10_A1_stay1_cycle__step_1_','20jul10_A1_stay1_cycle__step_2_','20jul10_A1_stay1_cycle__step_3_','20jul10_A1_stay1_cycle__step_4_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.5))
plotHitMiss(pdac,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.5))
plotScoreMiss(pdac,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.5))

savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20jul13_20jul10_A1_stay1_cycle__step_4_perf_all_steps_so_far.png

hmm, not doing as well as previous sims ... many reasons/differences (EMSTAY, stayStepLim==1, recurrent conn, feedback
conn, Pong-v0 vs v4 ...)

clf(); drawraster(dspkT,dspkID); xlim((790e3,800e3)); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul13_20jul10_A1_stay1_cycle__step_4_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(790e3,800e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul13_20jul10_A1_stay1_cycle__step_4_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul13_20jul10_A1_stay1_cycle__step_4_poshist.png

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl();
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul13_20jul10_A1_stay1_cycle__step_4_all_avg_weight.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)
gif/20jul13_20jul10_A1_stay1_cycle__step_4__input.mp4

** check output from multistep sims -- without intermediate reward/punishment

python -i simdat.py backupcfg/20jul10_B0_stay1_NOINTERMR_cycle__step_4_sim.json

lfn = ['20jul10_B0_stay1_NOINTERMR_cycle__step_0_','20jul10_B0_stay1_NOINTERMR_cycle__step_1_','20jul10_B0_stay1_NOINTERMR_cycle__step_2_','20jul10_B0_stay1_NOINTERMR_cycle__step_3_','20jul10_B0_stay1_NOINTERMR_cycle__step_4_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.5))
plotHitMiss(pdac,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.5))
plotScoreMiss(pdac,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.5))

savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20jul13_20jul10_B0_stay1_NOINTERMR_cycle__step_4_perf_all_steps_so_far.png

a lot worse performance than sim with intermediate score/punishment, as expected ...
though follow target probability may be increasing slowly ...

clf(); drawraster(dspkT,dspkID); xlim((790e3,800e3)); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul13_20jul10_B0_stay1_NOINTERMR_cycle__step_4_rast.png

EMSTAY rate lower than EMUP,EMDOWN ...

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(790e3,800e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul13_20jul10_B0_stay1_NOINTERMR_cycle__step_4_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul13_20jul10_B0_stay1_NOINTERMR_cycle__step_4_poshist.png

much more bias than sim with intermediate rewards

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl();
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul13_20jul10_B0_stay1_NOINTERMR_cycle__step_4_all_avg_weight.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)
gif/20jul13_20jul10_B0_stay1_NOINTERMR_cycle__step_4__input.mp4

** stopped sims since performance seems worse than earlier versions
** better w/o EMSTAY?? (20jul13_N0_cycle_)

also try longer step size for moves and RLantiwt too ...

* 20jul14
** check output from 20jul13_N0_cycle_

python -i simdat.py backupcfg/20jul13_N0_cycle_sim.json

plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.75))
plotHitMiss(actreward,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.75))
plotScoreMiss(actreward,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.75))

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul14_20jul13_N0_cycle_perf.png

decent for follow prob - others pretty low (hit, score)

clf(); drawraster(dspkT,dspkID); xlim((790e3,800e3)); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul14_20jul13_N0_cycle_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=(790e3,800e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul14_20jul13_N0_cycle_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl();
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul13_20jul10_B0_stay1_NOINTERMR_cycle__step_4_all_avg_weight.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)
gif/20jul14_20jul13_N0_cycle__input.mp4

stuck a lot ... 

can continue ...

"name": "20jul14_N1_cycle_"
 "simtype": {"ResumeSim": 1, "ResumeSimFromFile": "data/20jul13_N0_cycle_synWeights_final.pkl"},

./myrun 32 sn.json

started ~10:27 ...

finished ~15:30 ...

python -i simdat.py backupcfg/20jul14_N1_cycle_sim.json

plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.75))
plotHitMiss(actreward,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.75))
plotScoreMiss(actreward,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.75))

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul14_20jul14_N1_cycle_perf.png

clf(); drawraster(dspkT,dspkID); xlim((790e3,800e3)); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul14_20jul14_N1_cycle_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=(790e3,800e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul14_20jul14_N1_cycle_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul14_20jul14_N1_cycle_poshist.png

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl();
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul14_20jul14_N1_cycle_all_avg_weight.png

lfn = ['20jul13_N0_cycle_', '20jul14_N1_cycle_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.75))
plotHitMiss(pdac,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.75))
plotScoreMiss(pdac,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.75))

savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20jul14_20jul14_N1_cycle_perf_all_steps_so_far.png

does not look terribly good ... previous versions were better ...

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)

** continue previous sim that was doing better?

  -rw-rw-r-- 1 samn samn    111122 Jun 29 10:41 20jun29_20jun27_G1_cycle_perf_compare_step0_step1.png
  -rw-rw-r-- 1 samn samn     99241 Jun 29 10:11 20jun29_20jun27_G1_cycle_perf_step0_step1.png
  20jun29_20jun27_G1_cycle_perf.png
20jun29_20jun27_G1_cycle_rastB.png

problem was that rates seemed to get too high ... and never finished testing the weight norm

hmm, this one was good too:
 20jul6_20jul3_S4_cycle__step_3_perf.png

had stopped it since thought there was a bug in command encoding ...

could continue that one too ...

20jul3_S4_cycle__step_3_sim.json

"name": "20jul14_cont_20jul3_S4_cycle__step_3_"

python multistepSim.py sn.json 32 10 20jul14_MultiTestS4Continue

started ~16:21 ...

** comparison with weight norm

"name": "20jul14_cont_with_norm_20jul3_S4_cycle__step_3_"

"normalizeWeightStepSize":20000  <<-- that means weight norm every 400 s ... 
and "EEMPopNorm":1 <<-- that means use average weight to rescale both populations' weights to initial weight, but preserving relative values

python multistepSim.py sn.json 32 10 20jul14_MultiTestS4ContinueNorm

started ~16:29 ...

** setting up on gcp

created an ubuntu (20 LTS) c2 instance with 60 cores

trying to get chrome remote desktop :
https://cloud.google.com/solutions/chrome-desktop-remote-on-compute-engine

first ssh into the VM ... 

sudo apt update
sudo apt-get install --assume-yes wget

mkdir Downloads
cd Downloads
wget https://dl.google.com/linux/direct/chrome-remote-desktop_current_amd64.deb

sudo dpkg --install chrome-remote-desktop_current_amd64.deb
sudo apt install --assume-yes --fix-broken

sudo DEBIAN_FRONTEND=noninteractive \
    apt install --assume-yes xfce4 desktop-base

sudo bash -c 'echo "exec /etc/X11/Xsession /usr/bin/xfce4-session" > /etc/chrome-remote-desktop-session'

sudo apt install --assume-yes xscreensaver

sudo systemctl disable lightdm.service

wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb

sudo dpkg --install google-chrome-stable_current_amd64.deb
sudo apt install --assume-yes --fix-broken

sudo usermod -a -G chrome-remote-desktop $USER
logout

then after copying auth code to shell can login here:

https://remotedesktop.google.com/

seems to work !

ok, now that on gcp ...

setup ssh keys and added to github profile

cloned the repo

git clone git@github.com:NathanKlineInstitute/SMARTAgent.git
git branch development
git checkout development
git pull origin development

https://medium.com/google-cloud/set-up-anaconda-under-google-cloud-vm-on-windows-f71fc1064bd7

cd ~/Downloads
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh
rm Miniconda3-latest-Linux-x86_64.sh
source ~/.bashrc

then onward with the install.txt instructions (should be same as for cycle)

also had to do this:
sudo apt-get install build-essential
to compile with nrnivmodl ...

and make sure to set LD_LIBRARY_PATH in .bashrc

export LD_LIBRARY_PATH="/home/ext_samnemo_gmail_com/miniconda3/lib"

try a quick test ...

"name": "20jul14_testG0_gcp_"

./myrun 60 sn.json

  Simulated time: 2.0 s; 60 workers
  Run time: 35.17 s

seemed to work ... pretty fast ...

is it faster with fewer cores?

./myrun 32 sn.json

  Simulated time: 2.0 s; 32 workers
  Run time: 35.72 s

was the same duration ...

and with 16 cores?

./myrun 16 sn.json

  Simulated time: 2.0 s; 16 workers
  Run time: 37.38 s

so just slightly slower with 16 cores ... not really noticeable difference ...

so at current scale could run ~4 simulations each with 16 cores ... or could run larger
simulation ... see if that improves performance ...

python -i simdat.py backupcfg/20jul14_testG0_gcp_sim.json

try with 4X larger EMDOWN, EMUP, EMSTAY, IM ... (128, 128, 128, 96)

./myrun 60 sn.json

  Simulated time: 2.0 s; 60 workers
  Run time: 102.29 s

same speed with 32 cores?

./myrun 32 sn.json

  Simulated time: 2.0 s; 32 workers
  Run time: 113.94 s

yeah, similar duration ... slightly slower ...

would take ~25 hours to run 1600 s sim ... could compare weight norm to without weight norm on
the larger output pop size ... well, can run for 800 s ... to avoid overusing on a prelim test

will need higher weightvar ... 0.5?

ok ...

"name": "20jul14_testG0_nonorm_gcp_"

./myrun 30 sn.json

started ~22:38 ...

and another with weight norm every 400 s

"name": "20jul14_testG0_yesnorm_gcp_"
"normalizeWeightStepSize": 20000
"EEMPopNorm": 1

./myrun 30 sn.json

started ~22:44 ...

* 20jul15
** runs on gcp finished ~21:48

was not enough room on the disk image to save everything (only 20 GB in /, can probably increase
space if needed); the synweights files were each ~5.7 GB ... 

python -i simdat.py backupcfg/20jul14_testG0_nonorm_gcp_sim.json

lfn = ['20jul14_testG0_nonorm_gcp_', '20jul14_testG0_yesnorm_gcp_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
lpda = getindivactionreward(lfn)

#
for pda,clr in zip(lpda,['b','r']):
  plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color=clr); ylim((0,0.35))
  plotHitMiss(pda,ax=subplot(1,3,2),lclr=[clr],asratio=True); ylim((0,0.35))
  plotScoreMiss(pda,ax=subplot(1,3,3),clr=clr,asratio=True); ylim((0,0.35))

lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','r'],['No norm @ 400 s','Norm @ 400 s'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/'+dstr+simstr+'perf_compare_yes_no_norm_a0.png') # gif/20jul16_20jul14_testG0_nonorm_gcp_perf_compare_yes_no_norm_a0.png

so weight norm at 400 s may have helped a little...but performance is not better than smaller output layer

clf(); drawraster(dspkT,dspkID); xlim((790e3,800e3)); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul16_20jul14_testG0_nonorm_gcp_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(790e3,800e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul16_20jul14_testG0_nonorm_gcp_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul16_20jul14_testG0_nonorm_gcp_poshist.png

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True); xlabel('Time (ms)'); tl(); xlim((790e3,810e3)); savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul16_20jul14_testG0_nonorm_gcp_all_avg_weight.png

name # 20jul14_testG0_nonorm_gcp_

name = '20jul14_testG0_yesnorm_gcp_'

simConfig, pdf, actreward, dstartidx, dendidx, dnumc, dspkID, dspkT, InputImages, ldflow, dact = loadsimdat(name,getactmap=False,lpop=lpop)

simstr = '20jul14_testG0_yesnorm_gcp_'

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl(); xlim((790e3,810e3))
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul16_20jul14_testG0_yesnorm_gcp_all_avg_weight.png

average weights look ~same as no norm, probably since dfctr was just a bit below 1 ...

clf(); drawraster(dspkT,dspkID); xlim((790e3,800e3)); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul16_20jul14_testG0_yesnorm_gcp_rast.png

so, no point having a large output layer with full conn, since performance did not improve ...

** try large output layer but not 100% conn? (20jul15_testG0_gcp_)

ok, 100 of each EM, 75 IM
EEMProb of 0.3, EEMRecProb of 0.3

"name": "20jul15_testG0_gcp_"

and have to scale
"EEMWghtAM": 1.2e-05, "EEMWghtNM": 1.2e-06
and "RLhebbwt": 2e-07
by ~1/.3 (since most of inputs were from preM)
"EEMWghtAM": 3.6e-05, "EEMWghtNM": 3.6e-06
"RLhebbwt": 6e-07

./myrun 30 sn.json

  Simulated time: 10.0 s; 30 workers
  Run time: 166.28 s

well, it was faster to run ... due to fewer RL synapses ...

with 2 s sim took:
  Simulated time: 2.0 s; 30 workers
  Run time: 28.81 s

what's speed with 16 workers?
./myrun 16 sn.json
  Simulated time: 2.0 s; 16 workers
  Run time: 38.83 s
a lot longer, so may as well use 30 workers ...

and speed with 60 workers?
./myrun 60 sn.json
  Simulated time: 2.0 s; 60 workers
  Run time: 35.94 s
slower than with 30 workers ... so use 30 workers...

try 100 s before longer sim ...
./myrun 30 sn.json

  Spikes: 732174 (1.60 Hz)
  Simulated time: 100.0 s; 30 workers
  Run time: 1847.54 s
  so took ~30 minutes to run 100 s
and main output file was ~176 MB with 5 s increments for weight saves ...   
  -rw-r--r--  1 ext_samnemo_gmail_com 3015339689 176865149 Jul 16 03:27 20jul15_testG0_gcp_synWeights.pkl  

so can run for ~2000 s in ~10 hours ... but reduce frequency of weight saving ...

"recordWeightStepSize": 500

note that weightVar is 0.5 ...

./myrun 30 sn.json

started ~23:36 ... 

python -i simdat.py backupcfg/20jul15_testG0_gcp_sim.json

drawraster(dspkT,dspkID);
drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'])

plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,.75))
plotHitMiss(actreward,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,.75))
plotScoreMiss(actreward,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,.75))


** and another one with same params but lower weightVar (0.25); 20jul15_testH0_gcp_

./myrun 30 sn.json

started ~23:38 ...

both are around 1/2 way done ~9:30 AM ... so instead of 10 hours, closer to 20 hours to complete ...
this one not doing as well as 20jul15_testG0_gcp_ in terms of score (9 points compared to 14 points)
and 43 vs 67 hits ... so can stop this one ...

ok - stopped 20jul15_testH0_gcp_ since it's not doing as well and seems to be slowing down
the other sim...

* 20jul16
** check output on cycle

python -i simdat.py backupcfg/20jul14_cont_20jul3_S4_cycle__step_3__step_0_sim.json

plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='k');  ylim((0,1.))
plotHitMiss(actreward,ax=subplot(1,3,2),lclr=['k'],asratio=True); ylim((0,1.))
plotScoreMiss(actreward,ax=subplot(1,3,3),clr='k',asratio=True); ylim((0,1.))

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul16_20jul14_cont_20jul3_S4_cycle__step_3__step_0_perf.png

looks pretty good for most measures except for score/miss ... others seem at ~highest levels seen

and how does it compare to the one with weight normalization?

actN = pd.DataFrame(np.loadtxt('data/20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_0_ActionsRewards.txt'),columns=['time','action','reward','proposed','hit'])

clf()
plotFollowBall(actreward,ax=subplot(1,3,1),cumulative=True,color='b');  ylim((0,1.))
plotHitMiss(actreward,ax=subplot(1,3,2),lclr=['b'],asratio=True); ylim((0,1.))
plotScoreMiss(actreward,ax=subplot(1,3,3),clr='b',asratio=True); ylim((0,1.))
plotFollowBall(actN,ax=subplot(1,3,1),cumulative=True,color='r');  ylim((0,1.))
plotHitMiss(actN,ax=subplot(1,3,2),lclr=['r'],asratio=True); ylim((0,1.))
plotScoreMiss(actN,ax=subplot(1,3,3),clr='r',asratio=True); ylim((0,1.))

savefig('gif/'+dstr+simstr+'perf_compare_norm_no_norm.png') # gif/20jul16_20jul14_cont_20jul3_S4_cycle__step_3__step_0_perf_compare_norm_no_norm.png

so weight norm might help a little for hit/miss and score/miss but only briefly ...

and the full durations concatenated?

lfn = ['20jun30_S0_cycle_', '20jun30_S1_cycle_', '20jun30_S2_cycle_', '20jul2_S3_cycle_', '20jul3_S4_cycle__step_0_','20jul3_S4_cycle__step_1_','20jul3_S4_cycle__step_2_','20jul3_S4_cycle__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_0_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,.45))
plotHitMiss(pdac,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,.45))
plotScoreMiss(pdac,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,.45))

savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20jul16_20jul14_cont_20jul3_S4_cycle__step_3__step_0_perf_all_steps_so_far.png

clf(); drawraster(dspkT,dspkID); xlim((1590e3,1600e3)); ylim((0,sum(list(dnumc.values())))); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul16_20jul14_cont_20jul3_S4_cycle__step_3__step_0_rast.png

xlim((1599e3,1600e3))
savefig('gif/'+dstr+simstr+'rastB.png')
gif/20jul16_20jul14_cont_20jul3_S4_cycle__step_3__step_0_rastB.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1590e3,1600e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul16_20jul14_cont_20jul3_S4_cycle__step_3__step_0_Vm.png
xlim((1599e3,1600e3))
savefig('gif/'+dstr+simstr+'VmB.png')
gif/20jul16_20jul14_cont_20jul3_S4_cycle__step_3__step_0_VmB.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # 'gif/'+dstr+simstr+'poshist.png'
gif/20jul16_20jul14_cont_20jul3_S4_cycle__step_3__step_0_poshist.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)
gif/20jul16_20jul14_cont_20jul3_S4_cycle__step_3__step_0__input.mp4
performs pretty well on some of the volleys ... but still makes the usual mistakes ... 

lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN', 'EMSTAY']  
dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
fig, axs, plt = animActivityMaps(lpop=lpop)
gif/20jul14_cont_20jul3_S4_cycle__step_3__step_0_actmap.mp4

** setup google cloud sdk

so can more easily download/uploads files, etc.

https://cloud.google.com/sdk/docs#deb

echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list

sudo apt-get install apt-transport-https ca-certificates gnupg

curl --insecure https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -

(--insecure on cycle/NKI machines since they use zscaler)

sudo apt-get update && sudo apt-get install google-cloud-sdk

gcloud init

gcloud config set accessibility/screen_reader true

hmm, not working properly on nki machine ... will try install from source instead ...

downloaded
https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-301.0.0-linux-x86_64.tar.gz
to ~/Downloads
cd ~/Downloads
tar -xvf google-cloud-sdk-301.0.0-linux-x86_64.tar.gz
sudo mv ~/Downloads/google-cloud-sdk /opt/
cd /opt
./google-cloud-sdk/install.sh

./google-cloud-sdk/install.sh
Welcome to the Google Cloud SDK!

To help improve the quality of this product, we collect anonymized usage data
and anonymized stacktraces when crashes are encountered; additional information
is available at <https://cloud.google.com/sdk/usage-statistics>. This data is
handled in accordance with our privacy policy
<https://policies.google.com/privacy>. You may choose to opt in this
collection now (by choosing 'Y' at the below prompt), or at any time in the
future by running the following command:

    gcloud config set disable_usage_reporting false

Do you want to help improve the Google Cloud SDK (y/N)?  no

ERROR: (gcloud.components.list) Failed to fetch component listing from server. Check your network settings and try again.

hmm...problem ...

/opt/google-cloud-sdk/bin/gcloud init

/opt/google-cloud-sdk/bin/gcloud init
Welcome! This command will take you through the configuration of gcloud.

Your current configuration has been set to: [default]

You can skip diagnostics next time by using the following flag:
  gcloud init --skip-diagnostics

Network diagnostic detects and fixes local network connection issues.
Checking network connection...done.
ERROR: Reachability Check failed.
    Cannot reach https://www.google.com (SSLCertVerificationError)
    Cannot reach https://accounts.google.com (SSLCertVerificationError)
    Cannot reach https://cloudresourcemanager.googleapis.com/v1beta1/projects (SSLCertVerificationError)
    Cannot reach https://www.googleapis.com/auth/cloud-platform (SSLCertVerificationError)
    Cannot reach https://dl.google.com/dl/cloudsdk/channels/rapid/components-2.json (SSLCertVerificationError)
Network connection problems may be due to proxy or firewall settings.


Do you have a network proxy you would like to set in gcloud (Y/n)?  n

ERROR: Network diagnostic failed (0/1 checks passed).

Network errors detected.

Would you like to continue anyway (y/N)?  n

You can re-run diagnostics with the following command:
  gcloud info --run-diagnostics

looks like will be a problem installing/running on NKI machines

will install on laptop instead, can then scp files as needed ...

** check output from gcp run (20jul15_testG0_gcp_)

started ~23:38 night before
finished around 16:06 ...

  Spikes: 14349215 (1.57 Hz)
  Simulated time: 2000.0 s; 30 workers
  Run time: 58766.61 s

python -i simdat.py backupcfg/20jul15_testG0_gcp_sim.json

plotFollowBall(actreward,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,.35))
plotHitMiss(actreward,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,.35))
plotScoreMiss(actreward,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,.35))
ylabel('Performance')
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul16_20jul15_testG0_gcp_perf.png

looks ok, but not as good as other recent sims on cycle ...

clf(); drawraster(dspkT,dspkID); xlim((1990e3,2000e3)); ylim((0,sum(list(dnumc.values())))); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul16_20jul15_testG0_gcp_rast.png

xlim((1999e3,2000e3))
savefig('gif/'+dstr+simstr+'rastB.png') # gif/20jul16_20jul15_testG0_gcp_rastB.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1990e3,2000e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul16_20jul15_testG0_gcp_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul16_20jul15_testG0_gcp_poshist.png

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul16_20jul15_testG0_gcp_all_avg_weight.png

the weights are still fairly quickly ... rates very similar to start of simulation ...

can continue the simulation ... see if it improves ...

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)
20jul16_20jul15_testG0_gcp__input.mp4

#lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN', 'EMSTAY']  
#dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
#fig, axs, plt = animActivityMaps(lpop=lpop)

well, may as well continue ...

"name": "20jul16_testG1_gcp_"
    "simtype": {"ResumeSim": 1, "ResumeSimFromFile": "data/20jul15_testG0_gcp_synWeights_final.pkl"},

./myrun 30 sn.json

started ~16:59 ...
finished ~9:20 next day

  Spikes: 14948607 (1.63 Hz)
  Simulated time: 2000.0 s; 30 workers
  Run time: 43836.70 s

* 20jul17
** check output from 20jul16_testG1_gcp_

python -i simdat.py backupcfg/20jul16_testG1_gcp_sim.json

plotFollowBall(actreward,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,.65))
plotHitMiss(actreward,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,.65))
plotScoreMiss(actreward,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,.65))
ylabel('Performance')
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul17_20jul16_testG1_gcp_perf.png

seems better ... yeah, improved a bit...

lfn = ['20jul15_testG0_gcp_','20jul16_testG1_gcp_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,.35))
plotHitMiss(pdac,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,.35))
plotScoreMiss(pdac,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,.35))
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20jul17_20jul16_testG1_gcp_perf_all_steps_so_far.png

clf(); drawraster(dspkT,dspkID); xlim((1990e3,2000e3)); ylim((0,sum(list(dnumc.values())))); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul17_20jul16_testG1_gcp_rast.png

rates for EMUP,EMDOWN have increased, EMSTAY decreased

xlim((1999e3,2000e3))
savefig('gif/'+dstr+simstr+'rastB.png') # gif/20jul17_20jul16_testG1_gcp_rastB.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1990e3,2000e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul17_20jul16_testG1_gcp_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul17_20jul16_testG1_gcp_poshist.png

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul17_20jul16_testG1_gcp_all_avg_weight.png
weights for EMDOWN,EMUP still rising, EMSTAY lower but rising slowly
savefig('gif/'+dstr+simstr+'all_avg_weightB.png') # gif/20jul17_20jul16_testG1_gcp_all_avg_weightB.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)
gif/20jul17_20jul16_testG1_gcp__input.mp4

#lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN', 'EMSTAY']  
#dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
#fig, axs, plt = animActivityMaps(lpop=lpop)

ok, since it's been gradually improving, may as well continue this sim as multistep sim ...

    "simtype": {"ResumeSim": 1, "ResumeSimFromFile": "data/20jul16_testG1_gcp_synWeights_final.pkl"},
    "name": "20jul17_testG2_gcp_"

python multistepSim.py sn.json 30 10 20jul17_testG2_gcp_multistep_

started ~10:31 ...

** setup gcloud sdk on laptop

echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list

sudo apt-get install apt-transport-https ca-certificates gnupg

curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -

sudo apt-get update && sudo apt-get install google-cloud-sdk

gcloud init

gcloud config set accessibility/screen_reader true

authenticated with gmail address via browser

 Commands that require authentication will use samnemo@gmail.com by default
 Commands will reference project `ecas-2019` by default
 Compute Engine commands will use region `us-central1` by default
 Compute Engine commands will use zone `us-central1-c` by default

so now will more easily be able to transfer files ...

gsutil -m cp -r gs://samn_data/SMARTAgent/gif/* ./gif/

** check output from runs on cycle

python -i simdat.py backupcfg/20jul14_cont_20jul3_S4_cycle__step_3__step_1_sim.json

plotFollowBall(actreward,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,1.))
plotHitMiss(actreward,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,1.))
plotScoreMiss(actreward,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,1.))
ylabel('Performance')
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/'+dstr+simstr+'perf.png')
gif/20jul17_20jul14_cont_20jul3_S4_cycle__step_3__step_1_perf.png
that looks good - much higher scores than have seen before . . .

compare against the one with weight norm ..
lfn = ['20jul14_cont_20jul3_S4_cycle__step_3__step_1_', '20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_1_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
lpda = getindivactionreward(lfn)

#
for pda,clr in zip(lpda,['b','r']):
  plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color=clr); ylim((0,1.))
  plotHitMiss(pda,ax=subplot(1,3,2),lclr=[clr],asratio=True); ylim((0,1.))
  plotScoreMiss(pda,ax=subplot(1,3,3),clr=clr,asratio=True); ylim((0,1.))

lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','r'],['No Normalization every 400 s','Normalization every 400 s'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/'+dstr+simstr+'perf_nonorm_norm_compare.png')
gif/20jul17_20jul14_cont_20jul3_S4_cycle__step_3__step_1_perf_nonorm_norm_compare.png

norm seems to help sometimes

lfn = ['20jun30_S0_cycle_', '20jun30_S1_cycle_', '20jun30_S2_cycle_', '20jul2_S3_cycle_', '20jul3_S4_cycle__step_0_','20jul3_S4_cycle__step_1_','20jul3_S4_cycle__step_2_','20jul3_S4_cycle__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_0_','20jul14_cont_20jul3_S4_cycle__step_3__step_1_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,.45))
plotHitMiss(pdac,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,.45))
plotScoreMiss(pdac,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,.45))

ylabel('Performance')
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png')
gif/20jul17_20jul14_cont_20jul3_S4_cycle__step_3__step_1_perf_all_steps_so_far.png

clf(); drawraster(dspkT,dspkID); xlim((1590e3,1600e3)); ylim((0,sum(list(dnumc.values())))); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul17_20jul14_cont_20jul3_S4_cycle__step_3__step_1_rast.png

xlim((1599e3,1600e3))
savefig('gif/'+dstr+simstr+'rastB.png') # gif/20jul17_20jul14_cont_20jul3_S4_cycle__step_3__step_1_rastB.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1590e3,1600e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul17_20jul14_cont_20jul3_S4_cycle__step_3__step_1_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul17_20jul14_cont_20jul3_S4_cycle__step_3__step_1_poshist.png

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul17_20jul14_cont_20jul3_S4_cycle__step_3__step_1_all_avg_weight.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) # gif/20jul17_20jul14_cont_20jul3_S4_cycle__step_3__step_1__input.mp4
lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN', 'EMSTAY']  
dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
fig, axs, plt = animActivityMaps(lpop=lpop)
gif/20jul17_20jul14_cont_20jul3_S4_cycle__step_3__step_1_actmap.mp4

** check raster/activity/movies for weight normalized version too (on cycle)

python -i simdat.py backupcfg/20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_1_sim.json

plotFollowBall(actreward,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,1.))
plotHitMiss(actreward,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,1.))
plotScoreMiss(actreward,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,1.))
ylabel('Performance')
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/'+dstr+simstr+'perf.png') #
gif/20jul17_20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_1_perf.png
yeah, looks better than w/o weight norm ...
though still have a question of optimal frequency of weight norm

clf(); drawraster(dspkT,dspkID); xlim((1590e3,1600e3)); ylim((0,sum(list(dnumc.values())))); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul17_20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_1_rast.png
firing rates much better (~10 Hz instead of ~20 Hz for non-normalized weights version)

xlim((1599e3,1600e3))
savefig('gif/'+dstr+simstr+'rastB.png') # gif/20jul17_20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_1_rastB.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1590e3,1600e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul17_20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_1_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul17_20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_1_poshist.png

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') #
gif/20jul17_20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_1_all_avg_weight.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) # gif/20jul17_20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_1__input.mp4
lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN', 'EMSTAY']  
dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
fig, axs, plt = animActivityMaps(lpop=lpop)
gif/20jul17_20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_1_actmap.mp4

* 20jul18
** check next step output from gcp

python -i simdat.py backupcfg/20jul17_testG2_gcp__step_0_sim.json

plotFollowBall(actreward,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,1.))
plotHitMiss(actreward,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,1.))
plotScoreMiss(actreward,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,1.))
ylabel('Performance')
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul18_20jul17_testG2_gcp__step_0_perf.png
doing noticeably better than last step ...

lfn = ['20jul15_testG0_gcp_','20jul16_testG1_gcp_', '20jul17_testG2_gcp__step_0_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,.38))
plotHitMiss(pdac,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,.38))
plotScoreMiss(pdac,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,.38))
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)
ylabel('Performance')
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20jul18_20jul17_testG2_gcp__step_0_perf_all_steps_so_far.png

looks like all performance measures increasing ... 

clf(); drawraster(dspkT,dspkID); xlim((1990e3,2000e3)); ylim((0,sum(list(dnumc.values())))); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul18_20jul17_testG2_gcp__step_0_rast.png
and the rates are still low/good

xlim((1999e3,2000e3))
savefig('gif/'+dstr+simstr+'rastB.png') # gif/20jul18_20jul17_testG2_gcp__step_0_rastB.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1990e3,2000e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul18_20jul17_testG2_gcp__step_0_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul18_20jul17_testG2_gcp__step_0_poshist.png

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul18_20jul17_testG2_gcp__step_0_all_avg_weight.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)
gif/20jul18_20jul17_testG2_gcp__step_0__input.mp4

#lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN', 'EMSTAY']  
#dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
#fig, axs, plt = animActivityMaps(lpop=lpop)

* 20jul20
** check raster/activity/movies for weight normalized version (on cycle)

python -i simdat.py backupcfg/20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_4_sim.json

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul20_20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_4_perf.png

not clear it's better than a few steps ago ... 

clf(); drawraster(dspkT,dspkID); xlim((1590e3,1600e3)); ylim((0,sum(list(dnumc.values())))); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul20_20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_4_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1590e3,1600e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul20_20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_4_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul20_20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_4_poshist.png

the one without weight norm is still running same step so will wait to compare until it finishes (without norm takes
longer since higher firing rates)

lfn = ['20jun30_S0_cycle_', '20jun30_S1_cycle_', '20jun30_S2_cycle_', '20jul2_S3_cycle_', '20jul3_S4_cycle__step_0_','20jul3_S4_cycle__step_1_','20jul3_S4_cycle__step_2_','20jul3_S4_cycle__step_3_','20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_0_','20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_1_','20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_2_','20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_3_','20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_4_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,.45))
plotHitMiss(pdac,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,.45))
plotScoreMiss(pdac,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,.45))

ylabel('Performance',fontsize=30);
xlabel('Time (ms)',fontsize=30)
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1,fontsize=30)
tl()

savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png')
gif/20jul20_20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_4_perf_all_steps_so_far.png

lfn = ['20jun30_S0_cycle_', '20jun30_S1_cycle_', '20jun30_S2_cycle_', '20jul2_S3_cycle_', '20jul3_S4_cycle__step_0_','20jul3_S4_cycle__step_1_','20jul3_S4_cycle__step_2_','20jul3_S4_cycle__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_0_','20jul14_cont_20jul3_S4_cycle__step_3__step_1_','20jul14_cont_20jul3_S4_cycle__step_3__step_2_','20jul14_cont_20jul3_S4_cycle__step_3__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_4_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)
plotFollowBall(pdac,ax=subplot(1,1,1),cumulative=True,color='c');  ylim((0,.45))
plotHitMiss(pdac,ax=subplot(1,1,1),lclr=['m'],asratio=True); ylim((0,.45))
plotScoreMiss(pdac,ax=subplot(1,1,1),clr='y',asratio=True); ylim((0,.45))
savefig('gif/'+dstr+simstr+'perf_compare_all_steps_so_far_norm_no_norm.png')
gif/20jul20_20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_4_perf_compare_all_steps_so_far_norm_no_norm.png
so norm is helping slightly for follow, but not for score/miss
(c,m,y are the no-norm simulations)

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') #
gif/20jul20_20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_4_all_avg_weight.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) # 
lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN', 'EMSTAY']  
dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
fig, axs, plt = animActivityMaps(lpop=lpop)

** check raster/activity/movies for NO weight normalized version (on cycle)

python -i simdat.py backupcfg/20jul14_cont_20jul3_S4_cycle__step_3__step_4_sim.json

plotFollowBall(actreward,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,1.))
plotHitMiss(actreward,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,1.))
plotScoreMiss(actreward,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,1.))
ylabel('Performance')
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul20_20jul14_cont_20jul3_S4_cycle__step_3__step_4_perf.png
that's much worse than the one with weight norm; so should probably discontinue the one without weight norm
(could restart from final weight norm weights and just use score/loss rewards to see if it improves at all...)

clf(); drawraster(dspkT,dspkID); xlim((1590e3,1600e3)); ylim((0,sum(list(dnumc.values())))); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul20_20jul14_cont_20jul3_S4_cycle__step_3__step_4_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1590e3,1600e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul20_20jul14_cont_20jul3_S4_cycle__step_3__step_4_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul20_20jul14_cont_20jul3_S4_cycle__step_3__step_4_poshist.png

lfn = ['20jun30_S0_cycle_', '20jun30_S1_cycle_', '20jun30_S2_cycle_', '20jul2_S3_cycle_', '20jul3_S4_cycle__step_0_','20jul3_S4_cycle__step_1_','20jul3_S4_cycle__step_2_','20jul3_S4_cycle__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_0_','20jul14_cont_20jul3_S4_cycle__step_3__step_1_','20jul14_cont_20jul3_S4_cycle__step_3__step_2_','20jul14_cont_20jul3_S4_cycle__step_3__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_4_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,.45))
plotHitMiss(pdac,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,.45))
plotScoreMiss(pdac,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,.45))

ylabel('Performance',fontsize=30);
xlabel('Time (ms)',fontsize=30)
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1,fontsize=30)
tl()

savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png')
gif/20jul20_20jul14_cont_20jul3_S4_cycle__step_3__step_4_perf_all_steps_so_far.png

#clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
#xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
#savefig('gif/'+dstr+simstr+'all_avg_weight.png') #

#fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) # 
#lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN', 'EMSTAY']  
#dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
#fig, axs, plt = animActivityMaps(lpop=lpop)

** use last weight norm sim on cycle to continue sim with less frequent weight norm

cp backupcfg/20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_5_sim.json sn.json

    "simtype": {"ResumeSim": 1, "ResumeSimFromFile": "data/20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_4_synWeights_final.pkl"},

"name": "20jul20_cont_S_with_less_freq_norm_cycle_"
"normalizeWeightStepSize": 75000
that's norm every 1500 s
also cutting down recording weight step size to 1/2 as frequent...:
"recordWeightStepSize": 500

python multistepSim.py sn.json 32 10 20jul20_MultiTestSContinueNormLessFreq

started 15:43 ...

** use last weight norm sim on cycle to continue sim with no intermediate rewards

see if using the final weights that had intermediate rewards can be used
to bootstrap improved learning for hit/miss and score ... so there's partial
intermediate reward (hit ball will still get a reward)

data/20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_4_synWeights_final.pkl

will have to use longer time constant for RL ... 

    "simtype": {"ResumeSim": 1, "ResumeSimFromFile": "data/20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_4_synWeights_final.pkl"},
"name": "20jul20_cont_S_with_less_freq_norm_lessintermr_cycle_"
"normalizeWeightStepSize": 75000
that's norm every 1500 s
also cutting down recording weight step size to 1/2 as frequent...:
"recordWeightStepSize": 500
longer RL tau:
"RLlenhebb": 1000 (instead of 200)
    "rewardcodes": {"scorePoint": 1.0, "losePoint": -0.1, "followTarget": 0.0, "avoidTarget": 0.00, "hitBall": 0.5},
    
python multistepSim.py sn.json 32 10 20jul20_MultiTestSContinueNormLessFreqLessIntermR

started ~16:00 ...

** check GCP sim progress -->> looked good; interrupt and reload weights, restart with adjusted rewards/taus (similar to cycle sims above)

python -i simdat.py backupcfg/20jul17_testG2_gcp__step_5_sim.json

plotFollowBall(actreward,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,1.))
plotHitMiss(actreward,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,1.))
plotScoreMiss(actreward,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,1.))
ylabel('Performance')
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul20_20jul17_testG2_gcp__step_5_perf.png

similar perf to before ... not really improved further?

lfn = ['20jul15_testG0_gcp_','20jul16_testG1_gcp_', '20jul17_testG2_gcp__step_0_','20jul17_testG2_gcp__step_1_','20jul17_testG2_gcp__step_2_','20jul17_testG2_gcp__step_3_','20jul17_testG2_gcp__step_4_','20jul17_testG2_gcp__step_5_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,.45))
plotHitMiss(pdac,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,.45))
plotScoreMiss(pdac,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,.45))
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)
ylabel('Performance')
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') #
gif/20jul20_20jul17_testG2_gcp__step_5_perf_all_steps_so_far.png
has similar performance to network with full connectivity to output ... but not as good ...
question is how to improve performance further ... 

clf(); drawraster(dspkT,dspkID); xlim((1990e3,2000e3)); ylim((0,sum(list(dnumc.values())))); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul20_20jul17_testG2_gcp__step_5_rast.png
firing rates are still ok/low

xlim((1999e3,2000e3))
savefig('gif/'+dstr+simstr+'rastB.png') # gif/20jul20_20jul17_testG2_gcp__step_5_rastB.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1990e3,2000e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul20_20jul17_testG2_gcp__step_5_Vm.png

#clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
#xlabel('Time (ms)'); tl(); 
#savefig('gif/'+dstr+simstr+'all_avg_weight.png') # 

#fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)

lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN', 'EMSTAY']  
dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
fig, axs, plt = animActivityMaps(lpop=lpop)

will make that movie ... question is whether to continue this sim as is or adjust settings
as did on cycle ...

will try the new strategy that tried on cycle - get rid of follow target reward, increase
RL tau, and use the learned weights as starting point ... this is because current sim seems
to have stabilized follow probability ... 

cp backupcfg/20jul17_testG2_gcp__step_6_sim.json sn.json

"name": "20jul20_testG3_gcp_lessintermR_"
    "simtype": {"ResumeSim": 1, "ResumeSimFromFile": "data/20jul17_testG2_gcp__step_5_synWeights_final.pkl"},
    "rewardcodes": {"scorePoint": 1.0, "losePoint": -0.1, "followTarget": 0.0, "avoidTarget": 0.0, "hitBall": 0.5},    
    "RLlenhebb": 1000

python multistepSim.py sn.json 30 10 20jul20_MultiTestGCPContinueLessFreqLessIntermR

started ~16:46 ...

* 20jul21
** check continued output on GCP

python -i simdat.py backupcfg/20jul20_testG3_gcp_lessintermR__step_0_sim.json

plotFollowBall(actreward,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,1.))
plotHitMiss(actreward,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,1.))
plotScoreMiss(actreward,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,1.))
ylabel('Performance')
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul21_20jul20_testG3_gcp_lessintermR__step_0_perf.png
performance looks ~same as before ... so changing reward values did not have a negative impact ...
was hoping for positive impact ... well, hit/miss ratio is a little higher than before so that's
possible evidence of improvement ... will have to run longer

lfn = ['20jul15_testG0_gcp_','20jul16_testG1_gcp_', '20jul17_testG2_gcp__step_0_','20jul17_testG2_gcp__step_1_','20jul17_testG2_gcp__step_2_','20jul17_testG2_gcp__step_3_','20jul17_testG2_gcp__step_4_','20jul17_testG2_gcp__step_5_','20jul20_testG3_gcp_lessintermR__step_0_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

np.amax(pdac.time) / (1e3*60*60) # 4.999999500000001
so ~5 hours of training so far ... 

plotFollowBall(pdac,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,.45))
plotHitMiss(pdac,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,.45))
plotScoreMiss(pdac,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,.45))
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)
ylabel('Performance')
plot([np.amax(pdac.time)-2000e3,np.amax(pdac.time)-2000e3],[0,0.45],'--',color='gray')
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') #
gif/20jul21_20jul20_testG3_gcp_lessintermR__step_0_perf_all_steps_so_far.png

clf(); drawraster(dspkT,dspkID); xlim((1990e3,2000e3)); ylim((0,sum(list(dnumc.values())))); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul21_20jul20_testG3_gcp_lessintermR__step_0_rast.png

xlim((1999e3,2000e3))
savefig('gif/'+dstr+simstr+'rastB.png') # gif/20jul21_20jul20_testG3_gcp_lessintermR__step_0_rastB.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1990e3,2000e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul21_20jul20_testG3_gcp_lessintermR__step_0_Vm.png

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') #
gif/20jul21_20jul20_testG3_gcp_lessintermR__step_0_all_avg_weight.png
weights are changing but much more slowly ...
savefig('gif/'+dstr+simstr+'all_avg_weightB.png') #
gif/20jul21_20jul20_testG3_gcp_lessintermR__step_0_all_avg_weightB.png
savefig('gif/'+dstr+simstr+'all_avg_weightC.png') #
gif/20jul21_20jul20_testG3_gcp_lessintermR__step_0_all_avg_weightC.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)

* 20jul21
** check output on cycle (less frequent weight norm)

python -i simdat.py backupcfg/20jul20_cont_S_with_less_freq_norm_cycle__step_0_sim.json

plotFollowBall(actreward,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,1.))
plotHitMiss(actreward,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,1.))
plotScoreMiss(actreward,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,1.))
ylabel('Performance')
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul21_20jul20_cont_S_with_less_freq_norm_cycle__step_0_perf.png
does not seem better than the more frequent weight norm ... seems a bit worse ...

clf(); drawraster(dspkT,dspkID); xlim((1590e3,1600e3)); ylim((0,sum(list(dnumc.values())))); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul21_20jul20_cont_S_with_less_freq_norm_cycle__step_0_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1590e3,1600e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul21_20jul20_cont_S_with_less_freq_norm_cycle__step_0_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul21_20jul20_cont_S_with_less_freq_norm_cycle__step_0_poshist.png

lfn = ['20jun30_S0_cycle_', '20jun30_S1_cycle_', '20jun30_S2_cycle_', '20jul2_S3_cycle_', '20jul3_S4_cycle__step_0_','20jul3_S4_cycle__step_1_','20jul3_S4_cycle__step_2_','20jul3_S4_cycle__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_0_','20jul14_cont_20jul3_S4_cycle__step_3__step_1_','20jul14_cont_20jul3_S4_cycle__step_3__step_2_','20jul14_cont_20jul3_S4_cycle__step_3__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_4_','20jul20_cont_S_with_less_freq_norm_cycle__step_0_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,.45))
plotHitMiss(pdac,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,.45))
plotScoreMiss(pdac,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,.45))
plot([np.amax(pdac.time)-50e3,np.amax(pdac.time)-50e3],[0,0.45],'--',color='gray') # when weight norm applied last
plot([np.amax(pdac.time)-1600e3,np.amax(pdac.time)-1600e3],[0,0.45],'--',color='black') # last step start
ylabel('Performance',fontsize=30);
xlabel('Time (ms)',fontsize=30)
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1,fontsize=30)
tl()

savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20jul21_20jul20_cont_S_with_less_freq_norm_cycle__step_0_perf_all_steps_so_far.png

there might be a slight deflection upward in performance in last step of sim for follow
target, but need more time to see if improves substantially...

#clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
#xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
#savefig('gif/'+dstr+simstr+'all_avg_weight.png') #

#fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) # 
#lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN', 'EMSTAY']  
#dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
#fig, axs, plt = animActivityMaps(lpop=lpop)

** check output on cycle (less intermediate reward)

python -i simdat.py backupcfg/20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_0_sim.json

plotFollowBall(actreward,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,1.))
plotHitMiss(actreward,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,1.))
plotScoreMiss(actreward,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,1.))
ylabel('Performance')
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul21_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_0_perf.png

clf(); drawraster(dspkT,dspkID); xlim((1590e3,1600e3)); ylim((0,sum(list(dnumc.values())))); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul21_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_0_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1590e3,1600e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul21_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_0_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul21_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_0_poshist.png

lfn = ['20jun30_S0_cycle_', '20jun30_S1_cycle_', '20jun30_S2_cycle_', '20jul2_S3_cycle_', '20jul3_S4_cycle__step_0_','20jul3_S4_cycle__step_1_','20jul3_S4_cycle__step_2_','20jul3_S4_cycle__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_0_','20jul14_cont_20jul3_S4_cycle__step_3__step_1_','20jul14_cont_20jul3_S4_cycle__step_3__step_2_','20jul14_cont_20jul3_S4_cycle__step_3__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_4_','20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_0_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,.45))
plotHitMiss(pdac,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,.45))
plotScoreMiss(pdac,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,.45))
plot([np.amax(pdac.time)-50e3,np.amax(pdac.time)-50e3],[0,0.45],'--',color='gray') # when weight norm applied last
plot([np.amax(pdac.time)-1600e3,np.amax(pdac.time)-1600e3],[0,0.45],'--',color='black') # last step start
ylabel('Performance',fontsize=30);
xlabel('Time (ms)',fontsize=30)
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1,fontsize=30)
tl()

savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20jul21_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_0_perf_all_steps_so_far.png

hmm, can not tell diff from other sim above ... overlay ...

lfn = ['20jul20_cont_S_with_less_freq_norm_cycle__step_0_','20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_0_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
lpda = getindivactionreward(lfn)

#
for pda,clr in zip(lpda,['b','r']):
  plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color=clr); ylim((0,1.))
  plotHitMiss(pda,ax=subplot(1,3,2),lclr=[clr],asratio=True); ylim((0,1.))
  plotScoreMiss(pda,ax=subplot(1,3,3),clr=clr,asratio=True); ylim((0,1.))

lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','r'],['All Interm Reward','Less Interm Reward'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/'+dstr+simstr+'perf_compare_less_interm_reward.png')
gif/20jul21_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_0_perf_compare_less_interm_reward.png
the one with no follow target reward seems to be doing better overall ... in terms of hit/miss and score

#clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
#xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
#savefig('gif/'+dstr+simstr+'all_avg_weight.png') #

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) # 
#lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN', 'EMSTAY']  
#dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
#fig, axs, plt = animActivityMaps(lpop=lpop)

* 20jul22
** check gcp (step 1)

python -i simdat.py backupcfg/20jul20_testG3_gcp_lessintermR__step_1_sim.json

plotFollowBall(actreward,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,1.))
plotHitMiss(actreward,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,1.))
plotScoreMiss(actreward,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,1.))
ylabel('Performance')
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul22_20jul20_testG3_gcp_lessintermR__step_1_perf.png

lfn = ['20jul15_testG0_gcp_','20jul16_testG1_gcp_', '20jul17_testG2_gcp__step_0_','20jul17_testG2_gcp__step_1_','20jul17_testG2_gcp__step_2_','20jul17_testG2_gcp__step_3_','20jul17_testG2_gcp__step_4_','20jul17_testG2_gcp__step_5_','20jul20_testG3_gcp_lessintermR__step_0_','20jul20_testG3_gcp_lessintermR__step_1_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

np.amax(pdac.time) / (1e3*60*60) # 5.555555000000001

plotFollowBall(pdac,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,.45))
plotHitMiss(pdac,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,.45))
plotScoreMiss(pdac,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,.45))
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)
ylabel('Performance')
plot([np.amax(pdac.time)-4000e3,np.amax(pdac.time)-4000e3],[0,0.45],'--',color='gray')
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20jul22_20jul20_testG3_gcp_lessintermR__step_1_perf_all_steps_so_far.png

doesnt look like improving ... 

clf(); drawraster(dspkT,dspkID); xlim((1990e3,2000e3)); ylim((0,sum(list(dnumc.values())))); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul22_20jul20_testG3_gcp_lessintermR__step_1_rast.png
even though rates are fairly low...due to normalization

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1990e3,2000e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul22_20jul20_testG3_gcp_lessintermR__step_1_Vm.png

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul22_20jul20_testG3_gcp_lessintermR__step_1_all_avg_weight.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)

** check gcp (step 2)

python -i simdat.py backupcfg/20jul20_testG3_gcp_lessintermR__step_2_sim.json

plotFollowBall(actreward,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,1.))
plotHitMiss(actreward,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,1.))
plotScoreMiss(actreward,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,1.))
ylabel('Performance')
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul22_20jul20_testG3_gcp_lessintermR__step_2_perf.png
does not look like it's changing much...

lfn = ['20jul15_testG0_gcp_','20jul16_testG1_gcp_', '20jul17_testG2_gcp__step_0_','20jul17_testG2_gcp__step_1_','20jul17_testG2_gcp__step_2_','20jul17_testG2_gcp__step_3_','20jul17_testG2_gcp__step_4_','20jul17_testG2_gcp__step_5_','20jul20_testG3_gcp_lessintermR__step_0_','20jul20_testG3_gcp_lessintermR__step_1_','20jul20_testG3_gcp_lessintermR__step_2_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

np.amax(pdac.time) / (1e3*60*60) # 6.1111105000000014

plotFollowBall(pdac,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,.45))
plotHitMiss(pdac,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,.45))
plotScoreMiss(pdac,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,.45))
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)
ylabel('Performance')
plot([np.amax(pdac.time)-6000e3,np.amax(pdac.time)-6000e3],[0,0.45],'--',color='gray')
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20jul22_20jul20_testG3_gcp_lessintermR__step_2_perf_all_steps_so_far.png

doesnt look like improving ... 

clf(); drawraster(dspkT,dspkID); xlim((1990e3,2000e3)); ylim((0,sum(list(dnumc.values())))); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul22_20jul20_testG3_gcp_lessintermR__step_2_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1990e3,2000e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul22_20jul20_testG3_gcp_lessintermR__step_2_Vm.png

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul22_20jul20_testG3_gcp_lessintermR__step_2_all_avg_weight.png

weights are changing much more slowly since less frequent reward/punishment ... could increase weight increments and see if helps ... 

# fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)

* 20jul23
** check gcp (step 3)

python -i simdat.py backupcfg/20jul20_testG3_gcp_lessintermR__step_3_sim.json

plotFollowBall(actreward,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,1.))
plotHitMiss(actreward,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,1.))
plotScoreMiss(actreward,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,1.))
ylabel('Performance')
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul23_20jul20_testG3_gcp_lessintermR__step_3_perf.png
now performance is getting worse...

lfn = ['20jul15_testG0_gcp_','20jul16_testG1_gcp_', '20jul17_testG2_gcp__step_0_','20jul17_testG2_gcp__step_1_','20jul17_testG2_gcp__step_2_','20jul17_testG2_gcp__step_3_','20jul17_testG2_gcp__step_4_','20jul17_testG2_gcp__step_5_','20jul20_testG3_gcp_lessintermR__step_0_','20jul20_testG3_gcp_lessintermR__step_1_','20jul20_testG3_gcp_lessintermR__step_2_','20jul20_testG3_gcp_lessintermR__step_3_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

np.amax(pdac.time) / (1e3*60*60) # 6.666666000000001

plotFollowBall(pdac,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,.45))
plotHitMiss(pdac,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,.45))
plotScoreMiss(pdac,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,.45))
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)
ylabel('Performance')
plot([np.amax(pdac.time)-8000e3,np.amax(pdac.time)-8000e3],[0,0.45],'--',color='gray')
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20jul23_20jul20_testG3_gcp_lessintermR__step_3_perf_all_steps_so_far.png

performance getting worse...

clf(); drawraster(dspkT,dspkID); xlim((1990e3,2000e3)); ylim((0,sum(list(dnumc.values())))); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul23_20jul20_testG3_gcp_lessintermR__step_3_rast.png

but the firing rates are ok...since still using weight normalization every 1500 s... no, was not
using weight normalization, but the rates were still fairly low already ... 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1990e3,2000e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul23_20jul20_testG3_gcp_lessintermR__step_3_Vm.png

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)'); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul23_20jul20_testG3_gcp_lessintermR__step_3_all_avg_weight.png
zoom-in shows weights changing, but much too slowly ... should adjust scores and try again ...

# fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False)

** restart multistep on gcp but use larger scores

    "simtype": {"ResumeSim": 1, "ResumeSimFromFile": "data/20jul17_testG2_gcp__step_5_synWeights_final.pkl"},

can multiply RLhebbwt by by 10 - see if that makes a difference...
from 6e-07 to 6e-06

also increase the RL tau ... 1 s may not be long enough ...
"RLlenhebb": 2000

"name": "20jul23_testG4_gcp_lessintermR_"

python multistepSim.py sn.json 30 10 20jul23_MultiTestGCPContinue

started ~12:04 ...
terminated ~16:20 (see below; had to stop until get new gcp credits)

** check status/output on cycle

python -i simdat.py backupcfg/20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_1_sim.json

plotFollowBall(actreward,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,1.))
plotHitMiss(actreward,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,1.))
plotScoreMiss(actreward,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,1.))
ylabel('Performance')
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul23_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_1_perf.png
doing reasonably well (compared to prior sims), though not consistently improving ...
performance probably depends on where ball hit to ... so should not expect uniform performance

clf(); drawraster(dspkT,dspkID); xlim((1590e3,1600e3)); ylim((0,sum(list(dnumc.values())))); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul23_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_1_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1590e3,1600e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul23_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_1_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul23_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_1_poshist.png

lfn = ['20jun30_S0_cycle_', '20jun30_S1_cycle_', '20jun30_S2_cycle_', '20jul2_S3_cycle_', '20jul3_S4_cycle__step_0_','20jul3_S4_cycle__step_1_','20jul3_S4_cycle__step_2_','20jul3_S4_cycle__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_0_','20jul14_cont_20jul3_S4_cycle__step_3__step_1_','20jul14_cont_20jul3_S4_cycle__step_3__step_2_','20jul14_cont_20jul3_S4_cycle__step_3__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_4_','20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_0_','20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_1_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,.45))
plotHitMiss(pdac,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,.45))
plotScoreMiss(pdac,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,.45))
plot([np.amax(pdac.time)-50e3,np.amax(pdac.time)-50e3],[0,0.45],'--',color='gray') # when weight norm applied last
plot([np.amax(pdac.time)-3200e3,np.amax(pdac.time)-3200e3],[0,0.45],'--',color='black') # last step start
ylabel('Performance',fontsize=30);
xlabel('Time (ms)',fontsize=30)
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1,fontsize=30)
tl()

savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png')
gif/20jul23_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_1_perf_all_steps_so_far.png

savefig('gif/'+dstr+simstr+'perf_all_steps_so_farA.png') # gif/20jul23_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_1_perf_all_steps_so_farA.png
looks like follow score going up even though no longer explicitly reinforced...

everything else pretty flat ...

note that this sim has less frequent weight norm and no follow target reward ...

how does it compare to the one with only less frequent weight norm?

lfn = ['20jul20_cont_S_with_less_freq_norm_cycle__step_1_','20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_1_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
lpda = getindivactionreward(lfn)

#
for pda,clr in zip(lpda,['b','r']):
  plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color=clr); ylim((0,1.))
  plotHitMiss(pda,ax=subplot(1,3,2),lclr=[clr],asratio=True); ylim((0,1.))
  plotScoreMiss(pda,ax=subplot(1,3,3),clr=clr,asratio=True); ylim((0,1.))

lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','r'],['All Interm Reward','Less Interm Reward'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/'+dstr+simstr+'perf_compare_less_interm_reward.png')
gif/20jul23_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_1_perf_compare_less_interm_reward.png

less interm reward may be doing better on scoring, though there's still a lot of overlap
... should compare both steps so have more to compare ...

llfn = [['20jul20_cont_S_with_less_freq_norm_cycle__step_0_','20jul20_cont_S_with_less_freq_norm_cycle__step_1_'],
        ['20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_0_','20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_1_']]
lpda = [getconcatactionreward(lfn) for lfn in llfn]

#
for pda,clr in zip(lpda,['b','r']):
  plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color=clr); ylim((0,1.))
  plotHitMiss(pda,ax=subplot(1,3,2),lclr=[clr],asratio=True); ylim((0,1.))
  plotScoreMiss(pda,ax=subplot(1,3,3),clr=clr,asratio=True); ylim((0,1.))

lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','r'],['All Interm Reward','Less Interm Reward'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/'+dstr+simstr+'perf_compare_less_interm_reward.png')

gif/20jul23_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_1_perf_compare_less_interm_reward.png

seems like less intermediate reward sim doing better overall - definitely in terms of score ... 

so may want to stop the sim with the follow target rewards ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') #
gif/20jul23_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_1_all_avg_weight.png
weights changing at a somewhat slow but perhaps reasonable pace...

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) # 
#lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN', 'EMSTAY']  
#dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
#fig, axs, plt = animActivityMaps(lpop=lpop)

stopped this one (python multistepSim.py sn.json 32 10 20jul20_MultiTestSContinueNormLessFreq)
so, only the one with no follow target reward is running now ...

** have to stop gcp for now

wait 1-2 weeks until new credits arrive

so will continue on cycle...

copied this over:
backupcfg/20jul23_testG4_gcp_lessintermR__step_0_sim.json
as well as the final weights that had used for continuation on gcp
earlier today: data/20jul17_testG2_gcp__step_5_synWeights_final.pkl

cp backupcfg/20jul23_testG4_gcp_lessintermR__step_0_sim.json sn.json

python multistepSim.py sn.json 30 10 20jul23_MultiTestGCPContinue

started ~16:28 ...

* 20jul24
** check output on cycle

python -i simdat.py backupcfg/20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_2_sim.json

plotFollowBall(actreward,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,.55))
plotHitMiss(actreward,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,.55))
plotScoreMiss(actreward,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,.55))
ylabel('Performance')
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul24_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_2_perf.png

follow ~flat, hit/miss increasing in small steps, score ~flat

clf(); drawraster(dspkT,dspkID); xlim((1590e3,1600e3)); ylim((0,sum(list(dnumc.values())))); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul24_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_2_rast.png

rates are OK, EMUP,EMDOWN ~10 Hz, EMSTAY ~2 Hz, IM ~20 Hz

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1590e3,1600e3)); 
savefig('gif/'+dstr+simstr+'Vm.png'); # gif/20jul24_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_2_Vm.png

#
clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # 'gif/'+dstr+simstr+'poshist.png'

lfn = ['20jun30_S0_cycle_', '20jun30_S1_cycle_', '20jun30_S2_cycle_', '20jul2_S3_cycle_', '20jul3_S4_cycle__step_0_','20jul3_S4_cycle__step_1_','20jul3_S4_cycle__step_2_','20jul3_S4_cycle__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_0_','20jul14_cont_20jul3_S4_cycle__step_3__step_1_','20jul14_cont_20jul3_S4_cycle__step_3__step_2_','20jul14_cont_20jul3_S4_cycle__step_3__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_4_','20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_0_','20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_1_','20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_2_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

plotFollowBall(pdac,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,.45))
plotHitMiss(pdac,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,.45))
plotScoreMiss(pdac,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,.45))
plot([np.amax(pdac.time)-50e3,np.amax(pdac.time)-50e3],[0,0.45],'--',color='gray') # when weight norm applied last
plot([np.amax(pdac.time)-4800e3,np.amax(pdac.time)-4800e3],[0,0.45],'--',color='black') # last step start
ylabel('Performance',fontsize=30);
xlabel('Time (ms)',fontsize=30)
lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','g','r'],['Follow','Hit/Miss','Score/Miss'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1,fontsize=30)
tl()

savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png')
gif/20jul24_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_2_perf_all_steps_so_far.png

still seems mostly stuck, only follow seems to be increasing while the others
are decreasing ... ??

clf(); xx=plotFollowBall(pdac,ax=subplot(1,1,1),cumulative=False,binsz=10e3,color='b');  ylim((0,1))
plot([np.amax(pdac.time)-4800e3,np.amax(pdac.time)-4800e3],[0,1.],'--',color='black') # change in rewards, normalization timing
ylim((0,.6))

savefig('gif/'+dstr+simstr+'perf_all_steps_so_far_followB.png') #
gif/20jul24_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_2_perf_all_steps_so_far_followB.png

follow looks mostly flat during last few sims ...

not using cumulative for the other measures show anything different?
cumultaive follow looks like increasing but that's because it's relative to the dip
before ... doesn't mean short term follow is increasing, so cumulative looks a little misleading ...

clf(); xx=plotHitMiss(pdac,ax=subplot(1,1,1),lclr=['g'],asbin=True,binsz=100e3);
plot([np.amax(pdac.time)-4800e3,np.amax(pdac.time)-4800e3],[0,1.],'--',color='black') # change in rewards, normalization timing
ylim((0,.6))

savefig('gif/'+dstr+simstr+'perf_all_steps_so_far_hitB.png') #
gif/20jul24_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_2_perf_all_steps_so_far_hitB.png
hard to see anything there...

lfn = ['20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_0_','20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_1_','20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_2_']
pda = getconcatactionreward(lfn)

plotFollowBall(pda,ax=subplot(1,1,1),cumulative=True,color='b');  ylim((0,1))
plotHitMiss(pda,ax=subplot(1,1,1),lclr=['g'],asratio=True); ylim((0,1.))
plotScoreMiss(pda,ax=subplot(1,1,1),clr='r',asratio=True); ylim((0,1.))
savefig('gif/'+dstr+simstr+'perf_last_few_steps.png')
gif/20jul24_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_2_perf_last_few_steps.png
seems mostly flat ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') #
gif/20jul24_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_2_all_avg_weight.png

weights are probably changing too slowly ... and then normalization step at end may help but the
rates haven't gotten high enough yet ... ?

have not looked at consistency of pattern of weights over time ... that should be important

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) # 
#lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN', 'EMSTAY']  
#dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
#fig, axs, plt = animActivityMaps(lpop=lpop)

stopped this sim for now...need to look more carefully at pattern of weights (stablize over time, relatively fixed?)
and see what else could increase network capacity to improve performance ...

** stopped gcp run on cycle since do have some more gcp credits -- will restart it on gcp
** restart gcp run on gcp

cp backupcfg/20jul23_testG4_gcp_lessintermR__step_0_sim.json sn.json

then adjust in sn.json

    "simtype": {"ResumeSim": 1, "ResumeSimFromFile": "data/20jul17_testG2_gcp__step_5_synWeights_final.pkl"},
"name": "20jul24_testG4_gcp_lessintermR_"

python multistepSim.py sn.json 30 10 20jul24_MultiTestGCPContinue

started @ ~12:32 ...

** restart continuation run on cycle

above had this: 
cp backupcfg/20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_5_sim.json sn.json

will adjust parameters since did not look like improving here
20jul24_20jul20_cont_S_with_less_freq_norm_lessintermr_cycle__step_2_perf_all_steps_so_far.png

will use those final weights below but will also increase RL tau (RLlenhebb)and increase RLhebbwt 

    "simtype": {"ResumeSim": 1, "ResumeSimFromFile": "data/20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_4_synWeights_final.pkl"},
"name": "20jul24_cont_S_with_less_freq_norm_lessintermr_cycle_"
"normalizeWeightStepSize": 75000
longer RL tau:
"RLlenhebb": 2000
"RLhebbwt": 2e-06
will adjust scores too:
"rewardcodes": {"scorePoint": 1.0, "losePoint": -1.0, "followTarget": 0.0, "avoidTarget": 0.00, "hitBall": 0.5},

python multistepSim.py sn.json 32 10 20jul24_MultiTestSContinueNormLessFreqLessIntermR

started ~13:56 ...

** other test on gcp -- more EM neurons, sparser connectivity, more recurrent conn

    "rewardcodes": {"scorePoint": 1.0, "losePoint": -1.0, "followTarget": 0.0, "avoidTarget": 0.0, "hitBall": 0.0},
"name": "20jul24_testH0_gcp_"
    "RL": {"AMPA": {"wbase": 1e-07, "wmax": 0.00096, "RLon": 1, "RLlenhebb": 2000, "RLlenanti": 50, "useRLexp": 1, "RLhebbwt": 12e-06, "RLantiwt": -0.0, "hebbwt": 0, "antiwt": 0, "tauhebb": 10, "RLwindhebb": 50, "softthresh": 0, "verbose": 0},


    "net": {"scale": 1, "ER": 400, "IR": 100, "EV1": 400, "EV1DE": 400, "EV1DNE": 400, "EV1DN": 400, "EV1DNW": 400, "EV1DW": 400, "EV1DSW": 400, "EV1DS": 400, "EV1DSE": 400, "IV1": 100, "EV4": 0, "IV4": 0, "EMT": 0, "IMT": 0, "EMDOWN": 200, "EMUP": 200, "EMSTAY": 200, "IM": 75, "AngRFSigma": 22.5, "DirMinRate": 0.0, "DirMaxRate": 50.0, "EEMWghtAM": 7.2e-05, "EEMWghtNM": 7.2e-06, "EEPreMWghtAM": 8e-05, "EEPreMWghtNM": 2.5e-06, "EEMWghtThreshMin": 6.25e-06, "EEMWghtThreshMax": 0.00032, "EEMProb": 0.15, "EEMRecProb": 0.15, "EEPreMProb": 0.0, "EEMPopNorm": 1, "EEMRecProbCross": 0, "EEMFeedbackProb": 0.0, "EEMFeedbackWghtAM": 1.25e-05, "EEMFeedbackWghtNM": 1.25e-06, "VisualFeedback": 0, "weightVar": 0.5},

have more EM neurons, and lower feedforward and recurrent connectivity ... 

./myrun 24 sn.json

python -i simdat.py backupcfg/20jul24_testH0_gcp_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul24_20jul24_testH0_gcp_perf.png
already got 2 points ... so there's a chance learning can work without intermediate rewards

drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); #
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul24_20jul24_testH0_gcp_rast.png
rates are good - ~0.7-.8 Hz for EM, 6.3 for IM

drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(95e3,100e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20jul24_20jul24_testH0_gcp_Vm.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) #

can run this longer ...

may as well use the saved weights and start next ... using multistep

    "simtype": {"ResumeSim": 1, "ResumeSimFromFile": "data/20jul24_testH0_gcp_synWeights_final.pkl"},    
    "name": "20jul24_testH1_gcp_"

python multistepSim.py sn.json 24 10 20jul24_MultiTestGCP_H1

started ~16:06 ...

will stop this sim - not clear targetted RL makes sense here (see below)

** targettedRL -- should it be used when no intermediate rewards?

probably not? since when scoring a point, the actions taken to score it were a long
time ago...so no sense in rewarding only 1 action that contributed to the final outcome

for loss of points, it's more likely to be 1 move that contributed, but even there
often many moves contribute to the mistake

** restart last one on GCP -- adjust params

no targetted RL ... restore size of network to have 100 EMDOWN, EMUP, EMSTAY ...

20jul24_testI0_gcp_

will also bootstrap with previous weights

    "simtype": {"ResumeSim": 1, "ResumeSimFromFile": "data/20jul17_testG2_gcp__step_5_synWeights_final.pkl"},

RLlenhebb of 5000

EEMProb EEMRecProb back to 0.3 ... EEMWghtAM 3.6e-5, EEMWghtNM 3.6e-6

python multistepSim.py sn.json 30 10 20jul24_MultiTestGCP_I

started ~23:24 ...

* 20jul25
** almost no firing from I0 on gcp -->> adjust params, restart as 20jul25_testJ0_gcp_

after end of first step ... so there was probably too much punishment
from losing points ...

can make less drastic changes from other sim - have only score and lose point for reward
but 0.1 for losePoint ... and keep targetted ... since it was working before for the more
frequent reward cases ...

    "rewardcodes": {"scorePoint": 1.0, "losePoint": -0.1, "followTarget": 0.0, "avoidTarget": 0.0, "hitBall": 0.0},
    "simtype": {"ResumeSim": 1, "ResumeSimFromFile": "data/20jul17_testG2_gcp__step_5_synWeights_final.pkl"},    
20jul25_testJ0_gcp_

also put RLlenhebb down to 2e3 ...

python multistepSim.py sn.json 30 10 20jul25_MultiTestGCP_J

started ~22:54 ...

** continuation run on cycle was incorrect too -->> adjust, restart

this one:
(python multistepSim.py sn.json 32 10 20jul24_MultiTestSContinueNormLessFreqLessIntermR)

mistakenly had the follow/avoid reward codes ... and larger lose point punish value ...

these are the codes had intended:
    "rewardcodes": {"scorePoint": 1.0, "losePoint": -0.1, "followTarget": 0.0, "avoidTarget": 0.0, "hitBall": 0.5},
    "name": "20jul25_cont_S_lessintermr_cycle_"
    "simtype": {"ResumeSim": 1, "ResumeSimFromFile": "data/20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_4_synWeights_final.pkl"},

ok, restart ...

python multistepSim.py sn.json 32 10 20jul25_MultiTestSContinueNormLessFreqLessIntermR

started ~23:17 ...

** and another on cycle with no intermediate reward (but bootstrapping same as other above)

    "simtype": {"ResumeSim": 1, "ResumeSimFromFile": "data/20jul14_cont_with_norm_20jul3_S4_cycle__step_3__step_4_synWeights_final.pkl"},
    "rewardcodes": {"scorePoint": 1.0, "losePoint": -0.1, "followTarget": 0.0, "avoidTarget": 0.0, "hitBall": 0.5},
    "name": "20jul25_cont_S_nointermr_cycle_"

python multistepSim.py sn.json 32 10 20jul25_MultiTestSContinueNormLessFreqNoIntermR

* 20jul27
** check output from GCP -- 20jul24_testG4_gcp_lessintermR__step_2_ (this has score,loss and hit rewards)

python -i simdat.py backupcfg/20jul24_testG4_gcp_lessintermR__step_2_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul27_20jul24_testG4_gcp_lessintermR__step_2_perf.png

follow is ~0.5, others much lower ...

drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); #
xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul27_20jul24_testG4_gcp_lessintermR__step_2_rast.png

drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1990e3,2000e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20jul27_20jul24_testG4_gcp_lessintermR__step_2_Vm.png

lfn = ['20jul15_testG0_gcp_','20jul16_testG1_gcp_', '20jul17_testG2_gcp__step_0_','20jul17_testG2_gcp__step_1_','20jul17_testG2_gcp__step_2_','20jul17_testG2_gcp__step_3_','20jul17_testG2_gcp__step_4_','20jul17_testG2_gcp__step_5_','20jul24_testG4_gcp_lessintermR__step_0_','20jul24_testG4_gcp_lessintermR__step_1_','20jul24_testG4_gcp_lessintermR__step_2_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

ax=plotPerf(pdac,yl=(0,.55))
plot([np.amax(pdac.time)-6000e3,np.amax(pdac.time)-6000e3],[0,.55],'--',color='black') # change in rewards
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png')
gif/20jul27_20jul24_testG4_gcp_lessintermR__step_2_perf_all_steps_so_far.png

follow increasing, but hit/miss and score/miss are decreasing ... in this sim using score,loss and hit reward
but no follow target reward ... not clear why hit/miss score/miss performance would decrease
could be lower activity levels ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') #
weights look like mostly decreasing ... though near end they start to increase,
from this hits,scores at end of sim ...
savefig('gif/'+dstr+simstr+'all_avg_weightB.png') # gif/20jul27_20jul24_testG4_gcp_lessintermR__step_2_all_avg_weightB.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) #
gif/20jul27_20jul24_testG4_gcp_lessintermR__step_2__input.mp4

** check output from GCP -- 20jul25_testJ0_gcp__step_0_ (this has only score,loss reward/punish) -->> this one doing better?

python -i simdat.py backupcfg/20jul25_testJ0_gcp__step_0_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul27_20jul25_testJ0_gcp__step_0_perf.png
this one doing better than sim above ... hit/miss, score/miss slowly increasing in 2nd half of simulation...

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul27_20jul25_testJ0_gcp__step_0_rast.png
similar firing rates to sim above ... 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1990e3,2000e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20jul27_20jul25_testJ0_gcp__step_0_Vm.png

lfn = ['20jul15_testG0_gcp_','20jul16_testG1_gcp_', '20jul17_testG2_gcp__step_0_','20jul17_testG2_gcp__step_1_','20jul17_testG2_gcp__step_2_','20jul17_testG2_gcp__step_3_','20jul17_testG2_gcp__step_4_','20jul17_testG2_gcp__step_5_','20jul25_testJ0_gcp__step_0_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

ax=plotPerf(pdac,yl=(0,.55))
plot([np.amax(pdac.time)-2000e3,np.amax(pdac.time)-2000e3],[0,.55],'--',color='black') # change in rewards
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png')
gif/20jul27_20jul25_testJ0_gcp__step_0_perf_all_steps_so_far.png
savefig('gif/'+dstr+simstr+'perf_all_steps_so_farB.png')
gif/20jul27_20jul25_testJ0_gcp__step_0_perf_all_steps_so_farB.png
score/miss increasing slightly at end, but not to a peak in cumulative; so that
either reflects slow cumulative measure or slightly worse performance

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') #
gif/20jul27_20jul25_testJ0_gcp__step_0_all_avg_weight.png
in this one (compared to other above), the weights are increasing more...
so there's more stability...may need to adjust weight scores for the other simulation...
hmm, but this simulation has no reward for hit ... so may be due to it being
earlier simulation? should compare same step

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) #
gif/20jul27_20jul25_testJ0_gcp__step_0__input.mp4

** compare two sims on gcp

python -i simdat.py

lfn = ['20jul24_testG4_gcp_lessintermR__step_0_', '20jul25_testJ0_gcp__step_0_']
lpda = getindivactionreward(lfn)

#
for pda,clr in zip(lpda,['b','r']):
  plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color=clr); ylim((0,1.))
  plotHitMiss(pda,ax=subplot(1,3,2),lclr=[clr],asratio=True); ylim((0,1.))
  plotScoreMiss(pda,ax=subplot(1,3,3),clr=clr,asratio=True); ylim((0,1.))

lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','r'],['Score/Loss/Hit Reward','Score/Loss Reward'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/20jul27_compare_scorelosshit_scoreloss_gcp_perf.png')
'gif/20jul27_compare_scorelosshit_scoreloss_gcp_perf.png'

hmm, so even on first step, the one with the hit reward is doing much worse in getting hits
and in getting points... surprising ...

** stop 20jul24_testG4_gcp_lessintermR_ sim on gcp

this is the sim with score/loss and hit rewards that was continued from the weights of sim which also
had follow target reward; since this sim is doing worse than the sim with only score/loss reward (20jul25_testJ0_gcp__step_0_),
will stop this sim

### python multistepSim.py sn.json 30 10 20jul24_MultiTestGCPContinue ###

** other sim on gcp (20jul27_testK0_gcp_), bootstrap weights, only score/loss, longer RLlenhebb, smaller RLhebbwt

try same as J but with longer RL time constant and smaller RLhebbwt?

to see if learns better ...

cp backupcfg/20jul25_testJ0_gcp__step_0_.json sn.json

then adjust ...

    "RL": {"AMPA": {"wbase": 1e-07, "wmax": 0.00048, "RLon": 1, "RLlenhebb": 4000, "RLlenanti": 50, "useRLexp": 1, "RLhebbwt": 3e-06, "RLantiwt": -0.0, "hebbwt": 0, "antiwt": 0, "tauhebb": 10, "RLwindhebb": 50, "softthresh": 0, "verbose": 0},

(increased RLlenhebb to 4000 from 2000; and decreased RLhebbwt from 6e-06 to 3e-06)

"name": "20jul27_testK0_gcp_"

python multistepSim.py sn.json 30 10 20jul25_MultiTestGCP_K

started ~14:08 ...

** or try larger output layer

without the bootstrapping ... will try that later ...

** check sims on cycle -- first, compare less intermediate reward with no intermediate reward

python -i simdat.py backupcfg/20jul25_cont_S_nointermr_cycle__step_0_sim.json

lfn = ['20jul25_cont_S_lessintermr_cycle__step_0_', '20jul25_cont_S_nointermr_cycle__step_0_']
lpda = getindivactionreward(lfn)

#
for pda,clr in zip(lpda,['b','r']):
  plotFollowBall(pda,ax=subplot(1,3,1),cumulative=True,color=clr); ylim((0,.55))
  plotHitMiss(pda,ax=subplot(1,3,2),lclr=[clr],asratio=True); ylim((0,.55))
  plotScoreMiss(pda,ax=subplot(1,3,3),clr=clr,asratio=True); ylim((0,.55))

lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['b','r'],['Score/Loss/Hit Reward','Score/Loss Reward'])]
ax=gca()
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/20jul27_compare_lessintermr_nointermr_cycle_gcp_perf.png')
gif/20jul27_compare_lessintermr_nointermr_cycle_gcp_perf.png

here too, the sim without hit reward is doing better ... but both of their hit/miss ratios
seem to be decreasing after initial spike ...

compare cumulative ... 

lfn = ['20jun30_S0_cycle_', '20jun30_S1_cycle_', '20jun30_S2_cycle_', '20jul2_S3_cycle_', '20jul3_S4_cycle__step_0_','20jul3_S4_cycle__step_1_','20jul3_S4_cycle__step_2_','20jul3_S4_cycle__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_0_','20jul14_cont_20jul3_S4_cycle__step_3__step_1_','20jul14_cont_20jul3_S4_cycle__step_3__step_2_','20jul14_cont_20jul3_S4_cycle__step_3__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_4_','20jul25_cont_S_nointermr_cycle__step_0_']
pdac = getconcatactionreward(lfn)

ax=plotPerf(pdac,yl=(0,.55))
plot([np.amax(pdac.time)-1600e3,np.amax(pdac.time)-1600e3],[0,.55],'--',color='black') # change in rewards

savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png')
gif/20jul27_20jul25_cont_S_nointermr_cycle__step_0_perf_all_steps_so_far.png

overall, not doing better with the adjusted rewards ... may run another step ... 
but will stop the sim with the hit reward, since not doing as well as this one

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1590e3,1600e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul27_20jul25_cont_S_nointermr_cycle__step_0_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1590e3,1600e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20jul27_20jul25_cont_S_nointermr_cycle__step_0_Vm.png

clf(); dobjpos = loadObjPos() ## 
xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul27_20jul25_cont_S_nointermr_cycle__step_0_poshist.png

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul27_20jul25_cont_S_nointermr_cycle__step_0_all_avg_weight.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) #
gif/20jul27_20jul25_cont_S_nointermr_cycle__step_0__input.mp4

** try larger EM layer on cycle 

using params from gcp ... and adjusted to larger size

"name": "20jul27_T0_cycle_"

./myrun 32 sn.json

python -i simdat.py backupcfg/20jul27_T0_cycle_sim.json

drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'])

ax=plotPerf(actreward,yl=(0,.55))

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY','IM'],lclr=['r','b','g','c'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl();

ok, try a multistep here ...

python multistepSim.py sn.json 32 10 20jul25_MultiTestCycle_T

started ~16:53 ...

** EIPlast?

could have plasticity from each motor pop to other interneuron pop to allow competition
between the output commands ...

would that help the type of rebound in action seen ... where moving down or up for a few steps
leads to moves in opposite direction immediately after ...

even fixed weight activation of other interneurons that suppress other output actions could help with that...

** check next step on gcp (20jul25_testJ0_gcp__step_1_)

python -i simdat.py backupcfg/20jul25_testJ0_gcp__step_1_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul28_20jul25_testJ0_gcp__step_1_perf.png
does not look better from last step...

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul28_20jul25_testJ0_gcp__step_1_rast.png
rates look ok ... some synch between EMUP,EMDOWN ...
savefig('gif/'+dstr+simstr+'rastB.png') # gif/20jul28_20jul25_testJ0_gcp__step_1_rastB.png

suggests would be useful to plot rates or raster in actmap movies ... to help diagnose when
dynamics/behavior failing

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1990e3,2000e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20jul28_20jul25_testJ0_gcp__step_1_Vm.png

lfn = ['20jul15_testG0_gcp_','20jul16_testG1_gcp_', '20jul17_testG2_gcp__step_0_','20jul17_testG2_gcp__step_1_','20jul17_testG2_gcp__step_2_','20jul17_testG2_gcp__step_3_','20jul17_testG2_gcp__step_4_','20jul17_testG2_gcp__step_5_','20jul25_testJ0_gcp__step_0_','20jul25_testJ0_gcp__step_1_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

ax=plotPerf(pdac,yl=(0,.55))
plot([np.amax(pdac.time)-4000e3,np.amax(pdac.time)-4000e3],[0,.55],'--',color='black') # change in rewards
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png')
gif/20jul27_20jul25_testJ0_gcp__step_1_perf_all_steps_so_far.png
seems like decreasing in hit/miss ratio ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') #
gif/20jul27_20jul25_testJ0_gcp__step_1_all_avg_weight.png
weights go up/down in parallel with the performance ... 

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) #
gif/20jul27_20jul25_testJ0_gcp__step_1__input.mp4

* 20jul28
** check network with smaller RLhebbwt, and longer Rllenhebb (20jul27_testK0_gcp__step_0_)

python -i simdat.py backupcfg/20jul27_testK0_gcp__step_0_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul28_20jul27_testK0_gcp__step_0_perf.png

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul28_20jul27_testK0_gcp__step_0_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1990e3,2000e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20jul28_20jul27_testK0_gcp__step_0_Vm.png

how does performance compare to the other model which had bigger weights?

lfn = ['20jul25_testJ0_gcp__step_0_', '20jul27_testK0_gcp__step_0_']
lpda = getindivactionreward(lfn)

plotComparePerf(lpda,['b','r'],yl=(0,.55),lleg=lfn)
savefig('gif/'+dstr+simstr+'compare_perf.png') # gif/20jul28_20jul27_testK0_gcp__step_0_compare_perf.png
not clear which better, if any, need more time to compare performance...

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul28_20jul27_testK0_gcp__step_0_all_avg_weight.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) #
gif/20jul28_20jul27_testK0_gcp__step_0__input.mp4

** check next J0 step on gcp

python -i simdat.py backupcfg/20jul25_testJ0_gcp__step_2_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul28_20jul25_testJ0_gcp__step_2_perf.png
does not look better...just the opposite

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul28_20jul25_testJ0_gcp__step_2_rast.png
EMSTAY is almost entirely off ... so might be better off without them??

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1990e3,2000e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20jul28_20jul25_testJ0_gcp__step_2_Vm.png

lfn = ['20jul15_testG0_gcp_','20jul16_testG1_gcp_', '20jul17_testG2_gcp__step_0_','20jul17_testG2_gcp__step_1_','20jul17_testG2_gcp__step_2_','20jul17_testG2_gcp__step_3_','20jul17_testG2_gcp__step_4_','20jul17_testG2_gcp__step_5_','20jul25_testJ0_gcp__step_0_','20jul25_testJ0_gcp__step_1_','20jul25_testJ0_gcp__step_2_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

ax=plotPerf(pdac,yl=(0,.55))
plot([np.amax(pdac.time)-6000e3,np.amax(pdac.time)-6000e3],[0,.55],'--',color='black') # change in rewards
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png')
gif/20jul27_20jul25_testJ0_gcp__step_2_perf_all_steps_so_far.png
performance values dropping ... so, this strategy may not work ... 

pdfs = pdf[(pdf.preid>=dstartidx['EV1']) & (pdf.preid<=dendidx['EV1']) & (pdf.postid==dstartidx['EMDOWN'])]
len(pdfs) # 24000
plot(pdfs.time,pdfs.weight,'ko',markersize=3)
savefig('gif/'+dstr+simstr+'wght1.png')
so some weights go up and then down, and do not seem stable...

seems useful to know which x,y coordinates correspond to higher vs lower weights ... (similar
to RFs)

plotallinputmaps ...

drfmap = plotallinputmaps(pdf, np.amin(pdf.time), dstartidx['EMDOWN'] + 0, 'EMDOWN', dnumc, dstartidx, dendidx, asweight=True,cmap='jet')

savefig('gif/'+dstr+simstr+'map1.png')
gif/20jul28_20jul25_testJ0_gcp__step_2_map1.png
more representation at the left/right sides ... makes sense given that
it's where most of the reward/punishment occurs

#
lmap = [drfmap[x] for x in drfmap.keys()]
lmap = np.array(lmap)
nps = np.sum(lmap,axis=0)
clf(); imshow(nps,cmap='jet',origin='upper'); colorbar()
savefig('gif/'+dstr+simstr+'map2.png') # gif/20jul28_20jul25_testJ0_gcp__step_2_map2.png

#
drfmap = plotallinputmaps(pdf, np.amax(pdf.time), dstartidx['EMSTAY'] + 0, 'EMSTAY', dnumc, dstartidx, dendidx, asweight=True,cmap='jet')
lmap = [drfmap[x] for x in drfmap.keys()]
lmap = np.array(lmap)
nps = np.sum(lmap,axis=0)
clf(); imshow(nps,cmap='jet',origin='upper'); colorbar()
savefig('gif/'+dstr+simstr+'map3.png') # gif/20jul28_20jul25_testJ0_gcp__step_2_map3.png
but EMSTAY does not have that pattern...(EMUP does)

tt = np.unique(pdf.time)

dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMDOWN')
plotallinputmaps(pdfs,tt[-1],dstartidx['EMDOWN'],'EMDOWN',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)

savefig('gif/'+dstr+simstr+'EMDOWN_map4.png') # gif/20jul28_20jul25_testJ0_gcp__step_2_EMDOWN_map4.png
that's at EMDOWN population level ... seems interesting ...

dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMUP')
clf(); plotallinputmaps(pdfs,tt[-1],dstartidx['EMUP'],'EMUP',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMUP_map4.png') # gif/20jul28_20jul25_testJ0_gcp__step_2_EMUP_map4.png

dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMSTAY')
clf(); plotallinputmaps(pdfs,tt[-1],dstartidx['EMSTAY'],'EMSTAY',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMSTAY_map4.png') # gif/20jul28_20jul25_testJ0_gcp__step_2_EMSTAY_map4.png

EMSTAY much more noisy ...

so next, can see if the RFs change over time, and how ... 

#clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
#xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
#savefig('gif/'+dstr+simstr+'all_avg_weight.png') #
#gif/20jul27_20jul25_testJ0_gcp__step_2_all_avg_weight.png

#fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) #
#gif/20jul27_20jul25_testJ0_gcp__step_2__input.mp4

** check output from larger-output layer sim on cycle (20jul27_T0_cycle__step_0_)

python -i simdat.py backupcfg/20jul27_T0_cycle__step_0_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul28_20jul27_T0_cycle__step_0_perf.png
pretty bad so far - only ~7 hits and 1 point ...

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((790e3,800e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul28_20jul27_T0_cycle__step_0_rast.png
very low firing rates ... 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(790e3,800e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20jul28_20jul27_T0_cycle__step_0_Vm.png

tt = np.unique(pdf.time)

dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMDOWN')
plotallinputmaps(pdf,tt[-1],dstartidx['EMDOWN'],'EMDOWN',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMDOWN_inputmap.png') # gif/20jul28_20jul27_T0_cycle__step_0_EMDOWN_inputmap.png
looks like noise ... 

dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMUP')
clf(); plotallinputmaps(pdf,tt[-1],dstartidx['EMUP'],'EMUP',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMUP_inputmap.png') # gif/20jul28_20jul27_T0_cycle__step_0_EMUP_inputmap.png

dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMSTAY')
clf(); plotallinputmaps(pdf,tt[-1],dstartidx['EMSTAY'],'EMSTAY',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMSTAY_inputmap.png') # gif/20jul28_20jul27_T0_cycle__step_0_EMSTAY_inputmap.png
these EMSTAY patterns look less noisy than EMDOWN,EMUP ... but EV1DSE->EMSTAY has lower weights in bottom right
corner; would expect opposite - higher EMSTAY weights there ... maybe lower values in lower right and upper right
because that's where most of the lost points occur ... can see some of that for EMUP and EMDOWN weights
but not as clear ...

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul28_20jul27_T0_cycle__step_0_all_avg_weight.png
weights may be decreasing too quickly, so could reduce lose point value ...
stopped this sim ... 

** forced weight stabilization through sequential training?

could hold some weights from initial intermediate training fixed,
then apply the training with no intermediate rewards

** check 20jul25_cont_S_nointermr_cycle__step_1_

python -i simdat.py backupcfg/20jul25_cont_S_nointermr_cycle__step_1_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul28_20jul25_cont_S_nointermr_cycle__step_1_perf.png
nothing consistent ... ? 

lfn = ['20jun30_S0_cycle_', '20jun30_S1_cycle_', '20jun30_S2_cycle_', '20jul2_S3_cycle_', '20jul3_S4_cycle__step_0_','20jul3_S4_cycle__step_1_','20jul3_S4_cycle__step_2_','20jul3_S4_cycle__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_0_','20jul14_cont_20jul3_S4_cycle__step_3__step_1_','20jul14_cont_20jul3_S4_cycle__step_3__step_2_','20jul14_cont_20jul3_S4_cycle__step_3__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_4_','20jul25_cont_S_nointermr_cycle__step_0_','20jul25_cont_S_nointermr_cycle__step_1_']
pdac = getconcatactionreward(lfn)

ax=plotPerf(pdac,yl=(0,.55))
plot([np.amax(pdac.time)-3200e3,np.amax(pdac.time)-3200e3],[0,.55],'--',color='black') # change in rewards
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png')
gif/20jul28_20jul25_cont_S_nointermr_cycle__step_1_perf_all_steps_so_far.png
performance decreasing for hit/miss, score/miss ... seems problematic ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1590e3,1600e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul28_20jul25_cont_S_nointermr_cycle__step_1_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1590e3,1600e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20jul28_20jul25_cont_S_nointermr_cycle__step_1_Vm.png

clf(); dobjpos = loadObjPos() ## 
subplot(2,1,1); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
subplot(2,1,2); xlabel('Ball Y position'); hist(dobjpos['ball'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul28_20jul25_cont_S_nointermr_cycle__step_1_poshist.png
ball y position and racket y position closely aligned in histogram ... so may not make sense to consider
it a bias in the model ... however, paddle does get stuck at top too far from where it can hit ball ... and
that accounts for many misses. is it due to too large flow width? or some bug at the edges of image?

#clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
#xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
#savefig('gif/'+dstr+simstr+'all_avg_weight.png') # 

#fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) #

tt = np.unique(pdf.time)

dout = getpopinputmap(pdf, tt[0], dnumc, dstartidx, dendidx, 'EMDOWN')
plotallinputmaps(pdf,tt[0],dstartidx['EMDOWN'],'EMDOWN',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMDOWN_inputmap_first.png') # gif/20jul28_20jul25_cont_S_nointermr_cycle__step_1_EMDOWN_inputmap_first.png
dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMDOWN')
clf(); plotallinputmaps(pdf,tt[-1],dstartidx['EMDOWN'],'EMDOWN',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMDOWN_inputmap_last.png') # gif/20jul28_20jul25_cont_S_nointermr_cycle__step_1_EMDOWN_inputmap_last.png
those two maps look qualitatively similar ... 

dout = getpopinputmap(pdf, tt[0], dnumc, dstartidx, dendidx, 'EMUP')
clf(); plotallinputmaps(pdf,tt[0],dstartidx['EMUP'],'EMUP',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMUP_inputmap_first.png') # gif/20jul28_20jul25_cont_S_nointermr_cycle__step_1_EMUP_inputmap_first.png
dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMUP')
clf(); plotallinputmaps(pdf,tt[-1],dstartidx['EMUP'],'EMUP',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMUP_inputmap_last.png') # gif/20jul28_20jul25_cont_S_nointermr_cycle__step_1_EMUP_inputmap_last.png

dout = getpopinputmap(pdf, tt[0], dnumc, dstartidx, dendidx, 'EMSTAY')
clf(); plotallinputmaps(pdf,tt[0],dstartidx['EMSTAY'],'EMSTAY',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMSTAY_inputmap_first.png') # gif/20jul28_20jul25_cont_S_nointermr_cycle__step_1_EMSTAY_inputmap_first.png
dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMSTAY')
clf(); plotallinputmaps(pdf,tt[-1],dstartidx['EMSTAY'],'EMSTAY',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMSTAY_inputmap_last.png') # gif/20jul28_20jul25_cont_S_nointermr_cycle__step_1_EMSTAY_inputmap_last.png
here EMSTAY maps are not random and change more from first to last time step, ... more difficult to decipher

also, why is top left corner blank in all of these input maps?

gid2pos(dnumc['EMDOWN'],dstartidx['EMDOWN'], dstartidx['EMDOWN']) # (0, 0)
gid2pos(dnumc['EMDOWN'],dstartidx['EMDOWN'], dstartidx['EMDOWN']+1) # (1, 0)
those are x,y positions ... so coordinate 0,0 must not receive any input ... ??
no, there is a bug in getinputmap - had left off the first input in map creation ...
fixed now ...

** other sim with better resolution for motion detection

could put in the intermediate rewards again to check ...

"name": "20jul28_U0_cycle_"
    "rewardcodes": {"scorePoint": 1.0, "losePoint": -0.1, "followTarget": 0.1, "avoidTarget": -0.01, "hitBall": 0.5},
    "DirectionDetectionAlgo": {"CentroidTracker": 1, "OpticFlow": 0, "FlowWidth": 1, "UseFull": 1},

./myrun 32 sn.json

python -i simdat.py backupcfg/20jul28_U0_cycle_sim.json

ldflow = loadMotionFields(dconf['sim']['name'])
fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=True,ldflow=ldflow) #

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png')

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((90e3,100e3))

* 20jul29
** check 20jul27_testK0_gcp__step_1_ (smaller RLhebbwt, and longer Rllenhebb)

python -i simdat.py backupcfg/20jul27_testK0_gcp__step_1_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul28_20jul27_testK0_gcp__step_1_perf.png

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul28_20jul27_testK0_gcp__step_1_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1990e3,2000e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20jul28_20jul27_testK0_gcp__step_1_Vm.png

lfn = ['20jul25_testJ0_gcp__step_1_', '20jul27_testK0_gcp__step_1_']
lpda = getindivactionreward(lfn)

plotComparePerf(lpda,['b','r'],yl=(0,.55),lleg=lfn)
savefig('gif/'+dstr+simstr+'compare_perf.png') # gif/20jul28_20jul27_testK0_gcp__step_1_compare_perf.png
smaller step size looks better ... so may as well shut off J sims ...

lfn = ['20jul15_testG0_gcp_','20jul16_testG1_gcp_', '20jul17_testG2_gcp__step_0_','20jul17_testG2_gcp__step_1_','20jul17_testG2_gcp__step_2_','20jul17_testG2_gcp__step_3_','20jul17_testG2_gcp__step_4_','20jul17_testG2_gcp__step_5_','20jul27_testK0_gcp__step_0_','20jul27_testK0_gcp__step_1_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)
ax=plotPerf(pdac,yl=(0,.55))
plot([np.amax(pdac.time)-4000e3,np.amax(pdac.time)-4000e3],[0,.55],'--',color='black') # change in rewards
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20jul29_20jul27_testK0_gcp__step_1_perf_all_steps_so_far.png

performance not falling as fast as J series ... 

could reduce RLhebbwt even more and see if helps ... since there is a lot more frequent punishmnet
for losing points ... 

** check (20jul25_testJ0_gcp__step_3_) sim with higher RLhebbwt

python -i simdat.py backupcfg/20jul25_testJ0_gcp__step_3_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul28_20jul25_testJ0_gcp__step_3_perf.png
seems even worse than before

lfn = ['20jul15_testG0_gcp_','20jul16_testG1_gcp_', '20jul17_testG2_gcp__step_0_','20jul17_testG2_gcp__step_1_','20jul17_testG2_gcp__step_2_','20jul17_testG2_gcp__step_3_','20jul17_testG2_gcp__step_4_','20jul17_testG2_gcp__step_5_','20jul25_testJ0_gcp__step_0_','20jul25_testJ0_gcp__step_1_','20jul25_testJ0_gcp__step_2_','20jul25_testJ0_gcp__step_3_']
lfn = ['data/'+x+'ActionsRewards.txt' for x in lfn]
pdac = getconcatactionreward(lfn)

ax=plotPerf(pdac,yl=(0,.55))
plot([np.amax(pdac.time)-8000e3,np.amax(pdac.time)-8000e3],[0,.55],'--',color='black') # change in rewards
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png')
gif/20jul27_20jul25_testJ0_gcp__step_3_perf_all_steps_so_far.png
performance still dropping, will stop this sim

** next for gcp

stop J sims ...
start L sim with smaller weight inc (RLhebbwt)

cp backupcfg/20jul27_testK0_gcp__step_0_sim.json sn.json

then modify ...

        "name": "20jul29_testL0_gcp_",
            "RLlenhebb": 8000,
            "RLhebbwt": 1.5e-06,
    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20jul17_testG2_gcp__step_5_synWeights_final.pkl"
    },
    "rewardcodes": {
        "scorePoint": 1.0,
        "losePoint": -0.1,
        "followTarget": 0.0,
        "avoidTarget": 0.0,
        "hitBall": 0.0
    },
    
python multistepSim.py sn.json 30 10 20jul29_MultiTestGCP_L

started ~14:21 ...

** check output on cycle (20jul25_cont_S_nointermr_cycle__step_2_)

python -i simdat.py backupcfg/20jul25_cont_S_nointermr_cycle__step_2_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul28_20jul25_cont_S_nointermr_cycle__step_2_perf.png
that looks like a turnaround for hit/miss ratio ... seems to be rising ... same with score/miss ...
or maybe not, since last step had higher values ... 

lfn = ['20jun30_S0_cycle_', '20jun30_S1_cycle_', '20jun30_S2_cycle_', '20jul2_S3_cycle_', '20jul3_S4_cycle__step_0_','20jul3_S4_cycle__step_1_','20jul3_S4_cycle__step_2_','20jul3_S4_cycle__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_0_','20jul14_cont_20jul3_S4_cycle__step_3__step_1_','20jul14_cont_20jul3_S4_cycle__step_3__step_2_','20jul14_cont_20jul3_S4_cycle__step_3__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_4_','20jul25_cont_S_nointermr_cycle__step_0_','20jul25_cont_S_nointermr_cycle__step_1_','20jul25_cont_S_nointermr_cycle__step_2_']
pdac = getconcatactionreward(lfn)

ax=plotPerf(pdac,yl=(0,.55))
plot([np.amax(pdac.time)-4800e3,np.amax(pdac.time)-4800e3],[0,.55],'--',color='black') # change in rewards
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png')
gif/20jul28_20jul25_cont_S_nointermr_cycle__step_2_perf_all_steps_so_far.png

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1590e3,1600e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul28_20jul25_cont_S_nointermr_cycle__step_2_rast.png

clf(); dobjpos = loadObjPos() ## 
subplot(2,1,1); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
subplot(2,1,2); xlabel('Ball Y position'); hist(dobjpos['ball'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20jul28_20jul25_cont_S_nointermr_cycle__step_2_poshist.png

plot(dobjpos['ball'][:,1],'b')
plot(dobjpos['racket'][:,1],'r')
savefig('gif/'+dstr+simstr+'ball_racket_pos.png') # gif/20jul29_20jul25_cont_S_nointermr_cycle__step_2_ball_racket_pos.png

from scipy.stats import pearsonr
pearsonr(dobjpos['ball'][:,1],dobjpos['racket'][:,1]) # (0.41416891327846045, 0.0)
that could be another performance measure ...

should also overlay the firing rates of each EM population to see if can figure out where/why
performance degrades...

binsz=20; tmax=totalDur
tt = np.arange(0,tmax,binsz)
spkT = dspkT['EMDOWN']
nspk = [len(spkT[(spkT>=tstart) & (spkT<tstart+binsz)]) for tstart in tt]
#tt,nspk = getspikehist(dspkT['EMDOWN'],dnumc,binsz,tmax)

dhist = {pop:getspikehist(dspkT[pop],dnumc,binsz,totalDur) for pop in ['EMDOWN','EMUP','EMSTAY','IM']}

#
clf()
subplot(2,1,1)
tt = np.linspace(0,totalDur,len(dobjpos['ball'][:,1]))
plot(tt,dobjpos['ball'][:,1],'b')
plot(tt,dobjpos['racket'][:,1],'r')
xlim((0,totalDur))
subplot(2,1,2)
tt = dhist['EMDOWN'][0]
plot(tt,dhist['EMDOWN'][1],'r')
plot(tt,dhist['EMUP'][1],'b')
plot(tt,dhist['EMSTAY'][1],'g')
xlim((0,totalDur))

lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['r','b','g'],['EMDOWN','EMUP','EMSTAY'])]
ax=subplot(2,1,2)
ax.legend(handles=lpatch,handlelength=1)

savefig('gif/'+dstr+simstr+'_ball_racket_rates.png')
gif/20jul29_20jul25_cont_S_nointermr_cycle__step_2__ball_racket_rates.png

hmm, but do not know exact times from obj pos ...

subplot(2,1,1); xlim((11e3,16e3))
subplot(2,1,2); xlim((11e3,16e3))
savefig('gif/'+dstr+simstr+'_ball_racket_ratesB.png')

could competition between ensembles result in wrong moves after many right moves?
e.g. move up fast then up population goes into refractoriness and then down takes over ...
also note that EMSTAY rates are almost always lower than EMDOWN,EMUP so EMSTAY almost never
has an impact on behavior

pearsonr(dhist['EMDOWN'][1],dhist['EMUP'][1]) # (0.4815442693187105, 0.0)
pearsonr(dhist['EMDOWN'][1],dhist['IM'][1]) # (0.6387126328081073, 0.0)

#clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
#xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
#savefig('gif/'+dstr+simstr+'all_avg_weight.png') # 

#fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=False) #

tt = np.unique(pdf.time)

dout = getpopinputmap(pdf, tt[0], dnumc, dstartidx, dendidx, 'EMDOWN')
plotallinputmaps(pdf,tt[0],dstartidx['EMDOWN'],'EMDOWN',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMDOWN_inputmap_first.png') # gif/20jul28_20jul25_cont_S_nointermr_cycle__step_2_EMDOWN_inputmap_first.png
dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMDOWN')
clf(); plotallinputmaps(pdf,tt[-1],dstartidx['EMDOWN'],'EMDOWN',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMDOWN_inputmap_last.png') # gif/20jul28_20jul25_cont_S_nointermr_cycle__step_2_EMDOWN_inputmap_last.png

dout = getpopinputmap(pdf, tt[0], dnumc, dstartidx, dendidx, 'EMUP')
clf(); plotallinputmaps(pdf,tt[0],dstartidx['EMUP'],'EMUP',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMUP_inputmap_first.png') # gif/20jul28_20jul25_cont_S_nointermr_cycle__step_2_EMUP_inputmap_first.png
dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMUP')
clf(); plotallinputmaps(pdf,tt[-1],dstartidx['EMUP'],'EMUP',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMUP_inputmap_last.png') # gif/20jul28_20jul25_cont_S_nointermr_cycle__step_2_EMUP_inputmap_last.png

dout = getpopinputmap(pdf, tt[0], dnumc, dstartidx, dendidx, 'EMSTAY')
clf(); plotallinputmaps(pdf,tt[0],dstartidx['EMSTAY'],'EMSTAY',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMSTAY_inputmap_first.png') # gif/20jul28_20jul25_cont_S_nointermr_cycle__step_2_EMSTAY_inputmap_first.png
dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMSTAY')
clf(); plotallinputmaps(pdf,tt[-1],dstartidx['EMSTAY'],'EMSTAY',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMSTAY_inputmap_last.png') # gif/20jul28_20jul25_cont_S_nointermr_cycle__step_2_EMSTAY_inputmap_last.png

* 20jul30
** check 20jul27_testK0_gcp__step_2_ (smaller RLhebbwt, and longer Rllenhebb than testJ0_gcp)

python -i simdat.py backupcfg/20jul27_testK0_gcp__step_2_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul28_20jul27_testK0_gcp__step_2_perf.png
mostly flat ...

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul28_20jul27_testK0_gcp__step_2_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1990e3,2000e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20jul28_20jul27_testK0_gcp__step_2_Vm.png

lfn = ['20jul25_testJ0_gcp__step_2_', '20jul27_testK0_gcp__step_2_']
lpda = getindivactionreward(lfn)

plotComparePerf(lpda,['b','r'],yl=(0,.55),lleg=lfn)
savefig('gif/'+dstr+simstr+'compare_perf.png') # gif/20jul28_20jul27_testK0_gcp__step_2_compare_perf.png
again, smaller step size better at same step ... (already stopped off J series)

lfn = ['20jul15_testG0_gcp_','20jul16_testG1_gcp_', '20jul17_testG2_gcp__step_0_','20jul17_testG2_gcp__step_1_','20jul17_testG2_gcp__step_2_','20jul17_testG2_gcp__step_3_','20jul17_testG2_gcp__step_4_','20jul17_testG2_gcp__step_5_','20jul27_testK0_gcp__step_0_','20jul27_testK0_gcp__step_1_','20jul27_testK0_gcp__step_2_']
pdac = getconcatactionreward(lfn)
ax=plotPerf(pdac,yl=(0,.55))
plot([np.amax(pdac.time)-6000e3,np.amax(pdac.time)-6000e3],[0,.55],'--',color='black') # change in rewards
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20jul29_20jul27_testK0_gcp__step_2_perf_all_steps_so_far.png
hit/miss ratio still decreasing slowly (but more slowly than with J sims), so that's still a problem...

binsz=20
dhist = {pop:getspikehist(dspkT[pop],dnumc,binsz,totalDur) for pop in ['EMDOWN','EMUP','EMSTAY']}

#
clf()
subplot(2,1,1)
tt = np.linspace(0,totalDur,len(dobjpos['ball'][:,1]))
plot(tt,dobjpos['ball'][:,1],'b')
plot(tt,dobjpos['racket'][:,1],'r')
xlim((0,totalDur))
subplot(2,1,2)
tt = dhist['EMDOWN'][0]
plot(tt,dhist['EMDOWN'][1],'r')
plot(tt,dhist['EMUP'][1],'b')
plot(tt,dhist['EMSTAY'][1],'g')
xlim((0,totalDur))

actsel = []
for i in range(len(dhist['EMDOWN'][1])):
  dspk, uspk, sspk = dhist['EMDOWN'][1][i], dhist['EMUP'][1][i], dhist['EMSTAY'][1][i]
  if dspk > uspk and dspk > sspk:
    actsel.append(dconf['moves']['DOWN'])
  elif uspk > dspk and uspk > sspk:
    actsel.append(dconf['moves']['UP'])
  elif sspk > uspk and sspk > dspk:
    actsel.append(dconf['moves']['NOMOVE'])
  else: # dspk == uspk:
    actsel.append(dconf['moves']['NOMOVE'])
    
hist(actsel) # looks right
savefig('gif/'+dstr+simstr+'actsel_hist.png') #

actsel.count(dconf['moves']['NOMOVE']) # 14490

and how many of the NOMOVE commands are from when EMSTAY has higher rate?

actsel = []
for i in range(len(dhist['EMDOWN'][1])):
  dspk, uspk, sspk = dhist['EMDOWN'][1][i], dhist['EMUP'][1][i], dhist['EMSTAY'][1][i]
  if dspk > uspk and dspk > sspk:
    actsel.append(dconf['moves']['DOWN'])
  elif uspk > dspk and uspk > sspk:
    actsel.append(dconf['moves']['UP'])
  elif sspk > uspk and sspk > dspk:
    actsel.append(dconf['moves']['NOMOVE'])

actsel.count(dconf['moves']['NOMOVE']) # 175

so there were a very few times when EMSTAY had higher rates than EMUP,EMDOWN ...

175 / 14490. # 0.012077294685990338
but only 1% of the NOMOVE commands ... that means there are many situations
when EMUP and EMDOWN have the same firing rate, which means EMSTAY may not
be needed to provide extra stability ... 

** check output from low flowwidth (==1, high precision in move direction locations); 20jul28_U0_cycle_

python -i simdat.py backupcfg/20jul28_U0_cycle_sim.json

this sim had all the intermediate rewards ... 

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul30_20jul28_U0_cycle_perf.png
performance moving up  - gets close to highest values ... and that's with flowwidth of 1

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1590e3,1600e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul30_20jul28_U0_cycle_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1590e3,1600e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20jul30_20jul28_U0_cycle_Vm.png

at this earlier stage of training, how often are the stay moves from EMSTAY firing most?

binsz=20
dhist = {pop:getspikehist(dspkT[pop],dnumc,binsz,totalDur) for pop in ['EMDOWN','EMUP','EMSTAY']}

actsel = getactsel(dhist, actreward)
actsel.count(dconf['moves']['NOMOVE']) # 16079

actsel = []
for i in range(len(dhist['EMDOWN'][1])):
  dspk, uspk, sspk = dhist['EMDOWN'][1][i], dhist['EMUP'][1][i], dhist['EMSTAY'][1][i]
  if dspk > uspk and dspk > sspk:
    actsel.append(dconf['moves']['DOWN'])
  elif uspk > dspk and uspk > sspk:
    actsel.append(dconf['moves']['UP'])
  elif sspk > uspk and sspk > dspk:
    actsel.append(dconf['moves']['NOMOVE'])

actsel.count(dconf['moves']['NOMOVE']) # 3464

3464 / 16079. # 0.21543628335095466

so at the earlier stage of training, ~21% of the NOMOVE commands
are from EMSTAY neurons having higher firing rates than EMUP, EMDOWN neurons ...
as EMSTAY rate decreases, expect that ratio to decrease further

tt = np.unique(pdf.time)

dout = getpopinputmap(pdf, tt[0], dnumc, dstartidx, dendidx, 'EMDOWN')
plotallinputmaps(pdf,tt[0],dstartidx['EMDOWN'],'EMDOWN',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMDOWN_inputmap_first.png') # gif/20jul30_20jul28_U0_cycle_EMDOWN_inputmap_first.png
dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMDOWN')
clf(); plotallinputmaps(pdf,tt[-1],dstartidx['EMDOWN'],'EMDOWN',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMDOWN_inputmap_last.png') # gif/20jul30_20jul28_U0_cycle_EMDOWN_inputmap_last.png

dout = getpopinputmap(pdf, tt[0], dnumc, dstartidx, dendidx, 'EMUP')
clf(); plotallinputmaps(pdf,tt[0],dstartidx['EMUP'],'EMUP',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMUP_inputmap_first.png') # gif/20jul30_20jul28_U0_cycle_EMUP_inputmap_first.png
dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMUP')
clf(); plotallinputmaps(pdf,tt[-1],dstartidx['EMUP'],'EMUP',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMUP_inputmap_last.png') # gif/20jul30_20jul28_U0_cycle_EMUP_inputmap_last.png

dout = getpopinputmap(pdf, tt[0], dnumc, dstartidx, dendidx, 'EMSTAY')
clf(); plotallinputmaps(pdf,tt[0],dstartidx['EMSTAY'],'EMSTAY',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMSTAY_inputmap_first.png') # gif/20jul30_20jul28_U0_cycle_EMSTAY_inputmap_first.png
dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMSTAY')
clf(); plotallinputmaps(pdf,tt[-1],dstartidx['EMSTAY'],'EMSTAY',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMSTAY_inputmap_last.png') # gif/20jul30_20jul28_U0_cycle_EMSTAY_inputmap_last.png

ldoutEMDOWN = []
for t in tt:
  print(t)
  dout = getpopinputmap(pdf, t, dnumc, dstartidx, dendidx, 'EMDOWN')
  ldoutEMDOWN.append(dout)

len(ldoutEMDOWN) # 320

from scipy.stats import pearsonr

cmat = np.zeros((320,320))
for Adx,doutA in enumerate(ldoutEMDOWN):
  mA = np.reshape(doutA['EV1DSE'],(400,))
  for Bdx,doutB in enumerate(ldoutEMDOWN):
    mB = np.reshape(doutB['EV1DSE'],(400,))
    cmat[Adx,Bdx] = cmat[Bdx,Adx] = pearsonr(mA,mB)[0]

clf(); imshow(cmat,origin='lower',cmap='jet',interpolation='None',extent=(0,1600,0,1600),vmin=.9,vmax=1); colorbar()
xlabel('Time (s)'); ylabel('Time (s)'); title('EV1DSE inputmap correlation')
savefig('gif/'+dstr+simstr+'EMDOWN_inputmap_EV1DSE_corr.png')
gif/20jul30_20jul28_U0_cycle_EMDOWN_inputmap_EV1DSE_corr.png
so correlations are pretty high, even near beginning, showing map ~stabilized
but magnitude of map can change and individual synapses can still change ...
so there's still room for improvement

figure(); plot(np.linspace(0,1600,320),mean(cmat,axis=1))
xlabel('Time (s)'); ylabel('Average Correlation')
savefig('gif/'+dstr+simstr+'EMDOWN_inputmap_EV1DSE_corr_average.png')
gif/20jul30_20jul28_U0_cycle_EMDOWN_inputmap_EV1DSE_corr_average.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=True,ldflow=ldflow)

** check output on cycle (20jul25_cont_S_nointermr_cycle__step_3_) -->> getting worse, stopped

python -i simdat.py backupcfg/20jul25_cont_S_nointermr_cycle__step_3_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul30_20jul25_cont_S_nointermr_cycle__step_3_perf.png
performance dropping too much...

lfn = ['20jun30_S0_cycle_', '20jun30_S1_cycle_', '20jun30_S2_cycle_', '20jul2_S3_cycle_', '20jul3_S4_cycle__step_0_','20jul3_S4_cycle__step_1_','20jul3_S4_cycle__step_2_','20jul3_S4_cycle__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_0_','20jul14_cont_20jul3_S4_cycle__step_3__step_1_','20jul14_cont_20jul3_S4_cycle__step_3__step_2_','20jul14_cont_20jul3_S4_cycle__step_3__step_3_','20jul14_cont_20jul3_S4_cycle__step_3__step_4_','20jul25_cont_S_nointermr_cycle__step_0_','20jul25_cont_S_nointermr_cycle__step_1_','20jul25_cont_S_nointermr_cycle__step_2_','20jul25_cont_S_nointermr_cycle__step_3_']
pdac = getconcatactionreward(lfn)

ax=plotPerf(pdac,yl=(0,.55))
plot([np.amax(pdac.time)-6400e3,np.amax(pdac.time)-6400e3],[0,.55],'--',color='black') # change in rewards
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png')
gif/20jul30_20jul25_cont_S_nointermr_cycle__step_3_perf_all_steps_so_far.png

will stop this sim ...

** check output from 20jul29_testL0_gcp__step_0_

python -i simdat.py backupcfg/20jul29_testL0_gcp__step_0_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul30_20jul29_testL0_gcp__step_0_perf.png
doing pretty well ... better than other recent ones on gcp ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul30_20jul29_testL0_gcp__step_0_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1990e3,2000e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20jul30_20jul29_testL0_gcp__step_0_Vm.png

lfn = ['20jul25_testJ0_gcp__step_0_', '20jul27_testK0_gcp__step_0_', '20jul29_testL0_gcp__step_0_']
lpda = getindivactionreward(lfn)

plotComparePerf(lpda,['b','g', 'r'],yl=(0,.55),lleg=lfn)
savefig('gif/'+dstr+simstr+'compare_perf.png') # gif/20jul30_20jul29_testL0_gcp__step_0_compare_perf.png
so L series is much better than the others ... should stop K series

lfn = ['20jul15_testG0_gcp_','20jul16_testG1_gcp_', '20jul17_testG2_gcp__step_0_','20jul17_testG2_gcp__step_1_','20jul17_testG2_gcp__step_2_','20jul17_testG2_gcp__step_3_','20jul17_testG2_gcp__step_4_','20jul17_testG2_gcp__step_5_','20jul29_testL0_gcp__step_0_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.55))
plot([np.amax(pdac.time)-2000e3,np.amax(pdac.time)-2000e3],[0,.55],'--',color='black') # change in rewards
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20jul30_20jul29_testL0_gcp__step_0_perf_all_steps_so_far.png
seems to be improving slowly ... ? need more steps to see if performance falls off later similar to the J, K sims ...

savefig('gif/'+dstr+simstr+'perf_all_steps_so_farB.png') # gif/20jul30_20jul29_testL0_gcp__step_0_perf_all_steps_so_farB.png
savefig('gif/'+dstr+simstr+'perf_all_steps_so_farC.png') # gif/20jul30_20jul29_testL0_gcp__step_0_perf_all_steps_so_farC.png

weights changing?

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul30_20jul29_testL0_gcp__step_0_all_avg_weight.png
savefig('gif/'+dstr+simstr+'all_avg_weightB.png') # gif/20jul30_20jul29_testL0_gcp__step_0_all_avg_weightB.png
some increases seen ... so will let it run some more to see if improves 

#binsz=20
#dhist = {pop:getspikehist(dspkT[pop],dnumc,binsz,totalDur) for pop in ['EMDOWN','EMUP','EMSTAY']}

** setup model to use izhi neurons?

http://www.netpyne.org/advanced.html?highlight=izhi#import-izhi07b

netParams.importCellParams(label='PYR_Izhi07b_rule', conds={'cellType': 'PYR', 'cellModel':'Izhi2007b'},
        fileName='izhi2007Wrapper.py', cellName='IzhiCell',  cellArgs={'type':'RS'})

try out on cycle ...

./myrun 32 sn.json

python -i simdat.py backupcfg/20jul30_IzhiTest0_cycle_sim.json

drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'])

works - though have to adjust weight gains

not much faster than the 2-comp mainen and 1-comp basket cells ... since izhi2007b require a section
could try the izhi2007a, which sal mentioned are a little faster since point processes ...
also have different versions of intf cells ... though probably won't work with the RL stdp.mod ... 

** other sim on gcp - start learning from scratch - without EMSTAY, and with flowwidth=1

params based on 20jul29_testL0_gcp__step_1_sim.json but then adjusted
flowwidth to 1, EMSTAY to 0, IM to 50 , RLlenhebb to 200 ... ResumeSim to 0

"name": "20jul30_U0_gcp_"

    "rewardcodes": {
        "scorePoint": 1.0,
        "losePoint": -0.1,
        "followTarget": 0.1,
        "avoidTarget": -0.01,
        "hitBall": 0.5
    },

./myrun 30 sn.json

python -i simdat.py backupcfg/20jul30_U0_gcp_sim.json

ax=plotPerf(actreward,yl=(0,.55))

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1990e3,2000e3))

python multistepSim.py sn.json 30 10 20jul30_MultiTestGCP_U

** continue the flowwidth==1 sim on cycle?
** or test higher resolution impact on perf

        "name": "20jul30_HRTest0_cycle_",

from these numbers:
        "ER": 400,
        "IR": 100,
        "EV1": 400,
        "EV1DE": 400,
        "EV1DNE": 400,
        "EV1DN": 400,
        "EV1DNW": 400,
        "EV1DW": 400,
        "EV1DSW": 400,
        "EV1DS": 400,
        "EV1DSE": 400,
        "IV1": 100,
        "EV4": 0,
        "IV4": 0,
        "EMT": 0,
        "IMT": 0,
        "EMDOWN": 100,
        "EMUP": 100,
        "EMSTAY": 0,
        "IM": 50,

to:

        "ER": 1600,
        "IR": 400,
        "EV1": 1600,
        "EV1DE": 1600,
        "EV1DNE": 1600,
        "EV1DN": 1600,
        "EV1DNW": 1600,
        "EV1DW": 1600,
        "EV1DSW": 1600,
        "EV1DS": 1600,
        "EV1DSE": 1600,
        "IV1": 400,
        "EV4": 0,
        "IV4": 0,
        "EMT": 0,
        "IMT": 0,
        "EMDOWN": 100,
        "EMUP": 100,
        "EMSTAY": 0,
        "IM": 50,
	
./myrun 48 sn.json

python -i simdat.py backupcfg/20jul30_HRTest0_cycle_sim.json

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=True,ldflow=ldflow)

10 s took ~490 s with 48 cores (64 cores same, and 32 cores 520 s) ...

python -i simdat.py backupcfg/20jul30_HRTest0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,.55))

drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); 
drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'])

so around 800 minutes for 1000 s ...

will use longer interval between weight recordings, since more neurons ...
        "recordWeightStepSize": 1000,

./myrun 48 sn.json

* 20jul31
** check 20jul30_U0_gcp__step_0_

python -i simdat.py backupcfg/20jul30_U0_gcp__step_0_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul31_20jul30_U0_gcp__step_0_perf.png
improving steadily...which makes sense, given that the intermediate rewards are turned on and
this is the early stage of learning...also note here that flowwidth==1 and not using EMSTAY

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul31_20jul30_U0_gcp__step_0_rast.png
rates look good so far ...

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=(1990e3,2000e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20jul31_20jul30_U0_gcp__step_0_Vm.png

how does perf compare to the first step in previous sims that had EMSTAY and larger flowwidth?

lfn = ['20jul15_testG0_gcp_', '20jul30_U0_gcp__step_0_']
lpda = getindivactionreward(lfn)

clf(); plotComparePerf(lpda,['b','r'],yl=(0,.55),lleg=lfn)
savefig('gif/'+dstr+simstr+'compare_perf.png') # gif/20jul31_20jul30_U0_gcp__step_0_compare_perf.png
new version looks a lot better ... improving more clearly

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True); xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul31_20jul30_U0_gcp__step_0_all_avg_weight.png
weights going up, and pretty fast...

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=True,ldflow=ldflow)
gif/20jul31_20jul30_U0_gcp__step_0__input.mp4

also worth checking/animating the input maps ... to see how they vary over time, along with
the performance ... and get an indication of when/why performance saturates

** check 20jul29_testL0_gcp__step_1_

python -i simdat.py backupcfg/20jul29_testL0_gcp__step_1_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul31_20jul29_testL0_gcp__step_1_perf.png
doing very well in beginning, then some decrease - may be due to different locations ball sent to...

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul31_20jul29_testL0_gcp__step_1_rast.png
rates are ok

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EMSTAY','IM'],tlim=(1990e3,2000e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20jul31_20jul29_testL0_gcp__step_1_Vm.png

lfn = ['20jul25_testJ0_gcp__step_1_', '20jul27_testK0_gcp__step_1_', '20jul29_testL0_gcp__step_1_']
lpda = getindivactionreward(lfn)

clf(); plotComparePerf(lpda,['b','g','r'],yl=(0,.55),lleg=lfn)
savefig('gif/'+dstr+simstr+'compare_perf.png') # gif/20jul31_20jul29_testL0_gcp__step_1_compare_perf.png
seems a lot better than the others - at the given time

lfn = ['20jul15_testG0_gcp_','20jul16_testG1_gcp_', '20jul17_testG2_gcp__step_0_','20jul17_testG2_gcp__step_1_','20jul17_testG2_gcp__step_2_','20jul17_testG2_gcp__step_3_','20jul17_testG2_gcp__step_4_','20jul17_testG2_gcp__step_5_','20jul29_testL0_gcp__step_0_','20jul29_testL0_gcp__step_1_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.55))
plot([np.amax(pdac.time)-4000e3,np.amax(pdac.time)-4000e3],[0,.55],'--',color='black') # change in rewards
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20jul31_20jul29_testL0_gcp__step_1_perf_all_steps_so_far.png
cumulative not decreasing, but also does not appear to increase
is this just due to small weight incs (RLhebbwt)?
savefig('gif/'+dstr+simstr+'perf_all_steps_so_farB.png') # gif/20jul31_20jul29_testL0_gcp__step_1_perf_all_steps_so_farB.png
savefig('gif/'+dstr+simstr+'perf_all_steps_so_farC.png') # gif/20jul31_20jul29_testL0_gcp__step_1_perf_all_steps_so_farC.png

weights changing?

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20jul31_20jul29_testL0_gcp__step_1_all_avg_weight.png
savefig('gif/'+dstr+simstr+'all_avg_weightB.png') # gif/20jul31_20jul29_testL0_gcp__step_1_all_avg_weightB.png
many weights trending up slowly - so worth seeing if it improves ...
even if EMSTAY does not contribute to motor commands, it does influence IM and feedback inhib onto EMDOWN
and EMUP, so could influence commands indirectly; but might not be worth the extra computational cost

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4')
gif/20jul31_20jul29_testL0_gcp__step_1__input.mp4

** other sim on gcp?

to test recurrent conn between EMUP,EMDOWN impact on perf

** try INTF4?

https://www.neuron.yale.edu/neuron/static/py_doc/modelspec/programmatic/mechanisms/mech.html?highlight=intf#IntFire4

h.IntFire4

c = h.IntFire4()
c.taue --- ms excitatory input time constant
c.taui1 --- ms inhibitory input rise time constant
c.taui2 --- ms inhibitory input fall time constant
c.taum --- membrane time constant
c.m --- membrane state variable
c.M --- analytic value of membrane state at current time, t
c.e --- excitatory current state variable
c.E --- analytic value of excitation current
c.i1 c.i2 -- inhibitory current state variables
c.I --- analytic value of inhibitory current.

it's an event-based neuron ... that's what INTF6 was based on ...

http://www.netpyne.org/netpyne.cell.pointCell.html?highlight=intf

for izhi2007a have these additional changes to let cell model use its own V:
cellRule['secs']['soma']['pointps']['Izhi2007a_0']['vref'] = 'V' # specify that uses its own voltage V
cellRule['secs']['soma']['pointps']['Izhi2007a_0']['synList'] = ['AMPA', 'NMDA', 'GABAA', 'GABAB']  # specify its own synapses

** continue HR sim

cp backupcfg/20jul30_HRTest0_cycle_sim.json sn.json

and adjust ... 

        "name": "20jul31_HRTest1_cycle_",
    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20jul30_HRTest0_cycle_synWeights_final.pkl"
    },

still have to check output from previous one ...

./myrun 48 sn.json

** check output from first 20jul30_HRTest0_cycle_

python -i simdat.py backupcfg/20jul30_HRTest0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20jul31_20jul30_HRTest0_cycle_perf.png
looks pretty good...comparable to other recent simulations

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((990e3,1000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20jul31_20jul30_HRTest0_cycle_rast.png
good (low) firing rates

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=(990e3,1000e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20jul31_20jul30_HRTest0_cycle_Vm.png
looks ok

tt = np.unique(pdf.time)

dout = getpopinputmap(pdf, tt[0], dnumc, dstartidx, dendidx, 'EMDOWN')
plotallinputmaps(pdf,tt[0],dstartidx['EMDOWN'],'EMDOWN',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMDOWN_inputmap_first.png') # gif/20jul31_20jul30_HRTest0_cycle_EMDOWN_inputmap_first.png
dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMDOWN')
clf(); plotallinputmaps(pdf,tt[-1],dstartidx['EMDOWN'],'EMDOWN',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMDOWN_inputmap_last.png') # gif/20jul31_20jul30_HRTest0_cycle_EMDOWN_inputmap_last.png

dout = getpopinputmap(pdf, tt[0], dnumc, dstartidx, dendidx, 'EMUP')
clf(); plotallinputmaps(pdf,tt[0],dstartidx['EMUP'],'EMUP',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMUP_inputmap_first.png') # gif/20jul31_20jul30_HRTest0_cycle_EMUP_inputmap_first.png
dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMUP')
clf(); plotallinputmaps(pdf,tt[-1],dstartidx['EMUP'],'EMUP',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMUP_inputmap_last.png') # gif/20jul31_20jul30_HRTest0_cycle_EMUP_inputmap_last.png

ldoutEMDOWN = []
for t in tt:
  print(t)
  dout = getpopinputmap(pdf, t, dnumc, dstartidx, dendidx, 'EMDOWN')
  ldoutEMDOWN.append(dout)

len(ldoutEMDOWN) # 50

from scipy.stats import pearsonr

cmat = np.zeros((len(ldoutEMDOWN),len(ldoutEMDOWN)))
for Adx,doutA in enumerate(ldoutEMDOWN):
  mA = np.reshape(doutA['EV1DSE'],(dconf['net']['EV1DSE'],))
  for Bdx,doutB in enumerate(ldoutEMDOWN):
    mB = np.reshape(doutB['EV1DSE'],(dconf['net']['EV1DSE'],))
    cmat[Adx,Bdx] = cmat[Bdx,Adx] = pearsonr(mA,mB)[0]

clf(); imshow(cmat,origin='lower',cmap='jet',interpolation='None',extent=(0,1000,0,1000),vmin=0,vmax=1); colorbar()
xlabel('Time (s)'); ylabel('Time (s)'); title('EV1DSE inputmap correlation')
savefig('gif/'+dstr+simstr+'EMDOWN_inputmap_EV1DSE_corr.png') # gif/20jul31_20jul30_HRTest0_cycle_EMDOWN_inputmap_EV1DSE_corr.png

figure(); plot(np.linspace(0,1000,50),mean(cmat,axis=1))
xlabel('Time (s)'); ylabel('Average Correlation')
savefig('gif/'+dstr+simstr+'EMDOWN_inputmap_EV1DSE_corr_average.png')
gif/20jul31_20jul30_HRTest0_cycle_EMDOWN_inputmap_EV1DSE_corr_average.png

InputImages.shape # (50000, 20, 40)
hmm, input images are getting saved incorrectly ... !

    self.courtYRng = (34, 194) # court y range
    self.courtXRng = (20, 140) # court x range

hmm if court x and y range not same, input images will not be square after downsampling by same amount
in each direction ... problem? seems like there would be more loss of information in one dimension than
another after downsampling ... and/or distortion when projecting onto square ... better to allow neurons
to have rectangular grid ...

samndp7730% python
Python 3.6.10 |Anaconda, Inc.| (default, Jan  7 2020, 21:14:29) 
[GCC 7.3.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> from skimage.transform import downscale_local_mean, resize
>>> downsampshape = (8,8)
>>> courtYRng = (34, 194)
>>> courtXRng = (20, 140)
>>> lobs_gimage = np.zeros((courtYRng[1]-courtYRng[0]+1,courtXRng[1]-courtXRng[0]+1))
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'np' is not defined
>>> import numpy as np
>>> lobs_gimage = np.zeros((courtYRng[1]-courtYRng[0]+1,courtXRng[1]-courtXRng[0]+1))
>>> lobs_gimage.shape
(161, 121)
>>> lobs_gimage = np.zeros((courtYRng[1]-courtYRng[0],courtXRng[1]-courtXRng[0]))
>>> lobs_gimage.shape
(160, 120)
>>> lobs_gimage_ds = downscale_local_mean(lobs_gimage,downsampshape)
>>> lobs_gimage_ds.shape
(20, 15) <<-- that's wrong size if used for motion computation and projection to a square ... 
>>> 

** is motion in all directions represented with equal firing rates?

could this be a problem - for representation of direction info?
        "AngRFSigma": 22.5,

some directions will have lower firing rates ... anything off one of the 8 major directions
will have fall-off in rate ... that seems problematic ...
instead, should give each direction sensitive neuron a location (x,y), direction, and sigma ...
was planning to do that before ...

* 20aug1
** have to check those issues mentioned above (about images, representations, etc.)
** continue HR

        "name": "20aug1_HRTest2_cycle_",
	        "ResumeSimFromFile": "data/20jul31_HRTest1_cycle_synWeights_final.pkl"

** check output from 20jul31_HRTest1_cycle_

python -i simdat.py backupcfg/20jul31_HRTest1_cycle_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug1_20jul31_HRTest1_cycle_perf.png
doing pretty well...

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((990e3,1000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20aug1_20jul31_HRTest1_cycle_rast.png
rates still good (low)

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=(990e3,1000e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20aug1_20jul31_HRTest1_cycle_Vm.png

lfn = ['20jul30_HRTest0_cycle_', '20jul31_HRTest1_cycle_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20aug1_20jul31_HRTest1_cycle_perf_all_steps_so_far.png
still improving ... (continued run above too -- in 20aug1_HRTest2_cycle_)

InputImages.shape # (50000, 20, 40)
(note to fix that)

** check image representations

so have this code in aigame.py:

courtYRng = (34, 194)
courtXRng = (20, 140)

      gray_Image = 255.0*rgb2gray(observation[courtYRng[0]:courtYRng[1],:,:]) # convert to grayscale; rgb2gray has 0-1 range so mul by 255

that uses courtYRng which is 160 pixels and full x range, which is also 160 pixels ... (the atari games had 160x160 pixel display)

so based on that most of the operations below, including downscaling seem ok ... should produce a square ... 

      gray_ds = downscale_local_mean(gray_Image,self.downsampshape) # then downsample
      gray_ds = np.where(gray_ds>np.min(gray_ds)+1,255,gray_ds) # Different thresholding
      gray_ns = np.where(gray_Image>np.min(gray_Image)+1,255,gray_Image)
      lgimage_ns.append(lgwght[adx]*gray_ns)
      lgimage.append(lgwght[adx]*gray_ds) # save weighted grayscale image from current frame

but then why are input images for HRTest (above) not correct size?

downsampshape = (8,8)
courtYRng = (34, 194)
courtXRng = (20, 140)
lobs_gimage = np.zeros((courtYRng[1]-courtYRng[0],160))
lobs_gimage.shape # (160, 160)
from skimage.transform import downscale_local_mean, resize
lobs_gimage_ds = downscale_local_mean(lobs_gimage,downsampshape)
lobs_gimage_ds.shape # (20, 20)

downsampshape = (4,4)
lobs_gimage_ds = downscale_local_mean(lobs_gimage,downsampshape)
lobs_gimage_ds.shape # (40, 40)

try the HR Test for a few timesteps to see why InputImages saved with incorrect size ...

./myrun 16 sn.json

sim.AIGame.ReducedImages[0].shape # (40, 40)
so that's correct shape ...
len(sim.AIGame.ReducedImages) # 5, ran for 100 ms, image every 20 ms

head data/20jul31_HRTest1_cycle_InputImages.txt
# Array shape: (50000, 40, 40)

hmm, so must have fixed the problem already ... ?? no, the problem was not in the save

head data/20jul30_HRTest0_cycle_InputImages.txt
# Array shape: (50000, 40, 40)

so must be in the read in simdat.py ...

yeah, loadInputImages assumes 20x20:
    New_InputImages.append(Input_Images[fp:fp+20,:])

ok, fix that up ...

IM = np.loadtxt('data/20jul30_HRTest0_cycle_InputImages.txt')
IM.shape # (2000000, 40)
hmm, text file not great way to save the images ...
NB_Images = int(IM.shape[0]/IM.shape[1]) # 50000

IM = loadInputImages(name='20aug1_Debug_cycle_')
IM.shape # (5, 40, 40)

ok, fixed ... 

** can NE get confused with SE (with current RFs, sigmas) ?
* 20aug2
** check 20aug1_HRTest2_cycle_

python -i simdat.py backupcfg/20aug1_HRTest2_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1.))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug2_20aug1_HRTest2_cycle_perf.png
at times good, at times not ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((990e3,1000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20aug2_20aug1_HRTest2_cycle_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=(990e3,1000e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20aug2_20aug1_HRTest2_cycle_Vm.png

lfn = ['20jul30_HRTest0_cycle_', '20jul31_HRTest1_cycle_','20aug1_HRTest2_cycle_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20aug2_20aug1_HRTest2_cycle_perf_all_steps_so_far.png
some improvements, difficult to tell if consistent and/or still increasing...

InputImages.shape # (50000, 40, 40)

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4') # gif/20aug2_20aug1_HRTest2_cycle__input.mp4

continue this run ...

        "name": "20aug2_HRTest3_cycle_",
    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20aug1_HRTest2_cycle_synWeights_final.pkl"
    },

python multistepSim.py sn.json 48 10 20aug2_HRTest3_cycle_MultiTest

started @ ~21:35 ...

** check ang rep

fctr = np.exp(-1.0*(getangdiff(motiondir[y][x],dAngPeak[pop])**2)/AngRFSigma2)

have been using AngRFSigma of 22.5, so AngRFSigma2 == 22.5**2

# get smallest angle difference
def getangdiff (ang1, ang2):
  if ang1 > 180.0:
    ang1 -= 360.0
  if ang2 > 180.0:
    ang2 -= 360.0
  angdiff = ang1 - ang2
  if angdiff > 180.0:
    angdiff-=360.0
  elif angdiff < -180.0:
    angdiff+=360.0
  return angdiff

assume motiondir angle == 0 (east)

python

import numpy as np

AngRFSigma = 22.5
AngRFSigma2 = AngRFSigma**2

motiondir = 0.0
ang2 = 45

getangdiff(motiondir,ang2)**2/AngRFSigma2 # 4.0
np.exp(-1.0*getangdiff(motiondir,ang2)**2/AngRFSigma2) # 0.01831563888873418

so at 45 degree difference, that's a pretty big fall-off

ang2 = 22.5
getangdiff(motiondir,ang2)**2/AngRFSigma2 # 1.0
np.exp(-1.0*getangdiff(motiondir,ang2)**2/AngRFSigma2) # 0.36787944117144233

but at 22.5 degree diff, it's ~0.37 ...

lang = np.linspace(-180,180,361)
lfctr = [np.exp(-1.0*getangdiff(motiondir,ang2)**2/AngRFSigma2) for ang2 in lang]

from pylab import *

plot(lang, lfctr, 'ko')
xlabel('Ang Diff'); ylabel('Factor')
savefig('gif/20aug2_angrf_a0.png')

having only 8 primary directions means certain movement directions will always
have less representation in terms of number of spikes they produce ... so, that
means certain information is not propagating as effectively throughout the network,
and that the model is less likely to make an optimal decision ... 

so, then worth having all 360 deg of representation with ~equal weighting ...
but that means a lot more neurons ...

some inhib between these dir selective neurons could help promote correct answer ...

what if neurons at each coordinate had a more complex RF, that responded
in all directions, but not all directions equally (some bias in particular
directions?) - is that better than a dominant direction with fall-off in
other directions? 

AngRFSigma2 = 45.0**2
lfctr = [np.exp(-1.0*getangdiff(motiondir,ang2)**2/AngRFSigma2) for ang2 in lang]
plot(lang, lfctr, 'bo')

lang[225] # 45.0
lfctr[225] # 0.36787944117144233

savefig('gif/20aug2_angrf_a1.png')
that wider rep is too wide, since >90 deg apart (which has component of opposite
directions, still has positive value ~1.7%):
lang[271],lfctr[271] # (91.0, 0.016749569608612666)

AngRFSigma2 = 22.5**2
lfctr = [np.exp(-1.0*getangdiff(motiondir,ang2)**2/AngRFSigma2) for ang2 in lang]
whereas with sigma used now, many orders of magnitude smaller:
lang[271],lfctr[271] # (91.0, 7.870722635526579e-08)

but still, could be usefull to have the full set of directions
with equal rep ...

** how many neurons for 1/2 rep (80x80) ?

6400 for ER, EV1, and each of the dir selective neurons

        "name": "20aug2_HalfTest0_cycle_",

./myrun 48 sn.json

  Simulated time: 1.0 s; 48 workers
  Run time: 347.35 s

python -i simdat.py backupcfg/20aug2_HalfTest0_cycle_sim.json

sum(list(dnumc.values())) # 67450

ax=plotPerf(actreward,yl=(0,1.))

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'])

100 s would take ~10 hours on 48 cores ... of course, already using 48 cores on cycle ...

worth a try ...

had these as number of neurons:
        "ER": 6400,
        "IR": 1600,
        "EV1": 6400,
        "EV1DE": 6400,
        "EV1DNE": 6400,
        "EV1DN": 6400,
        "EV1DNW": 6400,
        "EV1DW": 6400,
        "EV1DSW": 6400,
        "EV1DS": 6400,
        "EV1DSE": 6400,
        "IV1": 1600,
        "EV4": 0,
        "IV4": 0,
        "EMT": 0,
        "IMT": 0,
        "EMDOWN": 100,
        "EMUP": 100,
        "EMSTAY": 0,
        "IM": 50,

        "EEMWghtAM": 1.25e-05,
        "EEMWghtNM": 1.25e-06,

            "RLhebbwt": 6.25e-07,

        "recordWeightStepSize": 4500,
	
and other params same as HR test above ...

./myrun 48 sn.json

started ~23:16 ... hmm, that was accidentally only 1 s sim ... 

* 20aug3
** discuss representations with ha

09:55
samn:meal: was looking at direction selective representations - to see if influencing outcomes
09:55
right now - certain directions have lower rates than / information than others
09:56
not sure if it's the main or even contributing problem - but think arbitrary direction RFs would be better
09:56
Haroon Anwar diagonals have higher rates
09:56
samn:meal: right, if in one of the 8 primary directions
09:57
if off a direction falls off
09:57
Haroon Anwar by arbitrary direction RFs what do you mean?
09:57
samn:meal: any of 360 directions with some sigma
09:58
Haroon Anwar you mean we could have a sigmoid where each angle could evoke different firing rates
09:58
?
09:58
samn:meal: i mean a dominant direction, and fall-off around it
09:58
Haroon Anwar and how many dominant directions?
09:58
samn:meal: for each neuron. and the dominant direction can be in any direction
09:59
Haroon Anwar and you want it to be random? without topology?
09:59
samn:meal: there can still be topology
10:00
Haroon Anwar i dont understand…. i think what you are suggesting would make more sense without toplogy
10:00
so position is already encoded by V1
10:00
and direction selective neurons just encode angle
10:01
samn:meal: each neuron would only be sensitive to motion at a particular location
10:01
and a direction with some fall-off
10:01
Haroon Anwar then we will need to have atleast 8 neurons for each location no? or how many you think would be enough
10:02
samn:meal: yeah, maybe so..that's a problem
10:02
Haroon Anwar its similar to what we have now…. i think if we dont worry about location
10:03
and just encode direction that should be fine too
10:03
why do same thing twice?
10:03
samn:meal: but one object can move up and another down
10:03
in different locations
10:03
shouldn't the neurons encode that information more accurately?
10:04
Haroon Anwar well then some neurons will encode one direction, others will encode another direction
10:04
and location will be in V1
10:04
and everything will be integrated in later stage
10:04
samn:meal: i agree it's possible to separate them - but will it help to reduce the info that dir selective neurons have?
10:05
Haroon Anwar not sure
10:05
so whats the problem with the other idea
10:06
— use a sigmoid to represent 0-360 for each location
10:06
samn:meal: sigmoid represents 0-360 at each location?
10:06
Haroon Anwar we will need to make sure that we have 8 firing rates per neuron
10:06
samn:meal: not sure what you mean
10:07
rate of the neuron represents the direction?
10:07
Haroon Anwar yes
10:07
samn:meal: that seems more difficult to decode downstream
10:07
Haroon Anwar yes you are right
10:08
i feel we have too many neurons encoding direction
10:09
also not sure what R is doing? other than converging input space
10:10
could drive V1 directly using poisson processes
10:10
as we are doing for direction selective neurons
10:10
samn:meal: i agree about both
10:10
Haroon Anwar its just relaying infor
10:11
i think goal is to speedup things while retaining max info
10:11
samn:meal: i thought R was used just to allow use of variable rate based on location
10:11
ER
10:11
but no point having two pops that have same info
10:12
Haroon Anwar i think they have same info
10:12
can double check
10:15
samn:meal: ok sg
10:15
for dir selective - still unclear what's best
10:16
Haroon Anwar yes
10:16
ok if same info, i will use an option for R and IR neurons
10:17
atleast it will reduce 500 neurons
10:17
samn:meal: yeah, seems worthwhile

** discuss corner cases with ha

main problem in losing points is the corners - for some reason model doesn't perform well when ball goes to top or bottom corner
10:23
any insight into why?
10:24
also, before you make changes to ER/IR, i'll merge dev code into main so we can work from same code
10:24
Haroon Anwar ok
10:24
you mean top/bottom corners?
10:24
samn:meal: yeah, top right, bottom right
10:25
Haroon Anwar probably should look at firing rates for those instances and compare it to rest
10:25
samn:meal: yeah, some of that analysis code sounded useful for it
10:25
Haroon Anwar may be it has something to do with less input drive
10:26
samn:meal: is it pushed/useful/etc.?
10:26
Haroon Anwar not pushed… i have it in script form. let me add as a function in simdat.py
10:27
samn:meal: ok, and can check some of those cases ... should push more regularly, otherwise code will diverge more and more
10:27
Haroon Anwar k
10:28
i will check those cases

** check perf from 20jul29_testL0_gcp__step_4_

python -i simdat.py backupcfg/20jul29_testL0_gcp__step_4_sim.json

lfn = ['20jul15_testG0_gcp_','20jul16_testG1_gcp_', '20jul17_testG2_gcp__step_0_','20jul17_testG2_gcp__step_1_','20jul17_testG2_gcp__step_2_','20jul17_testG2_gcp__step_3_','20jul17_testG2_gcp__step_4_','20jul17_testG2_gcp__step_5_','20jul29_testL0_gcp__step_0_','20jul29_testL0_gcp__step_1_','20jul29_testL0_gcp__step_2_','20jul29_testL0_gcp__step_3_','20jul29_testL0_gcp__step_4_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.55))
plot([np.amax(pdac.time)-10000e3,np.amax(pdac.time)-10000e3],[0,.55],'--',color='black') # change in rewards
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20aug3_20jul29_testL0_gcp__step_4_perf_all_steps_so_far.png

performance falling off ...

lpda = getindivactionreward(lfn)
ax=plotPerf(lpda[-1],yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug3_20jul29_testL0_gcp__step_4_perf.png
perf lower than before ...

probably no point continuing this run ... until figure out what's leading to perf decay...

what if model only received rewards, instead of rewards + punishments? would the weights stay close to
starting values and then learn further?

** check perf of 20jul30_U0_gcp__step_4_ and 20jul30_U0_gcp__step_5_

python -i simdat.py backupcfg/20jul30_U0_gcp__step_4_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug3_20jul30_U0_gcp__step_4_perf.png

lfn = ['20jul30_U0_gcp__step_0_','20jul30_U0_gcp__step_1_','20jul30_U0_gcp__step_2_','20jul30_U0_gcp__step_3_','20jul30_U0_gcp__step_4_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.55))

savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20aug3_20jul30_U0_gcp__step_4_perf_all_steps_so_far.png

seems to have reached a plateau ... and probably will not pass it ... 
will let next step (almost done) finish, to check...

python -i simdat.py backupcfg/20jul30_U0_gcp__step_5_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug3_20jul30_U0_gcp__step_5_perf.png

lfn = ['20jul30_U0_gcp__step_0_','20jul30_U0_gcp__step_1_','20jul30_U0_gcp__step_2_','20jul30_U0_gcp__step_3_','20jul30_U0_gcp__step_4_','20jul30_U0_gcp__step_5_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.55))

savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20aug3_20jul30_U0_gcp__step_5_perf_all_steps_so_far.png

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20aug3_20jul30_U0_gcp__step_5_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=(1990e3,2000e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20aug3_20jul30_U0_gcp__step_5_Vm.png

** simple change to AngRF

allow all directions within AngRFSigma of one of the 8 primary directions to have MaxRate

option specified with EXPDir (default is 1, not needed to be in the json file)

cp backupcfg/20jul30_U0_gcp_sim.json sn.json

then adjust ...

        "name": "20aug3_U0_noEXPDir_gcp_",
	"EXPDir": 0,

./myrun 30 sn.json

python -i simdat.py backupcfg/20aug3_U0_noEXPDir_gcp_sim.json

ax=plotPerf(actreward,yl=(0,.55))
clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values()))))

lpop = ['ER', 'EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'IR', 'EV1DW','EV1DE','IV1','EMUP','EV1DSW', 'EV1DS', 'EV1DSE','IM','EMDOWN', ]  
dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
fig, axs, plt = animActivityMaps(lpop=lpop)

looked ok in short run ... try 2000 s run to compare against 20jul30_U0_gcp_

./myrun 30 sn.json

** check 20aug2_HRTest3_cycle__step_0_

python -i simdat.py backupcfg/20aug2_HRTest3_cycle__step_0_sim.json

ax=plotPerf(actreward,yl=(0,1.))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug3_20aug2_HRTest3_cycle__step_0_perf.png

no clear improvement overall, highly variable ... so that probably just reflects where the ball
is getting hit to by opponent ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((990e3,1000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20aug3_20aug2_HRTest3_cycle__step_0_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=(990e3,1000e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20aug3_20aug2_HRTest3_cycle__step_0_Vm.png

lfn = ['20jul30_HRTest0_cycle_', '20jul31_HRTest1_cycle_','20aug1_HRTest2_cycle_','20aug2_HRTest3_cycle__step_0_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20aug3_20aug2_HRTest3_cycle__step_0_perf_all_steps_so_far.png

InputImages.shape # (50000, 40, 40)

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4') # gif/20aug3_20aug2_HRTest3_cycle__step_0__input.mp4

** rerun halftest (100 s; "name": "20aug3_HalfTest0_cycle_")

./myrun 48 sn.json

* 20aug4
** check 20aug3_U0_noEXPDir_gcp_

python -i simdat.py backupcfg/20aug3_U0_noEXPDir_gcp_sim.json

ax=plotPerf(actreward,yl=(0,1.))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug4_20aug3_U0_noEXPDir_gcp_perf.png
looks about as good as the others ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20aug4_20aug3_U0_noEXPDir_gcp_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=(1990e3,2000e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20aug4_20aug3_U0_noEXPDir_gcp_Vm.png

and how does performance compare to the sim with exp fall-off for angrf?

lfn = ['20jul30_U0_gcp__step_0_', '20aug3_U0_noEXPDir_gcp_']
lpda = getindivactionreward(lfn)
clf(); plotComparePerf(lpda,['b','r'],yl=(0,.55),lleg=lfn)
savefig('gif/'+dstr+simstr+'compare_perf.png') # gif/20aug4_20aug3_U0_noEXPDir_gcp_compare_perf.png

hmm, identical - had a mistake in aigame.py was not reading the value ... will have to rerun ...

        "name": "20aug4_U0_noEXPDir_gcp_",

./myrun 30 sn.json

stopped firing, so will stop this one ... 

** check output from 20jul30_U0_gcp__step_6_

python -i simdat.py backupcfg/20jul30_U0_gcp__step_6_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug4_20jul30_U0_gcp__step_6_perf.png
similar to before - nonuniform, but mostly flat

lfn = ['20jul30_U0_gcp__step_0_','20jul30_U0_gcp__step_1_','20jul30_U0_gcp__step_2_','20jul30_U0_gcp__step_3_','20jul30_U0_gcp__step_4_','20jul30_U0_gcp__step_5_','20jul30_U0_gcp__step_6_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.55))

savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20aug4_20jul30_U0_gcp__step_6_perf_all_steps_so_far.png

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20aug4_20jul30_U0_gcp__step_6_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=(1990e3,2000e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20aug4_20jul30_U0_gcp__step_6_Vm.png

will probably stop this one since planning some adjustments to network with HA that should improve perf...

** check 20aug3_HalfTest0_cycle_

python -i simdat.py backupcfg/20aug3_HalfTest0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1.))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug4_20aug3_HalfTest0_cycle_perf.png

hmm, neurons did not fire??

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((90e3,100e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20aug4_20aug3_HalfTest0_cycle_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=((90e3,100e3))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20aug4_20aug3_HalfTest0_cycle_Vm.png

so the weights were too low . . .

** stopped HRTest multistep -- well restart after other changes to net
** Haroon added option to leave out ER,IR

to use it, set ER==0 in the json file

this should add precision to the spatial location of inputs

trying it out ... adjusting specification so easier to read code; lot
of the population info can go into the json file, including ETypes, ITypes,
and their counts; so then will check if dnumc[type] > 0 instead of if 'ER' in dconf['net'], etc.

for example, here's part of what's in the net section of json file:

    "net": {
        "scale": 1,
	"allpops": {
	    "ER":400,
	    "IR":100,
	    "EV1":400,
	    "EV1DE":400,
	    "EV1DNE":400,
	    "EV1DN":400,
	    "EV1DNW":400,
	    "EV1DW":400,
	    "EV1DSW":400,
	    "EV1DS":400,
	    "EV1DSE":400,
	    "IV1":100,
	    "EV4":0,
	    "IV4":0,
	    "EMT":0,
	    "IMT":0,
	    "EMDOWN":100,
	    "EMUP":100,
	    "EMSTAY":100,
	    "IM":50},	
	"ETypes": ["ER","EV1","EV1DE","EV1DNE","EV1DN","EV1DNW","EV1DW","EV1DSW","EV1DS","EV1DSE","EV4","EMT","EMDOWN","EMUP","EMSTAY"],
	"ITypes": ["IR","IV1","IV4","IMT","IM"],
	"EMotorPops": ["EMDOWN", "EMUP", "EMSTAY"],
	"EPreMPops": ["EV1","EV1DE","EV1DNE","EV1DN","EV1DNW","EV1DW","EV1DSW","EV1DS","EV1DSE","EV4","EMT"],

is there a problem in updateInputRates? that sim.rank==0 is only updating the rate of
the ER/EV1 population and not for the direction selective neurons?
since sim.AIGame.lratepop only consists of ER,EV1? or does it contain dir selective pops too??
ah, it does contain the dir selective neurons too... so that's not a problem ...

./myrun 30 sn.json

python -i simdat.py backupcfg/20aug4_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1.))
savefig('gif/'+dstr+simstr+'_100s_perf.png') # gif/20aug4_20aug4_A0_cycle__100s_perf.png
gets to ~0.4 follow prob quickly...

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((90e3,100e3))
savefig('gif/'+dstr+simstr+'_100s_rast.png') # gif/20aug4_20aug4_A0_cycle__100s_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=((90e3,100e3))
savefig('gif/'+dstr+simstr+'_100s_Vm.png') # gif/20aug4_20aug4_A0_cycle__100s_Vm.png

ok, run longer ... 2000 s ... 

./myrun 30 sn.json

started ~16:20 ...

** also compare with cross prob (between EMDOWN,EMUP);         "name": "20aug4_B0_cycle_",

        "EEMRecProbCross": 1,

everything else same as 20aug4_A0_cycle_

./myrun 30 sn.json

started ~16:25 ...

* 20aug5
** fixup INTF for use in net -->> did not work yet
** try friesen cell

        "name": "20aug5_F0_gcp_",

python -i simdat.py backupcfg/20aug5_F0_gcp_sim.json

ax=plotPerf(actreward,yl=(0,1.))

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'])

got somewhat decent rates after adjusting gains ... and adding friesen FS cell
to cells/friesen.py ... note that these cells have explicit refrac period ...

not sure if they'll be faster than mainen cells, but interesting to compare
across the cell types to see if results ~consistent ...

try it out ...

./myrun 30 sn.json

started ~22:50 ...

** another friesen sim with cross EM connect (to compare to sims run on cycle recently)

        "name": "20aug5_F0_cross_gcp_",
	"EEMRecProbCross": 1,

./myrun 30 sn.json

* 20aug6
** check output from 20aug4_A0_cycle_

python -i simdat.py backupcfg/20aug4_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug6_20aug4_A0_cycle_perf.png
performance going up - for hits too ... but follow flattens quickly

lfn = ['20aug4_A0_cycle_','20aug4_B0_cycle_']
lpda = getindivactionreward(lfn)
clf(); plotComparePerf(lpda,['b','r'],yl=(0,.55),lleg=lfn)
savefig('gif/'+dstr+simstr+'compare_perf.png') # gif/20aug6_20aug4_A0_cycle_compare_perf.png
comparable performance

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20aug6_20aug4_A0_cycle_rast.png
rates ok, ... 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=((1990e3,2000e3)))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20aug6_20aug4_A0_cycle_Vm.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4') # gif/20aug6_20aug4_A0_cycle__input.mp4

continue as A1 ...

        "name": "20aug6_A1_cycle_",

    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20aug4_A0_cycle_synWeights_final.pkl"
    },

./myrun 30 sn.json

started ~10:29 ... 

** check output from 20aug4_B0_cycle_

python -i simdat.py backupcfg/20aug4_B0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug6_20aug4_B0_cycle_perf.png

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20aug6_20aug4_B0_cycle_rast.png
rates ok, ... slightly faster than for 20aug4_A0_cycle_ since there's recurrent connectivity
between the two motor populations here ... 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=((1990e3,2000e3)))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20aug6_20aug4_B0_cycle_Vm.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4') # gif/20aug6_20aug4_B0_cycle__input.mp4

continue as B1 ...

        "name": "20aug6_B1_cycle_",
    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20aug4_B0_cycle_synWeights_final.pkl"	
    },

./myrun 30 sn.json

started ~10:41 ...

meanwhile, try analyzeRepeatedInputSequences


lpop = ['EMUP','EMDOWN']  
dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
analyzeRepeatedInputSequences(dact,InputImages, targetPixel=(10,10),nbseq=14,targetCorr=0.9)

have to debug ... getting index out of bounds ...

targetPixel = (10,10)
midInds = np.where(InputImages[:,targetPixel[0],targetPixel[1]]>250)

** friesen sims on gcp - not much firing

the starting weights would need to be adjusted to produce anything meaningful
stopped the sims

** other sims on gcp
***  20aug6_A0_gcp_

same as 20aug4_A0_cycle_ but without targetted RL

./myrun 32 sn.json

*** 20aug6_B0_gcp_

same as 20aug4_B0_cycle_ but without targetted RL

./myrun 32 sn.json

started ~11:44 ... 

** better performance metrics

could look at performance over time, given similar inputs

* 20aug7
** check output
*** 20aug6_A1_cycle_

python -i simdat.py backupcfg/20aug6_A1_cycle_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug7_20aug6_A1_cycle_perf.png

lfn = ['20aug6_A1_cycle_','20aug6_B1_cycle_']
lpda = getindivactionreward(lfn)
clf(); plotComparePerf(lpda,['b','r'],yl=(0,.55),lleg=lfn)
savefig('gif/'+dstr+simstr+'compare_perf.png') # gif/20aug7_20aug6_A1_cycle_compare_perf.png
comparable performance, overall 20aug6_B1_cycle_ is a little better in terms of score/follow

lfn = ['20aug4_A0_cycle_','20aug6_A1_cycle_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20aug7_20aug6_A1_cycle_perf_all_steps_so_far.png

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20aug7_20aug6_A1_cycle_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=((1990e3,2000e3)))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20aug7_20aug6_A1_cycle_Vm.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4') # gif/20aug7_20aug6_A1_cycle__input.mp4

*** 20aug6_B1_cycle_

python -i simdat.py backupcfg/20aug6_B1_cycle_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug7_20aug6_B1_cycle_perf.png

lfn = ['20aug4_B0_cycle_','20aug6_B1_cycle_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20aug7_20aug6_B1_cycle_perf_all_steps_so_far.png
seems to be improving...

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20aug7_20aug6_B1_cycle_rast.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=((1990e3,2000e3)))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20aug7_20aug6_B1_cycle_Vm.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4') # gif/20aug7_20aug6_B1_cycle__input.mp4

lpop = ['EMUP','EMDOWN']  
dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)
analyzeRepeatedInputSequences(dact,InputImages, targetPixel=(10,10),nbseq=14,targetCorr=0.9)

analyzeRepeatedInputForSingleEvent(dact, InputImages, targetPixel=(10,10))
figure(); analyzeRepeatedInputForSingleEvent(dact, InputImages, targetPixel=(19,17))

savefig('gif/'+dstr+simstr+'seq0.png') # gif/20aug7_20aug6_B1_cycle_seq0.png

tt = np.unique(pdf.time)

dout = getpopinputmap(pdf, tt[0], dnumc, dstartidx, dendidx, 'EMDOWN')
plotallinputmaps(pdf,tt[0],dstartidx['EMDOWN'],'EMDOWN',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMDOWN_inputmap_first.png') # gif/20aug7_20aug6_B1_cycle_EMDOWN_inputmap_first.png
dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMDOWN')
clf(); plotallinputmaps(pdf,tt[-1],dstartidx['EMDOWN'],'EMDOWN',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMDOWN_inputmap_last.png') # gif/20aug7_20aug6_B1_cycle_EMDOWN_inputmap_last.png

dout = getpopinputmap(pdf, tt[0], dnumc, dstartidx, dendidx, 'EMUP')
clf(); plotallinputmaps(pdf,tt[0],dstartidx['EMUP'],'EMUP',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMUP_inputmap_first.png') # gif/20aug7_20aug6_B1_cycle_EMUP_inputmap_first.png
dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMUP')
clf(); plotallinputmaps(pdf,tt[-1],dstartidx['EMUP'],'EMUP',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig('gif/'+dstr+simstr+'EMUP_inputmap_last.png') # gif/20aug7_20aug6_B1_cycle_EMUP_inputmap_last.png

continue this one (20aug6_B1_cycle_) in multistep ... (but will not continue 20aug6_A1_cycle_ for now)

cp backupcfg/20aug6_B1_cycle_sim.json sn.json

then adjust ...

    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20aug6_B1_cycle_synWeights_final.pkl"	
    },
            "name": "20aug7_B2_cycle_",

python multistepSim.py sn.json 30 10 20aug7_B2_cycle_Multi

started ~10:31 ...

** try same as 20aug4_B0_cycle_ but with longer time window for action (20aug7_C0_cycle_)

        tstepPerAction == 40, instead of 20
        "ResumeSim": 0,
        "name": "20aug7_C0_cycle_",

./myrun 30 sn.json

started ~10:45 ...

** border issue

EV1 neurons at border project to fewer IV1 neurons
IV1 neurons at border project to fewer EV1 neurons

could this lead to problem at corners?

could pad neurons

should store x,y,padded vs not

*** discussion on this

15:05
samn do EV1 corners provide less activation of IV1 interneurons?
15:05
and receive less interneuron input?
15:05
since they're at the boundaries
15:06
Haroon Anwar yes
15:06
samn that's a problem?
15:06
and might explain some biases/problems at corners
15:07
Haroon Anwar i dont know how to compensate for that
15:07
yes thats possible
15:07
samn padding
15:07
add an extra two rows and columns of interneurons around the border
15:07
Haroon Anwar problem is feedforward
15:08
less drive is provided to the inhibitory neurons on the border
15:08
and corners are even less
15:08
corners receive input from 9 neurons
15:08
other border neurons receive 15
15:09
and nonborder receive 25
15:09
samn that should be a problem
15:09
Haroon Anwar hmm
15:09
good catch
15:10
samn suppose so, that may be why kept seeing issues at the corners
15:10
and if it's systematic issue with circuit wiring
15:11
Haroon Anwar it is systematic
15:11
samn paddle on top right isn't right at the corner, but close...
15:11
maybe in 20x20 it is close to a border
15:11
Haroon Anwar yes at least its receiving 15 inputs vs 25
15:12
samn so how to fix?
15:14
Haroon Anwar easy fix would be do padding of neurons in all layers
15:15
so that the border effect is pushed to padded neurons
15:15
samn any problem with that other than extra cost?
15:15
Haroon Anwar cant think of any problem at the moment
15:16
samn so the problem is in the EV1 edges, receiving less IV1 input
15:16
Haroon Anwar both ways
15:16
samn but also for IV1 borders receiving  less
15:16
Haroon Anwar IV1 receiving less input from EV1 edges
15:17
and in return EV1 edge neurons receiving even lesser inhibition
15:17
so its added effect
15:18
samn ok, probably should fix with padding...but if padded neurons used for behavior, won't they also have problems?
15:18
Haroon Anwar right
15:18
so for projects onto motor neurons, will have to exclude padded neurons
15:18
projections from premotor to motor
15:19
samn then need to carefully have set of properties of each neuron stored ... x, y, padded vs not padded
15:19
Haroon Anwar will need a function to get list of neurons for projections
15:19
samn otherwise, difficult to ensure correct
15:20
Haroon Anwar yes
15:20
samn and so can get all inputs/outputs to/from a type, based on neuron ID
15:20
to make sure right...
15:21
Haroon Anwar yes
15:21
samn could that be your priority?
15:21
seems important if systematic issue
15:22
alternative is to have random wiring
15:22
with fixed convergence
15:22
between EV1, IV1
15:22
Haroon Anwar yes this will be my priority…. but will have to wait for Monday for this…. quite busy on weekend
15:22
samn ok sg
15:22
Haroon Anwar random wiring--- that would be last resort…. i dont prefer that
15:24
samn makes sense
:+1:
1

* 20aug10
** check output on cycle (20aug7_B2_cycle__step_3_)

python -i simdat.py backupcfg/20aug7_B2_cycle__step_3_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug10_20aug7_B2_cycle__step_3_perf.png

lfn = ['20aug4_B0_cycle_','20aug6_B1_cycle_','20aug7_B2_cycle__step_0_','20aug7_B2_cycle__step_1_','20aug7_B2_cycle__step_2_','20aug7_B2_cycle__step_3_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20aug10_20aug7_B2_cycle__step_3_perf_all_steps_so_far.png
increasing for a while, then decreasing - due to overly high firing rates?

looked like performance starting decaying around 0.4*1e7 ms
0.4*1e7 # 4000 000.0 ... 4000 s ... stopped the sim ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20aug10_20aug7_B2_cycle__step_3_rast.png
xlim((1999e3,2000e3))
savefig('gif/'+dstr+simstr+'rastB.png') # gif/20aug10_20aug7_B2_cycle__step_3_rastB.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=((1990e3,2000e3)))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20aug10_20aug7_B2_cycle__step_3_Vm.png

## fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4') #

can restart the sim from where it was at 4000 s but first normalize the weights and then normalize weights every additional
4000 s ... see if that helps ...

so the first 4000 s were from these two 2000 s sims:
20aug4_B0_cycle_sim.json and 20aug6_B1_cycle_sim.json
so take weights from 20aug6_B1_cycle_synWeights_final.pkl and normalize them
and use that to continue sim ...

python -i simdat.py backupcfg/20aug6_B1_cycle_sim.json

can make a flag to normalize weights at start ...

and it will only be used when resumeSim:
    if 'normalizeWeightsAtStart' in dconf['sim']:
      if dconf['sim']['normalizeWeightsAtStart']:
        print('normalizing adjustable weights at start')
        normalizeAdjustableWeights(sim, 0, lpop = lrecpop)


...
        "name": "20aug10_B2_cycle_",
    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20aug6_B1_cycle_synWeights_final.pkl"
    },
	"normalizeWeightsAtStart": 1,

./myrun 30 sn.json

started @ 16:17 ...

normalizing adjustable weights at start
sim.rank= 0 davg: {'EMUP': 0.00015330298049694589, 'EMDOWN': 0.00014458421066697647} dfctr: {'EMUP': 0.3356975491603856, 'EMDOWN': 0.3356975491603856}

** check 20aug7_C0_cycle_ (same as 20aug4_B0_cycle_ but with tstepPerAction==40)

python -i simdat.py backupcfg/20aug7_C0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug10_20aug7_C0_cycle_perf.png

lfn = ['20aug4_B0_cycle_','20aug7_C0_cycle_']
lpda = getindivactionreward(lfn)
clf(); plotComparePerf(lpda,['b','r'],yl=(0,.55),lleg=lfn)
savefig('gif/'+dstr+simstr+'compare_perf.png') # gif/20aug10_20aug7_C0_cycle_compare_perf.png

the one with 20 ms tstepPerAction (blue) looks better, though it has 2X as much game-time
compared to the one with 40 ms tstepPerAction ...

** check output from gcp

these are two sims without targetted RL

20aug6_A0_gcp_ : same as 20aug4_A0_cycle_ but without targetted RL
20aug6_B0_gcp_ : same as 20aug4_B0_cycle_ but without targetted RL, has
RL plastic connectivity between EM populations

python -i simdat.py backupcfg/20aug6_A0_gcp_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug10_20aug6_A0_gcp_perf.png
hit/miss and score/miss somewhat worse than with targetted RL but the follow
probability is surprisingly similar to with targetted RL

lfn = ['20aug6_A0_gcp_', '20aug6_B0_gcp_']
lpda = getindivactionreward(lfn)
clf(); plotComparePerf(lpda,['b','r'],yl=(0,.55),lleg=lfn)
savefig('gif/'+dstr+simstr+'compare_perf.png') # gif/20aug10_20aug6_A0_gcp_compare_perf.png
in this case, the cross EM population recurrent connectivity (20aug6_B0_gcp_) sim
does worse in follow and hit/miss compared to the sim without (20aug6_A0_gcp_)

** V4, MT back?         "name": "20aug10_VM0_cycle_",

./myrun 30 sn.json

** conv for EV1->IV1 and IV1->EV1?

that way all get fixed convergence and no boundary/edge effects ...

add param to control whether I arranged topographically ... 
	"VTopoI": 0,

and then use it in code like this:

VTopoI = True # whether interneurons have topological arrangement
if "VTopoI" in dconf['net']: VTopoI = dconf['net']['VTopoI']

netParams.connParams['EV1->IV1'] = {
        'preConds': {'pop': 'EV1'},
        'postConds': {'pop': 'IV1'},
        'weight': 0.02 * cfg.EIGain,
        'delay': 2,
        'synMech': 'AMPA', 'sec':'soma', 'loc':0.5}
if VTopoI:
  netParams.connParams['EV1->IV1']['connList'] = blistEV1toIV1
else:
  netParams.connParams['EV1->IV1']['convergence'] = 9

netParams.connParams['IV1->EV1'] = {
  'preConds': {'pop': 'IV1'},
  'postConds': {'pop': 'EV1'},
  'weight': 0.2 * cfg.IEGain,
  'delay': 2,
  'synMech': 'GABA', 'sec':'soma', 'loc':0.5}
if VTopoI: netParams.connParams['IV1->EV1']['connList'] = blistIV1toEV1
else: netParams.connParams['IV1->EV1']['convergence'] = 25  

        "name": "20aug10_VTopoI0_cycle_",

./myrun 30 sn.json

** add interneurons to dir selective pop?

to breakup some of the hypersynch

ok, started that run on gcp -         "name": "20aug10_VTopoI0_ID800_gcp_",
with 800 ID neurons (project back to the EDir neurons)
to use them have to specify
	"EDirPops": ["EV1DE","EV1DNE","EV1DN","EV1DNW","EV1DW","EV1DSW","EV1DS","EV1DSE"],
	"IDirPops": ["ID"],
in json file
and their number in allpops 

* 20aug11
** ha finishing up padding and scaling

scaling = same number of inputs for each neuron - is that different
from fixed convergence? should be somewhat different since preserves
topology

** V4, MT?         "name": "20aug11_VTopoI0_ID800_V4MT_gcp_",

more layers? more RL plasticity?

will try with EV1->EV4 and EV4->EMT using RL plasticity
and probabilistic connectivity with fixed convergence, rather than topographic ...

EV4,EMT then project to EM populations with RL plasticity ...

	    "EV4":100,
	    "IV4":25,
	    "EMT":100,
	    "IMT":25,

also have a new VisualRL flag that controls whether to use RL from EV1->EV4, EV4->EMT

will leave targettedRL off since EV4,EMT do not produce motor commands directly ...
but will keep intermediate rewards turned on ...

also leave off         "EEMRecProbCross": 0,
without targettedRL seems to do worse ... 

./myrun 30 sn.json

** sal response to netpyne forum INTF question

You can just use: netParams.popParams['S'] = {'cellType': 'PYR', 'numCells': 1, 'cellModel': 'IntFire4'}

As described in the docs, for point neurons you don't need to define cellParams, you can just
include the name of the point neuron (ARTIFICIAL_CELL in mod file) as the cellModel :
http://www.netpyne.org/reference.html#population-parameters

You can also record any variables of the point neuron, e.g.: simConfig.recordTraces =
{'intfire4_i1': {'var': 'i1'}}

** fixing up INTF based on sal recc
** check output from 20aug10_VTopoI0_ID800_gcp_

python -i simdat.py backupcfg/20aug10_VTopoI0_ID800_gcp_sim.json

VTopoI was set to 0, there were 800 ID interneurons (feedback inhib
onto the direction selective excitatory neurons)

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug12_20aug10_VTopoI0_ID800_gcp_perf.png
looks similar to other simulations, so possible that inhib layout not an issue (inhib layout
here is random)

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20aug12_20aug10_VTopoI0_ID800_gcp_rast.png
xlim((1999e3,2000e3))
savefig('gif/'+dstr+simstr+'rastB.png') # gif/20aug12_20aug10_VTopoI0_ID800_gcp_rastB.png

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=((1990e3,2000e3)))
savefig('gif/'+dstr+simstr+'Vm.png') # gif/20aug12_20aug10_VTopoI0_ID800_gcp_Vm.png

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4') # gif/20aug12_20aug10_VTopoI0_ID800_gcp__input.mp4

may as well continue ...

cp backupcfg/20aug10_VTopoI0_ID800_gcp_sim.json sn.json
adjust...

        "name": "20aug11_VTopoI0_ID800_B_gcp_",
    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20aug10_VTopoI0_ID800_gcp_synWeights_final.pkl"	
    },

./myrun 30 sn.json

** check output from 20aug10_B2_cycle_

python -i simdat.py backupcfg/20aug10_B2_cycle_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug11_20aug10_B2_cycle_perf.png

lfn = ['20aug4_B0_cycle_','20aug6_B1_cycle_','20aug10_B2_cycle_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20aug11_20aug10_B2_cycle_perf_all_steps_so_far.png
looks good in that performance not decaying but not really getting past the highest performance level achieved...

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20aug11_20aug10_B2_cycle_rast.png
xlim((1999e3,2000e3))
savefig('gif/'+dstr+simstr+'rastB.png') # gif/20aug11_20aug10_B2_cycle_rastB.png

may continue later ... or now ... 

        "name": "20aug11_B3_cycle_",

    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20aug10_B2_cycle_synWeights_final.pkl"	
    },

this time
	"normalizeWeightsAtStart": 0,

./myrun 30 sn.json

* 20aug12
** check output from 20aug10_VTopoI0_

python -i simdat.py backupcfg/20aug10_VTopoI0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug12_20aug10_VTopoI0_cycle_perf.png

looks similar to other simulations -->> interneuron layout / padding not critical?

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20aug12_20aug10_VTopoI0_cycle_rast.png

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EMSTAY'],lclr=['r','b','g'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20aug12_20aug10_VTopoI0_cycle_all_avg_weight.png
(note that did not use EMSTAY in this simulation!)

simple measure of performance - how often is the paddle within a certain distance of the ball when
the ball is at each y coordinate at the right side? then measure how that changes over time ...
or just take average y distance from paddle to ball when ball is at right side (split by y position
of ball)

clf(); dobjpos = loadObjPos() ## 
subplot(2,1,1); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
subplot(2,1,2); xlabel('Ball Y position'); hist(dobjpos['ball'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20aug12_20aug10_VTopoI0_cycle_poshist.png

plot(dobjpos['ball'][:,1],'b')
plot(dobjpos['racket'][:,1],'r')
savefig('gif/'+dstr+simstr+'ball_racket_pos.png') # 

from scipy.stats import pearsonr
pearsonr(dobjpos['ball'][:,1],dobjpos['racket'][:,1]) # (0.20804581756251553, 0.0)
that could be another performance measure ...

plot(dobjpos['ball'][:,1],'b')
plot(dobjpos['racket'][:,1],'r')

len(dobjpos['ball']) # 99978
len(dobjpos['racket']) # 99978

ballX,ballY = dobjpos['ball'][:,0],dobjpos['ball'][:,1]
racketX,racketY = dobjpos['racket'][:,0],dobjpos['racket'][:,1]

min(ballX),max(ballX) # (18.0, 138.0)
min(ballY),max(ballY) # (-1.0, 159.0)

min(racketX),max(racketX),min(racketY),max(racketY) # (140.0, 142.0, 1.5, 157.5)
why does racketX vary? shouldn't it always be the same?

tt = np.linspace(0,totalDur,len(dobjpos['ball']))
pdpos = pd.DataFrame(np.array([tt, ballX, ballY, racketX, racketY]).T,columns=['time','ballX','ballY','racketX','racketY'])

pdposs = pdpos[(pdpos.ballY>-1.0) & (pdpos.ballX>137) & (pdpos.ballX<141)]

dist = np.sqrt((pdposs.ballY - pdposs.racketY)**2)
len(dist) # 1272

lbally = np.unique(pdposs.ballY)

lbally
array([  9.5,  11.5,  15.5,  17.5,  19.5,  21.5,  23.5,  25.5,  31.5,
        33.5,  43.5,  47.5,  53.5,  55.5,  57.5,  59.5,  61.5,  63.5,
        65.5,  81.5,  91.5,  93.5,  94. ,  95.5,  97.5,  99.5, 101.5,
       103.5, 105.5, 107.5, 109.5, 127.5, 129.5, 131.5, 135.5, 137.5,
       138. , 139.5, 141.5, 143.5, 145.5, 149.5])

note the non-integer values ... 

plot(pdposs.time, dist)
savefig('gif/'+dstr+simstr+'racket_ball_Y_dist_vs_time_pos.png') # gif/20aug12_20aug10_VTopoI0_cycle_racket_ball_Y_dist_vs_time_pos.png

need to arrange distances between racket and ball y over time, to see if they improve
note that these are the distances when ball is close to racket x position (right side of screen)

lr = []; ly = []
for y in lbally:
  pdposss = pdposs[(pdposs.ballY==y)]
  dist = np.sqrt((pdposss.ballY - pdposss.racketY)**2)
  plot(pdposss.time, dist)
  if len(pdposss.time) > 1:
    r,p = pearsonr(pdposss.time, dist)
    if p < 0.1:
      lr.append(r)
      ly.append(y)

mean(lr) # -0.38121276265057785
lr # [-0.13058295557793753, -0.9928797539872843, -0.9690671982663085, 0.9816262270426515, -0.28800520002775815, -0.2545581188678605, -0.8769565292049619, -0.32056193367274993, -0.32443788935043055, -0.6367042745931384]

that's correlation of y distance with time. if learning, should see a decrease ...
some of the values are decreasing, some are increasing ... should plot them as a function of y position at right side
to see if any pattern ... 

plot(ly, lr, 'ko', markersize=15)
plot(ly, lr, 'k', linewidth=3)
xlabel('Y position',fontsize=25); ylabel('Correlation between paddle/ball distance and time',fontsize=25)

savefig('gif/'+dstr+simstr+'racket_ball_Y_dist_vs_time_corr.png') # gif/20aug12_20aug10_VTopoI0_cycle_racket_ball_Y_dist_vs_time_corr.png

should make sure time saved properly for dobjpos to make sure consistent ... there was some offset at beginning ...

dout = getdistvstimecorr(pdpos,pval=0.1)

for y in dout['ly']:
  plot(dout[y]['time'],dout[y]['dist'])


dout['lbally']
dout['lN'] # [582, 3, 8, 4, 57, 58, 5, 175, 171, 8]

dout = getdistvstimecorr(pdpos,pval=1)
plot(dout['lN'],dout['lr'],'ko',markersize=15)
xlabel('Number examples',fontsize=25); ylabel('Correlation between paddle/ball distance and time',fontsize=25)

savefig('gif/'+dstr+simstr+'num_examples_and_racket_ball_Y_dist_vs_time_corr.png')
gif/20aug12_20aug10_VTopoI0_cycle_num_examples_and_racket_ball_Y_dist_vs_time_corr.png

so there's not always a correlation between number of examples and the performance over time ...
~600 examples going to upper right, and only weak learning ... some bug? or because racket
partially off-screen at top-right?

** check output from sim with VisualRL and V4,MT

note that this one had no targettedRL

python -i simdat.py backupcfg/20aug11_VTopoI0_ID800_V4MT_gcp_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug12_20aug11_VTopoI0_ID800_V4MT_gcp_perf.png

well, improving but not as good as with targetted ...

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20aug12_20aug11_VTopoI0_ID800_V4MT_gcp_rast.png
EV4,EMT barely firing ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EV4','EMT'],lclr=['r','b','g','c'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig('gif/'+dstr+simstr+'all_avg_weight.png') # gif/20aug12_20aug11_VTopoI0_ID800_V4MT_gcp_all_avg_weight.png

pdfs = pdf[(pdf.postid>=dstartidx['EV4'])&(pdf.postid<=dendidx['EV4'])]
len(pdfs) # 0

hmm, so did not record the EV4, EMT weights? so can't continue this simulation

lrecpop should have been updated to include EV4, EMT ... since VisualRL was turned on
dconf['net']['VisualRL'] # 1

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4') # gif/20aug12_20aug11_VTopoI0_ID800_V4MT_gcp__input.mp4

** check output from 20aug11_B3_cycle_

python -i simdat.py backupcfg/20aug11_B3_cycle_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug12_20aug11_B3_cycle_perf.png
better in beginning, then a little worse?

lfn = ['20aug4_B0_cycle_','20aug6_B1_cycle_','20aug10_B2_cycle_', '20aug11_B3_cycle_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20aug12_20aug11_B3_cycle_perf_all_steps_so_far.png

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20aug12_20aug11_B3_cycle_rast.png
strange - westward moving activity for a stretch, but has some eastward activity too ...
seems unlikely/impossible since only ball can move directly west or east -->> bug? poor representation?

check video and flow ... 
fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=True,ldflow=ldflow) # gif/20aug12_20aug11_B3_cycle__input.mp4

lfn = ['20aug4_B0_cycle_','20aug6_B1_cycle_','20aug10_B2_cycle_', '20aug11_B3_cycle_']
lpda = getindivactionreward(lfn)
clf(); plotComparePerf(lpda,['c','g','b','r'],yl=(0,1),lleg=lfn)
savefig('gif/'+dstr+simstr+'perf_compare_all_steps_so_far.png')
gif/20aug12_20aug11_B3_cycle_perf_compare_all_steps_so_far.png
look pretty similar ...later steps a bit better ... could continue or adjust architecture ...

will continue but have weight norm at start ...

cp backupcfg/20aug11_B3_cycle_sim.json sn.json
    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20aug11_B3_cycle_synWeights_final.pkl"
    },
        "name": "20aug12_B4_cycle_",

started ~16:52 ...

** check output from sim with ID800 (20aug11_VTopoI0_ID800_B_gcp_)

python -i simdat.py backupcfg/20aug11_VTopoI0_ID800_B_gcp_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug12_20aug11_VTopoI0_ID800_B_gcp_perf.png
seems decent...some of the score values getting higher briefly...
ylim((0,1)); savefig('gif/'+dstr+simstr+'perfB.png')
gif/20aug12_20aug11_VTopoI0_ID800_B_gcp_perfB.png

lfn = ['20aug10_VTopoI0_ID800_gcp_','20aug11_VTopoI0_ID800_B_gcp_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20aug12_20aug11_VTopoI0_ID800_B_gcp_perf_all_steps_so_far.png

lpda = getindivactionreward(lfn)
clf(); plotComparePerf(lpda,['b','r'],yl=(0,1),lleg=lfn)
savefig('gif/'+dstr+simstr+'perf_compare_all_steps_so_far.png')
gif/20aug12_20aug11_VTopoI0_ID800_B_gcp_perf_compare_all_steps_so_far.png
comparing individual steps seems more robust ... integrating cumulative over long
periods of time seems to obscure the shorter-term performance ... which seems to
clearly increase across steps here ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20aug12_20aug11_VTopoI0_ID800_B_gcp_rast.png
rates are low, note that there was weight normalization at start - so when continue this one
should have that again ...

clf(); dobjpos = loadObjPos() ## 
subplot(2,1,1); xlabel('Racket Y position'); hist(dobjpos['racket'][:,1])
subplot(2,1,2); xlabel('Ball Y position'); hist(dobjpos['ball'][:,1])
savefig('gif/'+dstr+simstr+'poshist.png') # gif/20aug12_20aug11_VTopoI0_ID800_B_gcp_poshist.png

pdpos = ObjPos2pd(dobjpos)
dout = getdistvstimecorr(pdpos,pval=1)
plot(dout['lN'],dout['lr'],'ko',markersize=15)
xlabel('Number examples'); ylabel('Correlation between paddle/ball distance and time')
savefig('gif/'+dstr+simstr+'num_examples_and_racket_ball_Y_dist_vs_time_corr.png')
gif/20aug12_20aug11_VTopoI0_ID800_B_gcp_num_examples_and_racket_ball_Y_dist_vs_time_corr.png

many of the values are positive ... though some for few examples ...
top right corner is doing bad too ...

plot(dout['lbally'], dout['lr'], 'ko', markersize=15)
plot(dout['lbally'], dout['lr'], 'k', linewidth=3)
xlabel('Y position'); ylabel('Correlation between paddle/ball distance and time')
savefig('gif/'+dstr+simstr+'racket_ball_Y_dist_vs_time_corr.png')
gif/20aug12_20aug11_VTopoI0_ID800_B_gcp_racket_ball_Y_dist_vs_time_corr.png

some are down and some are up ...

better to look at distance (between ball and paddle) over time at each y position ...

cp backupcfg/20aug11_VTopoI0_ID800_B_gcp_sim.json sn.json
then adjust ...

        "name": "20aug12_VTopoI0_ID800_C_gcp_",
	this one will have weight norm at beginning
    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20aug11_VTopoI0_ID800_B_gcp_synWeights_final.pkl"
    },

./myrun 30 sn.json

started ~16:36 ...

next one will have an additional weight norm halfway ...

        "name": "20aug12_VTopoI0_ID800_D_gcp_",
        "normalizeWeightStepSize": 50000,

./myrun 30 sn.json

started ~16:40 ...

* 20aug13
** try new padding? bin images?

pulled/merged development with master

** add default param value setup to conf.py

ensureDefaults

did not put all of them in yet ... but for new ones, easier to add there
than to enforce checking for presence of the params in the rest of the code

** check output from 20aug12_B4_cycle_

note that there was a weight norm at start ... 

python -i simdat.py backupcfg/20aug12_B4_cycle_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug13_20aug12_B4_cycle_perf.png

lfn = ['20aug4_B0_cycle_','20aug6_B1_cycle_','20aug10_B2_cycle_', '20aug11_B3_cycle_', '20aug12_B4_cycle_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20aug13_20aug12_B4_cycle_perf_all_steps_so_far.png

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20aug13_20aug12_B4_cycle_rast.png

lpda = getindivactionreward(lfn)
clf(); plotComparePerf(lpda,['c','g','b','m','r'],yl=(0,1),lleg=lfn)
savefig('gif/'+dstr+simstr+'perf_compare_all_steps_so_far.png') # gif/20aug13_20aug12_B4_cycle_perf_compare_all_steps_so_far.png

apart from the first and others, the rest look pretty similar overall ... 

clf(); dobjpos = loadObjPos() ## 
pdpos = ObjPos2pd(dobjpos)
dout = getdistvstimecorr(pdpos,minN=2)
plot(dout['lN'],dout['lr'],'ro',markersize=25)
xlabel('Number examples'); ylabel('Correlation between paddle/ball distance and time')
savefig('gif/'+dstr+simstr+'num_examples_and_racket_ball_Y_dist_vs_time_corr.png')

plot(dout['lbally'], dout['lr'], 'ko', markersize=15)
plot(dout['lbally'], dout['lr'], 'k', linewidth=3)
xlabel('Y position'); ylabel('Correlation between paddle/ball distance and time')
savefig('gif/'+dstr+simstr+'racket_ball_Y_dist_vs_time_corr.png')

should look at full distribution of distances (on right side) based on number
of examples

plot(dout[1.5]['time'],dout[1.5]['dist'],'ko',markersize=25)
plot(dout[15.5]['time'],dout[15.5]['dist'],'ro',markersize=25)

plot(dout['lbally'],dout['lN'],'ko',markersize=25)
xlabel('Y intercept',fontsize=20); ylabel('Count',fontsize=20)
savefig('gif/'+dstr+simstr+'ball_Y_intercept_count.png') # 'gif/'+dstr+simstr+'ball_Y_intercept_count.png'
so again can see most of the locations do not have many examples, most of the time the
ball goes to top right corner, followed by bottom right corner

len(dout[21.5]['time']) # 503
plot(dout[21.5]['time'],dout[21.5]['dist'])
plot(dout[21.5]['time'],dout[21.5]['dist'],'ko',markersize=10)
xlabel('time'); ylabel('distance')
savefig('gif/'+dstr+simstr+'ball_Y_21.5_distance_time.png') # gif/20aug13_20aug12_B4_cycle_ball_Y_21.5_distance_time.png'
that does not look like improvement...distance all over the place...should see paddle location at each time that
ball crosses right side.

hist(dout[21.5]['dist'])
hist(dout[21.5]['dist'],bins=160)
xlabel('Distance')
ylabel('Count')
savefig('gif/'+dstr+simstr+'ball_Y_21.5_distance_hist.png') # 'gif/'+dstr+simstr+'ball_Y_21.5_distance_hist.png'
so distances are biased towards correct - though there's a wide distribution 
that's somewhat reassuring ... but strange that there's a peak at distance of 20 

hist(dout[21.5]['rackety'])
hist(dout[21.5]['rackety'],bins=160)
plot([21.5,21.5],[0,140],'k--',linewidth=3)
savefig('gif/'+dstr+simstr+'ball_Y_21.5_position_hist.png') # 'gif/'+dstr+simstr+'ball_Y_21.5_position_hist.png'
so as observed in videos, the racket is all the way up top instead of at correct location (21.5)

will likely see same at other end (bottom of screen)

clf()
hist(dout[141.5]['rackety'])
hist(dout[141.5]['rackety'],bins=40)
plot([141.5,141.5],[0,90],'k--',linewidth=3)
savefig('gif/'+dstr+simstr+'ball_Y_141.5_position_hist.png') # gif/20aug13_20aug12_B4_cycle_ball_Y_141.5_position_hist.png

dout['lbally']
len(dout[81.5]['time'])

clf()
ypos = 93.5
hist(dout[ypos]['rackety'])
hist(dout[ypos]['rackety'],bins=20)
plot([ypos,ypos],[0,7],'k--',linewidth=3)
savefig('gif/'+dstr+simstr+'ball_Y_'+str(ypos)+'_position_hist.png') # gif/20aug13_20aug12_B4_cycle_ball_Y_93.5_position_hist.png
peak does not look as clear, but there are fewer examples ...

** check output from 20aug12_VTopoI0_ID800_C_gcp_
and 20aug12_VTopoI0_ID800_D_gcp_

python -i simdat.py backupcfg/20aug12_VTopoI0_ID800_C_gcp_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug13_20aug12_VTopoI0_ID800_C_gcp_perf.png
does not look bad ... gets to pretty high levels overall, though expect to see the usual problems at
the top-right and bottom-right corners...

lfn = ['20aug10_VTopoI0_ID800_gcp_','20aug11_VTopoI0_ID800_B_gcp_','20aug12_VTopoI0_ID800_C_gcp_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20aug13_20aug12_VTopoI0_ID800_C_gcp_perf_all_steps_so_far.png

lpda = getindivactionreward(lfn)
clf(); plotComparePerf(lpda,['b','g','r'],yl=(0,1),lleg=lfn)
savefig('gif/'+dstr+simstr+'perf_compare_all_steps_so_far.png')
gif/20aug13_20aug12_VTopoI0_ID800_C_gcp_perf_compare_all_steps_so_far.png
some evidence that improving overall, though not as clear as first two steps

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20aug13_20aug12_VTopoI0_ID800_C_gcp_rast.png
again see east/west activity at same time; do not think that should occur
xlim((1992000,1993000))
savefig('gif/'+dstr+simstr+'rastB.png') # gif/20aug13_20aug12_VTopoI0_ID800_C_gcp_rastB.png
could see if ball goes back and forth, seems unlikely...

compare to the sim with the weight normalization in the middle ...

lfn = ['20aug12_VTopoI0_ID800_C_gcp_', '20aug12_VTopoI0_ID800_D_gcp_']
lpda = getindivactionreward(lfn)
clf(); plotComparePerf(lpda,['b','r'],yl=(0,1),lleg=lfn)
savefig('gif/'+dstr+simstr+'perf_compare_against_more_norm.png')
gif/20aug13_20aug12_VTopoI0_ID800_C_gcp_perf_compare_against_more_norm.png
looks like the weight normalization 1/2-way through did help a little ... 

python -i simdat.py backupcfg/20aug12_VTopoI0_ID800_D_gcp_sim.json

may as well run one more continuation on gcp ...

cp backupcfg/20aug12_VTopoI0_ID800_D_gcp_sim.json sn.json
but make sure to turn off new padding so can use the last weights saved

        "name": "20aug13_VTopoI0_ID800_E_gcp_",
        "useNeuronPad": 0,
        "useBinaryImage": 0,
    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20aug12_VTopoI0_ID800_D_gcp_synWeights_final.pkl"
    },
	"normalizeWeightsAtStart": 1,
        "normalizeWeightStepSize": 50000,

./myrun 30 sn.json

started ~17:33 ...

** new version works?

yes...seems to run ok

python -i simdat.py backupcfg/20aug13_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values()))));

        "name": "20aug13_A0_cycle_",

./myrun 32 sn.json

* 20aug14
** check output from 20aug13_VTopoI0_ID800_E_gcp_

python -i simdat.py backupcfg/20aug13_VTopoI0_ID800_E_gcp_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig('gif/'+dstr+simstr+'perf.png') # 'gif/'+dstr+simstr+'perf.png'
looks good - has high hit/miss ratios (>0.5) for much of the simulation

lfn = ['20aug10_VTopoI0_ID800_gcp_','20aug11_VTopoI0_ID800_B_gcp_','20aug12_VTopoI0_ID800_D_gcp_','20aug13_VTopoI0_ID800_E_gcp_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf_all_steps_so_far.png') # gif/20aug14_20aug13_VTopoI0_ID800_E_gcp_perf_all_steps_so_far.png
looks like increasing, even in the cumulative

lpda = getindivactionreward(lfn)
clf(); plotComparePerf(lpda,['c','b','g','r'],yl=(0,1),lleg=lfn)
savefig('gif/'+dstr+simstr+'perf_compare_all_steps_so_far.png')
gif/20aug14_20aug13_VTopoI0_ID800_E_gcp_perf_compare_all_steps_so_far.png
some evidence that improving overall, though not as clear as between first two steps

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig('gif/'+dstr+simstr+'rast.png') # gif/20aug14_20aug13_VTopoI0_ID800_E_gcp_rast.png
xlim((1992000,1993000))
savefig('gif/'+dstr+simstr+'rastB.png') # gif/20aug14_20aug13_VTopoI0_ID800_E_gcp_rastB.png

possible that this sim doing 'better' since dir selective neurons have stronger inputs?
stimModInputW = 0.05
if 'stimModInputW' in dconf['net']: stimModInputW = dconf['net']['stimModInputW']
stimModDirW = 0.01
if 'stimModDirW' in dconf['net']: stimModDirW = dconf['net']['stimModDirW']

since have stimModDirW set to 0.05 ... compared to default in sim.py which is 0.01 ... 

check if east/west firing at same time...

binsz=20
dhist = {pop:getspikehist(dspkT[pop],dnumc,binsz,totalDur) for pop in ['EV1DE','EV1DW']}

for k,clr in zip(list(dhist.keys()),['r','b']): plot(dhist[k][0],dhist[k][1],clr)

lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['r','b'],['EV1DE','EV1DW'])]
ax=gca(); ax.legend(handles=lpatch,handlelength=1)
xlabel('Time (ms)'); ylabel('Spikes')
savefig(gifpath()+'EV1DE_EV1DW_spikes.png') # gif/20aug14_20aug13_VTopoI0_ID800_E_gcp_EV1DE_EV1DW_spikes.png
looks like there are many east,west spikes at same time?
savefig(gifpath()+'EV1DE_EV1DW_spikesB.png') # gif/20aug14_20aug13_VTopoI0_ID800_E_gcp_EV1DE_EV1DW_spikesB.png
savefig(gifpath()+'EV1DE_EV1DW_spikesC.png') # gif/20aug14_20aug13_VTopoI0_ID800_E_gcp_EV1DE_EV1DW_spikesC.png
savefig(gifpath()+'EV1DE_EV1DW_spikesD.png') # gif/20aug14_20aug13_VTopoI0_ID800_E_gcp_EV1DE_EV1DW_spikesD.png
that seems problematic for the motion encoding

pearsonr(dhist['EV1DE'][1],dhist['EV1DW'][1]) # (0.08642091163838092, 4.800983035787333e-165)
there's even a slight positive correlation between east and west motion ... 

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=True,ldflow=ldflow)
gif/20aug14_20aug13_VTopoI0_ID800_E_gcp__input.mp4

** check output and rates for east,west from 20aug13_A0_cycle_

python -i simdat.py backupcfg/20aug13_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig('gif/'+dstr+simstr+'perf.png') # gif/20aug14_20aug13_A0_cycle_perf.png

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig(gifpath()+'rast.png') # gif/20aug14_20aug13_A0_cycle_rast.png

binsz=20
dhist = {pop:getspikehist(dspkT[pop],dnumc,binsz,totalDur) for pop in ['EV1DE','EV1DW']}

for k,clr in zip(list(dhist.keys()),['r','b']): plot(dhist[k][0],dhist[k][1],clr)

lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['r','b'],['EV1DE','EV1DW'])]
ax=gca(); ax.legend(handles=lpatch,handlelength=1)
xlabel('Time (ms)'); ylabel('Spikes')
savefig(gifpath()+'EV1DE_EV1DW_spikes.png') # gif/20aug14_20aug13_A0_cycle_EV1DE_EV1DW_spikes.png
savefig(gifpath()+'EV1DE_EV1DW_spikesB.png') # gif/20aug14_20aug13_A0_cycle_EV1DE_EV1DW_spikesB.png
savefig(gifpath()+'EV1DE_EV1DW_spikesC.png') # gif/20aug14_20aug13_A0_cycle_EV1DE_EV1DW_spikesC.png

pearsonr(dhist['EV1DE'][1],dhist['EV1DW'][1]) # (0.1413228469056423, 0.0)
there's even a slight positive correlation between east and west motion ... 

seems like a problem in this simulation too ...

10 spikes in 20 ms ... 400 neurons ... is it a problem?

nspk = 10
ncell = 400
rate = 1e3*nspk/(20*ncell) # 1.25

nspk = 50
ncell = 400
rate = 1e3*nspk/(20*ncell) # 6.25

** check nsloc

it has a checkinterval flag

python -i simdat.py backupcfg/20aug14_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,.55))

drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); 

binsz=20
dhist = {pop:getspikehist(dspkT[pop],dnumc,binsz,totalDur) for pop in ['EV1DE','EV1DW']}

for k,clr in zip(list(dhist.keys()),['r','b']): plot(dhist[k][0],dhist[k][1],clr)

lpatch = [mpatches.Patch(color=c,label=s) for c,s in zip(['r','b'],['EV1DE','EV1DW'])]
ax=gca(); ax.legend(handles=lpatch,handlelength=1)
xlabel('Time (ms)'); ylabel('Spikes')

savefig('gif/20aug14_test_nsloc_a0.png') # <- with nsloc check_interval of 0.1
savefig('gif/20aug14_test_nsloc_a1.png') # <- with nsloc check_interval of 1
savefig('gif/20aug14_test_nsloc_a2.png') # <- with nsloc check_interval of 1

pearsonr(dhist['EV1DE'][1][1:],dhist['EV1DW'][1][1:]) # (-0.033181127887684764, 0.4595700382393278)

** activity/image viewer

allow step to specific time, show the previous input frame, current frame, motion fields,
and firing rates of specific populations

python -i simdat.py backupcfg/20aug14_A0_cycle_sim.json

python -i simdat.py backupcfg/20aug14_B0_cycle_sim.json

dobjpos = loadObjPos() ## 
binsz=20
dhist = {pop:getspikehist(dspkT[pop],dnumc,binsz,totalDur) for pop in ['EV1DE','EV1DW']}

clf(); viewInput(0,InputImages,ldflow,dhist,['EV1DE','EV1DW'],['r','b'], twin=1000)
clf(); viewInput(2000,InputImages,ldflow,dhist,['EV1DE','EV1DW'],['r','b'], twin=1000, dobjpos=dobjpos)
clf(); viewInput(2300,InputImages,ldflow,dhist,['EV1DE','EV1DW'],['r','b'], twin=1000, dobjpos=dobjpos)
clf(); viewInput(59000,InputImages,ldflow,dhist,['EV1DE','EV1DW'],['r','b'], twin=1000)

clf(); viewInput(59000,InputImages,ldflow,dhist,['EV1DE','EV1DW'],['r','b'], twin=1000, dobjpos=dobjpos)
clf(); viewInput(55000,InputImages,ldflow,dhist,['EV1DE','EV1DW'],['r','b'], twin=1000, dobjpos=dobjpos)

clf(); viewInput(2300,InputImages,ldflow,dhist,['EV1DE','EV1DW'],['r','b'], twin=1000, dobjpos=dobjpos)
t= 2300 ball x= 2.8125 y= 17.1875
t= 2300 racket x= 17.625 y= 9.1875
t= 2320 ball x= 2.6875 y= 17.3125
t= 2320 racket x= 17.625 y= 9.1875
savefig('gif/20aug14_test_viewinput_b0.png')

hmm, ball not visible at all, why does findobj think it is? ball is offscreen
and algorithm thinks opponent paddle is the ball...problem!
well, it's not correct, sometimes if opponent paddle mistakenly seen to move to the
right that could lead to wrong intermediate reward signal
the object positions also do not look correct, not in middle of object,
as thought they were ...

do same problems of E,W co-occurring happen with optical flow?

python -i simdat.py backupcfg/20aug14_C0_cycle_sim.json

dobjpos = loadObjPos() ## 
binsz=20
dhist = {pop:getspikehist(dspkT[pop],dnumc,binsz,totalDur) for pop in ['EV1DE','EV1DW']}

clf(); viewInput(2300,InputImages,ldflow,dhist,['EV1DE','EV1DW'],['r','b'], twin=1000, dobjpos=dobjpos)
t= 2300 ball x= 2.8125 y= 17.1875
t= 2300 racket x= 17.625 y= 8.6875
t= 2320 ball x= 2.6875 y= 17.3125
t= 2320 racket x= 17.625 y= 8.6875

savefig('gif/20aug14_test_viewinput_c0.png')

motion detection output looks a lot worse ...

* 20aug31
** setup again
* 20sep1
** testing with topol (padding causes problems with direction selective neurons!) (20sep1_A0_cycle_)

have to adjust weights
these are some of the params to set:
        "DirMinRate": 0.0,
        "DirMaxRate": 150.0,
        "LocMaxRate": 150.0,
        "FiringRateCutoff" : 50.0,
        "stimModDirW": 0.02,
        "stimModInputW": 0.02,

put the default conv/div for topol connections into conf.py

also trying with         "tstepPerAction": 50,

had         "EEMWghtAM": 5e-05,
        "EEMWghtNM": 5e-06,

EV1DE is firing very fast ( > 90 Hz ) even with no apparent motion to east ...
when game starts, the ball starts moving to west (towards opponent) - seems buggy??

20sep1_rast_a0.png

and this is with 
        "stimModDirW": 0.005,
        "stimModInputW": 0.005,

similar occurs with tstepPerAction of 20 ... 

does same occur without the topol conn?

yeah, similar occurs with EV1DE firing way too much, and for no apparent reason (no motion east seen)

and without useBinaryImage, useNeuronPad ?

yes, still have the EV1DE firing at very high rates (~50 Hz)

and with lower max rates?
        "DirMaxRate": 50.0,
        "LocMaxRate": 50.0,

much lower firing rates for EV1DE (~19 Hz) but still much higher than
the other direction selective neurons, even though no motion eastward ... 

was it because accidentally had opticflow turned on (instead of centroid tracker) ?

python -i simdat.py backupcfg/20sep1_A0_cycle_sim.json

fig=animInput(InputImages,'gif/'+dstr+simstr+'_input.mp4',showflow=True,ldflow=ldflow)
saved animation to gif/20sep1_20sep1_A0_cycle__input.mp4

do not see any east-pointing arrows in that mp4 ... 

problem goes away when turn off the padding ... 

	"useNeuronPad": 0,

so padding likely still has some bugs ... 

not sure this part in aigame.py makes sense:
    if dconf['net']['useNeuronPad']:
      self.input_dim = int(np.sqrt(self.dInputs[self.InputPop]))
    else:  
      self.input_dim = int(np.sqrt(dconf['net']['allpops'][self.InputPop])) # input image XY plane width,height -- not used anywhere    
since after the padding the size does not have to be a square ?

python -i simdat.py backupcfg/20sep1_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,.55))

ok, try a longer run with topol

100 s took only ~5 minutes ... 

try 2000 s ... note that tstepPerAction is 50 ms ... 

    "architecturePreMtoM": {
        "useProbabilistic": 0,
        "useTopological": 1
    },

./myrun 32 sn.json

started ~16:29 on cycle ... 

** and a comparison without topol (20sep1_B0_cycle_)

    "architecturePreMtoM": {
        "useProbabilistic": 1,
        "useTopological": 0
    },

./myrun 32 sn.json

started ~16:34 on cylce ...

* 20sep2
** check output from sim with/without topol conn (but no padding; 20sep1_A0_cycle_, 20sep1_B0_cycle_)

  Simulated time: 2000.0 s; 32 workers
  Run time: 32544.85 s

python -i simdat.py backupcfg/20sep1_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig(gifpath()+'perf.png') # gif/20sep2_20sep1_A0_cycle_perf.png

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig(gifpath()+'rast.png') # gif/20sep2_20sep1_A0_cycle_rast.png

rates look good

binsz=20
dhist = {pop:getspikehist(dspkT[pop],dnumc,binsz,totalDur) for pop in ['EV1DE','EV1DW']}

for k,clr in zip(list(dhist.keys()),['r','b']): plot(dhist[k][0],dhist[k][1],clr)

no longer see the overlap in E,W so that's good ... 

fig=animInput(InputImages,gifpath()+'_input.mp4',showflow=True,ldflow=ldflow) # gif/20sep2_20sep1_A0_cycle__input.mp4

looks ok for many cases but has the usual problem of overshooting when ball going to corner (paddle does not seem to
get stuck in corner but instead shoots too far down, too quickly, missing contact with the ball; would the EMSTAY
neurons help?)

how does it compare to the sim without topol conn?

lfn = ['20sep1_A0_cycle_', '20sep1_B0_cycle_']
lpda = getindivactionreward(lfn)
clf(); plotComparePerf(lpda,['b','r'],yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compare.png') # gif/20sep2_20sep1_A0_cycle_perf_compare.png
not clear that topol better ... 

check rates/activity for the other sim - looked like had much higher rates

took a lot longer to run 20sep1_B0_cycle_
  Run time: 55552.86 s

python -i simdat.py backupcfg/20sep1_B0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,.55))
savefig(gifpath()+'perf.png') # gif/20sep2_20sep1_B0_cycle_perf.png

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig(gifpath()+'rast.png') # gif/20sep2_20sep1_B0_cycle_rast.png
the EMDOWN,EMUP rates are much higher, but not pathologically high ... 
xlim((1998e3,1999e3))
savefig(gifpath()+'rastB.png') # gif/20sep2_20sep1_B0_cycle_rastB.png

fig=animInput(InputImages,gifpath()+'_input.mp4',showflow=True,ldflow=ldflow) # gif/20sep2_20sep1_B0_cycle__input.mp4

activity looks ok - nothing unusual ... 

** some emacs adjustments

M-x ielm (starts lisp interpreter)

https://github.com/cpaulik/emacs-material-theme
(put that el file into ~/.emacs.d/ )
(load-theme 'material t) ; <- that loads the theme
(setq org-support-shift-select t) ; <- use that to allow shift-selection in org mode

M-x goto-line goes to a line, should add a key-binding

https://emacs.stackexchange.com/questions/37887/send-region-to-shell-in-another-buffer

** xv for ubunbtu - use snap to install

https://snapcraft.io/install/xv/ubuntu

sudo snap install xv --edge

gets certificate error on cycle ... how to bypass certificate check with snap?

** simple tuts on dqn

https://www.analyticsvidhya.com/blog/2019/04/introduction-deep-q-learning-python/
https://medium.com/@jonathan_hui/rl-introduction-to-deep-reinforcement-learning-35c25e04c199

multiple networks
target and prediction to prevent instability in training - copy from one network to other every so often
experience replay important -- add it? store state,action,reward,next state then sample
from it randomly; problem is that neuronal network has a dynamic state ... but couldn't it handle
arbitrary inputs?

** output encoding problematic?
** other sims

smaller weight increments (RLhebbwt of 1e-6) prevent instability? also inc RLlenhebb to 500 ms from 200 ms
since tstepPerAction now longer (50 ms instead of 20 ms)

try another comparison with topo and w/o topo

20sep2_A0_cycle_ (with topo)
20sep2_B0_cycle_ (without topo)

./myrun 32 sn.json

20sep2_A0_cycle_ started ~17:05

./myrun 32 sn.json

20sep2_B0_cycle_ started ~17:06


ax=plotPerf(actreward,yl=(0,.55))
drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); 

** other bugs

noticed that when use EMSTAY now get a crash; also can only use certain sizes
for the layers when using topo conn

* 20sep3
** check output from last two sims on cycle

python -i simdat.py backupcfg/20sep2_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,.65))
savefig(gifpath()+'perf.png') # gif/20sep3_20sep2_A0_cycle_perf.png

some of the values get reasonably high (hit/miss), but happens so early on that
may not be due to learning??

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig(gifpath()+'rast.png') # gif/20sep3_20sep2_A0_cycle_rast.png

very sparse firing for EMUP, EMDOWN (~0.2 Hz on average) - all rates look good

how does it compare to the corresponding sim without topol conn?

lfn = ['20sep2_A0_cycle_', '20sep2_B0_cycle_']
lpda = getindivactionreward(lfn)
clf(); plotComparePerf(lpda,['b','r'],yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compare.png') # gif/20sep3_20sep2_A0_cycle_perf_compare.png
not clear which better; topol has higher hit/miss and score values but does not seem
to be increasing ... while w/o topol hit/miss looks like increasing somewhat steadily ... 

and compare against the sims with larger weight steps

lfn = ['20sep1_A0_cycle_', '20sep2_A0_cycle_']
lpda = getindivactionreward(lfn)
clf(); plotComparePerf(lpda,['b','r'],yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # gif/20sep3_20sep2_A0_cycle_perf_compareB.png
smaller step size with the longer RL tau seems better ... 

weights?

popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # gif/20sep3_20sep2_A0_cycle_all_avg_weight.png
many are flat, some rising

fig=animInput(InputImages,gifpath()+'_input.mp4') # gif/20sep3_20sep2_A0_cycle__input.mp4

does ok sometimes, but makes the same mistake many times and does not seem to adapt - are the EMUP,EMDOWN firing rates too low?

check rates/activity for the other sim - has higher firing rates

took longer to run 20sep2_B0_cycle_
  Run time: 53903.56 s

python -i simdat.py backupcfg/20sep2_B0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,.65))
savefig(gifpath()+'perf.png') # gif/20sep3_20sep2_B0_cycle_perf.png
hit/miss seems to be rising ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig(gifpath()+'rast.png') # gif/20sep3_20sep2_B0_cycle_rast.png
as before, the EMDOWN,EMUP rates are much higher (~4 Hz) than topo model (~0.2 Hz), but not pathologically high ... 

and compare to same sim (w/o topo) and with larger weight incs, shorter RL tau:
lfn = ['20sep1_B0_cycle_', '20sep2_B0_cycle_']
lpda = getindivactionreward(lfn)
clf(); plotComparePerf(lpda,['b','r'],yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # [[./gif/20sep3_20sep2_B0_cycle_perf_compareB.png]]
look pretty similar ... 

weights?
clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20sep3_20sep2_A0_cycle_all_avg_weight.png]]
these weights are going up much more broadly - does that support the idea that the topological connectivity is an effective strategy
to allow only the right weights to change?

fig=animInput(InputImages,gifpath()+'_input.mp4') # gif/20sep3_20sep2_B0_cycle__input.mp4

this one seems to perform better overall as the sim progresses ... has examples of returning the ball a few times in a row

probably worth continuing both of these sims for further testing ... 

with weight norm at beginning ... 

    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20sep2_B0_cycle_synWeights_final.pkl"
    },
        "name": "20sep3_B1_cycle_",
	"normalizeWeightsAtStart": 1,
    "architecturePreMtoM": {
        "useProbabilistic": 1,
        "useTopological": 0
    },
python multistepSim.py sn.json 32 10 20sep3_B1_cycle_multi
started ~12:08 ... 

    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20sep2_A0_cycle_synWeights_final.pkl"
    },
        "name": "20sep3_A1_cycle_",
	"normalizeWeightsAtStart": 1,
    "architecturePreMtoM": {
        "useProbabilistic": 0,
        "useTopological": 1
    },
python multistepSim.py sn.json 32 10 20sep3_A1_cycle_multi
started ~12:10 ...

* 20sep4
** stopped topo sims 20sep3_A1_cycle_multi, since did not look like improving
** check output from 20sep3_B1_cycle_multi

python -i simdat.py backupcfg/20sep3_B1_cycle__step_1_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20sep4_20sep3_B1_cycle__step_1_perf.png]]

looks ~flat during those 2000 s ... 


lfn = ['20sep2_B0_cycle_', '20sep3_B1_cycle__step_0_', '20sep3_B1_cycle__step_1_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20sep4_20sep3_B1_cycle__step_1_perf_all_steps_so_far.png]]
hmm, performance degrading slowly after ~2000 s

lpda = getindivactionreward(lfn)
clf(); plotComparePerf(lpda,['g','b','r'],yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # [[./gif/20sep4_20sep3_B1_cycle__step_1_perf_compareB.png]]
yes, perf getting worse ... need to understand if/why that's really occurring ... could be perf
differs in diff contexts

** only transfer weights periodically?

used in anns to promote stabiltiy (two networks)

* 20sep8
** check output

python -i simdat.py backupcfg/20sep3_B1_cycle__step_9_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20sep8_20sep3_B1_cycle__step_9_perf.png]]

lfn = ['20sep2_B0_cycle_', '20sep3_B1_cycle__step_0_', '20sep3_B1_cycle__step_1_']
for i in range(2,10,1): lfn.append('20sep3_B1_cycle__step_'+str(i)+'_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20sep8_20sep3_B1_cycle__step_9_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)

csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]

clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # [[./gif/20sep8_20sep3_B1_cycle__step_9_perf_compareB.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig(gifpath()+'rast.png') # [[./gif/20sep8_20sep3_B1_cycle__step_9_rast.png]]

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20sep8_20sep3_B1_cycle__step_9__input.mp4]]

** ha fixed padding
* 20sep24 - updates
** something still wrong with padding - HA dropping for now

make sure to set
	"useNeuronPad": 0,

he mentioned had only ~25% of V neurons projecting to M

** Had discussions with HA about multiple layers in V and M to produce more complex representations
and whether that could improve performance
** some code from Hananel using bindsnet to replicate circuitry - will discuss 

nki_network_v2.py
nki.v3.py

requires pytorch

** HA added more options for controlling which connections use RL
** HA working on verifying connectivity/positions of cells
since implicit representations are more difficult to debug will
plan to have a list of
cell ID, cell type, x location, y location, presynaptic IDs, postsynaptic IDs

visualization would be useful too 

** test net - have some V4, IT, and VisualRL 

adjusted some conn params

./myrun 32 sn.json

running for 1e3 s ... 

started ~16:53 ... 
finished @ ~03:16

* 20sep25
** check output from 20sep24_A0_cycle_

python -i simdat.py backupcfg/20sep24_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20sep25_20sep24_A0_cycle_perf.png]]
hmm, nothing improved ... had targetted RL off ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/20sep25_20sep24_A0_cycle_rast.png]]
had VisualRL turned on ... EMT, IMT fired 0 times ... ?? 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EV4','EMT'],lclr=['r','b','g','c'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20sep25_20sep24_A0_cycle_all_avg_weight.png]]

pdf.columns # Index(['time', 'preid', 'postid', 'weight'], dtype='object')

pdfs = pdf[(pdf.postid>=dstartidx['EV4'])&(pdf.postid<=dendidx['EV4'])]
len(pdfs) # 0

hmm, EV4 weights not recorded ... 

dconf['net']['VisualRL'] # False

dconf['net']['RLconns']['VisualRL'] # 1

had wrong test in sim.py: if dconf['net']['VisualRL']
should now be if dconf['net']['RLconns']['VisualRL']

** adjust sim

20sep25_A0_cycle_

python -i simdat.py backupcfg/20sep25_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20sep25_20sep25_A0_cycle_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EV4','EMT'],lclr=['r','b','g','c'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'])

** targetted RL 

is it same as backprop with one output layer (M) ? 
works OK as long as have one known output layer, but does not work when neuron/synapse has distance > 1 away from output

* 20sep26
** check output from 20sep25_A0_cycle_ & continue

python -i simdat.py backupcfg/20sep25_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20sep26_20sep25_A0_cycle_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/20sep26_20sep25_A0_cycle_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EV4','EMT'],lclr=['r','b','g','c'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20sep26_20sep25_A0_cycle_all_avg_weight.png]]
some of those EMT weights going towards max, could in limit ... 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=(990e3,1000e3))
savefig('gif/'+dstr+simstr+'Vm.png') # [[./gif/20sep26_20sep25_A0_cycle_Vm.png]]

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20sep26_20sep25_A0_cycle__input.mp4]]
in the mp4 seems to reach towards ball sometimes ... and makes some hits as well ...

some improvement in performance? despite not using targetted RL ... no harm continuing ...   



        "name": "20sep26_A1_cycle_",
	"normalizeWeightsAtStart": 1,
    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20sep25_A0_cycle_synWeights_final.pkl"
    },

increase RL, AMPA :             "wmax": 0.0006,

can run a multistep of 1000 s duration ... 
each took ~12 hours ... try 5 steps ... 

python multistepSim.py sn.json 32 5 20sep26_A1_cycle_multi

started ~23:38 ...

normalizing adjustable weights at start sim.rank= 0 davg: {'EMUP':
0.00020867031962702758, 'EMDOWN': 0.00020779394768806876, 'EV1':
5.167277828040315e-05, 'EV1DE': 2.2232877148600918e-05, 'EV1DNE':
0.00012805242663008963, 'EV1DN': 0.00012180793988897896, 'EV1DNW':
5.090969168689469e-05, 'EV1DW': 2.467512832385895e-05, 'EV1DSW':
3.992928171723875e-05, 'EV1DS': 0.00013136003806881182, 'EV1DSE':
0.00013527005146831366, 'EV4': 0.0003537733672259636, 'EMT':
0.0004743774372884642} dfctr: {'EMUP': 0.19994613911988296, 'EMDOWN':
0.19994613911988296, 'EV1': 0.19994613911988296, 'EV1DE':
0.19994613911988296, 'EV1DNE': 0.19994613911988296, 'EV1DN':
0.19994613911988296, 'EV1DNW': 0.19994613911988296, 'EV1DW':
0.19994613911988296, 'EV1DSW': 0.19994613911988296, 'EV1DS':
0.19994613911988296, 'EV1DSE': 0.19994613911988296, 'EV4':
0.19994613911988296, 'EMT': 0.19994613911988296}

* 20sep29
** check output from last multistep (no targetted RL, recurrent, visual, feedback conn and RL at those synapses)

python -i simdat.py backupcfg/20sep26_A1_cycle__step_3_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20sep29_20sep26_A1_cycle__step_3_perf.png]]

strange-looking performance...

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png')
[
h#

##333




[[./gif/20sep29_20sep26_A1_cycle__step_3_rast.png]]
network becomes hyperexcitable

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EV4','EMT'],lclr=['r','b','g','c'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20sep29_20sep26_A1_cycle__step_3_all_avg_weight.png]]
weights going up - then after ~200 s they get so high that leads to hyperexcit. but starting weight values seem to promote getting stuck
at a certain position - see that no hits close to when the hyperexcit emerges.

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'],tlim=(990e3,1000e3))
savefig(gifpath()+'Vm.png') # [[./gif/20sep29_20sep26_A1_cycle__step_3_Vm.png]]
note that no dep blockade

# fig=animInput(InputImages,gifpath()+'_input.mp4') # 


lfn = ['20sep25_A0_cycle_','20sep26_A1_cycle__step_0_','20sep26_A1_cycle__step_1_','20sep26_A1_cycle__step_2_','20sep26_A1_cycle__step_3_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.5))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20sep29_20sep26_A1_cycle__step_3_perf_all_steps_so_far.png]]
so perf was increasing but then in middle of step 0 of the multistep it started getting worse ... maybe due to hyperexcit

lpda = getindivactionreward(lfn)

csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]

clf(); plotComparePerf(lpda,lclr,yl=(0,0.5),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # [[./gif/20sep29_20sep26_A1_cycle__step_3_perf_compareB.png]]

** adjust net - to reduce hyperexcit

        "name": "20sep29_A0_cycle_",

could use ~same params but have weight norm every 300 s ... 
to check if that helps/is the issue

    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20sep25_A0_cycle_synWeights_final.pkl"
    },

        "normalizeWeightStepSize": 15000,
	"normalizeWeightsAtStart": 1,

./myrun 32 sn.json

started ~12:12 ... 

sim.rank= 0 davg: {'EMUP': 0.00020867031962702758, 'EMDOWN':
0.00020779394768806876, 'EV1': 5.167277828040315e-05, 'EV1DE':
2.2232877148600918e-05, 'EV1DNE': 0.00012805242663008963, 'EV1DN':
0.00012180793988897896, 'EV1DNW': 5.090969168689469e-05, 'EV1DW':
2.467512832385895e-05, 'EV1DSW': 3.992928171723875e-05, 'EV1DS':
0.00013136003806881182, 'EV1DSE': 0.00013527005146831366, 'EV4':
0.0003537733672259636, 'EMT': 0.0004743774372884642} dfctr: {'EMUP':
0.19994613911988296, 'EMDOWN': 0.19994613911988296, 'EV1':
0.19994613911988296, 'EV1DE': 0.19994613911988296, 'EV1DNE':
0.19994613911988296, 'EV1DN': 0.19994613911988296, 'EV1DNW':
0.19994613911988296, 'EV1DW': 0.19994613911988296, 'EV1DSW':
0.19994613911988296, 'EV1DS': 0.19994613911988296, 'EV1DSE':
0.19994613911988296, 'EV4': 0.19994613911988296, 'EMT':
0.19994613911988296}

** other sim (20sep29_B0_cycle_)

should aim for lower excitability

        "name": "20sep29_B0_cycle_",

python -i simdat.py backupcfg/20sep29_B0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20sep29_20sep29_B0_cycle_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((390e3,400e3))
savefig(gifpath()+'rast.png') # [[./gif/20sep29_20sep29_B0_cycle_rast.png]]

gets hyperexcitable again ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EV4','EMT'],lclr=['r','b','g','c'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20sep29_20sep29_B0_cycle_all_avg_weight.png]]

EMT and EV4 weights going up too high ... may want stronger inhibition in those layers, if EV4, EMT start with higher AM weights ... 

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20sep29_20sep29_B0_cycle__input.mp4]]

** other sim (20sep29_C0_cycle_) - see if hyperexcit a factor by checking with weight norm

try same as 20sep29_B0_cycle_ but with weight norm every 40 s ... 

./myrun 32 sn.json

* 20sep30
** check output from 20sep29_C0_cycle_ -->> no better


python -i simdat.py backupcfg/20sep29_C0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20sep30_20sep29_C0_cycle_perf.png]]
the norm had very little impact on learning ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((390e3,400e3))
savefig(gifpath()+'rast.png') # [[./gif/20sep30_20sep29_C0_cycle_rast.png]]
firing rates are better ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EV4','EMT'],lclr=['r','b','g','c'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20sep30_20sep29_C0_cycle_all_avg_weight.png]]
interesting pattern ... 

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20sep30_20sep29_C0_cycle__input.mp4]] 

** next sim (20sep30_A0_cycle_) -->> nothing special there

./myrun 32 sn.json

python -i simdat.py backupcfg/20sep30_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((390e3,400e3))
savefig(gifpath()+'rast.png') 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EV4','EMT'],lclr=['r','b','g','c'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') 

** bazh

2017

stdp in earlier layers then rl stdp in output layers

** added options to use STDP separate from RL 

controlled in sn.json and sim.py (should add to sim.json too)

e.g.
    "STDP": {
        "AMPA": {
            "wbase": 1e-09,
            "wmax": 0.00032,
            "RLon": 0,
	    "STDPon": 1,
            "RLlenhebb": 500,
            "RLlenanti": 500,
            "useRLexp": 1,
            "RLhebbwt": 0.0,
            "RLantiwt": 0.0,
            "hebbwt": 1e-06,
            "antiwt": -1e-06,
            "tauhebb": 10,
	    "tauanti": 10,
            "RLwindhebb": 50,
            "softthresh": 0,
            "verbose": 0
        },
        "NMDA": {
            "wbase": 1e-06,
            "wmax": 7.5e-05,
            "RLon": 0,
	    "STDPon": 0,
            "RLlenhebb": 800,
            "RLlenanti": 100,
            "useRLexp": 1,
            "RLhebbwt": 0.0,
            "RLantiwt": -0.0,
            "hebbwt": 0,
            "antiwt": 0,
            "tauhebb": 10,
	    "tauanti": 10,	    
            "RLwindhebb": 50,
            "softthresh": 0,
            "verbose": 0
        }
    },
    "RL": {
        "AMPA": {
            "wbase": 1e-09,
            "wmax": 0.00032,
            "RLon": 1,
	    "STDPon": 0,
            "RLlenhebb": 500,
            "RLlenanti": 500,
            "useRLexp": 1,
            "RLhebbwt": 1e-06,
            "RLantiwt": -1e-06,
            "hebbwt": 0,
            "antiwt": 0,
            "tauhebb": 10,
            "RLwindhebb": 50,
            "softthresh": 0,
            "verbose": 0
        },
        "NMDA": {
            "wbase": 1e-06,
            "wmax": 7.5e-05,
            "RLon": 0,
	    "STDPon": 0,
            "RLlenhebb": 800,
            "RLlenanti": 100,
            "useRLexp": 1,
            "RLhebbwt": 4e-06,
            "RLantiwt": -0.0,
            "hebbwt": 0,
            "antiwt": 0,
            "tauhebb": 10,
            "RLwindhebb": 50,
            "softthresh": 0,
            "verbose": 0
        }
    },

and

        "STDPconns":{
	    "EIPlast":0,
            "Visual":1,
            "RecurrentDirNeurons":1,
            "RecurrentLocNeurons":1,
            "FeedForwardDirNtoM":0,
            "FeedForwardLocNtoM":0,
            "FeedbackLocNeurons":1,
            "RecurrentMNeurons":0,
            "FeedbackMtoDirN":1,
            "FeedbackMtoLocN":1
        },		
        "RLconns":{
	    "EIPlast":0,
            "Visual":0,
            "RecurrentDirNeurons":0,
            "RecurrentLocNeurons":0,
            "FeedForwardDirNtoM":1,
            "FeedForwardLocNtoM":1,
            "FeedbackLocNeurons":0,
            "RecurrentMNeurons":1,
            "FeedbackMtoDirN":0,
            "FeedbackMtoLocN":0
        },	

** try sim with STDP and STDPRL separate for diff conns

could run in same sequence as bazh with stdp first and then stdpRL onto M neurons
or do both together to test ... 

./myrun 32 sn.json

python -i simdat.py backupcfg/20sep30_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20sep30_20sep30_A0_cycle_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((390e3,400e3))
savefig(gifpath()+'rast.png') # [./gif/20sep30_20sep30_A0_cycle_rast.png]] 

rates went down too much, due to LTD

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EV4','EMT'],lclr=['r','b','g','c'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # ./gif/20sep30_20sep30_A0_cycle_all_avg_weight.png]]
[[./gif/20sep30_20sep30_A0_cycle_all_avg_weightB.png]]

EMT, EV4 weights went down, EMUP, EMDOWN weights went up ... 

direction selective neuron weights must have decreased too?

so as setup here, STDP not helpful ... 

* 20oct1
** check output from prev sim (20sep30_B0_cycle_)

adjusted some of the weights to get more activity ... 

python -i simdat.py backupcfg/20sep30_B0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct1_20sep30_B0_cycle_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((390e3,400e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct1_20sep30_B0_cycle_rast.png]]
but EMT,IMT still not active

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EV4','EMT','EV1DN'],lclr=['r','b','g','c','m'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct1_20sep30_B0_cycle_all_avg_weight.png]]
savefig(gifpath()+'all_avg_weightB.png') # [[./gif/20oct1_20sep30_B0_cycle_all_avg_weightB.png]]

main problem is not getting much firing from EMT

** next sim (20oct1_A0_cycle_)

python -i simdat.py backupcfg/20oct1_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct1_20oct1_A0_cycle_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((90e3,100e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct1_20oct1_A0_cycle_rast.png]]
firing rates are too sparse ... so the weight scaling rule should help

#clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EV4','EMT','EV1DN'],lclr=['r','b','g','c','m'],plotindiv=True)
#xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
#savefig(gifpath()+'all_avg_weight.png') 
#savefig(gifpath()+'all_avg_weightB.png') 

** weight norm in sim.py only works for EM populations

was not setup for other populations so even to use that with plast in other pathways requires adjustment

** add simple cell based weight norm (20oct1_B0_cycle_) (CellWNorm==1)

python -i simdat.py backupcfg/20oct1_B0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct1_20oct1_B0_cycle_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((90e3,100e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct1_20oct1_B0_cycle_rast.png]] 


clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EV4','EMT','EV1DN'],lclr=['r','b','g','c','m'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct1_20oct1_B0_cycle_all_avg_weight.png]]

looks like mostly working - something strange going on with EMT weights in the beginning ... 

note that this operates on individual cell basis; to keep total weight constant ... and had set it to occur every 1000 ms ... 

it uses the initial weights as target ... so some individual weights can go up, others down, but sum remains ~constant 

but question is whether this will help ... 

also note that had low weightVar here (only 0.1) . . .

* 20oct2
** longer sim with CellWNorm==1; 20oct1_B0_cycle_

put weightVar back to 0.5

and with new cell-based weight norm every 1 s ... 

./myrun 32 sn.json

python -i simdat.py backupcfg/20oct1_B0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct2_20oct1_B0_cycle_perf.png]]
similar to some of the older sims ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct2_20oct1_B0_cycle_rast.png]]
decent rates at the end, but note that they vary by population - so using HA's new rule may
require adjustment to target diff rates to each pop

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EV4','EMT'],lclr=['r','b','g','c','m'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct2_20oct1_B0_cycle_all_avg_weight.png]]
so that seems to work ... 

ok, so weigths staying ~flat ... 

tt = np.unique(pdf.time)

dout = getpopinputmap(pdf, tt[0], dnumc, dstartidx, dendidx, 'EMDOWN')
clf(); plotallinputmaps(pdf,tt[0],dstartidx['EMDOWN'],'EMDOWN',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig(gifpath()+'EMDOWN_inputmap_first.png') # [[./gif/20oct2_20oct1_B0_cycle_EMDOWN_inputmap_first.png]]

dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMDOWN')
clf(); plotallinputmaps(pdf,tt[-1],dstartidx['EMDOWN'],'EMDOWN',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig(gifpath()+'EMDOWN_inputmap_last.png') # [[./gif/20oct2_20oct1_B0_cycle_EMDOWN_inputmap_last.png]]

not as much difference in input maps from start to end ... probably because the constraint on weights is too tight ... ? 
and that prevents some learning ... ? 

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20oct2_20oct1_B0_cycle__input.mp4]]

** check HA's new homeostasis rule

it uses firing rates to normalize weights

adjusted to allow setting min, max thresholds of firing rate used for weight adjustment

not clear why the 2017 paper uses dshift (fixed increment) instead of scaling by more or less depending
on how far from target rate

and why smaller interval for adjusting synaptic weights, compared to adjusting the target weights based on firing rates?
does that promote stability??

try it out ... 

keeping the EV1 and direction neuron min rate ~0.25 and up to 5 Hz
for EV4,EMT,EMUP,EMDOWN min rate of 1, and max rate of 5,6 Hz

        "name": "20oct2_A0_cycle_",

started ~17:58 ...
finished ~20:59 ...

python -i simdat.py backupcfg/20oct2_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct2_20oct2_A0_cycle_perf.png]]
looks pretty bad . . . 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((190e3,200e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct2_20oct2_A0_cycle_rast.png]]
rates are all reasonably low

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EV4','EMT'],lclr=['r','b','g','c','m'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct2_20oct2_A0_cycle_all_avg_weight.png]]

tt = np.unique(pdf.time)

dout = getpopinputmap(pdf, tt[0], dnumc, dstartidx, dendidx, 'EMDOWN')
clf(); plotallinputmaps(pdf,tt[0],dstartidx['EMDOWN'],'EMDOWN',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig(gifpath()+'EMDOWN_inputmap_first.png') # [[./gif/20oct2_20oct2_A0_cycle_EMDOWN_inputmap_first.png]]

dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMDOWN')
clf(); plotallinputmaps(pdf,tt[-1],dstartidx['EMDOWN'],'EMDOWN',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig(gifpath()+'EMDOWN_inputmap_last.png') # [[./gif/20oct2_20oct2_A0_cycle_EMDOWN_inputmap_last.png]]

## fig=animInput(InputImages,gifpath()+'_input.mp4') 

** found bug after changes to homPlast code, have to rerun

bug was that did not use the updated datastructures properly ... 

also noticed that if not careful, could have modified the stimMod weights which are also AMPA ...
so now checking for hSTDP in conns ... 

also added rule that if dshift == 0, should scale weights by the factor of desired, current rates 
rather than default, which is an arbitrary tiny dshift value on the weights ... 

./myrun 32 sn.json

started ~22:55 ... 

hmm, something messed up ... have to fix

** adjusted the CellWNorm to have min, max factors as well 

normalizes weight to boundaries of 
minFactor * initialWeight, and maxFactor * initialWeight
when weight falls below minFactor*initialWeight or above maxFactor*initialWeight

        "name": "20oct2_C0_cycle_",

keeping within range of 1X original weight and 3X original weight (sum)

./myrun 32 sn.json

started ~23:37 ... 

* 20oct3
** check 20oct2_C0_cycle_ 

finished at 14:15 ... 

python -i simdat.py backupcfg/20oct2_C0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct3_20oct2_C0_cycle_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct3_20oct2_C0_cycle_rast.png]]
firing rates appear close to original levels ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN'],lclr=['r'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct3_20oct2_C0_cycle_all_avg_weight.png]]
those weights look mostly flat ... not increasing to ~3X initial ... 
does that mean 2 s intervals for normalizing weights is too small?
or ... not measuring weights often enough to see increase and reset ... 

pdfs = pdf[(pdf.postid==dstartidx['EMDOWN'])&(pdf.preid==dstartidx['EV1DSW']+1)]
len(pdfs) # 100

plot(pdfs.time,pdfs.weight)
savefig(gifpath()+'single_weightA.png') # [[./gif/20oct3_20oct2_C0_cycle_single_weightA.png]]
so that weight is increasing ... 

pdfs = pdf[(pdf.postid==dstartidx['EMDOWN'])&(pdf.preid>=dstartidx['EV1DSW'])&(pdf.preid<=dendidx['EV1DSW'])]
len(pdfs) # 12000

plot(pdfs.time,pdfs.weight,'ko')
savefig(gifpath()+'many_weightA.png') # [[./gif/20oct3_20oct2_C0_cycle_many_weightA.png]]

can look at individual weights and see if there are trends, indicating whether the pathway is 'useful'
e.g. if weights are going down, that means weights not useful ... 
prety = 'EMDOWN'; poty = 'EMUP'
pdfs = pdf[(pdf.postid==dstartidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
clf(); plot(pdfs.time,pdfs.weight,'ko')

#
prety = 'EMDOWN'; poty = 'EMUP'
for pdx,prety in enumerate(['EV1', 'EV4', 'EMT', 'EV1DN', 'EV1DS', 'EV1DNW']):
  subplot(3,2,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid==dstartidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.weight,'ko')

savefig(gifpath()+'many_weightB.png') # [[./gif/20oct3_20oct2_C0_cycle_many_weightB.png]]

EMT weights -> EMUP generally going down, others mixed ... 

EV1 seems more useful, EV4 less (more going down), and EMT even less useful (all seem to decrease)
and this sim was without topological conn for EV4 and EMT ... 

so may need to keep topology in EV4 and EMT ... 

#
clf()
poty = 'EMT'
for pdx,prety in enumerate(['EV4', 'EMT', 'EMUP','EMDOWN']):
  subplot(2,2,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid==dstartidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.weight,'ko')

savefig(gifpath()+'many_weightC.png') # [[./gif/20oct3_20oct2_C0_cycle_many_weightC.png]]

some going up, some down ... some stuck at ceiling ... 

could raise max weight, max weight factor for norm, and also try longer interval between normalization ... 

ok, run that in 
        "name": "20oct3_A0_cycle_",
	"CellWNorm": {
	    "On": 1,
	    "MinFctr": 1.0,
	    "MaxFctr": 10.0
	},
            "wmax": 0.0005,
        "normalizeWeightStepSize": 250,

./myrun 32 sn.json

started ~23:52 ... 

if output looks ~same, might indicate these reward weights not driving
network towards epilepsy, and normalization params not critical yet ... 

* 20oct4
** check output from 20oct3_A0_cycle_

finished ~14:11 ... 

python -i simdat.py backupcfg/20oct3_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') #  [[./gif/20oct4_20oct3_A0_cycle_perf.png]]
perf looks pretty flat ...

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct4_20oct3_A0_cycle_rast.png]]
and the rates are similar to last run ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN'],lclr=['r'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct4_20oct3_A0_cycle_all_avg_weight.png]]
also looks similar to last run ...

pdfs = pdf[(pdf.postid==dstartidx['EMDOWN'])&(pdf.preid==dstartidx['EV1DSW']+1)]
len(pdfs) # 100

plot(pdfs.time,pdfs.weight)
savefig(gifpath()+'single_weightA.png') # [[./gif/20oct4_20oct3_A0_cycle_single_weightA.png]]

pdfs = pdf[(pdf.postid==dstartidx['EMDOWN'])&(pdf.preid>=dstartidx['EV1DSW'])&(pdf.preid<=dendidx['EV1DSW'])]
len(pdfs) # 12000

plot(pdfs.time,pdfs.weight,'ko')
savefig(gifpath()+'many_weightA.png') # [[./gif/20oct4_20oct3_A0_cycle_many_weightA.png]]

prety = 'EMDOWN'; poty = 'EMUP'
pdfs = pdf[(pdf.postid==dstartidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
clf(); plot(pdfs.time,pdfs.weight,'ko')

#
prety = 'EMDOWN'; poty = 'EMUP'
for pdx,prety in enumerate(['EV1', 'EV4', 'EMT', 'EV1DN', 'EV1DS', 'EV1DNW']):
  subplot(3,2,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid==dstartidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.weight,'ko')

savefig(gifpath()+'many_weightB.png') # [[./gif/20oct4_20oct3_A0_cycle_many_weightB.png]]

#
clf()
poty = 'EMT'
for pdx,prety in enumerate(['EV4', 'EMT', 'EMUP','EMDOWN']):
  subplot(2,2,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid==dstartidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.weight,'ko')

savefig(gifpath()+'many_weightC.png') # [[./gif/20oct4_20oct3_A0_cycle_many_weightC.png]]

these are the existing reward/punish values:
        "scorePoint": 1.0,
        "losePoint": -1.0,
        "followTarget": 0.1,
        "avoidTarget": -0.1,
        "hitBall": 0.5

...try same but with older reward scores to see if lack of improvement due to too much punishment...
scorePoint = 1, losePoint = -0.1, followTarget = 0.1, avoidTarget = -0.01, hitBall = 0.5 ... 

        "name": "20oct4_A0_cycle_",
    "rewardcodes": {
        "scorePoint": 1.0,
        "losePoint": -0.1,
        "followTarget": 0.1,
        "avoidTarget": -0.01,
        "hitBall": 0.5
    },

./myrun 32 sn.json

started ~21:44 ...

* 20oct5 
** check output from 20oct4_A0_cycle_

finished at ~11:34

python -i simdat.py backupcfg/20oct4_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct5_20oct4_A0_cycle_perf.png]]
this one looks better than previous ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct5_20oct4_A0_cycle_rast.png]]
still not much firing ... intermittent gaps in activity of both EM populations...probably occur when ball off screen and no motion input
yeah, that seems to be the case - note the lack of EV1D activity at those times of no EMUP,EMDOWN firing

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN'],lclr=['r'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct5_20oct4_A0_cycle_all_avg_weight.png]]
now the weights are going up and still have a lot of room to increase before hit limit where normalization kicks in ... 

#
prety = 'EMDOWN'; poty = 'EMUP'
for pdx,prety in enumerate(['EV1', 'EV4', 'EMT', 'EV1DN', 'EV1DS', 'EV1DNW','EMUP','EMDOWN']):
  subplot(2,4,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid==dstartidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.weight,'ko')

savefig(gifpath()+'many_weightB.png') # [[./gif/20oct5_20oct4_A0_cycle_many_weightB.png]]
now weights going up more ... from diff populations

#
clf()
poty = 'EMT'
for pdx,prety in enumerate(['EV4', 'EMT', 'EMUP','EMDOWN']):
  subplot(2,2,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid==dstartidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.weight,'ko')

savefig(gifpath()+'many_weightC.png') # [[./gif/20oct5_20oct4_A0_cycle_many_weightC.png]]

** sanda 2017 also has output balancing

output balancing same as constraining firing rates via homeostatic scaling? 
could also implement with mutual inhib from one output pop to other output pop 

"Thus,foreachmiddle-layercell,incrementsofthestrengthofoutgoingsynapsesresultingfromrewarded
STDPeventsweredividedbytheratioofthecurrentsumofsynapticoutputstotheinitialsumofsynapticoutputs
ofthesamecells(seeMethods).Theresultwasthatsynapsesoriginatingfromtheneuronswithmanystrongoutputs
werenotabletoincreasetheirsynapticstrengthasquicklyassynapsesfromtheneuronswitha
weakoutput.This gave a competitiveadvantagetothelaterneurons.It
helpedtocontrolsynapticoutput,"

so reward/punishment values scaled inversely by total input to the neuron 

that sounds similar to the soft threshold rule ... but operates across all input synapses
rather than individual synapse

suggested that could be achieved by reciprocal inhibition between output neuron populations:
"Output-sidebalancingallowedonlysynapsescorrelatedwithrewardtobestrengthenedviarewardedSTDPtraces.
Whilewedonotknowdirectexperimentalevidenceforthismechanism,a similareffectcanbepotentiallyachieved
bymorecomplexcircuitsinvolvingreciprocalinhibitionbetweenoutputneurons."

that seems worth/easy trying

also talked about importance of feedforward inhibition between layers, for preventing
runaway activity and high variability in output

** some adjustments - try reciprocal inhibition between EMUP and EMDOWN

also keeping IM population to provide some balance and not to allow EMUP or EMDOWN
to dominate too much - that's what seems to happen w/o IM (that gets inputs from both
EMUP and EMDOWN and projects to both - providing feedback inhib); IMUP and IMDOWN, in contrast
receive inputs from one population and project only to the other ... after an initial run, there
does seem to be clearer negative correlation between EMUP and EMDOWN firing activity ... to be
seen if that's helpful; could also put in EIPLAST to regulate ... 

also removed excitatory connections between the two dfferent EM populations ... 

        "name": "20oct5_A0_cycle_",

./myrun 32 sn.json

started 1000 s run ~15:08 ... 

paddle seems to go too far in either direction - may partially be due to the reciprocal
inhibition, since once one population starts firing, it suppresses the other, so there's a
loss of balance ... EI plasticity might help avoid that ... 

** lower activation to IMDOWN, IMUP ?  + EIPlast

        "name": "20oct5_B0_cycle_",

./myrun 32 sn.json

started ~23:25 ... 

python -i simdat.py backupcfg/20oct5_B0_cycle_sim.json

pdfs = pdf[(pdf.postid==dstartidx['IMUP'])]
len(pdfs) # 6
plot(pdfs.time,pdfs.weight,'ko')

* 20oct6
** check output from 20oct5_A0_cycle_

finished at ~7 AM

python -i simdat.py backupcfg/20oct5_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct6_20oct5_A0_cycle_perf.png]]
overall performance is worse

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct6_20oct5_A0_cycle_rast.png]]
low rates for EMUP,EMDOWN; can see out of phase firing with EMUP and EMDOWN

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN'],lclr=['r'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct6_20oct5_A0_cycle_all_avg_weight.png]]
average is mostly flat, as should be with the indiv cell weight norm

#
prety = 'EMDOWN'; poty = 'EMUP'
for pdx,prety in enumerate(['EV1', 'EV4', 'EMT', 'EV1DN', 'EV1DS', 'EV1DNW','EMUP','EMDOWN']):
  subplot(2,4,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid==dstartidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.weight,'ko')

savefig(gifpath()+'many_weightB.png') # [[./gif/20oct6_20oct5_A0_cycle_many_weightB.png]]
many going up, many down

#
clf()
poty = 'EMT'
for pdx,prety in enumerate(['EV4', 'EMT', 'EMUP','EMDOWN']):
  subplot(2,2,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid==dstartidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.weight,'ko')

savefig(gifpath()+'many_weightC.png') # [[./gif/20oct6_20oct5_A0_cycle_many_weightC.png]]

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20oct6_20oct5_A0_cycle__input.mp4]]

** counteracting over-reach

it's good that individual populations of EM neurons can now drive motion further
but would be useful to counteract overreach ... can do that in a few ways. testing one
in EIPLAST above (20oct5_B0_cycle_). could also use EMSTAY or restore connectivity between
EMUP and EMDOWN ... 

        "name": "20oct6_A0_cycle_",

try this for 1000 s too ...

./myrun 32 sn.json

started ~16:52 ... 

** py_broadcast, broadcast problems

broadcast and py_broadcast sometimes producing wrong-sized array on destination

had to use pyalltoall to get right size when including EMSTAY and IMSTAY populations

** check output from 20oct5_B0_cycle_ (has EIPLAST)

python -i simdat.py backupcfg/20oct5_B0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct6_20oct5_B0_cycle_perf.png]]
seems a little better ... than previous with no EIPLAST but reciprocal inhib (20oct5_A0_cycle_ [[./gif/20oct6_20oct5_A0_cycle_perf.png]])

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct6_20oct5_B0_cycle_rast.png]]
EMUP,EMDOWN no longer as much out of phase ... and have much higher rates than [[./20oct6_20oct5_A0_cycle_rast.png]]
the higher EMUP,EMDOWN rates due to lower firing of IM,IMUP,IMDOWN which changed due to EIPLAST

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN'],lclr=['r'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct6_20oct5_B0_cycle_all_avg_weight.png]]

#
poty = 'EMUP'
for pdx,prety in enumerate(['EV1', 'EV4', 'EMT', 'EV1DN', 'EV1DS', 'EV1DNW','EMUP','EMDOWN']):
  subplot(2,4,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid==dstartidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.weight,'ko')

savefig(gifpath()+'many_weightB.png') # [[./gif/20oct6_20oct5_B0_cycle_many_weightB.png]]

#
clf()
pdx=0
for prety,poty in zip(['EMDOWN','EMDOWN','EMUP','EMUP'],['IMUP','IM','IMDOWN','IM']):
  subplot(2,2,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid>=dstartidx[poty])&(pdf.postid<=dendidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  tt = np.unique(pdfs.time)
  lw = []
  for t in tt:
    pdfs2 = pdfs[(pdfs.time==t)]
    lw.append(np.mean(pdfs.weight))
  plot(tt,lw,'k')
  pdx+=1

savefig(gifpath()+'many_avgIB.png') # [[./gif/20oct6_20oct5_B0_cycle_many_avgIB.png]]
hmm, avg weights onto interneurons not changing ... ??

#
clf()
pdx=0
for prety,poty in zip(['EMDOWN','EMDOWN','EMUP','EMUP'],['IMUP','IM','IMDOWN','IM']):
  subplot(2,2,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid==dstartidx[poty]+1)&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])&(pdf.postid==dstartidx[poty]+1)]
  plot(pdfs.time,pdfs.weight,'ko')
  pdx+=1


#
clf()
poty = 'EMT'
for pdx,prety in enumerate(['EV4', 'EMT', 'EMUP','EMDOWN']):
  subplot(2,2,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid==dstartidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.weight,'ko')

savefig(gifpath()+'many_weightC.png') # [[./gif/20oct6_20oct5_B0_cycle_many_weightC.png]]

## fig=animInput(InputImages,gifpath()+'_input.mp4') 

may as well continue this one for now ... since was doing best ... but need to check if EIPLAST working properly ... 

        "name": "20oct6_B1_cycle_",

    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20oct5_B0_cycle_synWeights_final.pkl"
    },

./myrun 32 sn.json

started ~16:45 ...

** multiple EDir layers?

ideally want some place where motion of different objects is integrated - while that happens
directly in EM populations, may want better coverage earlier too ... ?

also, should the middle layers have larger number of neurons (for more complex rep)
compared to earlier layers??

* 20oct7
** check output from 20oct6_B1_cycle_

python -i simdat.py backupcfg/20oct6_B1_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct7_20oct6_B1_cycle_perf.png]]
~flat, does not look better than prior step ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct7_20oct6_B1_cycle_rast.png]]
rates look ok - a little higher than before

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN'],lclr=['r'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct7_20oct6_B1_cycle_all_avg_weight.png]]

#
poty = 'EMUP'
for pdx,prety in enumerate(['EV1', 'EV4', 'EMT', 'EV1DN', 'EV1DS', 'EV1DNW','EMUP','EMDOWN']):
  subplot(2,4,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid==dstartidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.weight,'ko')

savefig(gifpath()+'many_weightB.png') # [[./gif/20oct7_20oct6_B1_cycle_many_weightB.png]]

#
clf()
pdx=0
for prety,poty in zip(['EMDOWN','EMDOWN','EMUP','EMUP'],['IMUP','IM','IMDOWN','IM']):
  subplot(2,2,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid>=dstartidx[poty])&(pdf.postid<=dendidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  tt = np.unique(pdfs.time)
  lw = []
  for t in tt:
    pdfs2 = pdfs[(pdfs.time==t)]
    lw.append(np.mean(pdfs.weight))
  plot(tt,lw,'k')
  pdx+=1

savefig(gifpath()+'many_avgIB.png') # [[./gif/20oct7_20oct6_B1_cycle_many_avgIB.png]]

#
clf()
pdx=0
for prety,poty in zip(['EMDOWN','EMDOWN','EMUP','EMUP'],['IMUP','IM','IMDOWN','IM']):
  subplot(2,2,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid==dstartidx[poty]+1)&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])&(pdf.postid==dstartidx[poty]+1)]
  plot(pdfs.time,pdfs.weight,'ko')
  pdx+=1

savefig(gifpath()+'many_IC.png') # [[./gif/20oct7_20oct6_B1_cycle_many_IC.png]]

#
clf()
poty = 'EMT'
for pdx,prety in enumerate(['EV4', 'EMT', 'EMUP','EMDOWN']):
  subplot(2,2,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid==dstartidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.weight,'ko')

savefig(gifpath()+'many_weightC.png') # [[./gif/20oct7_20oct6_B1_cycle_many_weightC.png]]

do not see the EIPLAST working ... ? 

lfn = ['20oct5_B0_cycle_','20oct6_B1_cycle_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.5))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20oct7_20oct6_B1_cycle_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
clf(); plotComparePerf(lpda,['g','b','r'],yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # [[./gif/20oct7_20oct6_B1_cycle_perf_compareB.png]]

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20oct7_20oct6_B1_cycle__input.mp4]]

** why EIPLAST not working?

        "name": "20oct7_A0_cycle_",


** how to backprop?

could look at connectome to determine what each neuron contributes to in terms of move
and use that to decide whether to reinforce/punish specific synapses ... so currently
targetted looks at first degree synapses onto the EM pops; could look at 2nd degree conns
and weight them a little elss; 3rd degree conns weight them less, etc. that way could
take into account more of the synapses ... 

but that still would only work for individual moves ... unless integrated multiple
moves and compared to correct sequence ... 

e.g. if need 3 moves up to get to ball and instead took 1 move up and 2 moves down
then reinforce the path that led to 1 move up and punish the part that led to 2 moves down

test in a simple way ... 20oct7_B0_cycle_

hmm, bug in hit detection, saw it happen 2x in very short interval:
t= 77800.0 - adjusting weights based on RL critic value: 0.5
t= 77800.0  game rewards: [0.5]
t= 78060.0 - adjusting weights based on RL critic value: 0.5
t= 78060.0  game rewards: [0.5]

only really occurred first time ... 

also had too short recording duration ... will retry

** check output from 20oct6_A0_cycle_ (has EMSTAY)

python -i simdat.py backupcfg/20oct6_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct7_20oct6_A0_cycle_perf.png]]
hmm, looks much worse

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct7_20oct6_A0_cycle_rast.png]]
well, the network became epileptic ... 

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20oct7_20oct6_A0_cycle__input.mp4]]

* 20oct8
** simpler test again

        "name": "20oct8_A0_cycle_",
        "targettedRL": 2,

    "rewardcodes": {
        "scorePoint": 0.0,
        "losePoint": -0.0,
        "followTarget": 0.1,
        "avoidTarget": -0.1,
        "hitBall": 0.0
    },

./myrun 32 sn.json

python -i simdat.py backupcfg/20oct8_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct8_20oct8_A0_cycle_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct8_20oct8_A0_cycle_rast.png]]

nothing special there ...

** check EIplast

maybe did not work since all weights started higher (0.02) than the max specified in AMPAI ...
and did not have any weight var in those E->I synapses

python -i simdat.py backupcfg/20oct8_B0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct8_20oct8_B0_cycle_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); 
savefig(gifpath()+'rast.png') # [[./gif/20oct8_20oct8_B0_cycle_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','IM'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct8_20oct8_B0_cycle_all_avg_weight.png]]
ok, good - now can see the weight changes to interneurons ...

subplot(2,1,1)
popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['IM'],lclr=['b'],plotindiv=True)
xlim((0,10e3))
subplot(2,1,2)
plot(actreward.time,actreward.reward,'k')
xlim((0,10e3))

savefig(gifpath()+'IM_wght_reward.png') # [[./gif/20oct8_20oct8_B0_cycle_IM_wght_reward.png]]
for some reason weights do not seem to go up even when have positive reward ... ??

subplot(2,1,1)
popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN'],lclr=['r'],plotindiv=True)
xlim((0,10e3))
subplot(2,1,2)
plot(actreward.time,actreward.reward,'k')
xlim((0,10e3))

savefig(gifpath()+'EMDOWN_wght_reward.png') # [[./gif/20oct8_20oct8_B0_cycle_EMDOWN_wght_reward.png]]

ok, can see more increases there for EMDOWN ... 
savefig(gifpath()+'EMDOWN_wght_rewardB.png') # [[./gif/20oct8_20oct8_B0_cycle_EMDOWN_wght_rewardB.png]]

so why for the interneurons do weights only decrease?

look at indiv weights again ... 

#
clf()
poty = 'IM'
for prety,clr in zip(['EMDOWN','EMUP'],['r','b']):
  pdfs = pdf[(pdf.postid>=dstartidx[poty])&(pdf.postid<=dstartidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.weight,clr+'o')

savefig(gifpath()+'IM_wght_C.png') # [[./gif/20oct8_20oct8_B0_cycle_IM_wght_C.png]]

ok, some weights can be seen increasing ... 

can put in the reciprocal inhibition again and see how that does ... 

should also have fewer interneurons when adding new pop...
	    "IM":13,
	    "IMUP": 13,
	    "IMDOWN": 13,

ok, try that ... keep cell-based weight norm on too ... 

./myrun 32 sn.json

started ~16:56 ...

* 20oct9
** check output from 20oct8_B0_cycle_

finished ~7 AM ... so took ~14 hours total

python -i simdat.py backupcfg/20oct8_B0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct9_20oct8_B0_cycle_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct9_20oct8_B0_cycle_rast.png]]

what are the firing rates over time?

pop = 'EMDOWN'
binsz = 20
tt,nspk = getspikehist(dspkT[pop],dnumc,binsz,100e3)
plot(tt,nspk); xlim((0,100e3))
savefig(gifpath()+'EMDOWN_rate20.png') # [[./gif/20oct9_20oct8_B0_cycle_EMDOWN_rate20.png]]

dnspk = {pop:nspk}
pop='EMUP'; dnspk['EMUP'] = getspikehist(dspkT[pop],dnumc,binsz,100e3)
plot(dnspk['EMUP'][0],dnspk['EMUP'][1],'r'); 
savefig(gifpath()+'EMUP_EMDOWN_rate20.png') # [[./gif/20oct9_20oct8_B0_cycle_EMUP_EMDOWN_rate20.png]]
ylim((0,25))
savefig(gifpath()+'EMUP_EMDOWN_rate20B.png') # [[./gif/20oct9_20oct8_B0_cycle_EMUP_EMDOWN_rate20B.png]]
xlim((90e3,100e3))
savefig(gifpath()+'EMUP_EMDOWN_rate20C.png') # [[./gif/20oct9_20oct8_B0_cycle_EMUP_EMDOWN_rate20C.png]]
rates look pretty correlated ... but that could provide some balance ... ? 
pearsonr(dnspk['EMUP'][1],dnspk['EMDOWN'][1])

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','IM'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct9_20oct8_B0_cycle_all_avg_weight.png]]
savefig(gifpath()+'all_avg_weightB.png') # [[./gif/20oct9_20oct8_B0_cycle_all_avg_weightB.png]]

what's cumulative reward vs time?
plot(actreward.time,actreward.reward)
plot(actreward.time,np.cumsum(actreward.reward))
savefig(gifpath()+'cumsumreward.png') # [[./gif/20oct9_20oct8_B0_cycle_cumsumreward.png]]
plot(actreward.time,np.cumsum(abs(actreward.reward)))
savefig(gifpath()+'cumsum_absreward.png') # [[./gif/20oct9_20oct8_B0_cycle_cumsum_absreward.png]]

** papers/discussions about catastrophic forgetting
** HA brainstorming gdoc: https://docs.google.com/document/d/1JqBesNhatOw2KF_aSdU_JhqIDQzBx7fFnm1RVi-Q8x0/edit

EWC - elastic weight
synaptic intelligence (ganguli)
xdg - unit gating - via inhibitory plasticity?
context signal (from pfc/ppc) - learned? how? HA suggests STDP ... sounds similar to bazhenov STDP -> RL

** importance signal in stdp.mod ?

so rate of learning will depend on previous reward/punishment values

so if a synapse receives a lot of reward then it should have lower probability of changing further (?)
      deltaw = deltaw * (1.0 - cumreward / maxreward)

    cumreward = cumreward + abs(reinf) : cumulative reward magnitude

could have different maxreward values for different cell/synapse pathways ...

python -i simdat.py backupcfg/20oct9_A0_cycle_sim.json

#
clf()
poty = 'IM'
for prety,clr in zip(['EMDOWN','EMUP'],['r','b']):
  pdfs = pdf[(pdf.postid>=dstartidx[poty])&(pdf.postid<=dstartidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  subplot(2,1,1); plot(pdfs.time,pdfs.weight,clr+'o')
  subplot(2,1,2); plot(pdfs.time,pdfs.cumreward,clr+'o')

savefig(gifpath()+'w_creward_a0.png') # [[./gif/20oct9_20oct9_A0_cycle_w_creward_a0.png]]

so all those synapses seem to have gotten same rewards ... 

note that it's abs of cum reward (so punishmenet signals will contribute too)

set higher max reward for the interneurons ... lower for E neurons ... 

ok ...

./myrun 32 sn.json

started ~16:54 ...

* 20oct10
** check output from 20oct9_A0_cycle_

finished at ~19:28

python -i simdat.py backupcfg/20oct9_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct10_20oct9_A0_cycle_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1490e3,1500e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct10_20oct9_A0_cycle_rast.png]]

pop = 'EMDOWN'
binsz = 20
tt,nspk = getspikehist(dspkT[pop],dnumc,binsz,1500e3)
plot(tt,nspk); xlim((0,1500e3))
savefig(gifpath()+'EMDOWN_rate20.png') # [[./gif/20oct10_20oct9_A0_cycle_EMDOWN_rate20.png]]

dnspk = {pop:nspk}
pop='EMUP'; dnspk['EMUP'] = getspikehist(dspkT[pop],dnumc,binsz,1500e3)
plot(dnspk['EMUP'][0],dnspk['EMUP'][1],'r'); 
savefig(gifpath()+'EMUP_EMDOWN_rate20.png') # [[./gif/20oct10_20oct9_A0_cycle_EMUP_EMDOWN_rate20.png]]

what's cumulative reward vs time?
plot(actreward.time,np.cumsum(actreward.reward))
savefig(gifpath()+'cumsumreward.png') 
plot(actreward.time,np.cumsum(abs(actreward.reward)))
savefig(gifpath()+'cumsum_absreward.png') # [[./gif/20oct10_20oct9_A0_cycle_cumsum_absreward.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','IM'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct10_20oct9_A0_cycle_all_avg_weight.png]]
savefig(gifpath()+'all_avg_weightB.png') # [[./gif/20oct10_20oct9_A0_cycle_all_avg_weightB.png]]

#
clf()
pdx=0
for prety,poty in zip(['EMDOWN','EMDOWN','EMUP','EMUP'],['IMUP','IM','IMDOWN','IM']):
  subplot(2,2,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid==dstartidx[poty]+1)&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])&(pdf.postid==dstartidx[poty]+1)]
  plot(pdfs.time,pdfs.cumreward,'ko')
  pdx+=1

savefig(gifpath()+'crewardC.png') # [[./gif/20oct10_20oct9_A0_cycle_crewardC.png]]

so synapses haven't reached max reward magnitude yet ... 

#
poty = 'EMUP'
for pdx,prety in enumerate(['EV1', 'EV4', 'EMT', 'EV1DN', 'EV1DS', 'EV1DNW','EMUP','EMDOWN']):
  subplot(2,4,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid==dstartidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.cumreward,'ko')

savefig(gifpath()+'crewardD.png') # [[./gif/20oct10_20oct9_A0_cycle_crewardD.png]]

weights are all decreasing probably because there's too much punishment ... in similar simulation
backupcfg/20oct8_B0_cycle_sim.json , the average weights were ~flat with the same reward/punishment scores
but CellWNorm was On ... preventing the overall weights from moving too much ... and since cumreward only
reached ~400-500 which is far below maxreward value, that rule probably not responsible ... 

would it make sense to run same sim with CellWNorm turned on?
or adjust reward scores ? 

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20oct10_20oct9_A0_cycle__input.mp4]]

** test CellWNorm with cumreward rule for deltaw

        "name": "20oct10_A0_cycle_",

./myrun 32 sn.json

started ~22:22 ... 

* 20oct13
** check output from 20oct10_A0_cycle_ -> had wrong param in sn.json

finished ~08:57 on 20oct12 ... 

python -i simdat.py backupcfg/20oct10_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct13_20oct10_A0_cycle_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((2490e3,2500e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct13_20oct10_A0_cycle_rast.png]]

pop = 'EMDOWN'
binsz = 20
tt,nspk = getspikehist(dspkT[pop],dnumc,binsz,2500e3)
clf(); plot(tt,nspk); xlim((0,2500e3))
savefig(gifpath()+'EMDOWN_rate20.png') # [[./gifpath()+'EMDOWN_rate20.png']]

dnspk = {pop:nspk}
pop='EMUP'; dnspk['EMUP'] = getspikehist(dspkT[pop],dnumc,binsz,2500e3)
plot(dnspk['EMUP'][0],dnspk['EMUP'][1],'r'); 
savefig(gifpath()+'EMUP_EMDOWN_rate20.png') # [[./gif/20oct13_20oct10_A0_cycle_EMUP_EMDOWN_rate20.png]]

plot(actreward.time,np.cumsum(actreward.reward))
plot(actreward.time,np.cumsum(abs(actreward.reward)))
savefig(gifpath()+'cumsum_absreward.png') # [[./gif/20oct13_20oct10_A0_cycle_cumsum_absreward.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','IM'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct13_20oct10_A0_cycle_all_avg_weight.png]]
savefig(gifpath()+'all_avg_weightB.png') # [[./gif/20oct13_20oct10_A0_cycle_all_avg_weightB.png]]

hmm, weights decreasing because although had weight norm turned on for individual cells, the step size
was too large ("normalizeWeightStepSize": 5000000000000000000), so never kicked in ... mistake!

#
clf()
pdx=0
for prety,poty in zip(['EMDOWN','EMDOWN','EMUP','EMUP'],['IMUP','IM','IMDOWN','IM']):
  subplot(2,2,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid==dstartidx[poty]+1)&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])&(pdf.postid==dstartidx[poty]+1)]
  plot(pdfs.time,pdfs.cumreward,'ko')
  pdx+=1

savefig(gifpath()+'crewardC.png') # [[./gif/20oct13_20oct10_A0_cycle_crewardC.png]]

#
poty = 'EMUP'
for pdx,prety in enumerate(['EV1', 'EV4', 'EMT', 'EV1DN', 'EV1DS', 'EV1DNW','EMUP','EMDOWN']):
  subplot(2,4,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid==dstartidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.cumreward,'ko')

savefig(gifpath()+'crewardD.png') # [[./gif/20oct13_20oct10_A0_cycle_crewardD.png]]

# fig=animInput(InputImages,gifpath()+'_input.mp4') 

** fixup last sim with intended parameters

        "name": "20oct13_A0_cycle_",
        "normalizeWeightStepSize": 500,

./myrun 32 sn.json

started ~11:06 ...

** ball avoidance, origins

model does the right thing, but too late, so loses a point, gets punished,
with most recent action synapses having highest eligibility trace values,
then next time around, the opposite action (avoidance) takes over?

a related (or same) problem is that the most recent action might be correct, but all the
other actions leading up to it could be incorrect. it seems that eligibility
trace values will not properly encode that information. 

example, ball going to bottom right. paddle is stuck at the top moving up and getting
punished for many moves. finally the punishment signal allows the other population to 
overcome the moves up and the paddle starts moving down. by then it's too late for the
paddle to hit the ball, the model loses a point, and then gets punished for moving down.
even though it got punished for moving up before, the punishment for moving down will
still be remembered, and even may have a higher punishment value for lost point (-1.0) 
compared to wrong move (-0.1).

also, just because we find some problematic examples, doesn't mean it can't work (at all),
but the frequency of problematic situations compared to non-problematic, will put a
ceiling on learning ability and performance

** STDP-RL rule currently used

not really same as izhikevich
in izhikevich (2007) eligibility trace amplitude is increased based on the STDP rule time difference
and then decays exponentially
the synaptic weight rate of change is product of eligibility trace and extracellular dopamine concentration
and dopamine concentration is a function of reward/punishment signal

dopamine concentration also follows exponential decay to baseline concentration 

the STDP time difference impact on eligibility trace amplitude seems important since
it means that high precision in firing times is more likely to get a larger reward 
when dopamine is triggered ... 

continuous integration of synaptic weights is also more costly ...

** square pulse for RL? no score/lose point?

that removes some of the time info but prevents mistake of recency and if have long enough window
may attribute to all the synapses properly ?? but more likely to produce overly high credit
assignments ...

also, getting rid of score/lose point scores would prevent misleading info
but that would mean the system is fairly simple in what it can assess ... ? 

could also have different reward/punish adjustments for each metric
one for follow
one for hit
one for score/loss
which would require different synapses for each?

try with no exp rl and only follow metric, shorter RL tau ... 

20oct13_B0_cycle_

run for 300 s to test ...

other params same as last sim ...

./myrun 32 sn.json

started 16:49 ...

finisehd ~23:02 ...

python -i simdat.py backupcfg/20oct13_B0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct13_20oct13_B0_cycle_perf.png]]
similar to others ... some improvement - 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((290e3,300e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct13_20oct13_B0_cycle_rast.png]]

plot(actreward.time,np.cumsum(actreward.reward))
plot(actreward.time,np.cumsum(abs(actreward.reward)))
savefig(gifpath()+'cumsum_absreward.png') # [[./gif/20oct13_20oct13_B0_cycle_cumsum_absreward.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','IM'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct13_20oct13_B0_cycle_all_avg_weight.png]]
savefig(gifpath()+'all_avg_weightB.png') # [[./gif/20oct13_20oct13_B0_cycle_all_avg_weightB.png]]

ok, performed ~as expected ... can run for 1500 s to compare to other recent sim above

hmm, if took 6 hours to run with the other sim and IT's Matlab run in parallel, may as well wait until
other sim finishes ... otherwise will take ~30 hours to run to completion ... 

once re-setup gcp will have more cores available ... 

** other way to minimize interference btwn metrics

reduce the lose point punishment magnitude so it's similar to the non-follow ball value
that way, losing a point won't mess up the incremental follow rewards as much if over-
or under-shoot with some overall correctness

* 20oct14
** run w/o score/lose/hit reward/punish signals

"name": "20oct14_B0_cycle_",

./myrun 32 sn.json

started 9:37 ... stopped, since noticed problem with cumreward (mentioned below)

./myrun 32 sn.json

restarted at 10:40 ... 

stopped - cumreward needs adjustment (see below)

** check output from 20oct13_A0_cycle_ -->> had problem with cumreward

python -i simdat.py backupcfg/20oct13_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct14_20oct13_A0_cycle_perf.png]]
not bad performance, relatively speaking ... may require a lot more time to improve ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1490e3,1500e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct14_20oct13_A0_cycle_rast.png]]

clf(); plot(actreward.time,np.cumsum(actreward.reward))
plot(actreward.time,np.cumsum(abs(actreward.reward)))
savefig(gifpath()+'cumsum_absreward.png') # [[./gif/20oct14_20oct13_A0_cycle_cumsum_absreward.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','IM'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct14_20oct13_A0_cycle_all_avg_weight.png]]
savefig(gifpath()+'all_avg_weightB.png') # [[./gif/20oct14_20oct13_A0_cycle_all_avg_weightB.png]]

#
poty = 'EMUP'
for pdx,prety in enumerate(['EV1', 'EV4', 'EMT', 'EV1DN', 'EV1DS', 'EV1DNW','EMUP','EMDOWN']):
  #subplot(2,4,pdx+1)
  #title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid==dstartidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.cumreward,'ko')

savefig(gifpath()+'crewardD.png') # [[./gif/20oct14_20oct13_A0_cycle_crewardD.png]]

hmm, all cumulative reward values are same - that means not implemented correctly, was supposed
to be synapse-specific signal ... so should check if deltaw != 0.0 before incrementing cumreward
since deltaw != 0.0 only when a reward/punishment is provided to a synapse

ok, will fix that up ... 

** check reasonable values for maxreward

20oct14_C0_cycle_

./myrun 32 sn.json

python -i simdat.py backupcfg/20oct14_C0_cycle_sim.json

clf(); plot(actreward.time,np.cumsum(actreward.reward))
plot(actreward.time,np.cumsum(abs(actreward.reward)))
savefig(gifpath()+'cumsum_absreward.png') # [[./gif/20oct14_20oct14_C0_cycle_cumsum_absreward.png]]

np.amin(pdf.cumreward), np.amax(pdf.cumreward), np.mean(pdf.cumreward) # (0.0, 42.10000000000033, 19.33201044091506)

#
poty = 'EMUP'
for pdx,prety in enumerate(['EV1', 'EV4', 'EMT', 'EV1DN', 'EV1DS', 'EV1DNW','EMUP','EMDOWN']):
  subplot(2,4,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid>=dstartidx[poty])&(pdf.postid<=dendidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.cumreward,'ko')

savefig(gifpath()+'crewardD.png') # [[./gif/20oct14_20oct14_C0_cycle_crewardD.png]]

most of those look identical ... and that's for whole pre to postsynaptic population ?? 

different weight for each "synapse" ? but same cumreward variable, since that's associated with the STDP mechanism?
no, should be an individual STDP mechanism with its own NetCon, one for each synapse ... 

check stdp.mod comments at top - it uses two netcons, one netcon for receiving presynaptic neuron spikes and
one netcon for receiving postsynaptic neuron spikes ... 

i.e.,:
"
## Create synapses
threshold = 10 # Set voltage threshold
delay = 1 # Set connection delay
singlesyn = h.NetCon(cells[0],cells[1], threshold, delay, 0.5) # Create a connection between the cells
stdpmech = h.STDP(0,sec=dummy) # Create the STDP mechanism
presyn = h.NetCon(cells[0],stdpmech, threshold, delay, 1) # Feed presynaptic spikes to the STDP mechanism -- must have weight >0
pstsyn = h.NetCon(cells[1],stdpmech, threshold, delay, -1) # Feed postsynaptic spikes to the STDP mechanism -- must have weight <0
h.setpointer(singlesyn._ref_weight[0],'synweight',stdpmech) # Point the STDP mechanism to the connection weight
"

singlesyn is the NetCon that has its weights adjusted by the STDP mechanism ... the other weights are not changed ... 

maybe cumreward ~same for most synapses since rule is now if deltaw > 0 add to cumreward ?? and that could mean
very small deltaw still produces the same impact ... but would not expect all synapses to get changed same way ... 

lcreward = []; lctime = []
prety = 'EV1'
pdfs = pdf[(pdf.postid>=dstartidx[poty])&(pdf.postid<=dendidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
for preid in np.unique(pdfs.preid):
  pdfs2 = pdfs[(pdfs.preid==preid)]
  plot(pdfs2.time,pdfs2.cumreward)
  lcreward.append(np.array(pdfs2.cumreward))
  lctime.append(np.array(pdfs2.time))

lcreward = []; lctime = []
prety = 'EV1'
pdfs = pdf[(pdf.postid>=dstartidx[poty])&(pdf.postid<=dendidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
for preid in np.unique(pdfs.preid):
  pdfs2 = pdfs[(pdfs.preid==preid)&(pdfs.postid==dstartidx[poty])]
  plot(pdfs2.time,pdfs2.cumreward)
  lcreward.append(np.array(pdfs2.cumreward))
  lctime.append(np.array(pdfs2.time))

#
poty = 'EMUP'
for pdx,prety in enumerate(['EV1', 'EV4', 'EMT', 'EV1DN', 'EV1DS', 'EV1DNW','EMUP','EMDOWN']):
  subplot(2,4,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid>=dstartidx[poty])&(pdf.postid<=dendidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.weight,'ko')

does the same thing happen without RL exp ?? 
        "name": "20oct14_D0_cycle_",

python -i simdat.py backupcfg/20oct14_D0_cycle_sim.json

some more diversity now in the cumreward values ... 

the fabs(deltaw) > 0 rule not too sensible when using RLexp since
that will almost always be true ... just surprising that all presynaptic
neurons activated in 500 ms, and 25 ms between that and postsynaptic neuron firing ...

try a bit longer run ... see if they diverge more, also decrease window for pre/post tagging
and reduce duration of eligibility window

150 s run finished @ 19:46 ... 

#
poty = 'EMUP'
for pdx,prety in enumerate(['EV1', 'EV4', 'EMT', 'EV1DN', 'EV1DS', 'EV1DNW','EMUP','EMDOWN']):
  subplot(2,4,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid>=dstartidx[poty])&(pdf.postid<=dendidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.cumreward,'ko')

savefig(gifpath()+'crewardD.png') # [[./gif/20oct14_20oct14_D0_cycle_crewardD.png]]
now cumulative rewards at all populations do not look the same 

csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]

prety = 'EV1'
pdfs = pdf[(pdf.postid>=dstartidx[poty])&(pdf.postid<=dendidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
lpreid = np.unique(pdfs.preid)
for pdx,preid in enumerate(lpreid):
  pdfs2 = pdfs[(pdfs.preid==preid)]
  plot(pdfs2.time,pdfs2.cumreward,'o',color=csm.to_rgba(float(pdx)/(len(lpreid))))

savefig(gifpath()+'crewardE.png') # [[./gif/20oct14_20oct14_D0_cycle_crewardE.png]]

ok, look different now ... 

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct14_20oct14_D0_cycle_perf.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','IM'],lclr=['r','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 

savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct14_20oct14_D0_cycle_all_avg_weight.png]]
savefig(gifpath()+'all_avg_weightB.png') # [[./gif/20oct14_20oct14_D0_cycle_all_avg_weightB.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((140e3,150e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct14_20oct14_D0_cycle_rast.png]]

np.amin(pdf.cumreward), np.amax(pdf.cumreward), np.mean(pdf.cumreward) # (0.0, 161.8999999999951, 0.2228273540166179)

lc,lcmin,lcmax = [],[],[]
tt = np.unique(pdf.time)
for t in tt: 
  pdfs = pdf[pdf.time==t]
  lc.append(np.mean(pdfs.cumreward))
  lcmin.append(np.amin(pdfs.cumreward))
  lcmax.append(np.amax(pdfs.cumreward))

plot(tt,lc,'k')
plot(tt,lcmin,'b')
plot(tt,lcmax,'r')

savefig(gifpath()+'crewardavgvst.png') # [[./gif/20oct14_20oct14_D0_cycle_crewardavgvst.png]]
savefig(gifpath()+'crewardmaxvst.png') # [[./gif/20oct14_20oct14_D0_cycle_crewardmaxvst.png]]

ok, cumreward increasing over time ... average pretty low , max pretty high, so there's a wide range

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20oct14_20oct14_D0_cycle__input.mp4]]

can sim with these params longer ... 1000 s ... have to adjust reload weight code to load in cumreward values, if they're available
ok, adjusted that but will start from scratch anyway, so can set a different maxreward ... 

        "name": "20oct14_E0_cycle_",

will have maxreward at 200 for AMPA and 600 for AMPAI... 

./myrun 32 sn.json

started ~23:24 ...

* 20oct15
** check output from 20oct14_E0_cycle_

finished @ 13:00 ...

python -i simdat.py backupcfg/20oct14_E0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct15_20oct14_E0_cycle_perf.png]]
not so good ... 

np.amin(pdf.cumreward), np.amax(pdf.cumreward), np.mean(pdf.cumreward) # (0.0, 388.20000000001977, 1.3420942947377772)

#
poty = 'EMUP'
for pdx,prety in enumerate(['EV1', 'EV4', 'EMT', 'EV1DN', 'EV1DS', 'EV1DNW','EMUP','EMDOWN']):
  subplot(2,4,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid>=dstartidx[poty])&(pdf.postid<=dendidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.cumreward,'ko')

savefig(gifpath()+'crewardD.png') # [[./gif/20oct15_20oct14_E0_cycle_crewardD.png]]

some of those synapses are reaching the maxreward of 200 ... 

#
poty = 'EMUP'
for pdx,prety in enumerate(['EV1', 'EV4', 'EMT', 'EV1DN', 'EV1DS', 'EV1DNW','EMUP','EMDOWN']):
  subplot(2,4,pdx+1)
  title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid>=dstartidx[poty])&(pdf.postid<=dendidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.weight,'ko')

savefig(gifpath()+'cweightD.png') # [[./gif/20oct15_20oct14_E0_cycle_cweightD.png]]

#
poty = 'IM'; lclr = ['r','b']
for pdx,prety in enumerate(['EMDOWN','EMUP']):
  clr = lclr[pdx]
  #title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid>=dstartidx[poty])&(pdf.postid<=dendidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.cumreward,clr+'o')

savefig(gifpath()+'crewardI.png') # [[./gif/20oct15_20oct14_E0_cycle_crewardI.png]]

#
poty = 'IM'; lclr = ['r','b']
for pdx,prety in enumerate(['EMDOWN','EMUP']):
  clr = lclr[pdx]
  #title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid>=dstartidx[poty])&(pdf.postid<=dendidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.weight,clr+'o')

savefig(gifpath()+'cweightI.png') # [[./gif/20oct15_20oct14_E0_cycle_cweightI.png]]

hmm, overall did not do as well as [[./gif/20oct14_20oct13_A0_cycle_perf.png]]

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20oct15_20oct14_E0_cycle__input.mp4]]

** simplify again - ??

should aim to see good performance consistently, and during even the first 20 s of activity
that's what had seen with the 2D arm model when it was working properly
w/o that, seems unlikely to see good long term performance? 

larger scores to enforce better behavior ... ? 

no weight norm, cumreward tracking ... 

20oct15_A0_cycle_

python -i simdat.py backupcfg/20oct15_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct15_20oct15_A0_cycle_perf.png]]
hmm, did not get such good results ... not many hits

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((290e3,300e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct15_20oct15_A0_cycle_rast.png]]
well, it's a hyperactive network ... 

#
clf()
poty = 'IM'; lclr = ['r','b']
for pdx,prety in enumerate(['EMDOWN','EMUP']):
  clr = lclr[pdx]
  #title(prety+'->'+poty)  
  pdfs = pdf[(pdf.postid>=dstartidx[poty])&(pdf.postid<=dendidx[poty])&(pdf.preid>=dstartidx[prety])&(pdf.preid<=dendidx[prety])]
  plot(pdfs.time,pdfs.weight,clr+'o')

savefig(gifpath()+'cweightI.png') # [[./gif/20oct15_20oct15_A0_cycle_cweightI.png]]
E->I weights dropping to 0 ... had set wbase pretty low ... 

simplifying network ... back to smaller EM output population, so can run longer ... 
do away with many of the RL connections again ... all preM to M but with high weight variance (weightVar==1)

        "name": "20oct15_B0_cycle_",

python -i simdat.py backupcfg/20oct15_B0_cycle_sim.json

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((290e3,300e3))
savefig(gifpath()+'rast.png') 

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','IM'])
savefig(gifpath()+'Vm.png') 

./myrun 32 sn.json

started ~23:49 ... 

* 20oct16
** stopped last sim -- not enough firing

restart with weight norm for cell, every 10 s ... 
and increase NM to M neurons (EEMWghtNM to 1e-6 instead of 0.9375e-6)

        "name": "20oct16_A0_cycle_",

./myrun 32 sn.json

started ~09:20 ...

this one also turns to very low firing pretty quickly

adjust & restart ... 

./myrun 32 sn.json

need higher pre V -> M weights, since far fewer pre V neurons? (compared to direction
selective neurons - since noticed that don't get much/any firing unless direction
selective neurons are activated when ball moving)

** connectivity/architecture

ball in middle going down and to right, and will hit just above bottom right corner:
 if paddle is above bottom right corner -> need move down neuron to know to move down; and move up neuron to stay silent
 if paddle is below bottom right corner -> need move down neuron to know to stay silent; and move up neuron to fire

in the extreme case, if each motor neuron receives ALL the information, can it still make the right decision in
all situations? 

ball in middle goin

** discussion with ha re architecture

comes to the conclusion that current architecture makes no sense; need middle area that has
all associations between directions and positions ... then projects to motor neurons

so that would required 3200 x 400 neurons (if neurons are simple), or more detailed
neurons to have multiple states/associations at each neuron

** association layer -> try it out (20oct16_A0_cycle_) -> may be improving

EA, IA for EAssoc, IAssoc ... association neurons 

adjusting architecture to include association area that projects to motor neurons ... 

        "name": "20oct16_A0_cycle_",

./myrun 32 sn.json

took ~3.5 hours ... 

python -i simdat.py backupcfg/20oct16_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct16_20oct16_A0_cycle_perf.png]]

follow might be improving ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((190e3,200e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct16_20oct16_A0_cycle_rast.png]]

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EA', 'IM'],tlim=(190e3,200e3))
savefig(gifpath()+'Vm.png') # [[./gif/20oct16_20oct16_A0_cycle_Vm.png]]

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20oct16_20oct16_A0_cycle__input.mp4]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EA','EMDOWN','EMUP'],lclr=['r','g','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 

savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct16_20oct16_A0_cycle_all_avg_weight.png]]
savefig(gifpath()+'all_avg_weightB.png') # [[./gif/20oct16_20oct16_A0_cycle_all_avg_weightB.png]]

binsz = 100
dnspk = {pop:getspikehist(dspkT[pop],dnumc,binsz,200e3) for pop in ['EMDOWN','EMUP','EA']}
for clr,pop in zip(['r','g','b'],['EA','EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)

xlim((0,200e3)); ylim((-10,200))

savefig(gifpath()+'EA_EMDOWN_rate100.png') # [[./gif/20oct16_20oct16_A0_cycle_EA_EMDOWN_rate100.png]]

rates are pretty similar ... EA sets pace and EMDOWN,EMUP follow closely - though of course not identical 

certainly worth running longer ... 

synweights at 510 MB for 200 s run ... 

can get rid of saving cumreward for now . . .

ok, will run for 2000 s ... 

./myrun 32 sn.json

started ~22:00 ...

** and another EA layer sim with adjusted connection probabilities?

higher or lower prob, more/fewer EA?

try on gcp ...

        "name": "20oct16_B0_gcp_",

48 cores seems to run a little faster than 32 (60 runs a bit slower)

increase EEAProb from 0.4 to 0.8, and decrease EEARecProb from 0.35 to 0.175
decrease the EEAWghts by 1/2 ... 
        "EEAWghtAM": 1e-05,
        "EEAWghtNM": 1.5e-06,	
overall, this means each of the EA neurons get more info from the EV1 and EVDir neurons ... 
so a lot more redundance, but more of the info preserved for learning  ... will see if it helps ... 

short (10 s) run showed rates decent near start ... took ~35 MB to save weights
will take ~3.5 GB for saving weights at 20 s intervals

started 2000 s ~midnight ... 

./myrun 48 sn.json

* 20oct17
** next day ~23:28 - gcp run ~115/200 of the way done

but firing seems too high - many of the EMUP,EMDOWN rates near 100 for many
of the time-steps... the dense connectivity and not enough punishment may
prevent good outcome ... 

could run to 1000 s and see output - if any better than sim running on cycle

will run with higher punish value for move away from ball ... 

    "rewardcodes": {
        "scorePoint": 1.0,
        "losePoint":  0.0,
        "followTarget": 0.1,
        "avoidTarget": -0.1,
        "hitBall": 0.5
    },

and only run for 1000 s ... 

        "name": "20oct17_A0_gcp_",

./myrun 48 sn.json

* 20oct18
** check output from 20oct17_A0_gcp_

finished ~23:30 ...

python -i simdat.py backupcfg/20oct17_A0_gcp_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct19_20oct17_A0_gcp_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct19_20oct17_A0_gcp_rast.png]]

* 20oct19
** continue with output check on gcp -> perf. not good

python -i simdat.py backupcfg/20oct17_A0_gcp_sim.json

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EA','EMDOWN','EMUP'],lclr=['r','g','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 

savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct20_20oct17_A0_gcp_all_avg_weight.png]]
savefig(gifpath()+'all_avg_weightB.png') # [[./gif/20oct20_20oct17_A0_gcp_all_avg_weightB.png]]

ok, now all weights decreasing ... and firing rates/performance ~decreasing in tandem

[this next test with EA layer on gcp, probably not useful yet ... need to adjust architecture further]

what about normalizing population weights periodically as did before, while having lower punishment
magnitude?

** pairs, triples, etc., and architecture

EA layer might be better designed if it was static set of pairs of features
e.g. motion in one direction + high pixel intensity in another location 
static since do not need to learn these integrations ... can just pass them forward

however, that's high space complexity ... 400 x 3200 neurons for all pairs; so first
pass of learning which pairs of features useful could be valuable ... and those pairs
could be determined by spiking co-occurrence (hebbian or stdp) ... so could have
some feature selection via initial hebb/stdp ... ?

also, trajectory is fixed/determined right after ball hits racket, so do not need
direction selective neurons at every 20x20 location - just put at left/right edges
of screen (close to paddles)

** check output from 20oct16_A0_cycle_

python -i simdat.py backupcfg/20oct16_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,0.35))
savefig(gifpath()+'perf.png') # [[./gif/20oct19_20oct16_A0_cycle_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((1990e3,2000e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct19_20oct16_A0_cycle_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EA','EMDOWN','EMUP'],lclr=['r','g','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 

savefig(gifpath()+'all_avg_weight.png') 
savefig(gifpath()+'all_avg_weightB.png') 

** adjust architecture for EA

how many synapses to/within EA useful ? keep fixed ? 

ideally would have all temporally correlated representations grouped together into objects
... and that should all be learned ... to allow flexibility in representation 

https://psycnet.apa.org/fulltext/2018-25960-001.html <<-- akihiro eguchi paper on spiking
network model of ventral visual stream and spike polychronization for feature binding (via stdp)
suggests mechanism for object detection; will probably avoid adding that to current model for now...

in current model, intensity (V1) and direction (EV1) are kind of redundant since EV1 only get
activated if an object is detected in the neighborhood ... so may not need V1 at all. instead could have
integration of the direction selective neuron populations ... well, when paddle is stationary, still useful
to have that representation ... 

so, the simple idea of pairs of features
400 x 3200 = 1280000
that's ~how many neurons needed
but could have > 1 feature pair per neuron (noisy?)

had set 400 EA neurons ... with 0.4 conn prob
3600 * 0.4 = 900 connections per neuron
900 * 400 = 360000 ... only ~30% of total number of synapses needed ... 
but there was also recurrent connectivity ... 

so try ~1420 EA neurons w/o RL STDP ... ?

        "name": "20oct19_A0_cycle_",

[[./gif/20oct19_A0_cycle_rast.png]]

* 20oct20
** mistake in calc above about number of EA neurons, synapses needed for all pairs

pairs from 3600 neurons would be 3600 x 3599 = 12956400
so that's a lot more ... 

** discuss EA arch & simplified network architecture with H.A.

simplified arch. should be a good proof of concept and capture the relationships
between different objects (see brainstorming doc for some details)

** back to sim

        "name": "20oct20_A0_cycle_",

try with > EA neurons

note each EA neuron could represent more than a 'pair' of features (each simple feature is
ReceptiveF ield of a V1, EV1DE neuron), if each synaptic input is a 1D feature. although
then information is less selective, it still seems possible for the network to learn a correct
decision based on partial information received by each neuron.

./myrun 48 sn.json

run for 100 s to test - was having hyperexcit

took ~8 hours ... 

python -i simdat.py backupcfg/20oct20_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,0.35))
savefig(gifpath()+'perf.png') # [[./gif/20oct21_20oct20_A0_cycle_perf.png]]
hmm, waste of sim time ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((90e3,100e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct21_20oct20_A0_cycle_rast.png]]
just hyperexcitable

xlim((10e3,20e3))
savefig(gifpath()+'rastB.png') # [[./gif/20oct21_20oct20_A0_cycle_rastB.png]]
and started that way ... 

xlim((0e3,10e3))
savefig(gifpath()+'rastC.png') # [[./gif/20oct21_20oct20_A0_cycle_rastC.png]]

* 20oct21
** had not increased IA

20oct20_A0_cycle_

./myrun 48 sn.json

* 20oct22
** other adjustments (20oct22_A0_cycle_)

        "name": "20oct22_A0_cycle_",

ok, setting up to get some firing continuing in EA, EM ... 

better to have relatively sparse connectivity onto EA and higher
convergence onto EM ... ? even if contradictions arise in EA 
features, projection to EMUP and EMDOWN and RL could resolve them ... ?

had to increase weights to EM a lot to maintain firing there, since EA
rates are so low (~0.3 Hz)

        "EEMWghtAM": 200e-05,
        "EEMWghtNM": 100e-06,

./myrun 32 sn.json

started ~12:12 ... 
finished ~22:22 ...

python -i simdat.py backupcfg/20oct22_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,0.35))
savefig(gifpath()+'perf.png') # [[./gif/20oct22_20oct22_A0_cycle_perf.png]]

unusual pattern of increase, decrease, increase in perf ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((90e3,100e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct22_20oct22_A0_cycle_rast.png]]

savefig(gifpath()+'rastB.png') # [[./gif/20oct22_20oct22_A0_cycle_rastB.png]]

looks like too much synchrony ... EMDOWN and EMUP firing too much together; too much inhib
for the EAs, though a sparse code has its benefits

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EA','EMDOWN','EMUP'],lclr=['r','g','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 

savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct22_20oct22_A0_cycle_all_avg_weight.png]]

weights barely changing ... 

** direct path

also add direct path from EV1, EV1D to M ?

direct path would provide first order sensory info but would not be reward modulated ... 

so EA provides relationships (second, higher order) and direct path primary sensory

paddle in middle Y position ball moving to northeast (should move up to get reward); but 
if an EMDOWN gets that pixel and NE direction and if the paddle moves down then those synapses should get weakened
if an EMUP gets that pixel and NE direction and paddle moves down, those synapses should get strengthened (if that EMUP
fires later)

so using those direct pathways, the model could still learn something ... ? but only if it gets non-contradictory info
for example, if the EMDOWN neuron got the middle Y pixel but also a SE dir input and should therefore move down... the middle pixel
synapse would have been weakened, while the SE synapse should get strengthened ... 

ok, so RL-STDP for the direct path seems useless and leads to problems due to ambiguity in the correct
move based on first order info. but could direct pathway provide static context useful to make the correct
move, given the EA projections?

* 20oct23
** direct path and other conn changes (cmat)

added it ... adjusted conn rules/specifications for more clarity
(use cmat in json file - )

VL, VD are shorthands for loc and dir sensitive visual neurons

20oct23_A0_cycle_

./myrun 32 sn.json

started ~5 PM

** whether to include plasticity in the pathway to EA neurons? probably not

in some situations would that help produce stronger/correct inputs
onto EA neurons?

for example, ball moving from top left SE, paddle in middle Y
those first order representations converge onto an EA neuron
the EA neuron projects to EMDOWN; if EMDOWN activated, that
synapse onto EMDOWN is strengthened, and so are the SE and middle Y
inputs onto the EA neuron. next time that context arises, the SE
and middle Y inputs to EA will be stronger, and that path will
more strongly drive the EMDOWN. other first order representations
that converge onto the EA neuron would not be strengthened if
their presynaptic neurons did not fire. however, if later the
paddle is already at bottom right of screen, when ball is moving
SE to bottom right corner, the EMDOWN neuron will be more
strongly activated to move down further from stronger SE->EA->EMDOWN. 
so having plasticity onto the EA neuron will lead to  increased probability of an
incorrect response in the second context. however, the middle Y->EA->EMDOWN
will not be active, since paddle is in bottom right, counterbalancing the
increase from SE->EA->EMDOWN. each of those synaptic inputs by themselves
are ambiguous - what to do - but when they're both activated they will 
be more likely to drive EMDOWN properly. since each of those inputs
are ambiguous, it's likely that other combinations of inputs will
later reduce those synaptic weights. so, any benefit from that
could be short-lived. but difficult to predict and to rule out
any benefit ... 

** test similar model on gcp

forgot to put AM,NM weights for EM -> EM recurrent
connections in last sim on cycle  (20oct23_A0_cycle_)

will add that here ... 

run for 1000 s ... see how it does ... may want to scale up EA or EM populations later ... 

20oct23_B0_gcp_

./myrun 48 sn.json

started ~22:22 ...

firing rates get too high around 200 s ... need to put in (global) weight norm 

* 20oct24
** check output from 20oct23_A0_cycle_

finished at 04:11 AM ... 

python -i simdat.py backupcfg/20oct23_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,0.6))
savefig(gifpath()+'perf.png') # [[./gif/20oct24_20oct23_A0_cycle_perf.png]]
interesting, looks like a clear increase in hit/miss ratio

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((90e3,100e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct24_20oct23_A0_cycle_rast.png]]
but firing rates seem too high ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 

savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct24_20oct23_A0_cycle_all_avg_weight.png]]

weights going straight up ... 

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20oct24_20oct23_A0_cycle__input.mp4]]

so, this sim looks interesting ... but probably need to include weight norm to prevent firing rates
from getting too high ... 

in this sim only had learning at EM synapses ... so may not need to adjust the normalization code 

    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20oct23_A0_cycle_synWeights_final.pkl"
    },

	"normalizeWeightsAtStart": 1,
        "EEMPopNorm": 1,

and use cmat[EA][EM][AM] for norm of populations ... 

python multistepSim.py sn.json 32 5 20oct24_A1_cycle_multi

each step only 200 s ... 

started ~12:49 ... 

sim.rank= 0 davg: {'EMUP': 0.00183445747841833, 'EMDOWN': 0.0018308646473646731, 'EA': 0.0}
dfctr: {'EMUP': 0.32739277990298066, 'EMDOWN': 0.32739277990298066, 'EA': 0.32739277990298066}

* 20oct26
** check output from multistep sims with EA (20oct24_A1_cycle__step_3_)

right now, it's at last step of multistep sim (20oct24_A1_cycle__step_4_)
that sim will finish later today

python -i simdat.py backupcfg/20oct24_A1_cycle__step_3_sim.json

ax=plotPerf(actreward,yl=(0,0.6))
savefig(gifpath()+'perf.png') # [[./gif/20oct26_20oct24_A1_cycle__step_3_perf.png]]
hmm, perf much worse than first run ... so normalization might be problematic?

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((190e3,200e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct26_20oct24_A1_cycle__step_3_rast.png]]

lfn = ['20oct23_A0_cycle_', '20oct24_A1_cycle__step_0_','20oct24_A1_cycle__step_1_','20oct24_A1_cycle__step_2_','20oct24_A1_cycle__step_3_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20oct26_20oct24_A1_cycle__step_3_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
clf(); plotComparePerf(lpda,['g','b','r','c','m'],yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # [[./gif/20oct26_20oct24_A1_cycle__step_3_perf_compareB.png]]

not clear if weight norm is the problem ... ?

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 

savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct26_20oct24_A1_cycle__step_3_all_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20oct26_20oct24_A1_cycle__step_3__input.mp4]]

...

binsz = 100
dnspk = {pop:getspikehist(dspkT[pop],dnumc,binsz,200e3) for pop in ['EMDOWN','EMUP','EA']}
for clr,pop in zip(['r','g','b'],['EA','EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)
xlim((0,200e3))
savefig(gifpath()+'EA_EMDOWN_rate100.png') # [[./gif/20oct26_20oct24_A1_cycle__step_3_EA_EMDOWN_rate100.png]]

EMUP,EMDOWN rates are going up and there are many more population spikes towards the end of the simulation ... 

either need more frequent norm or lower starting weights ... with sparser connectivity ... and larger EA layer ? 

model is pretty slow to run already ... 

check last step ... 

** follow ball paradigm

should probably look at distance relative to ball rather than movement command
since movement command is internal state
distance is dependent on external environment

python -i simdat.py backupcfg/20oct26_A0_lp_sim.json

ax=plotPerf(actreward,yl=(0,0.6))
savefig(gifpath()+'perf.png') # [[./gif/20oct26_20oct26_A0_lp_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((190e3,200e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct26_20oct26_A0_lp_rast.png]]

not really doing better ... but have fewer neurons in EA in this model 

** similar test on gcp (20oct26_A0_gcp_)

./myrun 48 sn.json

started ~16:56 ...
finished ~22:29 ...

python -i simdat.py backupcfg/20oct26_A0_gcp_sim.json

ax=plotPerf(actreward,yl=(0,0.6))
savefig(gifpath()+'perf.png') # [[./gif/20oct27_20oct26_A0_gcp_perf.png]]
does not seem to improve (follow ~0.2, hit goes up a bit, score a bit)
note that follow here not identical to original follow score; here it's 
cumulative of when moves are considered closer 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((190e3,200e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct27_20oct26_A0_gcp_rast.png]]
EMUP,EMDOWN firing rates are too high ... 

** revise new follow rule

should revise the follow target closer rule - when gets closer to target
reward, when moves away punish, when same no reward or punish ... 
same = staying still - perhaps punishing staying still will punish/suppress some
of the neurons that could contribute to the correct move (in addition to the
other neurons that are correctly punished), so may want to avoid that ... will test it ... 

20oct26_B0_gcp_

./myrun 48 sn.json

started ~23:21 ...

* 20oct27
** added cells/hht.py for one comp HH cell model

main reason is to speed-up simulation (compared to mainen)
if using, will have to re-tune 

uses HHE, HHI for the EcellModel, ICellModel in json
the FS basket cell was already single compartment, so probably would not need to use it there ... 

** check output from 20oct26_B0_gcp_

finished ~10:57 AM ...

python -i simdat.py backupcfg/20oct26_B0_gcp_sim.json

ax=plotPerf(actreward,yl=(0,0.6))
savefig(gifpath()+'perf.png') # [[./gif/20oct27_20oct26_B0_gcp_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((390e3,400e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct27_20oct26_B0_gcp_rast.png]]

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20oct27_20oct26_B0_gcp__input.mp4]] 

performance improving ... ? some learning likely taking place ... but firing rates probably
too high and needs much more time to learn ... ?

** coreneuron

https://github.com/Neurosim-lab/netpyne/blob/coreneuron/examples/coreneuron/tut2_coreneuron.py
https://github.com/BlueBrain/CoreNeuron

might work with this model?

to compile mod files:
nrnivmodl -coreneuron mod

for netpyne have to have:
simConfig.coreneuron = True

pip install neuron-nightly --upgrade
pip install netpyne --upgrade

nrnivmodl -coreneuron mod

INFO : Using neuron-nightly Package (Developer Version)
/home/samnemo/SMARTAgent
mod/A.mod mod/GABAa.mod mod/Nca.mod mod/OFThpo.mod mod/OFThresh.mod mod/cadad.mod mod/hsyn.mod mod/izhi2007b.mod mod/kca.mod mod/kdrbwb.mod mod/km.mod mod/kv.mod mod/nafbwb.mod mod/naz.mod mod/nsloc.mod mod/stdp.mod
A.mod GABAa.mod Nca.mod OFThpo.mod OFThresh.mod cadad.mod hsyn.mod izhi2007b.mod kca.mod kdrbwb.mod km.mod kv.mod nafbwb.mod naz.mod nsloc.mod stdp.mod
ERROR : CoreNEURON support is not enabled!

so have to build ... 

cd ~
git clone git@github.com:neuronsimulator/nrn.git
cd nrn

mkdir build
cd build

cmake .. \
 -DNRN_ENABLE_CORENEURON=ON \
 -DNRN_ENABLE_INTERVIEWS=OFF \
 -DNRN_ENABLE_RX3D=OFF \
 -DCMAKE_INSTALL_PREFIX=$HOME/install

will try on laptop first ... 

** adjust model on gcp for lower firing rates

        "name": "20oct27_A0_gcp_",

ok, got lower firing rates ... will run for 500 s ... 

./myrun 48 sn.json

started ~15:25 ... 

gets stuck ... restart with somewhat higher weights @ 18:42 ...

** core neuron on laptop?

cd ~
git clone https://github.com/neuronsimulator/nrn
cd nrn
mkdir build
cd build

cmake .. \
 -DNRN_ENABLE_CORENEURON=ON \
 -DNRN_ENABLE_INTERVIEWS=OFF \
 -DNRN_ENABLE_RX3D=OFF \
 -DCMAKE_INSTALL_PREFIX=$HOME/install

export PYTHONPATH=$HOME/install/lib/python:$PYTHONPATH
export PATH=$HOME/install/bin:$PATH

cd ~/SMARTAgent
nrnivmodl -coreneuron mod_directory

compilation produces a lot of errors ... 

** try IntFire4 again

this works:
https://github.com/Neurosim-lab/netpyne/blob/802bb6a5ce5a9da40a740add4f119ad2249f5611/doc/source/code/tut_artif.py

python -i tut_artif.py

savefig('gif/20oct27_cycle_artif_a0.png') # [[./gif/20oct27_cycle_artif_a0.png]]

        "name": "20oct27_I0_cycle_",

* 20oct28
** sa debugging intf in netpyne

does not seem to be able to receive netstim inputs properly

** check output from 20oct27_A0_gcp_

finished ~10:49 ...

python -i simdat.py backupcfg/20oct27_A0_gcp_sim.json

ax=plotPerf(actreward,yl=(0,0.6))
savefig(gifpath()+'perf.png') # [[./gif/20oct28_20oct27_A0_gcp_perf.png]]
looks decent, relative to other sims - early performance seems better than late performance

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct28_20oct27_A0_gcp_rast.png]]
in general firing rates are ok but EA looks hypersynchronous ... is that how it looks early in the sim?

xlim((10e3,20e3))
savefig(gifpath()+'rastB.png') # [[./gif/20oct28_20oct27_A0_gcp_rastB.png]]

looks like do not have the hypersynch earlier in the simulation; surprising that hypersynch develops
given that there's no plasticity for the EA neurons

binsz = 100
dnspk = {pop:getspikehist(dspkT[pop],dnumc,binsz,500e3) for pop in ['EMDOWN','EMUP','EA']}
for clr,pop in zip(['r','g','b'],['EA','EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)
xlim((0,500e3))
savefig(gifpath()+'EA_EMDOWN_rate100.png') # [[./gif/20oct28_20oct27_A0_gcp_EA_EMDOWN_rate100.png]]
looks like those synchronous EA spikes occur multiple times during the simulation, not
just at the end; seem to occur together with high EM firing

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 

savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct28_20oct27_A0_gcp_all_avg_weight.png]]
interesting, as the weights go down, the performance is decreasing ... 
will perf and weights increase again later? or punishment weights from moving away are too large ... 

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20oct28_20oct27_A0_gcp__input.mp4]]

the hypersynch may be due to recurrent EA connections

** other changes to architecture

get rid of directional neurons? implicit in the pixels/EV1 is movement directions ... 

add another EA layer? EA2 ... integrating EA inputs and could have some RL plasticity from
EA -> EA2
EA -> EM
EA2 -> EA2
EM -> EM

EA2, that would be ~same as V4 ... 

trying it out ... 

        "name": "20oct28_A0_gcp_",

python -i simdat.py backupcfg/20oct28_A0_gcp_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct28_20oct28_A0_gcp_perf.png]]

perf looks similar to model with the direction selective neurons ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((190e3,200e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct28_20oct28_A0_gcp_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EA2'],lclr=['r','g','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 

savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct28_20oct28_A0_gcp_all_avg_weight.png]]
EA2 weights do not rise as quickly ... 

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20oct28_20oct28_A0_gcp__input.mp4]]

may as well continue ... 

        "name": "20oct28_A1_gcp_",
    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20oct28_A0_gcp_synWeights_final.pkl"
    },

./myrun 32 sn.json

started ~5PM
finished ~9:40PM

python -i simdat.py backupcfg/20oct28_A1_gcp_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct29_20oct28_A1_gcp_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((390e3,400e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct29_20oct28_A1_gcp_rast.png]]

lfn = ['20oct28_A0_gcp_','20oct28_A1_gcp_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20oct29_20oct28_A1_gcp_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
clf(); plotComparePerf(lpda,['g','b','r','c','m'],yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # [[./gif/20oct29_20oct28_A1_gcp_perf_compareB.png]]

not improved and worse than model with the dir selective neurons

** issue with INTFs

sa: the issue is that adding stims via stimSourceParams/stimTargetParams is not yet implemented to target artificial cells
however, you can get the same effect by creating a pop of netstims and connecting it to the artif3 (Intfire4) pop
should work too if have a source population of stimmod connected (using connParams) to an Intfire4 population


try that again ... 

** dir selective neurons

does it make sense to exclude dir selective neurons? right now, without them, no mechanism for integrating
the movement sequences ... individual pixel locations are not enough to determine a movement decision ... 

could have pixel at one location (PA) project to EA at delay=1, pixel at other location (PB) project
to EA at delay=2
PA, PB -> EA -> EM
when PA,PB get activated and activate EA and EM if EM is correct action
then EA->EM is strengthened and so are PA,PB -> EA ? 
but may not want PA,PB -> EA to always get strengthened;; ... PA,PB -> EA are static
but if some EA receives a neighboring PA,PB then it will implicitly encode movement ...
though when EA fires, it could fire either due to PA or due to PB or due to both firing ... 

should probably keep the dir selective neurons around for now, though expensive computationally ... 

** next sim on gcp

this one was ok: 20oct27_A0_gcp_

could add EA2 and take it from there ... 

        "name": "20oct28_E0_gcp_",

python multistepSim.py sn.json 48 20 20oct28_E0_cycle_multi

* 20oct29
** intfs (IntFire4)

got most of it to work properly
see sim.py
have to use hPointp to set the interval of the variable rate NetStim (NSLOC)
and have to explicitly make a population of NetStims that represent the
visual input (rather than the simpler connecting source and target)
there's a population of netstims (with 1-to-1 connectivity to target) for
each type of visual input (EV1, EV1DE, etc.)

inhibitory synapses require negative weights so make sure to set IEGain, IIGain
to a negative number in the json file

need to make sure that negative weights do not mess up stdp.mod's functioning

get some crashes once in a while depending on scaling weights

had to scale up the EEGain and EIGain a lot to get any activity using the
previous weights ... 

        "name": "20oct29_I0_lp_",

runs pretty quickly on laptop with 12 cores ... 

problem with IntFire4 is only has a single excitatory input type...INTF6 has
AM,AM2,NM,NM2 but doesn't compile properly without mkmod ... could try that too later on
if need arises ... 

./myrun 12 sn.json

python -i simdat.py backupcfg/20oct29_I0_lp_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); 
savefig(gifpath()+'rast.png') # [[./gif/20oct29_20oct29_I0_lp_rast.png]]
note that the stimMod (NetStim populations) are drawn in raster too - should allow excluding some populations

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EA', 'IM'])
savefig(gifpath()+'Vm.png') # [[./gif/20oct29_20oct29_I0_lp_Vm.png]]

try on cycle ...

./myrun 32 sn.json

python -i simdat.py backupcfg/20oct29_I0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct29_20oct29_I0_cycle_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); 
savefig(gifpath()+'rast.png') # [[./gif/20oct29_20oct29_I0_cycle_rast.png]]

EA, IA, IM firing too fast ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png')

hmm, weights empty ... maybe stdp not setup properly to work with IntFire4 ... 

* 20oct30
** info from sa on plasticity problem in NetPyNE in IntFire4 

10:16
samn:speech_balloon: happen to know if any reason stdp.mod/hSTDP wouldn't work with IntFire4? thx
10:39
salvadord hmm I guess you are using the ‘plasticitiy’ field to insert the syn with stdp?
10:39
samn:speech_balloon: yeah
10:39
salvadord that might not be implemented for point neurons… let me check
10:39
samn:speech_balloon: thx
10:41
salvadord yeah, so the stdp.mod needs to be connected in a particular way and it’s only implemetned for multicomp neurons
10:41
Untitled 
    def _addConnPlasticity (self, params, sec, netcon, weightIndex):
        from .. import sim
        plasticity = params.get('plast')
        if plasticity and sim.cfg.createNEURONObj:
            try:
                plastMech = getattr(h, plasticity['mech'], None)(0, sec=sec['hObj'])  # create plasticity mechanism (eg. h.STDP)
                for plastParamName,plastParamValue in plasticity['params'].items():  # add params of the plasticity mechanism
                    setattr(plastMech, plastParamName, plastParamValue)
                if plasticity['mech'] == 'STDP':  # specific implementation steps required for the STDP mech
                    precon = sim.pc.gid_connect(params['preGid'], plastMech); precon.weight[0] = 1 # Send presynaptic spikes to the STDP adjuster
                    pstcon = sim.pc.gid_connect(self.gid, plastMech); pstcon.weight[0] = -1 # Send postsynaptic spikes to the STDP adjuster
                    h.setpointer(netcon._ref_weight[weightIndex], 'synweight', plastMech) # Associate the STDP adjuster with this weight
                    #self.conns[-1]['hPlastSection'] = plastSection
                    self.conns[-1]['hSTDP']         = plastMech
                    self.conns[-1]['hSTDPprecon']   = precon
                    self.conns[-1]['hSTDPpstcon']   = pstcon
                    self.conns[-1]['STDPdata']      = {'preGid':params['preGid'], 'postGid': self.gid, 'receptor': weightIndex} # Not used; FYI only; store here just so it's all in one place
                    if sim.cfg.verbose: print('  Added STDP plasticity to synaptic mechanism')
            except:
                print('Error: exception when adding plasticity using %s mechanism' % (plasticity['mech']))
Collapse



10:41
samn:speech_balloon: :disappointed:
10:41
salvadord you can try adding the corresponding code in netpyne/cells/pointCell.py
10:42
or can try doing it ‘manually’ for your net after the net is created
10:42
samn:speech_balloon: ic, thx - will take a look at adding that
10:42
salvadord can also add an issue and will look into it asap, or ask joe to have a look
10:43
samn:speech_balloon: joe - if has time, i can add an issue
10:43
will look too later
10:43
salvadord here’s the code for compart cells: https://github.com/Neurosim-lab/netpyne/blob/development/netpyne/cell/compartCell.py#L1242

netpyne/cell/compartCell.py:1242
    def _addConnPlasticity (self, params, sec, netcon, weightIndex):
<https://github.com/Neurosim-lab/netpyne|Neurosim-lab/netpyne>Neurosim-lab/netpyne | Added by GitHub
10:44
joe working on a bunch of things, but maybe he can have a look next week at some point
10:44
samn:speech_balloon: sg, will create issue and take a look myself meanwhile
10:47
not sure if this should be bug or feature request but added as bug: https://github.com/Neurosim-lab/netpyne/issues/535

samnemosamnemo
#535 [Bug report] plasticity not working in point neurons
Describe the bug
plasticity rules, such as STDP are not working/implemented in point neurons
Reproducing the bug
Steps to reproduce the behavior:  
create a network with artificial neurons (IntFire4) and add plasticity rule (e.g. stdp.mod)
Expected behavior
plasticity works across neuron types supported by netpyne
Labels
bug
<https://github.com/Neurosim-lab/netpyne|Neurosim-lab/netpyne>Neurosim-lab/netpyne | Today at 10:47 | Added by GitHub
:+1:
1

10:48
will try your suggestion later

** check output from gcp runs

python -i simdat.py backupcfg/20oct28_E0_gcp__step_1_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20oct30_20oct28_E0_gcp__step_1_perf.png]]
hmm, very bad performance ... much worse than first step ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); 
savefig(gifpath()+'rast.png') # [[./gif/20oct30_20oct28_E0_gcp__step_1_rast.png]]

xlim((499e3,500e3))
savefig(gifpath()+'rastB.png') # [[./gif/20oct30_20oct28_E0_gcp__step_1_rastB.png]]

lfn = ['20oct28_E0_gcp__step_0_','20oct28_E0_gcp__step_1_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20oct30_20oct28_E0_gcp__step_1_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
clf(); plotComparePerf(lpda,['g','b','r','c','m'],yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # [[./gif/20oct30_20oct28_E0_gcp__step_1_perf_compareB.png]]
overall 2nd step is worse than 1st step ... but hit probability may be increasing slowly?

stopped this on gcp for now ... 

also, too slow to run right now ... may want to use INTFs instead ... 

at minimum could replace EV1, EV1D, etc. with INTFs, since they
do not even have plasticity right now ... 

** try fixup for INTFs

first on laptop ... 

python import netpyne netpyne.__version__ '0.9.6' 
import sys
sys.path ['','/usr/site/python/netpyne', '/usr/arch/nrn/lib/python', '/usr/arch/nrn/nrn/share/nrn/lib/python',
'/usr/site/nrniv/python/anaconda3/envs/py36/lib/python3.6/site-packages',
'/usr/arch/nrn/share/python/lib/python', '/usr/site/nrniv/local/python',
'/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python36.zip',
'/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6',
'/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/lib-dynload',
'/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/site-packages'] 

/usr/site/python/netpyne is empty ... 

should have netpyne installed in conda py3 env

/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/site-packages/netpyne

/usr/site/nrniv/local/python/anaconda3/envs/py36/lib/python3.6/site-packages/netpyne/cell/pointCell.py

ok, added the _addConnPlasticity code to the pointCell class ... will see if works

./myrun 12 sn.json

python -i simdat.py backupcfg/20oct30_I0_lp_sim.json

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 

looks like they're changing, as they should ... 

made pull request to netpyne here:
 https://github.com/Neurosim-lab/netpyne/pull/536

meanwhile, on cycle also copied modified pointCell.py code to /opt/anaconda3/lib/python3.7/site-packages/netpyne/cell/pointCell.py

try on cycle ...

./myrun 32 sn.json

python -i simdat.py backupcfg/20oct30_I0_cycle_sim.json

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 

savefig(gifpath()+'all_avg_weight.png') # [[./gif/20oct30_20oct30_I0_cycle_all_avg_weight.png]]

now run and make sure that rates increase over time ... 

python -i simdat.py backupcfg/20oct30_I0_cycle_sim.json

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 

savefig(gifpath()+'all_avg_weightB.png') # [[./gif/20oct30_20oct30_I0_cycle_all_avg_weightB.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); 
xlim((190e3,200e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct30_20oct30_I0_cycle_rast.png]]

binsz = 100
dnspk = {pop:getspikehist(dspkT[pop],dnumc,binsz,totalDur) for pop in ['EMDOWN','EMUP']}
for clr,pop in zip(['r','g'],['EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)
xlim((0,totalDur))
ylim((0,150))
savefig(gifpath()+'EMDOWN_EMUP_rate100.png') # [[./gif/20oct30_20oct30_I0_cycle_EMDOWN_EMUP_rate100.png]]

yes, rates look like they increase ... 

and make sure there's a different pattern when RLon == 0 
or when no positive reward ... 

        "name": "20oct30_J0_cycle_",
    "rewardcodes": {
        "scorePoint": 0.0,
        "losePoint":  0.0,
        "followTarget": 0.0,
        "avoidTarget": -0.01,
        "hitBall": 0.0
    },

./myrun 32 sn.json

python -i simdat.py backupcfg/20oct30_J0_cycle_sim.json

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 

savefig(gifpath()+'all_avg_weight.png') # [[./gifpath()+'all_avg_weight.png']]

weights mostly going down now

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((190e3,200e3))
savefig(gifpath()+'rast.png') # [[./gif/20oct30_20oct30_J0_cycle_rast.png]]
and the firing rates are much lower ... so seems to be working as expected ...

        "name": "20oct30_K0_cycle_",

python -i simdat.py backupcfg/20oct30_K0_cycle_sim.json

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); 
savefig(gifpath()+'rast.png')

clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EMDOWN','EA', 'IM'])

python multistepSim.py sn.json 32 10 20oct30_K0_cycle_multi

started ~23:58 ... 

after ~8 hours, rates go towards 0 ... and paddle mostly stays still ... not a good param regime

* 20oct31
** adjust the IntFire4 sim some more

        "name": "20oct31_A0_cycle_",

python multistepSim.py sn.json 32 10 20oct31_A0_cycle_multi

re-started ~13:57 ...

still goes mostly towards 0 ... 

restart a single sim ...

./myrun 32 sn.json

23:44 ...

* 20nov1
** check output from 20oct31_A0_cycle_

t= 71760.0  U,D spikes: [0.0] [0.0]
t= 71760.0 proposed,model action: [-1] [1]
t= 71780.0  U,D spikes: [0.0] [0.0]
t= 71780.0 proposed,model action: [-1] [1]
t= 71800.0  U,D spikes: [0.0] [0.0]
t= 71800.0 proposed,model action: [-1] [1]
t= 71820.0  U,D spikes: [0.0] [0.0]
t= 71820.0 proposed,model action: [-1] [1]
t= 71840.0  U,D spikes: [0.0] [0.0]
t= 71840.0 proposed,model action: [-1] [1]
t= 71860.0  U,D spikes: [0.0] [0.0]
t= 71860.0 proposed,model action: [-1] [1]
t= 71880.0  U,D spikes: [0.0] [0.0]
t= 71880.0 proposed,model action: [-1] [1]
t= 71900.0  U,D spikes: [180.0] [21.0]
t= 71900.0 proposed,model action: [-1] [4]
t= 71920.0  U,D spikes: [5111.0] [3444.0]
t= 71920.0 proposed,model action: [-1] [4]
t= 71940.0  U,D spikes: [19826.0] [8270.0]
t= 71940.0 proposed,model action: [-1] [4]
t= 71960.0  U,D spikes: [43615.0] [261.0]
t= 71960.0 proposed,model action: [-1] [4]
t= 71980.0  U,D spikes: [97266.0] [0.0]
t= 71980.0 proposed,model action: [-1] [4]
t= 72000.0  U,D spikes: [277322.0] [0.0]
t= 72000.0 proposed,model action: [-1] [4]
t= 72020.0  U,D spikes: [926587.0] [0.0]
t= 72020.0 proposed,model action: [-1] [4]
t= 72040.0  U,D spikes: [3310498.0] [0.0]
t= 72040.0 proposed,model action: [-1] [4]
t= 72060.0  U,D spikes: [12085577.0] [0.0]
t= 72060.0 proposed,model action: [-1] [4]
t= 72080.0  U,D spikes: [44447982.0] [0.0]
t= 72080.0 proposed,model action: [-1] [4]
nrn_timeout t=72081
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD
with errorcode 0.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
(base) samn@cycle:~/SMARTAgent$ 
(base) samn@cycle:~/SMARTAgent$ 

never finished ... had overly high firing rates ... 

** another adjustment for IntFire4 test (20nov1_A0_cycle_)

./myrun 32 sn.json

started ~22:28 ...

crashed after a while ... firing rates god too high

** & another adjustment for IntFire4 test (20nov1_B0_cycle_)

same as one above but slightly lower EEGain ... 

./myrun 32 sn.json

started ~22:38 ...

crashed after a while ... firing rates god too high

* 20nov2
** more adjustments for IntFire4 net

        "name": "20nov2_A0_cycle_",

./myrun 32 sn.json

** adjusting intf6.mod to minimum in mod/intf7.mod

intf6.mod was more flexible in time constants and so on ... compared to IntFire4

* 20nov3
** check intf7.mod


first testing from adjusted tut_artif.py

need to adjust Netpyne's pointCell.py to allow specifying weightIndex
to use for a specific connection, since that's how intf7.mod right now
supports different synapse types within its NET_RECEIVE

on cycle
/opt/anaconda3/lib/python3.7/site-packages/netpyne/cell/pointCell.py

ok, made modification, will try it out ... 

also need to change _addCellConn in
/opt/anaconda3/lib/python3.7/site-packages/netpyne/network/conn.py
        if 'weightIndex' in connParam: params['weightIndex'] = connParam.get('weightIndex')

ok, made that adjustment and it seems to work ... will modify local netpyne, do pull request, etc.

for that make push via samnemo fork
git push git@github.com:samnemo/netpyne.git
and then do pull request to main neurosim netpyne repo

samndp7730% git checkout development
Switched to branch 'development'
Your branch is ahead of 'origin/development' by 1 commit.
  (use "git push" to publish your local commits)
samndp7730% pwd
/u/samn/netpyne
samndp7730% git add netpyne/cell/pointCell.py netpyne/network/conn.py
samndp7730% git commit -m 'add weightIndex option to connParam for pointCell'
[development ef79fc6] add weightIndex option to connParam for pointCell
 2 files changed, 5 insertions(+), 3 deletions(-)
samndp7730% git push git@github.com:samnemo/netpyne.git

** test INTF7 in full sim (20nov3_A0_cycle_)

        "name": "20nov3_A0_cycle_",

python -i simdat.py backupcfg/20nov3_A0_cycle_sim.json

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); 
savefig(gifpath()+'rast.png') # [[./gif/20nov3_20nov3_A0_cycle_rast.png]]
not enough firing ... 

clf(); drawcellVm(simConfig,ldrawpop=['EV1','EMUP','EMDOWN','EA', 'IM'])
savefig(gifpath()+'Vm.png') # [[./gif/20nov3_20nov3_A0_cycle_Vm.png]]

python -i simdat.py backupcfg/20nov3_B0_cycle_sim.json

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); 
clf(); drawcellVm(simConfig,ldrawpop=['EV1','EMUP','EMDOWN','EA', 'IM'])
* 20nov4
** update netpyne pointCell related changes on gcp

python
import netpyne
netpyne.__file__ # '/home/samnemo/netpyne/netpyne/__init__.py

updated /home/samnemo/netpyne/netpyne/cell/pointCell.py
from samnemo fork of netpyne

updated /home/samnemo/netpyne/netpyne/network/conn.py
from samnemo fork of netpyne

python -i tut_artif.py
produces spiking in the intf7 cells

** try same sim as on cycle but with targetted RL (20nov4_A0_gcp_)

./myrun 32 sn.json

started ~9:47 ...

** try ~same sim as on cycle but w/o noise (20nov4_B0_gcp_), with targetted RL

./myrun 32 sn.json

no firing  ... have to readjust weights if leaving off noise

ok, readjusted (increased EEGain) - start over

./myrun 32 sn.json

started ~10:22 ... 
increased EEGain again since rates went to 0
10:36 ...

./myrun 32 sn.json

stopped again - rates went down too low once more

** note for stdp.mod weight array -- only uses weight[0]

h.setpointer(singlesyn._ref_weight[0],'synweight',stdpmech) # Point the STDP mechanism to the connection weight

so for now when using on intf7 cells make sure only using plast at AM (AMPA) synapse (has weightIndex of 0)

** ID -> IV1DE, IV1DNE, etc. ?

each population should be treated separately?
otherwise too much competition between direction selective neurons

not clear that would help ... 

well, if opponent racket is moving south and ball moving north
then opponent racket activity would inhibit north moving activity ... 

for that reason may want topo for the interneurons ... 

or since EV1, EV1DE are mostly just spike sources
could avoid the interneurons in those areas ... 

in that case EV1, EV1DE may as well just be NSLOC type NetStim ... 

but then if ever want feedback connectivity/plasticity would have to redo ... 

** other test

increase conv onto EA??

** check output from (20nov3_B0_cycle_)

python -i simdat.py backupcfg/20nov3_B0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov4_20nov3_B0_cycle_perf.png]]
not bad for follow ~0.44 at end
hit, score are a bit low ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov4_20nov3_B0_cycle_rast.png]]
EA rates close to 0 ... do not see firing at end ... 
average EMDOWN,EMUP rates high ... ~30 Hz overall
were EA neurons turned off due to lack of input from EV1,EV1D?? from netstims running out of spikes to send?

xlim((0,10e3))
savefig(gifpath()+'rastB.png') # [[./gif/20nov4_20nov3_B0_cycle_rastB.png]]

xlim((500e3,510e3))
savefig(gifpath()+'rastC.png') # [[./gif/20nov4_20nov3_B0_cycle_rastC.png]]

xlim((250e3,260e3))
savefig(gifpath()+'rastD.png') # [[./gif/20nov4_20nov3_B0_cycle_rastD.png]]

xlim((0,1000e3))
savefig(gifpath()+'rastE.png') # [[./gif/20nov4_20nov3_B0_cycle_rastE.png]]
strange, activity definitely getting more sparse over the course of the simulation...
even EV1DN has sparser activity as the simulation progresses ... 

nsloc.mod has default number at 3000 ... and only used nsloc (as opposed to NetStim)
when using the INTF cells ... 

lc = [c for c in sim.net.cells if c.gid in sim.net.pops['stimModEV1DN'].cellGids]
ln = [c.hPointp.number for c in lc]

lc = [c for c in sim.net.cells if c.gid in sim.net.pops['stimModEV1'].cellGids]
ln = [c.hPointp.number for c in lc]

for pop in ['EV1DE', 'EV1DNE', 'EV1DN', 'EV1DNW', 'EV1DW', 'EV1DSW', 'EV1DS', 'EV1DSE']:
  lc = [c for c in sim.net.cells if c.gid in sim.net.pops['stimMod'+pop].cellGids]
  ln = [c.hPointp.number for c in lc]
  lint = [c.hPointp.ispike for c in lc]
  print(pop,ln,lint)

** fixed nsloc.mod -- to not limit number of spikes

removed conditional where ispike compared to number to turn off further spikes

** restart sim on cycle (20nov4_A0_cycle_)

./myrun 32 sn.json

started ~15:42 ... 

python -i simdat.py backupcfg/20nov4_A0_cycle_sim.json

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g','b'],plotindiv=True)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 

** restart sim on gcp (20nov4_A0_gcp_)

this one is same as 20nov4_A0_cycle_ but with targetted RL ... 

./myrun 32 sn.json

started ~15:44 ... 

* 20nov5
** check output from 20nov4_A0_gcp_

python -i simdat.py backupcfg/20nov4_A0_gcp_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov5_20nov4_A0_gcp_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov5_20nov4_A0_gcp_rast.png]]

EMDOWN,EMUP rates look too high

## clf(); drawcellVm(simConfig,ldrawpop=['EMUP','EA', 'IM'])

binsz = 100
dnspk = {pop:getspikehist(dspkT[pop],dnumc,binsz,totalDur) for pop in ['EMDOWN','EMUP','EA']}
for clr,pop in zip(['r','g','b'],['EMDOWN','EMUP','EA']): plot(dnspk[pop][0],dnspk[pop][1],clr)
xlim((0,totalDur))
ylim((0,900))
savefig(gifpath()+'EMDOWN_EMUP_EA_rate100.png') # [[./gif/20nov5_20nov4_A0_gcp_EMDOWN_EMUP_EA_rate100.png]]
EMDOWN,EMUP firing rates went up but couldn't get that high ... 
that was just a count of spikes - make getspikehist return freq in Hz

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP','EA']}

for clr,pop in zip(['r','g','b'],['EMDOWN','EMUP','EA']): plot(dnspk[pop][0],dnspk[pop][1],clr)
xlim((0,totalDur))
ylim((0,50))
savefig(gifpath()+'EMDOWN_EMUP_EA_rate1000.png') # [[./gif/20nov5_20nov4_A0_gcp_EMDOWN_EMUP_EA_rate1000.png]]
so rate goes much higher ~1/2 way through ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
xlabel('Time (ms)',fontsize=30); ylabel('Average weight',fontsize=30); tl(); 
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov5_20nov4_A0_gcp_all_avg_weight.png]]
ok, so avg weights increasing (at least intf7 stdp/rl working properly)

could run a continuation and/or get rid of noise ... 
or reduce noise since weights went up

        "name": "20nov5_A1_gcp_",

hmm, the noise weights were way too high ... 10000 (since 0.5 x EEGain)

so no sense in continuing that sim ... 

** readjust params for gcp sim -->> 20nov5_A0_gcp_ activity too sparse, hypersynch

        "name": "20nov5_A0_gcp_",

ok...started ~11:33 ... 500 s sim ...

python -i simdat.py backupcfg/20nov5_A0_gcp_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov5_20nov5_A0_gcp_perf.png]]
savefig(gifpath()+'perfB.png') # [[./gif/20nov5_20nov5_A0_gcp_perfB.png]]
pretty bad overall - but is it improving?

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov5_20nov5_A0_gcp_rast.png]]

EMDOWN,EMUP activity too sparse ... ? and hypersynch when it does occur

savefig(gifpath()+'rastB.png') # [[./gif/20nov5_20nov5_A0_gcp_rastB.png]]

** check output from 20nov4_A0_cycle_

python -i simdat.py backupcfg/20nov4_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov5_20nov4_A0_cycle_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov5_20nov4_A0_cycle_rast.png]]
same as other recent model from yesterday (20nov4_A0_gcp_) too much noise to EM

** next sim on cycle/gcp -->> rates too high

seems like not enough exploration , overly synchronized firing when
EM turns on - could add some noise or reduce conv onto EA and weight from EA -> EM

        "name": "20nov5_A0_cycle_",

        "name": "20nov5_A0_gcp_",

python -i simdat.py backupcfg/20nov5_A0_gcp_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov6_20nov5_A0_gcp_perf.png]]
bad performance - EMUP and EMDOWN populations got stuck competing too much ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov6_20nov5_A0_gcp_rast.png]]

rates way too high ...

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP','EA']}
for clr,pop in zip(['r','g','b'],['EMDOWN','EMUP','EA']): plot(dnspk[pop][0],dnspk[pop][1],clr)
xlim((0,totalDur))
savefig(gifpath()+'EMDOWN_EMUP_EA_rate1000.png') # [[./gif/20nov6_20nov5_A0_gcp_EMDOWN_EMUP_EA_rate1000.png]]

** next sim on gcp (20nov5_B0_gcp_)
** next sim on cycle (20nov5_B0_cycle_)
* 20nov6
** rates got too high - even early in sim (~20 s)

and then paddle gets stuck at top or bottom

stopped sim ... 

** adjust intf7 sim some more (20nov6_A0_cycle_)

turned off most of NM, adjusted EIGain ... 
reduce EM to 100 each ...
put in weight norm every 100 s ... to prevent later hypersynch ... 

./myrun 32 sn.json

started ~16:53 ... 
finished ~21:51 ... 

python -i simdat.py backupcfg/20nov6_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov6_20nov6_A0_cycle_perf.png]]
seems like some metrics increasing - note the normalization every 100 s ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov6_20nov6_A0_cycle_rast.png]]
hmm, firing rates way too high ... 

clf(); drawcellVm(simConfig,tlim=(490e3,500e3),lclr=['r','g','b','c','m','y'])
savefig(gifpath()+'Vm.png') # [[./gif/20nov6_20nov6_A0_cycle_Vm.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov6_20nov6_A0_cycle_all_avg_weight.png]]
some normalization taking place every 100 s as specified but does not seem like average weight is preserved ... ?? 

##clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False,prety='EMDOWN')
##savefig(gifpath()+'all_avg_weight.png')

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP','EA']}
for clr,pop in zip(['r','g','b'],['EMDOWN','EMUP','EA']): plot(dnspk[pop][0],dnspk[pop][1],clr)
xlim((0,totalDur))
ylim((0,200))
savefig(gifpath()+'EMDOWN_EMUP_EA_rate1000.png') # [[./gif/20nov6_20nov6_A0_cycle_EMDOWN_EMUP_EA_rate1000.png]]

ok, adjusted normalization ... 

* 20nov7
** next sim - norm, multistep (20nov7_A0_cycle_)

seems that paddle gets stuck when model first learns to go to one corner, then eventually weights get shifted in other
direction after many misses; but then there's a bias in the other direction and paddle gets stuck there
smaller weights may help but it seems like the model just flips back and forth between the extremes
so that means not learning much about the context ... or it is but requires refinement via small weight changes?

thought that the norm rule might keep balance between competing populations ... 

try a multistep to test ... 

have norm every 10 s when pop weights get below 0.9 or > 1.5 original ... 
small weight step (0.01) and short rl hebb window (15 ms) to try to prevent overlearning/getting stuck

python multistepSim.py sn.json 32 20 20nov7_A0_cycle_multi

started ~00:09 ...

** check output

got through ~5 steps by 20:15 ... 

synaptic weights are close to max of 2.4 (1.5X original of 1.6)

python -i simdat.py backupcfg/20nov7_A0_cycle__step_5_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov7_20nov7_A0_cycle__step_5_perf.png]]
not terrible ... relative to other sims

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov7_20nov7_A0_cycle__step_5_rast.png]]
but EMDOWN,EMUP rates have gotten pretty high (~28 Hz)

clf(); drawcellVm(simConfig,tlim=(490e3,500e3),lclr=['r','g','b','c','m','y'])
savefig(gifpath()+'Vm.png') # [[./gif/20nov7_20nov7_A0_cycle__step_5_Vm.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov7_20nov7_A0_cycle__step_5_all_avg_weight.png]]
weights already maxed-out...some alternation between whether EMUP or EMDOWN has higher weights... 

lfn = ['20nov7_A0_cycle__step_' + str(i) + '_' for i in range(0,7,1)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.3))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov7_20nov7_A0_cycle__step_5_perf_all_steps_so_far.png]]
values increasing ... but haven't gotten to best perf seen yet (compared to prev sims) ... 

lpda = getindivactionreward(lfn)
clf(); plotComparePerf(lpda,['g','b','r','c','m','y','k'],yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # [[./gif/20nov7_20nov7_A0_cycle__step_5_perf_compareB.png]]

can see if improves further but firing rates already pretty high and average weights close to limit ... so 
reshuffling weights only way to reorg network to produce appropriate response ... 

could run another sim from here - with higher max weights - or first normalize weights to starting level (preserving
relative values)... 

will see if allowing the weights to move higher helps ... 

** another multirun in parallel - higher max weights (continue from 20nov7_A0_cycle_ into 20nov7_B0_cycle_)

use these as starting weights:
data/20nov7_A0_cycle__step_6_synWeights_final.pkl

python multistepSim.py sn.json 32 13 20nov7_B0_cycle_multi

started ~23:22 ... 

* 20nov9
** check output from 20nov7_A0_cycle__step_12

python -i simdat.py backupcfg/20nov7_A0_cycle__step_12_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov9_20nov7_A0_cycle__step_12_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov9_20nov7_A0_cycle__step_12_rast.png]]
so the rates have continued to rise despire the normalization every 10 s ... and this one had max of 1.5 x initial weight
for each pop

clf(); drawcellVm(simConfig,tlim=(490e3,500e3),lclr=['r','g','b','c','m','y'])
savefig(gifpath()+'Vm.png') # [[./gif/20nov9_20nov7_A0_cycle__step_12_Vm.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)w
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov9_20nov7_A0_cycle__step_12_all_avg_weight.png]]
no stability yet ... 

lfn = ['20nov7_A0_cycle__step_' + str(i) + '_' for i in range(0,13,1)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov9_20nov7_A0_cycle__step_12_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # [[./gif/20nov9_20nov7_A0_cycle__step_12_perf_compareB.png]]

see some gradual improvements ... ? at least follow seems to be increasing ... 

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20nov9_20nov7_A0_cycle__step_12__input.mp4]]

should compare that one against the one with higher max weights, below ... 

** check output from 20nov7_B0_cycle__step_4

python -i simdat.py backupcfg/20nov7_B0_cycle__step_4_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov9_20nov7_B0_cycle__step_4_perf.png]]
this one looks decidedly worse ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov9_20nov7_B0_cycle__step_4_rast.png]]
EMDOWN,EMUP rates close to 200 Hz on avg, IM close to 400 Hz ... 

clf(); drawcellVm(simConfig,tlim=(490e3,500e3),lclr=['r','g','b','c','m','y'])
savefig(gifpath()+'Vm.png') # [[./gif/20nov9_20nov7_B0_cycle__step_4_Vm.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov9_20nov7_B0_cycle__step_4_all_avg_weight.png]]

lfn = ['20nov7_A0_cycle__step_' + str(i) + '_' for i in range(0,7,1)]
for i in range(0,5,1): lfn.append('20nov7_B0_cycle__step_'+str(i)+'_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov9_20nov7_B0_cycle__step_4_perf_all_steps_so_far.png]]
went up for a bit then started to decay, prob due to hypersynch

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # [[./gif/20nov9_20nov7_B0_cycle__step_4_perf_compareB.png]]
savefig(gifpath()+'perf_compareB2.png') # [[./gif/20nov9_20nov7_B0_cycle__step_4_perf_compareB2.png]]

will stop this multistep run ... should revise rules for normalization ... 

** check output from 20nov7_A0_cycle__step_13_

python -i simdat.py backupcfg/20nov7_A0_cycle__step_13_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov9_20nov7_A0_cycle__step_13_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov9_20nov7_A0_cycle__step_13_rast.png]]

clf(); drawcellVm(simConfig,tlim=(490e3,500e3),lclr=['r','g','b','c','m','y'])
savefig(gifpath()+'Vm.png') # [[./gif/20nov9_20nov7_A0_cycle__step_13_Vm.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov9_20nov7_A0_cycle__step_13_all_avg_weight.png]]

lfn = ['20nov7_A0_cycle__step_' + str(i) + '_' for i in range(0,14,1)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov9_20nov7_A0_cycle__step_13_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # [[./gif/20nov9_20nov7_A0_cycle__step_13_perf_compareB.png]]

** adjust norm rules

not clear which rule to use for norm ... ideally would want to preserve learning - would pop norm work
if same scaling factor was applied periodically? rate based homeostasis is ok but then have to push the
weights back to a boundary ... 

original weight norm rule may be ok if applied more often ... ? and would avoid rates ever getting too high ... 

        "name": "20nov9_C0_cycle_",

python -i simdat.py backupcfg/20nov9_C0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov9_20nov9_C0_cycle_perf.png]]
that looks worse than last step checked above from multirun ... ( [[./gif/20nov9_20nov7_A0_cycle__step_13_perf.png]] )
and from the comparable (from duration) step 7 of the multirun, seen here [[./gif/20nov9_20nov7_A0_cycle__step_13_perf_compareB.png]]

so that original weight norm rule did not seem to help ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov9_20nov9_C0_cycle_rast.png]]

clf(); drawcellVm(simConfig,tlim=(490e3,500e3),lclr=['r','g','b','c','m','y'])
savefig(gifpath()+'Vm.png') # [[./gif/20nov9_20nov9_C0_cycle_Vm.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov9_20nov9_C0_cycle_all_avg_weight.png]]

** other norm rule - go back to start after pass max thresh (20nov9_F0_cycle_)

use pop weight norm but allow more room for weights to change
go back to initial weight after passes max threshold ... and allow it to continue from there 

this sim also has smaller window for stdp tagging (10 ms) and smaller weight increments

python multistepSim.py sn.json 32 20 20nov9_E0_cycle_multi

started ~16:16 ...

check first few steps ~21:45 ..

python -i simdat.py backupcfg/20nov9_F0_cycle__step_1_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov9_20nov9_F0_cycle__step_1_perf.png]]

lfn = ['20nov9_F0_cycle__step_0_', '20nov9_F0_cycle__step_1_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov9_20nov9_F0_cycle__step_1_perf_all_steps_so_far.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov9_20nov9_F0_cycle__step_1_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov9_20nov9_F0_cycle__step_1_all_avg_weight.png]]

** another to compare (20nov9_G0_cycle_) -->> later -->> now

shorter RLlenhebb (from 200 to 50) and no reward for scoring point

will leave that for later (or now) ... sometimes a few frames before move taken even with command from a few ago, 
so could keep longer window ... 

    "rewardcodes": {
        "scorePoint": 0.0,
        "losePoint":  0.0,
        "followTarget": 0.1,
        "avoidTarget": -0.1,
        "hitBall": 0.5
    },

        "AMPA": {
            "wbase": 0.16,
            "wmax": 16,
            "RLon": 1,
	    "STDPon": 0,
            "RLlenhebb": 50,
            "RLlenanti": 50,
            "useRLexp": 0,
            "RLhebbwt": 0.005,
            "RLantiwt": 0,
            "hebbwt": 0.0,
            "antiwt": 0.0,
            "tauhebb": 10,
            "tauanti": 10,	    
            "RLwindhebb": 10,
            "softthresh": 0,
            "verbose": 0,
	    "maxreward": 0.0
        },

norm same as above ... 

python multistepSim.py sn.json 32 20 20nov9_G0_cycle_multi

started ~22:23 ...

* 20nov10
** check 20nov9_G0_cycle__step_1_

python -i simdat.py backupcfg/20nov9_G0_cycle__step_1_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov10_20nov9_G0_cycle__step_1_perf.png]]
much worse with the shorter tau, more punishment for not follow, no reward score

lfn = ['20nov9_G0_cycle__step_0_','20nov9_G0_cycle__step_1_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov10_20nov9_G0_cycle__step_1_perf_all_steps_so_far.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov10_20nov9_G0_cycle__step_1_rast.png]]
firing rates are also much lower than other sim

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov10_20nov9_G0_cycle__step_1_all_avg_weight.png]]
average weights are mostly lower too ... 

will stop this one ... 

** check 20nov9_F0_cycle__step_3_

python -i simdat.py backupcfg/20nov9_F0_cycle__step_3_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov10_20nov9_F0_cycle__step_3_perf.png]]

lfn = ['20nov9_F0_cycle__step_0_','20nov9_F0_cycle__step_1_','20nov9_F0_cycle__step_2_','20nov9_F0_cycle__step_3_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov10_20nov9_F0_cycle__step_3_perf_all_steps_so_far.png]]
not so great either ... so far ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov10_20nov9_F0_cycle__step_3_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov10_20nov9_F0_cycle__step_3_all_avg_weight.png]]

lfn = ['20nov9_F0_cycle__step_0_','20nov9_F0_cycle__step_1_','20nov9_F0_cycle__step_2_','20nov9_F0_cycle__step_3_','20nov9_F0_cycle__step_4_']
lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # [[./gif/20nov10_20nov9_F0_cycle__step_3_perf_compareB.png]]

improving ... will take time 

** why does paddle get stuck at corners? (20nov10_B0_cycle_)

maybe because there are a lot more direction selective neurons compared to location specific?
generally northeast moving ball means paddle should move up so the signal for ball moving northeast
may overwhelm the location specific information??

could increase weights/connections from EV1 -> EA
could have a rule that prevents paddle from moving up if already at top, or from moving down if already at bottom
see if that helps ... 

ok, added a simple rule for that ... will try it out ...

./myrun 32 sn.json 

python -i simdat.py backupcfg/20nov10_B0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov10_20nov10_B0_cycle_perf.png]]
looks much better than w/o the avoidstuck rule ... 

lfn = ['20nov10_B0_cycle_', '20nov9_F0_cycle__step_0_']
lpda = getindivactionreward(lfn)
lclr = ['r','b']
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareA.png') # [[./gif/20nov10_20nov10_B0_cycle_perf_compareA.png]]
much better with the avoidstuck rule ... question is whether it's ok to use it
or other way around ... alternatives are to penalize for spending time in corner, or increase
weight of visual location neurons ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov10_20nov10_B0_cycle_rast.png]]

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20nov10_20nov10_B0_cycle__input.mp4]]

will continue this one in a multistep run ... 

    "avoidStuck": 1,
        "name": "20nov10_B1_cycle_",
    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20nov10_B0_cycle_synWeights.pkl"
    },

python multistepSim.py sn.json 32 20 20nov10_B1_cycle_multi

started ~22:53 ...

** meanwhile check 20nov9_F0_cycle__step_7_ -->> some improvements

python -i simdat.py backupcfg/20nov9_F0_cycle__step_7_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov10_20nov9_F0_cycle__step_7_perf.png]]

lfn = ['20nov9_F0_cycle__step_' + str(i) + '_' for i in range(0,8,1)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov10_20nov9_F0_cycle__step_7_perf_all_steps_so_far.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov10_20nov9_F0_cycle__step_7_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov10_20nov9_F0_cycle__step_7_all_avg_weight.png]]

weights getting close to boundary of 2.8 when normalization will activate, can then see if results
improve further with normalization-induced lower firing rates

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # [[./gif/20nov10_20nov9_F0_cycle__step_7_perf_compareB.png]]

** check 20nov9_F0_cycle__step_8_

python -i simdat.py backupcfg/20nov9_F0_cycle__step_8_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov10_20nov9_F0_cycle__step_8_perf.png]]

lfn = ['20nov9_F0_cycle__step_' + str(i) + '_' for i in range(0,9,1)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov10_20nov9_F0_cycle__step_8_perf_all_steps_so_far.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov10_20nov9_F0_cycle__step_8_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov10_20nov9_F0_cycle__step_8_all_avg_weight.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # [[./gif/20nov10_20nov9_F0_cycle__step_8_perf_compareB.png]]
still improving somewhat, and have not reached max weights in this one yet, so did not get to see if
norm and then inc weights help ... so will let this multistep sim continue further

* 20nov11
** check 20nov9_F0_cycle__step_11_ -->> this multistep stopped after step 12 completed (avoidstuck doing better)

python -i simdat.py backupcfg/20nov9_F0_cycle__step_11_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov11_20nov9_F0_cycle__step_11_perf.png]]

lfn = ['20nov9_F0_cycle__step_' + str(i) + '_' for i in range(0,12,1)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov11_20nov9_F0_cycle__step_11_perf_all_steps_so_far.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov11_20nov9_F0_cycle__step_11_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov11_20nov9_F0_cycle__step_11_all_avg_weight.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # [[./gif/20nov11_20nov9_F0_cycle__step_11_perf_compareB.png]]
step 9 much worse than step 8 ... 
step 9 is where the change in weights took place ... 

** check 20nov10_B1_cycle__step_1_ , 20nov10_B1_cycle__step_2_

python -i simdat.py backupcfg/20nov10_B1_cycle__step_1_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov11_20nov10_B1_cycle__step_1_perf.png]]
hit/miss and score much higher than got before - consistently ... 

step 2 just finished ... 

python -i simdat.py backupcfg/20nov10_B1_cycle__step_2_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov11_20nov10_B1_cycle__step_2_perf.png]]
looks good too ... 

lfn = ['20nov10_B0_cycle_']
for i in range(0,3,1): lfn.append('20nov10_B1_cycle__step_' + str(i) + '_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov11_20nov10_B1_cycle__step_2_perf_all_steps_so_far.png]]
hit/miss looks improving ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov11_20nov10_B1_cycle__step_2_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov11_20nov10_B1_cycle__step_2_all_avg_weight.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # [[./gif/20nov11_20nov10_B1_cycle__step_2_perf_compareB.png]]

step1 was best ... but step 2 comparable ... well, step 2 had more points

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20nov11_20nov10_B1_cycle__step_2__input.mp4]]

can make movie of step 1 too ...

python -i simdat.py backupcfg/20nov10_B1_cycle__step_1_sim.json

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov11_20nov10_B1_cycle__step_1_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov11_20nov10_B1_cycle__step_1_all_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20nov11_20nov10_B1_cycle__step_1__input.mp4]]

** other adjustments to improve perf

analog output - similar to simon's output encoding?
higher resolution for visual inputs? 
higher weight from EV1 -> X ? to have a way out of the explicit avoid stuck rule? or
other punishment signal for when gets stuck in corner?
or leave that issue alone for now - note that we're using a 'crutch' - and when get
better/winning performance go back and see if worth fixing ... 

other circuit solution for avoidstuck - have more interneurons synapse on EMUP at
the top and mre interneurons synapse on EMDOWN at the bottom ... but that would only
work if there was some topology to the EM populations ... or it could be learned
via I -> E plasticity ... 

** try with 1600 EV1 (40x40) neurons 

        "name": "20nov11_C0_cycle_",

since increased the number of EV1 4X reduced their weights to EA, EMDOWN, EMUP somewhat
though not exactly by 1/4 ... since EV1 have sparse firing rates ... got similar rates in EA (~3 Hz)
and similar starting rates for EMDOWN, EMUP ... running for 500 s to test ... not noticeably slower
than with lower number of EV1 ... 

./myrun 32 sn.json

python -i simdat.py backupcfg/20nov11_C0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov11_20nov11_C0_cycle_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov11_20nov11_C0_cycle_rast.png]]

lfn = ['20nov11_C0_cycle_', '20nov10_B0_cycle_']
lpda = getindivactionreward(lfn)
lclr = ['r','b']
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareA.png') # [[./gif/20nov11_20nov11_C0_cycle_perf_compareA.png]]
higher res for EV1 (red) slightly better in hits/ & score ... although also has very slightly higher firing rates ... 

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20nov11_20nov11_C0_cycle__input.mp4]]
note that in that movie the ball's shape changes when it flies across the screen; it alternates
between being vertically or horizontally oriented; ...although
it's probably a thresholding/discretization artifact, this might contribute to some errors
could check the image processing/downsampling routines and make sure no better way to do it
(simon suggested taking max instead of mean? would that preserve shape better?)

** continue 1600 EV1 (40x40) with multistep on gcp

copied 20nov11_C0_cycle_synWeights_final.pkl from cycle to nrngames3
copied 20nov11_C0_cycle_sim.json from cycle to nrngames3

while at it could inc size of direction selective neurons too ...
and EA ... or just inc size of EV1 ... to 80x80 since motion directions
are highly redundant but spatial/location info more critical for moving
to precise location to hit ball (?) ... will do that later ... for now
will keep with the 1600 EV1, already higher resolution ...

#python -i simdat.py backupcfg/20nov11_D0_gcp_sim.json
#
#clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); 
#savefig(gifpath()+'rast.png')
#
#clf(); drawcellVm(simConfig,lclr=['r','g','b','c','m','y'])

    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20nov11_C0_cycle_synWeights_final.pkl"
    },

python multistepSim.py sn.json 32 20 20nov11_D0_gcp_multi

started ~23:21 ...

* 20nov12
** adjustment of avoidStuck?

if paddle not visible or obscured could also force a move down
the reason is that current avoidStuck rule only avoids going into the
corner further, and only moves away from the corner when that move is
generated by the model 

** check output from 20nov11_D0_gcp__step_3_

python -i simdat.py backupcfg/20nov11_D0_gcp__step_3_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov12_20nov11_D0_gcp__step_3_perf.png]]
good perf.

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov12_20nov11_D0_gcp__step_3_rast.png]]

will move data to cycle @ nki before continuing analysis ... 

#lfn = ['20nov11_C0_cycle_', '20nov10_B0_cycle_']
#lpda = getindivactionreward(lfn)
#lclr = ['r','b']
#clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
#savefig(gifpath()+'perf_compareA.png') 
#
#fig=animInput(InputImages,gifpath()+'_input.mp4')
** check output from 20nov10_B1_cycle__step_9_

python -i simdat.py backupcfg/20nov10_B1_cycle__step_9_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov12_20nov10_B1_cycle__step_9_perf.png]]

lfn = ['20nov10_B0_cycle_']
for i in range(0,10,1): lfn.append('20nov10_B1_cycle__step_' + str(i) + '_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov12_20nov10_B1_cycle__step_9_perf_all_steps_so_far.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov12_20nov10_B1_cycle__step_9_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov12_20nov10_B1_cycle__step_9_all_avg_weight.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.5),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # [[./gif/20nov12_20nov10_B1_cycle__step_9_perf_compareB.png]]

step 5 best so far; hit/miss ratio even goes > 1 ... 

load that one to look at movie and rates ...

python -i simdat.py backupcfg/20nov10_B1_cycle__step_5_sim.json

ax=plotPerf(actreward,yl=(0,1.5))
savefig(gifpath()+'perf.png') # [[./gif/20nov12_20nov10_B1_cycle__step_5_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov12_20nov10_B1_cycle__step_5_rast.png]]
EMDOWN,EMUP rates ~30 Hz ... ~same as in step 9 ...

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov12_20nov10_B1_cycle__step_5_all_avg_weight.png]]
so this step is wehre the normalization occurred - near the end 

so normalization question is whether performance will get higher than it was before ... if not, network might be saturated by
the time get to those higher weights/rates. but note that the rates ~30 Hz occurred when performance was highest...

fig=animInput(InputImages,gifpath()+'_input.mp4') 

** get data from gcp so can look at it -- check 20nov11_D0_gcp__step_5_

ok, downloaded it to laptop then uploaded to cycle

e.g. used this to get data to laptop:
gsutil -m cp -r gs://samn_data2/SMARTAgent/data/ ./data/
gsutil -m cp -r gs://samn_data2/SMARTAgent/gif/ ./gif/
gsutil -m cp -r gs://samn_data2/SMARTAgent/backupcfg/ ./backupcfg/

then sftp'ed over to cycle

python -i simdat.py backupcfg/20nov11_D0_gcp__step_5_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov12_20nov11_D0_gcp__step_5_perf.png]]
pretty good ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov12_20nov11_D0_gcp__step_5_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov12_20nov11_D0_gcp__step_5_all_avg_weight.png]]
weights right before normalization ... 

lfn = ['20nov11_C0_cycle_']
for i in range(6): lfn.append('20nov11_D0_gcp__step_' + str(i) + '_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov12_20nov11_D0_gcp__step_5_perf_all_steps_so_far.png]]
improving ...how does it compare to the multistep sim being run on cycle, with fewer EV1?

lfn2 = ['20nov10_B0_cycle_']
for i in range(0,10,1): lfn2.append('20nov10_B1_cycle__step_' + str(i) + '_')
pdac2 = getconcatactionreward(lfn2)

lpda = [pdac, pdac2]
lclr = ['r','b']
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=['EV1 40x40','EV1 20x20'])
savefig(gifpath()+'perf_compareA.png') # [[./gif/20nov12_20nov11_D0_gcp__step_5_perf_compareA.png]]
scoring is a little higher for the 40x40 EV1; but other metrics are a little lower/unclear ... 
hit/miss is sometimes higher, sometimes lower ...
for EV1 40x40 to work properly may need larger middle EA layer ... and reduced VD,VL -> EA weights
but ultimately score is what matters ... so might make sense to use the 40x40 EV1 ...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.5),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # [[./gif/20nov12_20nov11_D0_gcp__step_5_perf_compareB.png]]
step3 best so far ... will make that movie 

python -i simdat.py backupcfg/20nov11_D0_gcp__step_3_sim.json

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20nov12_20nov11_D0_gcp__step_3__input.mp4]]

should show ongoing score and metrics in animInput ... 

stopped this one for now ... 

** other sim on gcp - no interm reward

no targetted, only score/loss ? ? 

        "name": "20nov12_E0_gcp_",

and use first 500 s of training with targetted + intermediate rewards to bootstrap?

unlikely to work but worth a try ... 

python -i simdat.py backupcfg/20nov12_E0_gcp_sim.json

drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); 

python multistepSim.py sn.json 32 20 20nov12_E0_gcp_multi

started ~20:56 ...

* 20nov13
** check output from 20nov12_E0_gcp__step_4_

python -i simdat.py backupcfg/20nov12_E0_gcp__step_4_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov13_20nov12_E0_gcp__step_4_perf.png]]
expected it to be doing worse ... given only the sparse rewards ... maybe due
to initial training with intermediate rewards ...

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov13_20nov12_E0_gcp__step_4_rast.png]]
rates are ok ... but overall the activity is sparse/bursty and there aren't moves
generated on each step ... too many 0s ... might do better with some firing on every step

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov13_20nov12_E0_gcp__step_4_all_avg_weight.png]]
weights are still going up on average due to model scoring points, and in between down slightly each time
(more numerous) a point is lost. 

lfn = ['20nov11_C0_cycle_'] # sim with the intermediate rewards
for i in range(5): lfn.append('20nov12_E0_gcp__step_'+str(i)+'_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov13_20nov12_E0_gcp__step_4_perf_all_steps_so_far.png]]
not clear getting better ... ? maybe slightly ... note that 0-500 s is using the intermediate
training, then at 500 s it's turned off and only uses score/lose ... might improve a bit
ylim((0.25,0.375))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/20nov13_20nov12_E0_gcp__step_4_perf_all_steps_so_farB.png]]
ylim((0.04,0.14))
savefig(gifpath()+'perf_all_steps_so_farC.png') # [[./gif/20nov13_20nov12_E0_gcp__step_4_perf_all_steps_so_farC.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.5),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20nov13_20nov12_E0_gcp__step_4_perf_compareD.png]]
step 3 seems best ... and that's after intermediate reward was turned off ... 

** useful karpathy article

https://karpathy.github.io/2016/05/31/rl/

2 layers with policy gradient
first hidden layer gets all inputs (all to all; 100 neurons), second layer gets all from first hidden
layer and uses that to make decision stochastically. when probability of output variable > threshold
produce an up move, otherwise down (no stay move used). uses gradient descent to train weights to
hidden layer and to policy output. makes the argument that credit assignment problem does not have to
be solved, just twiddling the weights over time will smooth out the errors in credit assignment.
would a similar architecture work in our case?

stochastic decisions would allow removing one population of EM (or just a single output neuron)
as well as the interneurons. but would require learning all to hidden layer, which is first
order information.

worth a try ... 

** new opt stochmove

when stochmove == 1 then randomly pick an up/down move if it's a tie between EMUP,EMDOWN (including if both 0)

** simpler arch - based on karpathy

it's just all to all for two layers ... and up/down w/o any stay moves
plast between VL,VD -> EA -> EM
but not clear VL,VD -> EA should use RL/STDP ... 

    "stochmove": 1,
        "name": "20nov13_A0_lp_",

python -i simdat.py backupcfg/20nov13_A0_lp_sim.json

drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); 

drawcellVm(simConfig,lclr=['r','g','b','c','m','y'])

** check output from 20nov10_B1_cycle__step_17_ and final step of multistep (19)

python -i simdat.py backupcfg/20nov10_B1_cycle__step_17_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov13_20nov10_B1_cycle__step_17_perf.png]]
score seems to be clearly going up ... hit/miss goes up > 50% ... 

lfn = ['20nov10_B0_cycle_']
for i in range(0,18,1): lfn.append('20nov10_B1_cycle__step_' + str(i) + '_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov13_20nov10_B1_cycle__step_17_perf_all_steps_so_far.png]]
looks like improving overall ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov13_20nov10_B1_cycle__step_17_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov13_20nov10_B1_cycle__step_17_all_avg_weight.png]]
weight norm right near beginning ... so that's where activity dropped and perf increased from there

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.5),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # [[./gif/20nov13_20nov10_B1_cycle__step_17_perf_compareB.png]]

step 7 looks best in terms of score ... 

python -i simdat.py backupcfg/20nov10_B1_cycle__step_7_sim.json

ax=plotPerf(actreward,yl=(0,1.5))
savefig(gifpath()+'perf.png') # [[./gif/20nov13_20nov10_B1_cycle__step_7_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov13_20nov10_B1_cycle__step_7_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov13_20nov10_B1_cycle__step_7_all_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20nov13_20nov10_B1_cycle__step_7__input.mp4]]

python -i simdat.py backupcfg/20nov10_B1_cycle__step_19_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov13_20nov10_B1_cycle__step_19_perf.png]]

lfn = ['20nov10_B0_cycle_']
for i in range(0,20,1): lfn.append('20nov10_B1_cycle__step_' + str(i) + '_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov13_20nov10_B1_cycle__step_19_perf_all_steps_so_far.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov13_20nov10_B1_cycle__step_19_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov13_20nov10_B1_cycle__step_19_all_avg_weight.png]][[

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.5),lleg=lfn)
savefig(gifpath()+'perf_compareB.png') # [[./gif/20nov13_20nov10_B1_cycle__step_19_perf_compareB.png]]

so now that this sim is finished and the perf not increased as much as had hoped - continue or adjust avoidstuck rule?

** adjust avoidstuck

add these:
if paddle < 8 go down
if paddle > 152 go up

** sim with EA2 on cycle (20nov13_B0_cycle_)

have plast in EA2 recurrent and EA2 -> EM, EA -> EA2
no targetted RL, no intermediate ... only score/loss
but have avoidstuck on ...

python multistepSim.py sn.json 32 20 20nov13_B0_gcp_multi

started ~23:25 ...

* 20nov14
** check output from gcp (final step 19) -->> do not see improvement

python -i simdat.py backupcfg/20nov12_E0_gcp__step_19_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov15_20nov12_E0_gcp__step_19_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov15_20nov12_E0_gcp__step_19_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov15_20nov12_E0_gcp__step_19_all_avg_weight.png]]

lfn = ['20nov11_C0_cycle_'] # sim with the intermediate rewards
for i in range(20): lfn.append('20nov12_E0_gcp__step_'+str(i)+'_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov15_20nov12_E0_gcp__step_19_perf_all_steps_so_far.png]]
does not look like improving ... 

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.5),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20nov15_20nov12_E0_gcp__step_19_perf_compareD.png]]

not clear if normalization is preventing improvement ... could use softhresh rule with same max weight ... 

** check output from 20nov13_B0_cycle__step_4_

python -i simdat.py backupcfg/20nov13_B0_cycle__step_4_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov14_20nov13_B0_cycle__step_4_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov14_20nov13_B0_cycle__step_4_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov14_20nov13_B0_cycle__step_4_all_avg_weight.png]]
weights just dropping ... 

lfn = ['20nov13_B0_cycle__step_'+str(i)+'_' for i in range(5)] 
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov14_20nov13_B0_cycle__step_4_perf_all_steps_so_far.png]]
does not look like improving ... except for during a small stretch

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,.5),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20nov14_20nov13_B0_cycle__step_4_perf_compareD.png]]

do not see improvement ... at least in those metrics ... do see score once in a long while,
which is why average weight slightly above initial (1.2)

too many 0s in firing rates ... could try the stochmove and see if helps move paddle
more to where model could learn ... 

0 punishment would help weights avoid getting too low ... but miss out on most of the learning ... 

stopped for now ... 

** update to rules

what if instead of stochmove in case there's a tie or 0 rates, just continued in same direction as last move?
that way sparse rates would not always be a problem ... that's similar to analog with 100% weighting for last move
tried that with stochmove param - looks like often goes too far 
also changed avoidstuck to first check if needs to go in opposite direction, to avoid having it stuck for longer...
that creates a bounce-back effect ... 

** 20nov14_A0_cycle_

back to targetted ... but also have the EA2 with RL plast to EM ... 

python multistepSim.py sn.json 32 20 20nov14_A0_gcp_multi

started ~23:21 ...

* 20nov15
** check output from 20nov14_A0_cycle__step_5_ -->> doing well (has targetted RL + intermediate reward)

python -i simdat.py backupcfg/20nov14_A0_cycle__step_5_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov15_20nov14_A0_cycle__step_5_perf.png]]
perf looks pretty high ... including score/miss ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov15_20nov14_A0_cycle__step_5_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov15_20nov14_A0_cycle__step_5_all_avg_weight.png]]

lfn = ['20nov14_A0_cycle__step_'+str(i)+'_' for i in range(6)] 
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.5))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov15_20nov14_A0_cycle__step_5_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20nov15_20nov14_A0_cycle__step_5_perf_compareD.png]]

so far last step is the best ... seems better than other sims in terms of overall score/loss

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20nov15_20nov14_A0_cycle__step_5__input.mp4]]

by mistake had rllenhebb of 2000 ... leftover from when had no interm reward ... 

** comparison sim

still would be good to get progress w/o intermediate reward ... 

could compare what get w/o intermediate reward, no targetted RL, and no punishment for loss ... to see
if decreasing weights/rates are the issue/problem

        "name": "20nov15_B0_cycle_",
        "targettedRL": 0,
    "rewardcodes": {
        "scorePoint": 1.0,
        "losePoint":  0.0,
        "followTarget": 0.0,
        "avoidTarget": 0.0,
        "hitBall": 0.0
    },
        "RLconns":{
	    "EIPlast":0,
            "Visual":0,
            "RecurrentDirNeurons":0,
            "RecurrentLocNeurons":0,
            "FeedForwardDirNtoA":0,
            "FeedForwardLocNtoA":0,
            "FeedForwardDirNtoM":0,
            "FeedForwardLocNtoM":0,	    
            "FeedForwardAtoM":1,
            "FeedForwardAtoA2":1,
            "FeedForwardA2toM":1,	    
            "FeedbackLocNeurons":0,
            "RecurrentMNeurons":1,
            "RecurrentANeurons":0,
            "RecurrentA2Neurons":1,
            "FeedbackAtoDirN":0,
            "FeedbackAtoLocN":0
        },	

python multistepSim.py sn.json 32 20 20nov15_B0_gcp_multi

started ~22:25 ... 

* 20nov16
** check 20nov15_B0_cycle__step_1_

python -i simdat.py backupcfg/20nov15_B0_cycle__step_1_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov16_20nov15_B0_cycle__step_1_perf.png]]
worse perf than with the punishment for point loss ... 

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov16_20nov15_B0_cycle__step_1_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov16_20nov15_B0_cycle__step_1_all_avg_weight.png]]

lfn = ['20nov15_B0_cycle__step_'+str(i)+'_' for i in range(2)] 
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.5))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov16_20nov15_B0_cycle__step_1_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20nov16_20nov15_B0_cycle__step_1_perf_compareD.png]]

so barely any progress with that one ... 

** check 20nov14_A0_cycle__step_8_

python -i simdat.py backupcfg/20nov14_A0_cycle__step_8_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov16_20nov14_A0_cycle__step_8_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov16_20nov14_A0_cycle__step_8_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov16_20nov14_A0_cycle__step_8_all_avg_weight.png]]

lfn = ['20nov14_A0_cycle__step_'+str(i)+'_' for i in range(9)] 
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.5))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov16_20nov14_A0_cycle__step_8_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20nov16_20nov14_A0_cycle__step_8_perf_compareD.png]]

step 5 still best ... 

** HA put useImagePadding option in

to use set it in json file and increase number of neurons to 576 (EV1, EV1DE, etc.)
24**2

** other sim

should prob shorten the RL tau for the sim with targetted RL ... 

        "name": "20nov16_A0_cycle_",

python -i simdat.py backupcfg/20nov16_A0_cycle_sim.json

python -i simdat.py backupcfg/20nov16_B0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png')

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','g','b','c'],plotindiv=False)

drawcellVm(simConfig,lclr=['r','g','b','c','m','y'])

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP','EA','EA2']}
for clr,pop in zip(['r','g','b','c'],['EMDOWN','EMUP','EA','EA2']): plot(dnspk[pop][0],dnspk[pop][1],clr)
xlim((0,totalDur))
ylim((0,200))

* 20nov17
** stochmove,imagepadding test

python -i simdat.py backupcfg/20nov16_C0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov17_20nov16_C0_cycle_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov17_20nov16_C0_cycle_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g','b','c'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov17_20nov16_C0_cycle_all_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20nov17_20nov16_C0_cycle__input.mp4]]

** fixup issues with image padding (paddle size changing) and ball size changing

./myrun 12 sn.json

#python -i simdat.py backupcfg/20nov17_A0_lp_sim.json
#fig=animInput(InputImages,gifpath()+'_input.mp4') 
** check output from 20nov14_A0_cycle__step_19_

python -i simdat.py backupcfg/20nov14_A0_cycle__step_19_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov17_20nov14_A0_cycle__step_19_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov17_20nov14_A0_cycle__step_19_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov17_20nov14_A0_cycle__step_19_all_avg_weight.png]]

lfn = ['20nov14_A0_cycle__step_'+str(i)+'_' for i in range(20)] 
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.5))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov17_20nov14_A0_cycle__step_19_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20nov17_20nov14_A0_cycle__step_19_perf_compareD.png]]

still has not done much better than an early step (step 5 or 6)

and the normalization does seem to knock performance down ... and builds up from there but
probably erases a lot of what was learned ? 

** sim with more EV1 on cycle (20nov17_A0_cycle_)

6400 EV1 ... 400 of direction selective, avoidstuck ... 
targetted ... more EMDOWN, EMUP neurons ... 

with the usual weight norm but won't kick in for a while ... 

./myrun 32 sn.json

started ~16:52 ... 
finished ~23:44 ...

python -i simdat.py backupcfg/20nov17_A0_cycle_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov17_20nov17_A0_cycle_perf.png]]

clf(); drawraster(dspkT,dspkID); ylim((0,sum(list(dnumc.values())))); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov17_20nov17_A0_cycle_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov17_20nov17_A0_cycle_all_avg_weight.png]]

may as well continue overnight ... 

        "name": "20nov17_A1_cycle_",
    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20nov17_A0_cycle_synWeights_final.pkl"
    },

python multistepSim.py sn.json 32 20 20nov17_A1_gcp_multi

* 20nov18
** check output from 20nov17_A1_cycle__step_0_

python -i simdat.py backupcfg/20nov17_A1_cycle__step_0_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov18_20nov17_A1_cycle__step_0_perf.png]]
that jumped up quite a bit from last step ... 

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov18_20nov17_A1_cycle__step_0_rast.png]]

adjusted drawraster to not draw the stimmods by default

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov18_20nov17_A1_cycle__step_0_all_avg_weight.png]]

lfn = ['20nov17_A0_cycle_', '20nov17_A1_cycle__step_0_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.36))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov18_20nov17_A1_cycle__step_0_perf_all_steps_so_far.png]]

looks like clearly improving ...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20nov18_20nov17_A1_cycle__step_0_perf_compareD.png]]

should include the scores/metrics in animinput ... 

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gifpath()+'_input.mp4']]

a,b,c = getCumPerfCols(actreward)

fig=animInput(InputImages,'test.mp4',actreward=actreward)

binsz = 20
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP']}
for clr,pop in zip(['r','b'],['EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)

EMDOWN, EMUP rates are almost the same at each step ... 

rdiff = np.array(dnspk['EMUP'][1]) - np.array(dnspk['EMDOWN'][1])

plot(dnspk['EMDOWN'][0], rdiff, color='k', linewidth=3); xlim((0,totalDur))
savefig(gifpath()+'EMUP_minus_EMDOWN.png') # [[./gif/20nov18_20nov17_A1_cycle__step_0_EMUP_minus_EMDOWN.png]]


would be useful to visualize what each EM neuron knows about the environment - RFs
that's what getinputmap shows ... but only 1st order connections ... and uses pdf ... which only
has the plastic weights ... or to show the spatial evidence/weight for a specific move 

meanwhile, check next step

python -i simdat.py backupcfg/20nov17_A1_cycle__step_1_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov18_20nov17_A1_cycle__step_1_perf.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov18_20nov17_A1_cycle__step_1_rast.png]]
rates have gone up quite a bit ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov18_20nov17_A1_cycle__step_1_all_avg_weight.png]]

lfn = ['20nov17_A0_cycle_', '20nov17_A1_cycle__step_0_',  '20nov17_A1_cycle__step_1_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.425))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov18_20nov17_A1_cycle__step_1_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20nov18_20nov17_A1_cycle__step_1_perf_compareD.png]]
looks clearly better this step ...

fig=animInput(InputImages,gifpath()+'_input.mp4',actreward=actreward) # [[./gif/20nov18_20nov17_A1_cycle__step_1__input.mp4]]


tt = np.unique(pdf.time)

dout = getpopinputmap(pdf, tt[0], dnumc, dstartidx, dendidx, 'EA')
clf(); plotallinputmaps(pdf,tt[0],dstartidx['EMDOWN'],'EMDOWN',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)

savefig(gifpath()+'EMDOWN_inputmap_first.png') 

dout = getpopinputmap(pdf, tt[-1], dnumc, dstartidx, dendidx, 'EMDOWN')
clf(); plotallinputmaps(pdf,tt[-1],dstartidx['EMDOWN'],'EMDOWN',dnumc,dstartidx,dendidx,asweight=True,dmap=dout)
savefig(gifpath()+'EMDOWN_inputmap_last.png') 

** related sim on gcp -- more EV1 (25600), no EV1DE, etc.

        "name": "20nov18_A0_gcp_",

can try with full scale for EV1 and no directional neurons?

160**2 = 25600

#pravgrates(dspkT,dspkID,dnumc)
drawraster(dspkT,dspkID)
drawcellVm(simConfig,lclr=['r','g','b','c','m','y'])

./myrun 48 sn.json

started ~17:25 ...

no more firing after a few hundred s ... weights were too low to start ... 

adjusted weights and kept probabilities  as original ... note that there are
400 EM neurons ... 

./myrun 48 sn.json

started ~23:45 ... finished ~6 AM

* 20nov19
** check output from 20nov18_A0_gcp_ -->> continue

python -i simdat.py backupcfg/20nov18_A0_gcp_sim.json

had good rates overall:
EV1 0.69 Hz
EA 3.55 Hz
EA2 5.3 Hz
IA2 12.91 Hz
EMDOWN 15.91 Hz
EMUP 15.91 Hz
IM 27.01 Hz
stimModEV1 0.76 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov19_20nov18_A0_gcp_perf.png]]
not great, but similar to other first steps ...

clf(); drawraster(dspkT,dspkID); xlim((496e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov19_20nov18_A0_gcp_rast.png]]
based on the raster, EA,EM only fire when there's motion, even though there are no
explicitly motion-sensitive neurons ... or just due to ball being on screen, contributing
to firing activity

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov19_20nov18_A0_gcp_all_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_input.mp4',actreward=actreward) # [[./gif/20nov19_20nov18_A0_gcp__input.mp4]]

so, worth continuing this one in multistep ... or lowering weights/rates of EM first

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP']}
for clr,pop in zip(['r','b'],['EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)

savefig(gifpath()+'EM_rate_hist.png') # [[./gif/20nov19_20nov18_A0_gcp_EM_rate_hist.png]]
rates increasing ... start somewhat high ... firing also seems more bursty in this sim ... 

** adjust gcp sim

./myrun 48 sn.json

too slow ... not terrible but perhaps no need for 160x160

** next sim on gcp

will use same sim as on cycle with EV1 of 80x80 (instead of 160x160) , remove direction selective
neurons, and scale up weights from EV1 -> X ...

ok, somewhat better rates ... 

./myrun 32 sn.json

python -i simdat.py backupcfg/20nov19_A0_gcp_sim.json

EV1 0.7 Hz
EA 5.25 Hz
EA2 8.35 Hz
IA2 20.73 Hz
EMDOWN 11.85 Hz
EMUP 11.83 Hz
IM 44.98 Hz
stimModEV1 0.76 Hz

overall rates ok so far ... 

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov20_20nov19_A0_gcp_perf.png]]
perf (hit/miss) increasing slowly ...

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov20_20nov19_A0_gcp_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov20_20nov19_A0_gcp_all_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_input.mp4',actreward=actreward) # [[./gif/20nov20_20nov19_A0_gcp__input.mp4]]

so may as well continue this one in a multistep ... 

    "name": "20nov19_A1_gcp_",
    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20nov19_A0_gcp_synWeights_final.pkl"
    },

will use old norm rules and after a few steps if rates get too high will adjust ... 
still testing homplast in sim on cycle below ...

python multistepSim.py sn.json 32 20 20nov19_A1_gcp_multi

started ~21:17 ... 

** check output from 20nov17_A1_cycle__step_4_

python -i simdat.py backupcfg/20nov17_A1_cycle__step_4_sim.json

EV1 0.7 Hz
EV1DE 0.26 Hz
EV1DNE 1.24 Hz
EV1DN 4.0 Hz
EV1DNW 0.3 Hz
EV1DW 0.11 Hz
EV1DSW 0.27 Hz
EV1DS 2.42 Hz
EV1DSE 0.92 Hz
EA 3.25 Hz
EA2 8.14 Hz
IA2 18.4 Hz
EMDOWN 51.97 Hz
EMUP 52.25 Hz
IM 34.87 Hz
stimModEV1 0.75 Hz
stimModEV1DE 0.27 Hz
stimModEV1DNE 1.62 Hz
stimModEV1DN 4.28 Hz
stimModEV1DNW 0.34 Hz
stimModEV1DW 0.12 Hz
stimModEV1DSW 0.32 Hz
stimModEV1DS 2.51 Hz
stimModEV1DSE 0.99 Hz

rates too high . . . so performance not as good as previous . ?

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov19_20nov17_A1_cycle__step_4_perf.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov19_20nov17_A1_cycle__step_4_rast.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov19_20nov17_A1_cycle__step_4_all_avg_weight.png]]
too much difference between EMUP and EMDOWN weights ... should add a func to load weights across steps of multistep (same as concat for actions, etc.)

lfn = ['20nov17_A0_cycle_']
for i in range(5): lfn.append('20nov17_A1_cycle__step_' + str(i) + '_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.36))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov19_20nov17_A1_cycle__step_4_perf_all_steps_so_far.png]]
so perf was increasing then started decreasing for a while now ... should stop sim and figure out homeostasis/norm
or lower the upper weight limit

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20nov19_20nov17_A1_cycle__step_4_perf_compareD.png]]
20nov17_A1_cycle__step_1_ was best perf and after that decayed - weights got too high

check that step ...

python -i simdat.py backupcfg/20nov17_A1_cycle__step_1_sim.json

those rates better ... so max should be ~20 Hz ...

EV1 0.7 Hz
EV1DE 0.22 Hz
EV1DNE 0.89 Hz
EV1DN 4.03 Hz
EV1DNW 0.48 Hz
EV1DW 0.15 Hz
EV1DSW 0.38 Hz
EV1DS 2.8 Hz
EV1DSE 1.12 Hz
EA 3.43 Hz
EA2 9.69 Hz
IA2 21.82 Hz
EMDOWN 18.49 Hz
EMUP 18.49 Hz
IM 39.03 Hz
stimModEV1 0.77 Hz
stimModEV1DE 0.23 Hz
stimModEV1DNE 1.11 Hz
stimModEV1DN 4.37 Hz
stimModEV1DNW 0.54 Hz
stimModEV1DW 0.15 Hz
stimModEV1DSW 0.47 Hz
stimModEV1DS 2.94 Hz
stimModEV1DSE 1.22 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov19_20nov17_A1_cycle__step_1_perf.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov19_20nov17_A1_cycle__step_1_all_avg_weight.png]]

so may want to keep upper weight limit ~1.5-1.6 -- and original average weight was 1.2 ... so only increased ~33% on average before
activity got out of hand ... 

fig=animInput(InputImages,gifpath()+'_input.mp4') # [[./gif/20nov19_20nov17_A1_cycle__step_1__input.mp4]]

** next sim on cycle - 20nov19_A0_cycle_ homplast

continue it from data/20nov17_A1_cycle__step_1_synWeights_final.pkl since that had learning and rates
were getting close to max ... but include the homplast to prevent rates from getting too high ...

        "name": "20nov19_A0_cycle_",

        "homPlast": {
          "On":1, 
          "dshift": 0.00001,
          "mintargetFR":{"EMUP":0.25,"EMDOWN":0.25},
          "maxtargetFR":{"EMUP":25,"EMDOWN":25},
          "hsIntervalSteps":100,
          "updateIntervalSteps":500,
          "synType":"AMPA"
        },

old dshift value was linear and set to small amount:           "dshift": 0.00001,

instead could just multiply by fraction of total weight ... e.g. 0.5% ... 
dscale = 0.001 ...
will try that ... since dscale gets integrated (5x above) using hsIntervalSteps (based on cell firing
rate), which is usually smaller than updateIntervalSteps ... 

then looks like weights getting pushed up if use too small of an interval ... since the EMs are sometimes
quiet when no activity...so will switch to hsIntervalSteps of 500 ... (10 seconds) and dscale of 0.005 ...

./myrun 32 sn.json

* 20nov20
** check output from 20nov19_A0_cycle_

python -i simdat.py backupcfg/20nov19_A0_cycle_sim.json

EV1 0.7 Hz
EV1DE 0.18 Hz
EV1DNE 1.12 Hz
EV1DN 4.13 Hz
EV1DNW 0.55 Hz
EV1DW 0.12 Hz
EV1DSW 0.4 Hz
EV1DS 2.74 Hz
EV1DSE 0.79 Hz
EA 3.65 Hz
EA2 11.04 Hz
IA2 24.92 Hz
EMDOWN 32.14 Hz
EMUP 32.21 Hz
IM 46.78 Hz

those rates seem too high ... the weights were always getting pushed up ... did not see them get pushed down

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov20_20nov19_A0_cycle_perf.png]]
but from 100 s on - perf is improving; for the first 100 s, what's going on? initialization problem?

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov20_20nov19_A0_cycle_all_avg_weight.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov20_20nov19_A0_cycle_rast.png]]

binsz = 10000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP']}
for clr,pop in zip(['r','b'],['EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)

savefig(gifpath()+'EMUPDOWN_rates.png') # [[./gif/20nov20_20nov19_A0_cycle_EMUPDOWN_rates.png]]

hmm, so rates going up past 30 Hz despite the homplast on...?? something not working ...

there was a bug in the code for checking the firing rate over the interval ... and the weight should only get
changed towards target weight if the firing rate is out of the min/max firing rate bounds ... 

fixed that so can run again ... 

        "name": "20nov20_A2_cycle_",
        "homPlast": {
          "On":1,
	  "dscale": 0.005,
          "dshift": 0.0,
          "mintargetFR":{"EMUP":0.125,"EMDOWN":0.125},
          "maxtargetFR":{"EMUP":30,"EMDOWN":30},
          "hsIntervalSteps":250,
          "updateIntervalSteps":250,
          "synType":"AMPA"
        },

./myrun 32 sn.json

python -i simdat.py backupcfg/20nov20_A0_cycle_sim.json

clf(); drawraster(dspkT,dspkID); 

binsz = 250
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP']}
for clr,pop in zip(['r','b'],['EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)

ok, see what's expected ... will try a multistep sim using these homplast params ... but overall, seems somewhat problematic in that
the weights will get pushed down to lower high firing rates, but then will just go back up again ... but pushing them too far down will potentially
lose info and reduce perf.

python multistepSim.py sn.json 32 20 20nov20_A2_gcp_multi
(note the name gcp not correct but does not impact output; also first name was 20nov20_A2_cycle_)

started ~16:17 ...

** check output from 20nov19_A1_gcp__step_2_

python -i simdat.py backupcfg/20nov19_A1_gcp__step_2_sim.json

EV1 0.72 Hz
EA 6.14 Hz
EA2 10.5 Hz
IA2 26.06 Hz
EMDOWN 83.34 Hz
EMUP 82.84 Hz
IM 36.15 Hz
stimModEV1 0.76 Hz

rates already too high ...

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov20_20nov19_A1_gcp__step_2_perf.png]]

lfn = ['20nov19_A0_gcp_']
for i in range(3): lfn.append('20nov19_A1_gcp__step_' + str(i) + '_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov20_20nov19_A1_gcp__step_2_perf_all_steps_so_far.png]]
so perf increased for a while then stopped ... probably from overly high rates ...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20nov20_20nov19_A1_gcp__step_2_perf_compareD.png]]

step 0 or step 1 are best ... then performance drops ...

will check step 0 to see rates ... 

python -i simdat.py backupcfg/20nov19_A1_gcp__step_0_sim.json

EV1 0.72 Hz
EA 6.19 Hz
EA2 10.64 Hz
IA2 26.49 Hz
EMDOWN 26.89 Hz
EMUP 26.92 Hz
IM 68.02 Hz
stimModEV1 0.77 Hz

ok, those rates are already pretty high ... so can use that one as starting point for continuation
with homeostatic plasticity ... 

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov20_20nov19_A1_gcp__step_0_perf.png]]

well, first check rates in next step

python -i simdat.py backupcfg/20nov19_A1_gcp__step_1_sim.json

EV1 0.72 Hz
EA 6.29 Hz
EA2 10.8 Hz
IA2 26.9 Hz
EMDOWN 51.52 Hz
EMUP 51.82 Hz
IM 61.67 Hz
stimModEV1 0.76 Hz

yeah, those rates are too high ... 

continue with multistep
        "name": "20nov20_A2_gcp_",
    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20nov19_A1_gcp__step_0_synWeights_final.pkl"
    },
        "homPlast": {
          "On":1,
	  "dscale": 0.005,
          "dshift": 0.0,
          "mintargetFR":{"EMUP":0.125,"EMDOWN":0.125},
          "maxtargetFR":{"EMUP":30,"EMDOWN":30},
          "hsIntervalSteps":250,
          "updateIntervalSteps":250,
          "synType":"AMPA"
        },	

python multistepSim.py sn.json 32 20 20nov20_A2_real_gcp_multi

started ~16:51 ...

* 20nov23
** check output from 20nov20_A2_gcp__step_8_

python -i simdat.py backupcfg/20nov20_A2_gcp__step_8_sim.json

EV1 0.75 Hz
EA 5.8 Hz
EA2 9.27 Hz
IA2 23.17 Hz
EMDOWN 24.27 Hz
EMUP 10.22 Hz
IM 42.77 Hz
stimModEV1 0.8 Hz

hmm, definitely not working if the EMDOWN, EMUP rates are so different. how did that happen?

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov23_20nov20_A2_gcp__step_8_perf.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov23_20nov20_A2_gcp__step_8_rast.png]]

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP']}
for clr,pop in zip(['r','b'],['EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)

savefig(gifpath()+'EMUPDOWN_rates.png') # [[./gif/20nov23_20nov20_A2_gcp__step_8_EMUPDOWN_rates.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov23_20nov20_A2_gcp__step_8_all_avg_weight.png]]

EMUP weight changes look much smoother ... is there a bug?

lfn = ['20nov19_A0_gcp_','20nov19_A1_gcp__step_0_']
for i in range(9): lfn.append('20nov20_A2_gcp__step_' + str(i) + '_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov23_20nov20_A2_gcp__step_8_perf_all_steps_so_far.png]]
so performance was increasing but right after new homplast rule was turned on performance started to decay
that's either due to a bug or the rule itself ...

stop the multistep gcp sim ... and fix before continuing ... 

** check output from cycle 20nov20_A2_cycle__step_6_

python -i simdat.py backupcfg/20nov20_A2_cycle__step_6_sim.json

EV1 0.66 Hz
EV1DE 0.27 Hz
EV1DNE 1.32 Hz
EV1DN 3.55 Hz
EV1DNW 0.34 Hz
EV1DW 0.08 Hz
EV1DSW 0.15 Hz
EV1DS 1.83 Hz
EV1DSE 0.87 Hz
EA 2.63 Hz
EA2 6.56 Hz
IA2 14.72 Hz
EMDOWN 18.85 Hz
EMUP 19.53 Hz
IM 24.12 Hz
stimModEV1 0.74 Hz
stimModEV1DE 0.27 Hz
stimModEV1DNE 1.74 Hz
stimModEV1DN 3.81 Hz
stimModEV1DNW 0.38 Hz
stimModEV1DW 0.08 Hz
stimModEV1DSW 0.17 Hz
stimModEV1DS 1.89 Hz
stimModEV1DSE 0.93 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov23_20nov20_A2_cycle__step_6_perf.png]]
this one not as bad as the one on gcp ... but not very good - worse than before the homplast was turned on

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov23_20nov20_A2_cycle__step_6_rast.png]]
those rates are more similar ... 

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP']}
for clr,pop in zip(['r','b'],['EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)

savefig(gifpath()+'EMUPDOWN_rates.png') # [[./gif/20nov23_20nov20_A2_cycle__step_6_EMUPDOWN_rates.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov23_20nov20_A2_cycle__step_6_all_avg_weight.png]]

lfn = ['20nov17_A0_cycle_']
for i in range(2): lfn.append('20nov17_A1_cycle__step_' + str(i) + '_')
for i in range(9): lfn.append('20nov20_A2_cycle__step_' + str(i) + '_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.435))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov23_20nov20_A2_cycle__step_6_perf_all_steps_so_far.png]]

same as the gcp sim this one starts to decrease in performance after homplast turned on ...

** use eempopnorm on cycle, with lower max threshold (20nov23_A2_cycle_) -->> catches up hit/miss,score within 500 s

try with eempopnorm again - since that preserves relative weights - but with lower max threshold ... of 1.4 ? 

        "name": "20nov23_A2_cycle_",
        "EEMWghtThreshMin": 0.9,
        "EEMWghtThreshMax": 1.31,
        "EEMPopNorm": 1,
    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20nov17_A1_cycle__step_1_synWeights_final.pkl"
    },

python multistepSim.py sn.json 32 20 20nov23_A2_gcp_multi

python -i simdat.py backupcfg/20nov23_A2_cycle__step_0_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov23_20nov23_A2_cycle__step_0_perf.png]]
not bad, but takes time to build up to previous level of performance...

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov23_20nov23_A2_cycle__step_0_rast.png]]

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP']}
for clr,pop in zip(['r','b'],['EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)

savefig(gifpath()+'EMUPDOWN_rates.png') # [[./gif/20nov23_20nov23_A2_cycle__step_0_EMUPDOWN_rates.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov23_20nov23_A2_cycle__step_0_all_avg_weight.png]]

lfn = ['20nov17_A0_cycle_']
for i in range(2): lfn.append('20nov17_A1_cycle__step_' + str(i) + '_')
i=0; lfn.append('20nov23_A2_cycle__step_' + str(i) + '_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.47))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov23_20nov23_A2_cycle__step_0_perf_all_steps_so_far.png]]
seems like perf increasing in last 500 s of sim (new step with eempopnorm)?

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20nov23_20nov23_A2_cycle__step_0_perf_compareD.png]]
so last step is better than where started (first step - dark blue), but not as good as previous step ... 
question is, whether it will surpass the best step by continuing for a few more iterations ... 

** use eempopnorm on gcp, with lower max threshold

        "name": "20nov23_A2_gcp_",
        "EEMWghtThreshMin": 0.9,
        "EEMWghtThreshMax": 1.31,
    "simtype": {
        "ResumeSim": 1,
	"ResumeSimFromFile": "data/20nov19_A1_gcp__step_0_synWeights_final.pkl"
    },

python multistepSim.py sn.json 32 20 20nov23_A2_realgcp_multi

** noise help?

        "name": "20nov23_B2_gcp_",
    "simtype": {
        "ResumeSim": 1,
	"ResumeSimFromFile": "data/20nov19_A1_gcp__step_0_synWeights_final.pkl"
    },
with eempopnorm ... and reloading weights but add some noise ... to reduce sparsity of EM firing

* 20nov24
** check output from gcp 20nov23_A2_gcp__step_2_

python -i simdat.py backupcfg/20nov23_A2_gcp__step_2_sim.json

EV1 0.72 Hz
EA 5.95 Hz
EA2 10.25 Hz
IA2 25.55 Hz
EMDOWN 36.14 Hz
EMUP 36.7 Hz
IM 38.55 Hz
stimModEV1 0.77 Hz

rates were higher ... for this sim (w/o direction selective neurons) could set a lower max threshold 

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov24_20nov23_A2_gcp__step_2_perf.png]]
not terrible or good ... 

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov23_20nov20_A2_gcp__step_8_rast.png]]

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP']}
for clr,pop in zip(['r','b'],['EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)

savefig(gifpath()+'EMUPDOWN_rates.png') # [[./gif/20nov24_20nov23_A2_gcp__step_2_EMUPDOWN_rates.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov24_20nov23_A2_gcp__step_2_all_avg_weight.png]]

lfn = ['20nov19_A0_gcp_','20nov19_A1_gcp__step_0_']
for i in range(3): lfn.append('20nov23_A2_gcp__step_' + str(i) + '_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov24_20nov23_A2_gcp__step_2_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20nov24_20nov23_A2_gcp__step_2_perf_compareD.png]]
last step does not appear the best ... 

** check output from 20nov23_A2_cycle__step_2_

python -i simdat.py backupcfg/20nov23_A2_cycle__step_2_sim.json

EV1 0.7 Hz
EV1DE 0.24 Hz
EV1DNE 0.91 Hz
EV1DN 3.89 Hz
EV1DNW 0.35 Hz
EV1DW 0.13 Hz
EV1DSW 0.33 Hz
EV1DS 2.57 Hz
EV1DSE 1.18 Hz
EA 3.09 Hz
EA2 8.39 Hz
IA2 18.92 Hz
EMDOWN 19.19 Hz
EMUP 19.25 Hz
IM 31.38 Hz
stimModEV1 0.77 Hz
stimModEV1DE 0.24 Hz
stimModEV1DNE 1.15 Hz
stimModEV1DN 4.18 Hz
stimModEV1DNW 0.4 Hz
stimModEV1DW 0.13 Hz
stimModEV1DSW 0.39 Hz
stimModEV1DS 2.69 Hz
stimModEV1DSE 1.25 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov24_20nov23_A2_cycle__step_2_perf.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov24_20nov23_A2_cycle__step_2_rast.png]]

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP']}
for clr,pop in zip(['r','b'],['EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)

savefig(gifpath()+'EMUPDOWN_rates.png') # [[./gif/20nov24_20nov23_A2_cycle__step_2_EMUPDOWN_rates.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov24_20nov23_A2_cycle__step_2_all_avg_weight.png]]

lfn = ['20nov17_A0_cycle_']
for i in range(3): lfn.append('20nov17_A1_cycle__step_' + str(i) + '_')
for i in range(3): lfn.append('20nov23_A2_cycle__step_' + str(i) + '_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.47))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov24_20nov23_A2_cycle__step_2_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20nov24_20nov23_A2_cycle__step_2_perf_compareD.png]]

latest step does not seem best ... 20nov17_A1_cycle__step_0_ still sees best ... 

stopping this multistep sim for now ...

** adjust targetted rule and try it out (20nov24_C0_gcp_)

right now population that contributed to the move gets rewarded or punished (when right or wrong move)
but other population does not get impacted
could revise the rule to also give opposite critic value to the other population

        if dconf['sim']['targettedRL']:
          if not noWinner: # if there's a clear winner in terms of firing rates
            if UPactions==DOWNactions:
              if dconf['verbose']: print('APPLY RL to both EMUP and EMDOWN')
              for STDPmech in dSTDPmech['all']: STDPmech.reward_punish(float(critic))          
            elif UPactions>DOWNactions: # UP WINS vs DOWN
              if dconf['verbose']: print('APPLY RL to EMUP')
              for STDPmech in dSTDPmech['EMUP']: STDPmech.reward_punish(float(critic))
              if if dconf['sim']['targettedRL']==3: # opposite to pop that did not contribute
                for STDPmech in dSTDPmech['EMDOWN']: STDPmech.reward_punish(float(-critic))
            elif DOWNactions>UPactions: # DOWN WINS vs UP
              if dconf['verbose']: print('APPLY RL to EMDOWN')
              for STDPmech in dSTDPmech['EMDOWN']: STDPmech.reward_punish(float(critic))
              if if dconf['sim']['targettedRL']==3: # opposite to pop that did not contribute
                for STDPmech in dSTDPmech['EMUP']: STDPmech.reward_punish(float(-critic))              

also, should it reward up/down if they're both 0??

with 0 actions
            if F_UPs[ts]>F_DOWNs[ts]: # UP WINS
              actions.append(dconf['moves']['UP'])
            elif F_DOWNs[ts]>F_UPs[ts]: # DOWN WINS
              actions.append(dconf['moves']['DOWN'])
            elif dconf['0rand'] and F_DOWNs[ts]==0 and F_UPs[ts]==0: # random move when 0 rate for both pops?
              lmoves = list(dconf['moves'].values())
              actions.append(lmoves[np.random.randint(0,len(lmoves))])
            else:
              actions.append(dconf['moves']['NOMOVE']) # No move
              noWinner = True

ok, fixed that up ... with targetted RL only apply critic when there are spikes

to use the addition to the rule specify targettedRL==3

this is with the EV1DE, etc. direction selective neurons included

python multistepSim.py sn.json 32 20 20nov23_C0_gcp_multi

not much firing ... still seems like some noise would help, or stronger inputs ... otherwise, most
of the time, the EMDOWN,EMUP are not firing at all ... 

readjust weights ... increase them a bit to 1.3 and the rlhebbwt too ...

python multistepSim.py sn.json 32 20 20nov23_C0_gcp_multi

check first step ...

python -i simdat.py backupcfg/20nov24_C0_gcp__step_0_sim.json

EV1 0.68 Hz
EV1DE 0.26 Hz
EV1DNE 1.02 Hz
EV1DN 3.73 Hz
EV1DNW 0.25 Hz
EV1DW 0.21 Hz
EV1DSW 0.26 Hz
EV1DS 2.38 Hz
EV1DSE 1.2 Hz
EA 2.68 Hz
EA2 6.67 Hz
IA2 15.04 Hz
EMDOWN 8.44 Hz
EMUP 8.38 Hz
IM 23.39 Hz
stimModEV1 0.76 Hz
stimModEV1DE 0.26 Hz
stimModEV1DNE 1.29 Hz
stimModEV1DN 4.01 Hz
stimModEV1DNW 0.29 Hz
stimModEV1DW 0.22 Hz
stimModEV1DSW 0.33 Hz
stimModEV1DS 2.48 Hz
stimModEV1DSE 1.29 Hz

overall, lower rates for EMDOWN,EMUP than other sims

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov25_20nov24_C0_gcp__step_0_perf.png]]

hit/miss perf may be better than 20nov17_A0_cycle_
but fewer score ... need to run longer to see if improves more rapidly ... 

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov25_20nov24_C0_gcp__step_0_rast.png]]

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP']}
for clr,pop in zip(['r','b'],['EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)

savefig(gifpath()+'EMUPDOWN_rates.png') # [[./gif/20nov25_20nov24_C0_gcp__step_0_EMUPDOWN_rates.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov25_20nov24_C0_gcp__step_0_all_avg_weight.png]]
weights going up much more slowly than before change to the targetted rule ... possibly due to 
not applying critic when have 0 firing rates ... which combined with sparse
firing rates means the reward from score usually does not get applied ... other reason weights
do not go up as much is that whenever there's a good action from one pop and spikes from another pop,
the other pop gets punishment signal...

** controls - shuffle learned weights then run

that way will have similar firing rates

take weights from 20nov17_A1_cycle__step_1_ and shuffle them to compare ... 

python -i simdat.py backupcfg/20nov17_A1_cycle__step_1_sim.json

pdf.columns # Index(['time', 'preid', 'postid', 'weight'], dtype='object')

A = readweightsfile2pdf(dconf['simtype']['ResumeSimFromFile'])
A.columns # Index(['time', 'preid', 'postid', 'weight'], dtype='object')

len(A) # 279000
so only 279 K plastic weights ... 

npwt = np.array(A.weight)
len(npwt) # 279000

npwt[0],npwt[-1], mean(npwt) # (1.8478514639505095, 1.2779553633436187, 1.3947560822475773)

np.random.shuffle(npwt)

npwt[0],npwt[-1], mean(npwt) # (1.9610259314541767, 1.953392821125234, 1.3947560822475775)
len(npwt) # 279000

Ashuf = np.array([A.time,A.preid,A.postid,npwt]).T
pdfshuf = pd.DataFrame(Ashuf,columns=['time','preid','postid','weight'])

D = pdf2weightsdict(pdfshuf); 
pickle.dump(D, open('data/20nov24_20nov17_A1_cycle__step_0_synWeights_final_shuffled.pkl','wb'))

ok, can use that as resume weights ... will run that later - once other sim finishes on cycle.

can use at command to schedule
https://askubuntu.com/questions/339298/conveniently-schedule-a-command-to-run-later

    "simtype": {
        "ResumeSim": 1,
	"ResumeSimFromFile": "data/20nov24_20nov17_A1_cycle__step_0_synWeights_final_shuffled.pkl"
    },
        "name": "20nov24_load_shuffle_weight_test_cycle_E0_",

put command into myscript.sh:
./myrun 32 sn.json

then run this from terminal ... 

at now + 1 hours -f ~/SMARTAgent/myscript.sh

** test after learning - test performance after learning turned off

and compare to controls


use these weights - 20nov17_A1_cycle__step_1_synWeights_final.pkl

just set rlhebbwt to 0 ... 

        "name": "20nov24_load_weight_test_cycle_D0_",
    "simtype": {
        "ResumeSim": 1,
	"ResumeSimFromFile": "data/20nov17_A1_cycle__step_1_synWeights_final.pkl"
    },

./myrun 32 sn.json

** adjust avoidstuck rule?

right now puts the stop stuck down a bit too early ... 

          elif ypos_Racket - 1 - self.racketH*0.8125 <= 0 and caction==dconf['moves']['UP']:
            print('STUCK STOP UP, YPOS RACKET=', ypos_Racket, 'bound=',ypos_Racket - 1 - self.racketH/2)
            caction = dconf['moves']['NOMOVE']
          elif ypos_Racket + 1 + self.racketH*0.8125 >= self.maxYPixel and caction==dconf['moves']['DOWN']:
            print('STUCK STOP DOWN, YPOS RACKET=',ypos_Racket, 'bound=',ypos_Racket + 1 + self.racketH/2)
            caction = dconf['moves']['NOMOVE']

could instead put limit at  ypos_Racket + 1 + self.racketH*0.5 >= self.maxYPixel ... 

* 20nov25
** compare sims (during learning, after learning, control with shuffled weights)

python -i simdat.py backupcfg/20nov24_load_weight_test_cycle_D0_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov25_20nov24_load_weight_test_cycle_D0_perf.png]]
not as good as during learning ... 

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov25_20nov24_load_weight_test_cycle_D0_rast.png]]

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP']}
for clr,pop in zip(['r','b'],['EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)

savefig(gifpath()+'EMUPDOWN_rates.png') # [[./gif/20nov25_20nov24_load_weight_test_cycle_D0_EMUPDOWN_rates.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
ylim((1.579, 1.5835))
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov25_20nov24_load_weight_test_cycle_D0_all_avg_weight.png]]
ok, weights stayed flat as intended ... 

lfn = ['20nov17_A1_cycle__step_1_' , '20nov24_load_weight_test_cycle_D0_', '20nov24_load_shuffle_weight_test_cycle_E0_']

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20nov25_20nov24_load_weight_test_cycle_D0_perf_compareD.png]]

for shuffle weights test only used 100 s since sim was doing so poorly ... need to run longer ... 

for i in [1,2,3]: subplot(1,3,i); xlim((0,500e3))
savefig(gifpath()+'perf_compareE.png') # [[./gif/20nov25_20nov24_load_weight_test_cycle_D0_perf_compareE.png]]

need to run shuffled weight test longer to get accurate comparison ... reloaded weights w/o learning might
converge on a similar value as sim with learning on ... 

for now, will run shuffle sim for 500 s ... or could run sim with completely random moves ... 

        "name": "20nov25_load_shuffle_weight_test_cycle_E0_",
** check output from 20nov24_C0_gcp__step_2_

python -i simdat.py backupcfg/20nov24_C0_gcp__step_2_sim.json

EV1 0.72 Hz
EV1DE 0.19 Hz
EV1DNE 0.93 Hz
EV1DN 4.12 Hz
EV1DNW 0.56 Hz
EV1DW 0.18 Hz
EV1DSW 0.44 Hz
EV1DS 2.99 Hz
EV1DSE 0.97 Hz
EA 3.72 Hz
EA2 12.1 Hz
IA2 27.32 Hz
EMDOWN 16.16 Hz
EMUP 16.15 Hz
IM 40.72 Hz
stimModEV1 0.77 Hz
stimModEV1DE 0.21 Hz
stimModEV1DNE 1.18 Hz
stimModEV1DN 4.5 Hz
stimModEV1DNW 0.63 Hz
stimModEV1DW 0.19 Hz
stimModEV1DSW 0.53 Hz
stimModEV1DS 3.13 Hz
stimModEV1DSE 1.05 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov25_20nov24_C0_gcp__step_2_perf.png]]

hmm, that's pretty high hit/miss ratio, hovering ~0.8

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov25_20nov24_C0_gcp__step_2_rast.png]]

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP']}
for clr,pop in zip(['r','b'],['EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)

savefig(gifpath()+'EMUPDOWN_rates.png') # [[./gif/20nov25_20nov24_C0_gcp__step_2_EMUPDOWN_rates.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov25_20nov24_C0_gcp__step_2_all_avg_weight.png]]
weights still moving slowly ... and they look like mirror images - as one goes up, other goes down - not perfectly
but that could help produce different firing patterns/rates in the two populations ... 

would be interesting to test the network's response to systematically arranged stimuli - vary ball direction and paddle
position and see the EMUP,EMDOWN responses. 

lfn = ['20nov24_C0_gcp__step_' + str(i) + '_' for i in range(3)]

pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov25_20nov24_C0_gcp__step_2_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20nov25_20nov24_C0_gcp__step_2_perf_compareD.png]]

should make at least one movie ... 

updated actmap  ... ? with scores ... ? 

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
close(); fig=animInput(InputImages,gifpath()+'_no_reward_input.mp4')

 [[./gif/20nov25_20nov24_C0_gcp__step_2__with_reward_input.mp4]]
[[./gif/20nov25_20nov24_C0_gcp__step_2__no_reward_input.mp4]]

#lpop = ['EV1DNW', 'EV1DN', 'EV1DNE','EV1', 'EV1DW','EV1DE','EMUP','EV1DSW', 'EV1DS', 'EV1DSE', 'EMDOWN', ]

lpop = [k for k in dnumc.keys() if dnumc[k] > 0 and k.count('stim')<1]
['EV1', 'EV1DE', 'EV1DNE', 'EV1DN', 'EV1DNW', 'EV1DW', 'EV1DSW', 'EV1DS', 'EV1DSE', 'EA', 'EA2', 'IA2', 'EMDOWN', 'EMUP', 'IM']
  
dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)

fig, axs, plt = animActivityMaps(outpath=gifpath()+'actmap.mp4',lpop=lpop,nframe=100)

** check latest shuffled weight sim (20nov25_load_shuffle_weight_test_cycle_E0_)

python -i simdat.py backupcfg/20nov25_load_shuffle_weight_test_cycle_E0_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov25_20nov25_load_shuffle_weight_test_cycle_E0_perf.png]]
good, over 500 s sim, shuffled weights sim displays much worse performance

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov25_20nov25_load_shuffle_weight_test_cycle_E0_rast.png]]

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP']}
for clr,pop in zip(['r','b'],['EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)

savefig(gifpath()+'EMUPDOWN_rates.png') # [[./gif/20nov25_20nov25_load_shuffle_weight_test_cycle_E0_EMUPDOWN_rates.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
ylim((1.394,1.396))
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov25_20nov25_load_shuffle_weight_test_cycle_E0_all_avg_weight.png]]

lfn = ['20nov17_A1_cycle__step_1_' , '20nov24_load_weight_test_cycle_D0_', '20nov25_load_shuffle_weight_test_cycle_E0_']

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)

for i in [1,2,3]: subplot(1,3,i); xlim((100e3,500e3)); ylim((0,0.8))

savefig(gifpath()+'perf_compareD.png') # [[./gif/20nov25_20nov25_load_shuffle_weight_test_cycle_E0_perf_compareD.png]]

ok, so after training performance is retained, but not 100% ... in long run may converge ... 

can make a movie of shuffled weight performance ... and also display total number of hits, scores, etc ... also note that it's not likely to be
identical inputs; since all differences in model behavior can lead to wide divergence in opponent moves, etc.

for pda,fn in zip(lpda,lfn):
  cumHits, cumMissed, cumScore = getCumPerfCols(pda)    
  print(fn,cumHits[-1],cumMissed[-1],cumScore[-1])

20nov17_A1_cycle__step_1_                  55 98  23
20nov24_load_weight_test_cycle_D0_         40 115 16
20nov25_load_shuffle_weight_test_cycle_E0_ 16 150  5

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward) # [[./20nov25_20nov25_load_shuffle_weight_test_cycle_E0__with_reward_input.mp4]]

** run sim with randmove (other control for comparison; 20nov25_random_move_F0_)

randmove = 1

and again RLhebbwt is 0 ... 

./myrun 32 sn.json

* 20nov26
** check output from 20nov25_random_move_F0_

python -i simdat.py backupcfg/20nov25_random_move_F0_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov26_20nov25_random_move_F0_perf.png]]
follow probability right ~0.33 ... from equal probability of each command (up, down, stay)

lfn = ['20nov17_A1_cycle__step_1_' , '20nov24_load_weight_test_cycle_D0_', '20nov25_load_shuffle_weight_test_cycle_E0_', '20nov25_random_move_F0_']

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipfollow=True)

for i in [1,2]: subplot(1,2,i); xlim((100e3,500e3)); ylim((0,0.8))

savefig(gifpath()+'perf_compareD.png') # [[./gif/20nov26_20nov25_random_move_F0_perf_compareD.png]]

randmove looks better than after learning at some times ... but running longer should show better
performance for the one after learning ... 

clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)

for i in [1,2,3]: subplot(1,3,i); xlim((100e3,500e3)); ylim((0,0.8))

savefig(gifpath()+'perf_compareE.png') # [[./gif/20nov26_20nov25_random_move_F0_perf_compareE.png]]


for pda,fn in zip(lpda,lfn):
  cumHits, cumMissed, cumScore = getCumPerfCols(pda)    
  print(fn,cumHits[-1],cumMissed[-1],cumScore[-1])

20nov17_A1_cycle__step_1_                  55  98 23
20nov24_load_weight_test_cycle_D0_         40 115 16
20nov25_load_shuffle_weight_test_cycle_E0_ 16 150  5
20nov25_random_move_F0_                    30 140  7

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward) # [[./gif/20nov26_20nov25_random_move_F0__with_reward_input.mp4]]

may as well run longer randmove - 1000 s ... and reduce number of neurons since they're
not used anyway ... 

** run longer sim with randmove (other control for comparison; 20nov26_random_move_G0_)

randmove = 1

and again RLhebbwt is 0 ... 

fewer neurons so runs more quickly ... (neurons not used for decision making with randmove anyway)

./myrun 32 sn.json

python -i simdat.py backupcfg/20nov26_random_move_G0_sim.json

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov26_20nov26_random_move_G0_perf.png]]

ok, so over longer duration, it's clear randmove has much lower perf compared to the trained sims ... 
will see exactly how it compares when they're done ... (running 1000 s for shuffled weights and
for restore learned weights [keep them fixed]); can combine step 0,1 or 1,2 for learning to get 1000 s ... 

cumHits, cumMissed, cumScore = getCumPerfCols(actreward) 
print(simstr,cumHits[-1],cumMissed[-1],cumScore[-1]) # 20nov26_random_move_G0_ 42 292 13

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward) # [[./gif/20nov26_20nov26_random_move_G0__with_reward_input.mp4]]

** check output from 20nov24_C0_gcp__step_7_ -->> activity drops after a few steps

python -i simdat.py backupcfg/20nov24_C0_gcp__step_7_sim.json

EV1 0.71 Hz
EV1DE 0.33 Hz
EV1DNE 0.85 Hz
EV1DN 4.02 Hz
EV1DNW 0.18 Hz
EV1DW 0.04 Hz
EV1DSW 0.13 Hz
EV1DS 2.52 Hz
EV1DSE 1.47 Hz
EA 3.19 Hz
EA2 8.42 Hz
IA2 19.19 Hz
EMDOWN 18.18 Hz
EMUP 16.39 Hz
IM 40.42 Hz
stimModEV1 0.76 Hz
stimModEV1DE 0.33 Hz
stimModEV1DNE 1.11 Hz
stimModEV1DN 4.23 Hz
stimModEV1DNW 0.21 Hz
stimModEV1DW 0.04 Hz
stimModEV1DSW 0.15 Hz
stimModEV1DS 2.61 Hz
stimModEV1DSE 1.54 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov26_20nov24_C0_gcp__step_7_perf.png]]
hmm, this one has really bad performance ... how'd that happen? rates not terrible 
but do see large imbalances between the weights - and average EMDOWN at 18 Hz and EMUP at 16 Hz
so that's the problem ... too much imbalance ... maybe due to the new targetted rule  == 3
that can cause too much opposition between the populations ... ?

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov26_20nov24_C0_gcp__step_7_rast.png]]

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP']}
for clr,pop in zip(['r','b'],['EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)

savefig(gifpath()+'EMUPDOWN_rates.png') # [[./gif/20nov26_20nov24_C0_gcp__step_7_EMUPDOWN_rates.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov26_20nov24_C0_gcp__step_7_all_avg_weight.png]]
yeah, large diff btwn the weights ... ; probably need to keep them closer together ... must be because there
are some overlapping inputs where both populations should be activated?

lfn = ['20nov24_C0_gcp__step_' + str(i) + '_' for i in range(8)]

pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov26_20nov24_C0_gcp__step_7_perf_all_steps_so_far.png]]
ok, so there's a clear rise and then decay ... at which step does the decay start to occur?

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20nov26_20nov24_C0_gcp__step_7_perf_compareD.png]]

step 1 or 2 look the best ... will try a continuation run with fixed weights from step 2 for 1000 s ... 

#lpop = [k for k in dnumc.keys() if dnumc[k] > 0 and k.count('stim')<1]
#['EV1', 'EV1DE', 'EV1DNE', 'EV1DN', 'EV1DNW', 'EV1DW', 'EV1DSW', 'EV1DS', 'EV1DSE', 'EA', 'EA2', 'IA2', 'EMDOWN', 'EMUP', 'IM']
  
#dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)

#fig, axs, plt = animActivityMaps(outpath=gifpath()+'actmap.mp4',lpop=lpop,nframe=100)

** sim with fixed learned weights on gcp (20nov26_C1_gcp_)

    "simtype": {
        "ResumeSim": 1,
	"ResumeSimFromFile": "data/20nov24_C0_gcp__step_2_synWeights_final.pkl"
    },

            "RLhebbwt": 0.0,  <<-- that makes sure weights do not change further

        "recordWeightStepSize": 5000,
        "normalizeWeightStepSize": 5000000000000000000000000000000,
	"normalizeWeightsAtStart": 0,

run it for 1000 s ... 

./myrun 32 sn.json

started ~16:22 ...

** shuffled weights control sim from gcp -- run for 1000 s (20nov26_load_shuffle_weight_test_C0_gcp__step_2_C1_)

python -i simdat.py backupcfg/20nov24_C0_gcp__step_2_sim.json

pdff = readweightsfile2pdf('data/20nov24_C0_gcp__step_2_synWeights_final.pkl')
pdfshuf = shuffleweights(pdff)
D = pdf2weightsdict(pdfshuf); 
pickle.dump(D, open('data/20nov26_20nov24_C0_gcp_cycle__step_2_synWeights_final_shuffled.pkl','wb'))

    "simtype": {
        "ResumeSim": 1,
	"ResumeSimFromFile": "data/20nov26_20nov24_C0_gcp_cycle__step_2_synWeights_final_shuffled.pkl'"
    },

            "RLhebbwt": 0.0,
        "recordWeightStepSize": 5000,
        "normalizeWeightStepSize": 5000000000000000000000000000000,
	"normalizeWeightsAtStart": 0,

./myrun 32 sn.json

started ~17:31 ... on cycle ... 

** actmap movie from 20nov24_C0_gcp__step_2_ ?

python -i simdat.py backupcfg/20nov24_C0_gcp__step_2_sim.json

** perf from gcp sim w/o motion selective neurons (20nov19_A0_gcp_, 20nov19_A1_gcp__step_0_, etc)

show steps 0,1,2 where improvement was occurring - before it dropped due to higher rates

python -i simdat.py

lfn = ['20nov19_A0_gcp_','20nov19_A1_gcp__step_0_']
for i in range(3): lfn.append('20nov23_A2_gcp__step_' + str(i) + '_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.4))
xlim((25e3,1.5e6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20nov27_20nov16_A0_testPaddedImage_reduced_2obj_INTF7_perf_all_steps_so_far.png]]

ok, shows improvement ... 

* 20nov27
** check output from 20nov26_C1_gcp_ (this is sim that continued with weights fixed after learning)

python -i simdat.py backupcfg/20nov26_C1_gcp_sim.json

EV1 0.73 Hz
EV1DE 0.18 Hz
EV1DNE 0.62 Hz
EV1DN 4.16 Hz
EV1DNW 0.63 Hz
EV1DW 0.12 Hz
EV1DSW 0.42 Hz
EV1DS 3.21 Hz
EV1DSE 1.32 Hz
EA 3.79 Hz
EA2 12.52 Hz
IA2 28.14 Hz
EMDOWN 16.96 Hz
EMUP 17.0 Hz
IM 41.83 Hz
stimModEV1 0.78 Hz
stimModEV1DE 0.19 Hz
stimModEV1DNE 0.75 Hz
stimModEV1DN 4.51 Hz
stimModEV1DNW 0.72 Hz
stimModEV1DW 0.13 Hz
stimModEV1DSW 0.52 Hz
stimModEV1DS 3.37 Hz
stimModEV1DSE 1.41 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20nov27_20nov26_C1_gcp_perf.png]]
looks very good ...

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20nov27_20nov26_C1_gcp_rast.png]]

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP']}
for clr,pop in zip(['r','b'],['EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)

savefig(gifpath()+'EMUPDOWN_rates.png') # [[./gif/20nov27_20nov26_C1_gcp_EMUPDOWN_rates.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
ylim((1.33,1.38))
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20nov27_20nov26_C1_gcp_all_avg_weight.png]]
ok, weights stay put as intended for this test

will save the data on cycle for more analysis ... and comparison with controls ...

cumHits, cumMissed, cumScore = getCumPerfCols(actreward) 
print(simstr,cumHits[-1],cumMissed[-1],cumScore[-1]) # 20nov26_C1_gcp_ 112 173 56
that's over 1000 s ... 

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
close(); fig=animInput(InputImages,gifpath()+'_no_reward_input.mp4')

lpop = [k for k in dnumc.keys() if dnumc[k] > 0 and k.count('stim')<1]
['EV1', 'EV1DE', 'EV1DNE', 'EV1DN', 'EV1DNW', 'EV1DW', 'EV1DSW', 'EV1DS', 'EV1DSE', 'EA', 'EA2', 'IA2', 'EMDOWN', 'EMUP', 'IM']
  
dact = getdActMap(totalDur, tstepPerAction, dspkT, dspkID, dnumc, dstartidx, lpop)

fig, axs, plt = animActivityMaps(outpath=gifpath()+'actmap.mp4',lpop=lpop,nframe=100)

lpop = ['EV1', 'EV1DNW', 'EV1DN', 'EV1DNE',\
        'EA', 'EA2', 'EV1DW', 'EV1DE', \
        'IA2', 'EMUP', 'EV1DSW', 'EV1DS', 'EV1DSE', \
        'IM', 'EMDOWN']
        
fig, axs, plt = animActivityMaps(outpath=gifpath()+'actmap.mp4',lpop=lpop,nframe=100)

** figure showing learning, after learning (weights fixed), control (random move), control (shuffled weights)

python -i simdat.py backupcfg/20nov26_random_move_G0_sim.json

lfn = ['20nov24_C0_gcp__step_1_', '20nov24_C0_gcp__step_2_']
pdac = getconcatactionreward(lfn)
lpda = [pdac]

lfn = ['20nov26_C1_gcp_', '20nov26_load_shuffle_weight_test_C0_gcp__step_2_C1_', '20nov26_random_move_G0_']
ltmp = getindivactionreward(lfn)
for pda in ltmp: lpda.append(pda)

lleg = ['During Learning', 'After Learning', 'Shuffle Weight', 'Random Move']

csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lleg,skipfollow=True)

savefig(gifpath()+'perf_compareD.png') # [[./gif/20nov27_20nov26_random_move_G0_perf_compareD.png]]

learning and continuation looks much better in this set of sims ... compared to controls ...

for pda,name in zip(lpda,lleg):
  cumHits, cumMissed, cumScore = getCumPerfCols(pda)    
  print(name,cumHits[-1],cumMissed[-1],cumScore[-1])

During Learning 127 171 50
After Learning  112 173 56
Shuffle Weight   24 309 12
Random Move      42 292 13

** video of shuffled weight test performance (from 20nov26_load_shuffle_weight_test_C0_gcp__step_2_C1_)

python -i simdat.py backupcfg/20nov26_load_shuffle_weight_test_C0_gcp__step_2_C1_sim.json

fig=animInput(InputImages,gifpath()+'_no_reward_input.mp4')
close(); fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)

[[./gif/20nov27_20nov26_load_shuffle_weight_test_C0_gcp__step_2_C1__no_reward_input.mp4]]
[[./gif/20nov27_20nov26_load_shuffle_weight_test_C0_gcp__step_2_C1__with_reward_input.mp4]]

* 20nov30
** movies with reward but no opponent score -- and higher framerate for realtime

to allow comparison between different versions performance relative to each other ... 

also can make animation in real-time framerate of 50 frames / s (since 20 ms timestep)

python -i simdat.py backupcfg/20nov26_C1_gcp_sim.json

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward,skipopp=True,framerate=50)
[[./gif/20nov30_20nov26_C1_gcp__with_reward_input.mp4]]

python -i simdat.py backupcfg/20nov26_random_move_G0_sim.json
fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward,skipopp=True,framerate=50)
[[./gif/20nov30_20nov26_random_move_G0__with_reward_input.mp4]]

python -i simdat.py backupcfg/20nov24_C0_gcp__step_2_sim.json
fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward,skipopp=True,framerate=50)
[[./gif/20nov30_20nov24_C0_gcp__step_2__with_reward_input.mp4]]

python -i simdat.py backupcfg/20nov26_load_shuffle_weight_test_C0_gcp__step_2_C1_sim.json
fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward,skipopp=True,framerate=50)
[[./gif/20nov30_20nov26_load_shuffle_weight_test_C0_gcp__step_2_C1__with_reward_input.mp4]]

* 20dec1
** need to adjust getpopinputmap to use non plastic weights

python -i simdat.py backupcfg/20nov26_C1_gcp_sim.json

simConfig.keys() # dict_keys(['netpyne_version', 'netpyne_changeset', 'net', 'simConfig', 'simData'])
simConfig['net'].keys() # dict_keys(['params', 'cells', 'pops'])
len(simConfig['net']['cells']) # 23025
simConfig['net']['cells'][0] 
{gid: 0, tags: {cellType: 'EV1', cellModel: 'INTF7', pop: 'EV1', xnorm: 0.8282152698775253,
ynorm: 0.27553096546895545, znorm: 0.09482398626980745, x: 82.82152698775252, y:
27.553096546895546, z: 9.482398626980745}, conns: [], stims: [], params: {ahpwt: 1, tauahp: 400,
RMP: -65, VTH: -40, refrac: 5, Vblock: -25, tauAM: 5.5, tauNM: 166, tauGA: 10, tauGA2: 20,
tauAM2: 20, tauNM2: 166, tauRR: 1, RRWght: 0.25}, secs: None, secLists: None}

conns not saved by default ... 

cfg.saveCellSecs = bool(dconf['sim']['saveCellSecs']) # if False removes all data on cell sections prior to gathering from nodes
cfg.saveCellConns = bool(dconf['sim']['saveCellConns']) # if False removes all data on cell connections prior to gathering from nodes

so run again to get the connectivity saved ...
        "name": "20dec1_C1_cycle_",
        "saveCellConns": 1,
        "duration": 1000,
    "simtype": {
        "ResumeSim": 1,
	"ResumeSimFromFile": "data/20nov24_C0_gcp__step_2_synWeights_final.pkl"
    },

./myrun 32 sn.json

python -i simdat.py backupcfg/20dec1_C1_cycle_sim.json

lcell = simConfig['net']['cells']
lcell[0]['tags']['cellType']

lcell[dstartidx['EA']]['tags']['cellType'] # 'EA'
cell = lcell[dstartidx['EA']]
len(cell['conns']) # 1920
cell['conns'][0] # {preGid: 288, sec: 'soma', loc: 0.5, synMech: 'AMPA', weight: 2.8408488267239065, delay: 3.630597109992384, weightIndex: 0, label: 'EV1->EA'}

cmap = getinputconnmap(simConfig, 'EV1', dstartidx['EA'], dnumc, dstartidx, 'AMPA')
imshow(cmap,cmap='gray',origin='upper'); 
savefig(gifpath()+'cmap0.png') # [[./gif/20dec1_20dec1_C1_cycle_cmap0.png]]

cmap = getinputconnmap(simConfig, 'EV1', dstartidx['EA'], dnumc, dstartidx, 'AMPA', asweight=True)
imshow(cmap,cmap='gray',origin='upper'); 
colorbar()
savefig(gifpath()+'cmap1.png') 

lcmap = [getinputconnmap(simConfig, 'EV1', idx, dnumc, dstartidx, 'AMPA', asweight=True) for idx in range(dstartidx['EA'],dendidx['EA']+1,1)]
npmap = np.array(lcmap)
lcmapEA = mean(npmap,axis=0)
imshow(lcmapEA,cmap='gray',origin='upper'); 
colorbar()
savefig(gifpath()+'cmapEV1toEA.png') # [[./gif/20dec1_20dec1_C1_cycle_cmapEV1toEA.png]]

np.min(lcmapEA) # 0.1956854546171613
np.max(lcmapEA) # 0.32465289418770804
np.mean(lcmapEA) # 0.2599121860767819

summed across EA neurons, all of the space is covered 

since there are 6400 EV1 neurons and 10% connectivity
and 2800 EA ... that's 640 * 2800 synapses ... 
640 * 2800 # 1792000
~1.8 million synapses ... 

lcmap = [getinputconnmap(simConfig, 'EV1DN', idx, dnumc, dstartidx, 'AMPA', asweight=True) for idx in range(dstartidx['EA'],dendidx['EA']+1,1)]
npmap = np.array(lcmap)
lcmapEA = mean(npmap,axis=0)
imshow(lcmapEA,cmap='gray',origin='upper'); 
colorbar()

np.min(lcmapEA),np.max(lcmapEA),np.mean(lcmapEA) # (0.21032619053719823, 0.31009591697696376, 0.2600183613005337)
ok, so whole space covered for EV1D neurons as well . . .

savefig(gifpath()+'cmapEV1DNtoEA.png') # [[./gif/20dec1_20dec1_C1_cycle_cmapEV1DNtoEA.png]]

dnumc['EV1DN'] * dconf['net']['cmat']['VD']['EA']['p'] * dnumc['EA'] # 112000.0
so only 112K synapses for EV1DN ... 
but ~900K synapses for all the direction selective neurons ... 

and that's because have 20x20 for each pop of dir selective and 80x80 for EV1 ... 

could have the synapse counts for location and direction selective roughly equivalent instead of ~1/2 ... 
but direction selective neurons are more redundant with each other given that motion trajectories follow
straight lines and only change after collisions (rarely)

** smoother activity

via noise ... 

        "name": "20dec1_A0_cycle_",

noise not working properly when use NetStim ... when use NSLOC with INTF7 the noise does seem to work ...

* 20dec3
** new simulatePongFull.py 

HA implemented own version of pong that does not have the momentum issues/problems
interfaced with the model via:

"useSimulatedEnv": 1,
    "simulatedEnvParams": {
        "random":0,
        "yball":80,
        "yracket":40
    },

also prevents rackets from going off-screen at all so do not need padding or avoidstuck rule

** use new simulatedPongFull in simulation - on cycle (20dec3_A0_cycle_) -->> stopped

        "name": "20dec3_A0_cycle_",

python multistepSim.py sn.json 32 20 20dec3_A0_cycle_multi

** other new simulatedPongFull sim on gcp (20dec3_A0_nodirselective_gcp_) -->> stopped

use sim w/o the motion selective neurons ... 

based on params from backupcfg/20nov19_A0_gcp_sim.json

but will use the new full simulated Pong environment and targettedRL of 3

        "name": "20dec3_A0_nodirselective_gcp_",

those firing rates over 20 s are too high ... try adjusting (cmat) weights first ... 

python multistepSim.py sn.json 32 20 20dec3_A0_nondirselective_gcp_multi

at some point ball goes back and forth horizontally while model paddle holds still
this seems to happen indefinitely, so will probably have to adjust some of the dynamics ...

* 20dec4
** adjusted simulatePongFull.py in development branch

the paddles were oscillating around the target location so introduced wiggle term
to prevent that

also testing ability for right racket to get controlled by follow rule (with wiggle)

now when ball hits a paddle its dy (y velocity) is picked randomly

noticed that sometimes the ball goes through the paddle - so that means there's
a bug in collision detection

** revised rules 

use simulated pong but could use the follow ball paradigm - that way would have same
strategy used by model and game ... or have model reward driven by target location when
ball moving toward right side and driven by follow ball when ball moving away from racket - that
way model would not sit around doing nothing 1/2 the time

also adjust the target tracking rule ... to avoid the oscillations; since the paddle movements
are now bigger (5 pixels) in the simulated full pong ... otherwise paddle overshoots and then has to go
in opposite direction

        # targetY = ypos_Racket2 - predY # this is midpoint of racket with ball 
        if ypos_Racket2 - self.racketH2 + self.wiggle > predY: # as long as racket overlaps with predY it's OK (to avoid oscillations)
          proposed_action = dconf['moves']['UP'] #move up
        elif ypos_Racket2 + self.racketH2 - wiggle < predY: # as long as racket overlaps with predY it's OK (to avoid oscillations)
          proposed_action = dconf['moves']['DOWN'] #move down
        else:
          proposed_action = dconf['moves']['NOMOVE'] #no move

** next sim on cycle - with adjusted rules

so will use follow ball when ball moving away from racket, and when ball moving towards racket then
use the target tracking rule

predictBallRacketYIntercept <<-- that does not seem to work properly when ball will bounce
on bottom of court ... 

had
          elif predY_nodeflection>160:
            predY = predY_nodeflection-160     <<-- so if ball was going to hit at 170 it will instead be
predicted to hit at 10 (top) ?? 

should be:
          elif predY_nodeflection>160:
            predY = 160 - (predY_nodeflection-160)
then if ball was going to hit right side at 170, it will instead be predicted to hit at 150 (10 above 160 instead of 10 below 160)

hmm, still some bugs in y prediction ... and changes sign from UP to DOWN for one step right when ball gets close to racket
some boundary condition may be off ... 

also have ball ypos found to be < 0 when it is clearly in the image/frame ... leading to no predicted move sometimes ... 

 t= 58905.0  U,D spikes: [0.0] [0.0]
no pred ypos1 < 0
t= 58905.0 proposed,model action: ['NOP'] ['STAY']
t= 58924.8  U,D spikes: [0.0] [0.0]
t= 58924.8 proposed,model action: ['DOWN'] ['STAY']
t= 58924.8 RLcritic: -0.01
t= 58944.6  U,D spikes: [0.0] [0.0]
t= 58944.6 proposed,model action: ['DOWN'] ['STAY']
t= 58944.6 RLcritic: -0.01
t= 58964.4  U,D spikes: [0.0] [0.0]
t= 58964.4 proposed,model action: ['DOWN'] ['STAY']
t= 58964.4 RLcritic: -0.01
t= 58984.2  U,D spikes: [0.0] [0.0]

problem caused by reaching score of 20 in simulatePongFull.py setting done state to 1

      if (self.GamePoints>1 and self.GamePoints%20==0) or (self.ModelPoints and self.ModelPoints%20==0):
        self.done = 1
      else:
        self.done = 0

which then causes aigame.py to set last_obs to empty list ... which then causes no ability to examine
ball motion from previous frame; then done stays at 1 in simulatePongFull.py until next point scored
all of that is a bug ... for now shutting of self.done being set to 1 in simulatePongFull.py

and here's another ... noticed that when ball passes above or below racket predicted move switches
from up to down or vice versa ... 

should allow hitting from top of paddle as well ... 

for when get this prediction code working better, would be better to have less sparse firing in output populations ... 
there's often no movement at all 

* 20dec5
** meanwhile, try a multistep sim on cycle

with previous params for network (with motion selective neurons) and the fixes mentioned above

        "name": "20dec5_A0_cycle_",

note these params:
    "followOnlyTowards": 0,
    "useRacketPredictedPos": 1,

which means will follow ball when it's moving to the left and follow predicted target when ball is moving to the right

python multistepSim.py sn.json 32 20 20dec5_A0_cycle_multi

* 20dec7
** check output from 20dec5_A0_cycle__step_2_ -->> learned fast then dropped -->> not doing well, EMUP, EMDOWN weights diverged

python -i simdat.py backupcfg/20dec5_A0_cycle__step_2_sim.json

EV1 0.71 Hz
EV1DE 0.16 Hz
EV1DNE 1.4 Hz
EV1DN 2.46 Hz
EV1DNW 0.29 Hz
EV1DW 0.08 Hz
EV1DSW 0.7 Hz
EV1DS 2.43 Hz
EV1DSE 1.25 Hz
EA 2.82 Hz
EA2 9.53 Hz
IA2 20.61 Hz
EMDOWN 11.95 Hz
EMUP 12.1 Hz
IM 21.88 Hz
stimModEV1 0.8 Hz
stimModEV1DE 0.17 Hz
stimModEV1DNE 1.51 Hz
stimModEV1DN 2.61 Hz
stimModEV1DNW 0.31 Hz
stimModEV1DW 0.08 Hz
stimModEV1DSW 0.73 Hz
stimModEV1DS 2.46 Hz
stimModEV1DSE 1.3 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20dec7_20dec5_A0_cycle__step_2_perf.png]]
does not seem to be doing so well ... 

lfn = ['20dec5_A0_cycle__step_' + str(i) + '_' for i in range(3)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec7_20dec5_A0_cycle__step_2_perf_all_steps_so_far.png]]

hit/miss ratio was going up then decayed ... no points scored at all ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,simConfig['simConfig']['duration']),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20dec7_20dec5_A0_cycle__step_2_all_avg_weight.png]]
weights diverged too much ...

pdfc = getconcatweightpdf(lfn)
clf(); popwts = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/20dec7_20dec5_A0_cycle__step_2_all_steps_avg_weight.png]]

so targetted RL of 3 might be a problem that causes the weights to diverge too much . . . 

** adjust sim on cycle (20dec7_A0_cycle_)

add noise
use onlyfollow
targetted - use 0 or 1 ??

./myrun 32 sn.json

EV1 0.44 Hz
EV1DE 0.13 Hz
EV1DNE 0.73 Hz
EV1DN 3.04 Hz
EV1DNW 0.33 Hz
EV1DW 0.09 Hz
EV1DSW 0.44 Hz
EV1DS 3.02 Hz
EV1DSE 0.95 Hz
EA 1.19 Hz
EA2 0.25 Hz
IA2 0.52 Hz
EMDOWN 6.17 Hz
EMUP 6.15 Hz
IM 80.69 Hz
stimModEV1 0.81 Hz
stimModEV1DE 0.19 Hz
stimModEV1DNE 1.43 Hz
stimModEV1DN 5.27 Hz
stimModEV1DNW 0.59 Hz
stimModEV1DW 0.12 Hz
stimModEV1DSW 0.82 Hz
stimModEV1DS 5.23 Hz
stimModEV1DSE 1.85 Hz
stimNoiseEMDOWN_AMPA 1000.08 Hz
stimNoiseEMUP_AMPA 999.96 Hz
stimNoiseEMDOWN_GABA 1000.11 Hz
stimNoiseEMUP_GABA 999.86 Hz

rates are ok ... EA2 somewhat low ... IM somewhat high

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20dec7_20dec7_A0_cycle_perf.png]]

hit rate pretty good ... at least starts that way ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,np.amax(pdf.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/20dec7_20dec7_A0_cycle_all_steps_avg_weight.png]]

clf(); drawraster(dspkT,dspkID); xlim((90e3,100e3))
savefig(gifpath()+'rast.png') # [[./gif/20dec7_20dec7_A0_cycle_rast.png]]

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP']}
for clr,pop in zip(['r','b'],['EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)

savefig(gifpath()+'EMUPDOWN_rates.png') # [[./gif/20dec7_20dec7_A0_cycle_EMUPDOWN_rates.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward,framerate=50)
[[./gif/20dec7_20dec7_A0_cycle__with_reward_input.mp4]]

looks ok but looks like ball passes through right racket sometimes ... and only time model scored is when the
ball went to fast for opponent to respond (randomly - not through model hitting ball)

so need to debug that problem ... 

and should have slightly higher EA2 rates ... 

** changed rules to have dx,dy change each hit - might not keep that rule

and top and bottom hits when paddles moving up and down increase the ball dy * 2

still may have cases where ball seemingly passes through paddle ... 

** meanwhile run a test (20dec7_C0_cycle_)

./myrun 32 sn.json

t= 300000.0 proposed,model action: ['NOP'] ['UP']
  Done; run time = 26286.13 s; real-time ratio: 0.01.

Gathering data...
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
[cycle:707029] *** Process received signal ***
[cycle:707029] Signal: Aborted (6)
[cycle:707029] Signal code:  (-6)
[cycle:707029] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x153c0)[0x7f229c4153c0]
[cycle:707029] [ 1] /lib/x86_64-linux-gnu/libc.so.6(gsignal+0xcb)[0x7f229c25418b]
[cycle:707029] [ 2] /lib/x86_64-linux-gnu/libc.so.6(abort+0x12b)[0x7f229c233859]
[cycle:707029] [ 3] /opt/anaconda3/lib/libstdc++.so.6(_ZN9__gnu_cxx27__verbose_terminate_handlerEv+0xbc)[0x7f229c63584a]
[cycle:707029] [ 4] /opt/anaconda3/lib/libstdc++.so.6(+0xabf47)[0x7f229c633f47]
[cycle:707029] [ 5] /opt/anaconda3/lib/libstdc++.so.6(+0xabf7d)[0x7f229c633f7d]
[cycle:707029] [ 6] /opt/anaconda3/lib/libstdc++.so.6(__cxa_rethrow+0x0)[0x7f229c63415a]
[cycle:707029] [ 7] /opt/anaconda3/lib/libstdc++.so.6(_Znwm+0x52)[0x7f229c634522]
[cycle:707029] [ 8] /opt/anaconda3/lib/python3.7/site-packages/neuron/.data/share/nrn/../../lib/libnrnpython3.so(+0x1d751)[0x7f229003e751]
[cycle:707029] [ 9] /opt/anaconda3/lib/python3.7/site-packages/neuron/.data/bin/../lib/libnrniv.so(+0x273405)[0x7f229c98c405]
[cycle:707029] [10] /opt/anaconda3/lib/python3.7/site-packages/neuron/.data/bin/../lib/libnrniv.so(hoc_call_ob_proc+0x2ab)[0x7f229c9c6d3b]
[cycle:707029] [11] /opt/anaconda3/lib/python3.7/site-packages/neuron/.data/bin/../lib/libnrniv.so(hoc_object_component+0x5c7)[0x7f229c9c7a47]
[cycle:707029] [12] /opt/anaconda3/lib/python3.7/site-packages/neuron/.data/share/nrn/../../lib/libnrnpython3.so(+0xf93b)[0x7f229003093b]
[cycle:707029] [13] /opt/anaconda3/lib/python3.7/site-packages/neuron/.data/share/nrn/../../lib/libnrnpython3.so(+0x12b74)[0x7f2290033b74]
[cycle:707029] [14] /opt/anaconda3/lib/python3.7/site-packages/neuron/.data/bin/../lib/libnrniv.so(_ZN10OcJumpImpl7fpycallEPFPvS0_S0_ES0_S0_+0x3e)[0x7f229c99233e]
[cycle:707029] [15] /opt/anaconda3/lib/python3.7/site-packages/neuron/.data/share/nrn/../../lib/libnrnpython3.so(+0x12fce)[0x7f2290033fce]
[cycle:707029] [16] /opt/anaconda3/lib/./libpython3.7m.so.1.0(_PyObject_FastCallKeywords+0xc5)[0x7f22895d3945]
[cycle:707029] [17] /opt/anaconda3/lib/./libpython3.7m.so.1.0(+0x6f091)[0x7f22894fc091]
[cycle:707029] [18] /opt/anaconda3/lib/./libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x710a)[0x7f22894fa10a]
[cycle:707029] [19] /opt/anaconda3/lib/./libpython3.7m.so.1.0(_PyEval_EvalCodeWithName+0xade)[0x7f22896acfae]
[cycle:707029] [20] /opt/anaconda3/lib/./libpython3.7m.so.1.0(_PyFunction_FastCallKeywords+0x90)[0x7f22895d2fc0]
[cycle:707029] [21] /opt/anaconda3/lib/./libpython3.7m.so.1.0(+0x6f116)[0x7f22894fc116]
[cycle:707029] [22] /opt/anaconda3/lib/./libpython3.7m.so.1.0(_PyEval_EvalFrameDefault+0x710a)[0x7f22894fa10a]
[cycle:707029] [23] /opt/anaconda3/lib/./libpython3.7m.so.1.0(_PyEval_EvalCodeWithName+0xade)[0x7f22896acfae]
[cycle:707029] [24] /opt/anaconda3/lib/./libpython3.7m.so.1.0(PyEval_EvalCodeEx+0x3f)[0x7f22896ad09f]
[cycle:707029] [25] /opt/anaconda3/lib/./libpython3.7m.so.1.0(PyEval_EvalCode+0x1c)[0x7f228959c0cc]
[cycle:707029] [26] /opt/anaconda3/lib/./libpython3.7m.so.1.0(PyRun_FileExFlags+0xb7)[0x7f228958b7d7]
[cycle:707029] [27] /opt/anaconda3/lib/./libpython3.7m.so.1.0(PyRun_SimpleFileExFlags+0xf4)[0x7f2289601d64]
[cycle:707029] [28] /opt/anaconda3/lib/python3.7/site-packages/neuron/.data/share/nrn/../../lib/libnrnpython3.so(nrnpy_pyrun+0x2c)[0x7f22900300ac]
[cycle:707029] [29] /opt/anaconda3/lib/python3.7/site-packages/neuron/.data/share/nrn/../../lib/libnrnpython3.so(nrnpython_start+0x278)[0x7f2290030638]
[cycle:707029] *** End of error message ***

hmm, so data was not saved ... probably crashed due to high rate of netstim inputs (1 kHz for each EM neuron)... 

* 20dec8
** avoid saving spikes from stimMod and noiseStim 

	"recordStim": 0,

in netpyne can adjust simConfig after sim initialized via sim.cfg (will have an effect on what's recorded as long as it's set before sim.setupRecording)
sim.cfg.recordCellsSpikes array determines which gids to record from
can also use population labels

** initialtime in stdp.mod

added initialization time global variable in stdp.mod to make sure synapses not tagged during network
initialization transient; set to 1000 ms by default. checked and seems to work

popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,np.amax(pdf.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
ylim((.5,.5013))
savefig('gif/20dc8_test_initial_time_a0.png') # [[./gif/20dc8_test_initial_time_a0.png]]
savefig('gif/20dc8_test_initial_time_a1.png') # [[./gif/20dc8_test_initial_time_a1.png]]

** last sim crashed at data save, rerun part 20dec8_A0_cycle_ -->> seems to be improving

first test new collision detection rule that HA fixed ... 

./myrun 32 sn.json

EV1 0.48 Hz
EV1DE 0.1 Hz
EV1DNE 0.68 Hz
EV1DN 3.38 Hz
EV1DNW 0.24 Hz
EV1DW 0.06 Hz
EV1DSW 0.16 Hz
EV1DS 3.38 Hz
EV1DSE 0.78 Hz
EA 1.49 Hz
EA2 3.27 Hz
IA2 7.6 Hz
EMDOWN 6.89 Hz
EMUP 6.86 Hz
IM 86.91 Hz

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward) # [[./gif/20dec8_20dec8_A0_cycle__with_reward_input.mp4]]

ok, looks good ... 

can run longer sim now ... 

will run for 500 s continuing from above 50 s sim... 

    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20dec8_A1_cycle_synWeights_final.pkl"
    },

        "name": "20dec8_A1_cycle_",

./myrun 32 sn.json

started ~13:55 ...

finished ~18:45 ... 

so ~5 hours to run 500 s ... 

EV1 0.46 Hz
EV1DE 0.07 Hz
EV1DNE 0.71 Hz
EV1DN 3.43 Hz
EV1DNW 0.19 Hz
EV1DW 0.06 Hz
EV1DSW 0.36 Hz
EV1DS 3.38 Hz
EV1DSE 0.64 Hz
EA 1.27 Hz
EA2 2.91 Hz
IA2 6.84 Hz
EMDOWN 7.09 Hz
EMUP 7.08 Hz
IM 90.11 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20dec8_20dec8_A1_cycle_perf.png]]
hit rate not bad, looks like increasing in steps ... score-rate bad ... but not much
chance for the model to win against opponent
also note that targetted RL is off

popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,np.amax(pdf.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20dec8_20dec8_A1_cycle_all_avg_weight.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20dec8_20dec8_A1_cycle_rast.png]]
xlim((499e3,500e3))
savefig(gifpath()+'rastB.png') # [[./gif/20dec8_20dec8_A1_cycle_rastB.png]] 

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP']}
for clr,pop in zip(['r','b'],['EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)

savefig(gifpath()+'EMUPDOWN_rates.png') # [[./gif/20dec8_20dec8_A1_cycle_EMUPDOWN_rates.png]]
rates are decent throughout ...

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward) # [[./gif/20dec8_20dec8_A1_cycle__with_reward_input.mp4]]

may as well continue this one ... can compare to another later with lower racket speed to see if get more points
for model ... 


name: 20dec8_A2_cycle_
    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/20dec8_A1_cycle_synWeights_final.pkl"
    },

python multistepSim.py sn.json 32 20 20dec8_A2_cycle_multi

started ~21:16 ...

** sim on gcp (20dec8_B0_nodirselective_gcp_)

no dir selective neurons?
longer RL tau?
slower racket speeds?

will try w/o dir selective neurons first ... with cmat from VL -> EA at 0.2375 probability instead
of 0.1; all other params same as 20dec8_A2_cycle_ 
(has noise to EM, no targetted RL, intermediate rewards for predicted y location, 'simulated' pong)

python multistepSim.py sn.json 32 20 20dec8_B0_nodirselective_gcp_multi

started ~22:00 ...

* 20dec9
** check output from 20dec8_B0_nodirselective_gcp__step_1_ and step_2 ... decent, not improving much

python -i simdat.py backupcfg/20dec8_B0_nodirselective_gcp__step_1_sim.json

EV1 0.46 Hz
EA 1.17 Hz
EA2 2.45 Hz
IA2 5.91 Hz
EMDOWN 7.09 Hz
EMUP 7.08 Hz
IM 81.39 Hz
stimModEV1 0.0 Hz
stimNoiseEMDOWN_AMPA 0.0 Hz
stimNoiseEMUP_AMPA 0.0 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20dec9_20dec8_B0_nodirselective_gcp__step_1_perf.png]]
looks good for hit/miss rate; for score/miss not good - but in new pong more difficult
to score points ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,np.amax(pdf.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20dec9_20dec8_B0_nodirselective_gcp__step_1_all_avg_weight.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20dec9_20dec8_B0_nodirselective_gcp__step_1_rast.png]]

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP']}
for clr,pop in zip(['r','b'],['EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)
xlim((0,totalDur))

savefig(gifpath()+'EMUPDOWN_rates.png') # [[./gif/20dec9_20dec8_B0_nodirselective_gcp__step_1_EMUPDOWN_rates.png]]

lfn = ['20dec8_B0_nodirselective_gcp__step_' + str(i) + '_' for i in range(2)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.7))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec9_20dec8_B0_nodirselective_gcp__step_1_perf_all_steps_so_far.png]]
not clear there's an increase in performance ...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20dec9_20dec8_B0_nodirselective_gcp__step_1_perf_compareD.png]]
there might be a slight increase ... 

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward) 
[[./gif/20dec9_20dec8_B0_nodirselective_gcp__step_1__with_reward_input.mp4]]

python -i simdat.py backupcfg/20dec8_B0_nodirselective_gcp__step_2_sim.json

EV1 0.45 Hz
EA 1.12 Hz
EA2 2.23 Hz
IA2 5.38 Hz
EMDOWN 8.21 Hz
EMUP 8.2 Hz
IM 81.8 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20dec9_20dec8_B0_nodirselective_gcp__step_2_perf.png]]
looks similar to prior step

lfn = ['20dec8_B0_nodirselective_gcp__step_' + str(i) + '_' for i in range(3)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.7))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec9_20dec8_B0_nodirselective_gcp__step_2_perf_all_steps_so_far.png]]

may switch to targetted RL and/or reduce noise ... 

** check output from 20dec8_A2_cycle__step_1_

python -i simdat.py backupcfg/20dec8_A2_cycle__step_1_sim.json

EV1 0.46 Hz
EV1DE 0.09 Hz
EV1DNE 0.71 Hz
EV1DN 3.34 Hz
EV1DNW 0.25 Hz
EV1DW 0.06 Hz
EV1DSW 0.38 Hz
EV1DS 3.3 Hz
EV1DSE 0.67 Hz
EA 1.25 Hz
EA2 2.91 Hz
IA2 6.86 Hz
EMDOWN 12.65 Hz
EMUP 12.61 Hz
IM 87.28 Hz

rates getting high ...

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20dec9_20dec8_A2_cycle__step_1_perf.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,np.amax(pdf.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20dec9_20dec8_A2_cycle__step_1_all_avg_weight.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20dec9_20dec8_A2_cycle__step_1_rast.png]]

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP']}
for clr,pop in zip(['r','b'],['EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)
xlim((0,totalDur))

savefig(gifpath()+'EMUPDOWN_rates.png') # [[./gif/20dec9_20dec8_A2_cycle__step_1_EMUPDOWN_rates.png]]

lfn = ['20dec8_A0_cycle_', '20dec8_A1_cycle_', '20dec8_A2_cycle__step_0_', '20dec8_A2_cycle__step_1_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.7))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec9_20dec8_A2_cycle__step_1_perf_all_steps_so_far.png]]
~flat ... 

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20dec9_20dec8_A2_cycle__step_1_perf_compareD.png]]

some improvement, but previous step was better ...

python -i simdat.py backupcfg/20dec8_A2_cycle__step_0_sim.json

EV1 0.46 Hz
EV1DE 0.09 Hz
EV1DNE 0.63 Hz
EV1DN 3.39 Hz
EV1DNW 0.23 Hz
EV1DW 0.05 Hz
EV1DSW 0.41 Hz
EV1DS 3.34 Hz
EV1DSE 0.65 Hz
EA 1.28 Hz
EA2 2.9 Hz
IA2 6.84 Hz
EMDOWN 8.54 Hz
EMUP 8.51 Hz
IM 93.03 Hz

lower rates ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,np.amax(pdf.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20dec9_20dec8_A2_cycle__step_0_all_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward) 
[[./gif/20dec9_20dec8_A2_cycle__step_0__with_reward_input.mp4]]

python -i simdat.py backupcfg/20dec8_A2_cycle__step_2_sim.json

EV1 0.46 Hz
EV1DE 0.1 Hz
EV1DNE 0.66 Hz
EV1DN 3.39 Hz
EV1DNW 0.27 Hz
EV1DW 0.06 Hz
EV1DSW 0.39 Hz
EV1DS 3.34 Hz
EV1DSE 0.67 Hz
EA 1.3 Hz
EA2 3.05 Hz
IA2 7.16 Hz
EMDOWN 27.64 Hz
EMUP 27.56 Hz
IM 60.68 Hz

firing rates too high ... 

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20dec9_20dec8_A2_cycle__step_2_perf.png]]

lfn = ['20dec8_A0_cycle_', '20dec8_A1_cycle_', '20dec8_A2_cycle__step_0_', '20dec8_A2_cycle__step_1_', '20dec8_A2_cycle__step_2_']
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.7))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec9_20dec8_A2_cycle__step_2_perf_all_steps_so_far.png]]

looks ~same ... 

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20dec9_20dec8_A2_cycle__step_2_perf_compareD.png]]
this last step a bit better ... but firing rates now too high ... 

will stop this multistep for now ... 

** adjust sim on gcp (20dec9_A0_nodirselective_gcp_)

less noise?
ok...HA using 500 Hz with weight of 5...can do same ... 

rates after 10 s:
EV1 0.88 Hz
EA 8.42 Hz
EA2 14.69 Hz
IA2 34.9 Hz
EMDOWN 5.61 Hz
EMUP 5.66 Hz
IM 40.38 Hz

also will use targettedRL of 3 ... the noise might help prevent divergence of weights

python multistepSim.py sn.json 32 20 20dec9_A0_nodirselective_gcp_multi

started ~13:00 ... 

** adjust sim on cycle (20dec9_A0_cycle_)

same as 20dec8_A0_cycle_but less noise (500 Hz, weight of 5) and targetted RL of 3 ... 
(also increased stimModVD and stimModVL to 35)

python multistepSim.py sn.json 32 20 20dec9_A0_cycle_multi

started ~13:23 ... 

* 20dec10
** check output from 20dec9_A0_nodirselective_gcp__step_3_

python -i simdat.py backupcfg/20dec9_A0_nodirselective_gcp__step_3_sim.json

EV1 0.77 Hz
EA 6.57 Hz
EA2 11.67 Hz
IA2 29.08 Hz
EMDOWN 3.08 Hz
EMUP 3.07 Hz
IM 36.18 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20dec10_20dec9_A0_nodirselective_gcp__step_3_perf.png]]
has peak ~0.8 but then drops to ~0.4 and stays there ... 

lfn = ['20dec9_A0_nodirselective_gcp__step_' + str(i) + '_' for i in range(4)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec10_20dec9_A0_nodirselective_gcp__step_3_perf_all_steps_so_far.png]]
mostly hovers around 0.4 - 0.5 ... 

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20dec10_20dec9_A0_nodirselective_gcp__step_3_perf_compareD.png]]
step 1,2 are best, steps 0,3 are not as good ... 

pdfc = getconcatweightpdf(lfn)
clf(); popwts = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png')
[[./gif/20dec10_20dec9_A0_nodirselective_gcp__step_3_all_steps_avg_weight.png]]

so on average the weights are staying pretty flat with some minor positive slope
sometimes EMUP and EMDOWN diverge, other times converge ... 

can check raster of step 1 and make video to see behavior ... 

python -i simdat.py backupcfg/20dec9_A0_nodirselective_gcp__step_1_sim.json

EV1 0.78 Hz
EA 6.79 Hz
EA2 12.14 Hz
IA2 30.23 Hz
EMDOWN 3.18 Hz
EMUP 3.15 Hz
IM 36.31 Hz

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20dec10_20dec9_A0_nodirselective_gcp__step_1_rast.png]]
xlim((499e3,500e3))
savefig(gifpath()+'rastB.png') # [[./gif/20dec10_20dec9_A0_nodirselective_gcp__step_1_rastB.png]]

EMUP and EMDOWN less tightly synchronized due to the noise ... EA and EA2 still pretty tightly synchronized from EV1 ... 

would the model perform bettwe with more EA2 neurons? right now most of the input to EM are the EA neurons (2800)
compared to EA2 (only 100 neurons)

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward) 
[[./gif/20dec10_20dec9_A0_nodirselective_gcp__step_1__with_reward_input.mp4]]

** check output from 20dec9_A0_cycle__step_2_

python -i simdat.py backupcfg/20dec9_A0_cycle__step_2_sim.json

EV1 0.78 Hz
EV1DE 0.09 Hz
EV1DNE 1.05 Hz
EV1DN 5.46 Hz
EV1DNW 0.53 Hz
EV1DW 0.05 Hz
EV1DSW 0.74 Hz
EV1DS 5.43 Hz
EV1DSE 1.1 Hz
EA 6.72 Hz
EA2 24.71 Hz
IA2 55.93 Hz
EMDOWN 9.5 Hz
EMUP 9.67 Hz
IM 64.18 Hz

ax=plotPerf(actreward,yl=(0,5))
savefig(gifpath()+'perf.png') # [[./gif/20dec10_20dec9_A0_cycle__step_2_perf.png]]
interesting, hit/miss ratio looks very high - greater than 1 for the first ~200 s of simulation
then decays and remains ~0.5 ... is initial peak an artifact?

lfn = ['20dec9_A0_cycle__step_' + str(i) + '_' for i in range(3)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec10_20dec9_A0_cycle__step_2_perf_all_steps_so_far.png]]
ylim((0,1))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/20dec10_20dec9_A0_cycle__step_2_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,5),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20dec10_20dec9_A0_cycle__step_2_perf_compareD.png]]
seems like an artifact due to early hits in model's favor ... especially since values decay towards ~0.5?
clf(); plotComparePerf(lpda,lclr,yl=(0,2),lleg=lfn)
savefig(gifpath()+'perf_compareDB.png') # [[./gif/20dec10_20dec9_A0_cycle__step_2_perf_compareDB.png]]

pdfc = getconcatweightpdf(lfn)
clf(); popwts = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/20dec10_20dec9_A0_cycle__step_2_all_steps_avg_weight.png]]
weights going up more clearly in this sim (compared to one on gcp with no direction selective neurons)

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20dec10_20dec9_A0_cycle__step_2_rast.png]]
xlim((499e3,500e3))
savefig(gifpath()+'rastB.png') # [[./gif/20dec10_20dec9_A0_cycle__step_2_rastB.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward) 
[[./gif/20dec10_20dec9_A0_cycle__step_2__with_reward_input.mp4]]

** adaptive noise?

could have a population of neurons that are source of noise and provide feedback to them (or interneurons
synapsing on them) from EM populations when EM populations firing fast then they'll activate interneurons 
and suppress their driving noise; that way if EM rates go up via learning, they'll get less noise input

that's ~same as negative feedback from EM -> IM -> EM

** bug found in hit detection for simulatePongFull so stopped sims on cycle and gcp
** check update

looks ok

** further reduced pong

now ha working on further reduced version of pong - without opponent paddle and
reduce number of pixels (reduced # of pixels for later)

that way can improve hit performance to ~max before moving onto score
and opponent racket location wont confuse model

this will be a separate environment so can use environment with opponent if/when needed

** adjust arch (20dec10_C0_cycle_)

would more EA2 neurons help?
ok...added some more...changed weights

and now using the simple simulated pong (only 1 paddle)

python multistepSim.py sn.json 32 20 20dec10_C0_cycle_multi

started ~16:55 ...

* 20dec11
** check output from 20dec10_C0_cycle__step_1_

python -i simdat.py backupcfg/20dec10_C0_cycle__step_1_sim.json

EV1 0.45 Hz
EV1DE 0.12 Hz
EV1DNE 1.44 Hz
EV1DN 3.67 Hz
EV1DNW 0.34 Hz
EV1DW 0.0 Hz
EV1DSW 0.24 Hz
EV1DS 3.69 Hz
EV1DSE 1.74 Hz
EA 0.93 Hz
EA2 0.53 Hz
IA2 3.52 Hz
EMDOWN 1.52 Hz
EMUP 1.52 Hz
IM 8.32 Hz

hmm, very low rates ... 

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20dec11_20dec10_C0_cycle__step_1_perf.png]]

lfn = ['20dec10_C0_cycle__step_' + str(i) + '_' for i in range(2)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,2))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec11_20dec10_C0_cycle__step_1_perf_all_steps_so_far.png]]
ylim((0,1))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/20dec11_20dec10_C0_cycle__step_1_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,5),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20dec11_20dec10_C0_cycle__step_1_perf_compareD.png]]

perf getting worse ... 

pdfc = getconcatweightpdf(lfn)
clf(); popwts = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/20dec11_20dec10_C0_cycle__step_1_all_steps_avg_weight.png]]

hmm, forgot to turn on targetted RL to 3 ... this is w/o targetted RL 

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20dec11_20dec10_C0_cycle__step_1_rast.png]]

those rates look > 1.5 Hz for EMUP ... ??

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP']}
for clr,pop in zip(['r','b'],['EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)
xlim((0,totalDur)); ylim((0,10))

savefig(gifpath()+'EMUPDOWN_rates.png') # [[./gif/20dec11_20dec10_C0_cycle__step_1_EMUPDOWN_rates.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward,skipopp=True) 
[[./gif/20dec11_20dec10_C0_cycle__step_1__with_reward_input.mp4]]

python -i simdat.py backupcfg/20dec10_C0_cycle__step_2_sim.json

EV1 0.45 Hz
EV1DE 0.15 Hz
EV1DNE 1.47 Hz
EV1DN 3.68 Hz
EV1DNW 0.26 Hz
EV1DW 0.02 Hz
EV1DSW 0.21 Hz
EV1DS 3.71 Hz
EV1DSE 1.54 Hz
EA 0.87 Hz
EA2 0.48 Hz
IA2 3.0 Hz
EMDOWN 1.57 Hz
EMUP 1.58 Hz
IM 8.3 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20dec11_20dec10_C0_cycle__step_2_perf.png]]

lfn = ['20dec10_C0_cycle__step_' + str(i) + '_' for i in range(3)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,2))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec11_20dec10_C0_cycle__step_2_perf_all_steps_so_far.png]]
ylim((0,1))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/20dec11_20dec10_C0_cycle__step_2_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,5),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20dec11_20dec10_C0_cycle__step_2_perf_compareD.png]]

does not look good ...

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward,skipopp=True) 
[[./gif/20dec11_20dec10_C0_cycle__step_2__with_reward_input.mp4]]

pdfc = getconcatweightpdf(lfn)
clf(); popwts = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/20dec11_20dec10_C0_cycle__step_2_all_steps_avg_weight.png]]

** adjusted sim a bit more (20dec11_A0_cycle_)

most of the params are the same...if reduce noise have to raise internal weights, and then often
leads to epileptic-like activity ...  

this one does not use targetted RL ... so, may as well include RL from A -> A2, and recurrent A2 as well ...  ?

python multistepSim.py sn.json 32 20 20dec11_A0_cycle_multi

started ~16:38 ...

** next sim on gcp (20dec11_B0_gcp_)

same as one on cycle but targetted RL of 3
and no plasticity for the A2 neurons (since does not work with targetted)

python multistepSim.py sn.json 32 20 20dec11_B0_gcp_multi

started ~16:42 ...

* 20dec14
** check output from 20dec11_B0_gcp__step_11_

python -i simdat.py backupcfg/20dec11_B0_gcp__step_11_sim.json

EV1 0.45 Hz
EV1DE 0.1 Hz
EV1DNE 1.38 Hz
EV1DN 3.91 Hz
EV1DNW 0.35 Hz
EV1DW 0.02 Hz
EV1DSW 0.26 Hz
EV1DS 3.92 Hz
EV1DSE 1.51 Hz
EA 0.95 Hz
EA2 0.58 Hz
IA2 3.82 Hz
EMDOWN 1.75 Hz
EMUP 1.27 Hz
IM 8.71 Hz

large diff in firing rates of EMDOWN and EMUP

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20dec14_20dec11_B0_gcp__step_11_perf.png]]
still at ~0.4 ... 

lfn = ['20dec11_B0_gcp__step_' + str(i) + '_' for i in range(12)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.5))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec14_20dec11_B0_gcp__step_11_perf_all_steps_so_far.png]]
stuck below 0.5 ... 

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,5),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20dec14_20dec11_B0_gcp__step_11_perf_compareD.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,np.amax(pdf.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
ylim((0.44,0.64))
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20dec14_20dec11_B0_gcp__step_11_all_avg_weight.png]]
weights diverged too much ... and that's reflected in the higher EMDOWN vs EMUP firing rates ...
so do not expect this targetted RL == 3 to work ... unless pull the weights back towards each other periodically ...
or have opposite population weights change less than the increase to other population to reduce the counterbalancing ... 

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/20dec14_20dec11_B0_gcp__step_11__with_reward_input.mp4]] 

** adjust targetted==3 rule? (20dec14_A0_gcp_)

      if dconf['sim']['targettedRL']:
        if UPactions==DOWNactions and \
           sum(F_UPs)>0 and sum(F_DOWNs)>0: # same number of actions/spikes -> stay; only apply critic when > 0 spikes
          if dconf['verbose']: print('APPLY RL to both EMUP and EMDOWN')
          for STDPmech in dSTDPmech['all']: STDPmech.reward_punish(float(critic))          
        elif UPactions>DOWNactions: # UP WINS vs DOWN
          if dconf['verbose']: print('APPLY RL to EMUP')
          for STDPmech in dSTDPmech['EMUP']: STDPmech.reward_punish(float(critic))
          if dconf['sim']['targettedRL']==3 and sum(F_DOWNs)>0: # opposite to pop that did not contribute
            if dconf['verbose']: print('APPLY -RL to EMDOWN')
            for STDPmech in dSTDPmech['EMDOWN']: STDPmech.reward_punish(float(-critic))
        elif DOWNactions>UPactions: # DOWN WINS vs UP
          if dconf['verbose']: print('APPLY RL to EMDOWN')
          for STDPmech in dSTDPmech['EMDOWN']: STDPmech.reward_punish(float(critic))
          if dconf['sim']['targettedRL']==3 and sum(F_UPs)>0: # opposite to pop that did not contribute
            if dconf['verbose']: print('APPLY -RL to EMUP')            
            for STDPmech in dSTDPmech['EMUP']: STDPmech.reward_punish(float(-critic))              

could have reward/punish signal for other population with -factor * critic

where factor btwn 0 and 1 (0 for targettedRL==1)

could do that or just use targetted RL of 1 ... 

will try 0.1 for the factor ...

        "targettedRL": 3,
	"targettedRLOppFctr": 0.5,

python multistepSim.py sn.json 32 20 20dec14_A0_gcp_multi

started ~10:20 ...

** check output from 20dec11_A0_cycle__step_3_

python -i simdat.py backupcfg/20dec11_A0_cycle__step_3_sim.json

EV1 0.46 Hz
EV1DE 0.0 Hz
EV1DNE 3.37 Hz
EV1DN 3.13 Hz
EV1DNW 0.0 Hz
EV1DW 0.0 Hz
EV1DSW 0.0 Hz
EV1DS 3.62 Hz
EV1DSE 0.06 Hz
EA 0.59 Hz
EA2 0.01 Hz
IA2 0.03 Hz
EMDOWN 1.16 Hz
EMUP 1.12 Hz
IM 6.35 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20dec14_20dec11_A0_cycle__step_3_perf.png]]

lfn = ['20dec11_A0_cycle__step_' + str(i) + '_' for i in range(4)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.5))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec14_20dec11_A0_cycle__step_3_perf_all_steps_so_far.png]]
this seems to be improving, but slowly ... 

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20dec14_20dec11_A0_cycle__step_3_perf_compareD.png]]
some small improvement from first and later steps, ... 

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,np.amax(pdf.time)),lpop=['EMDOWN','EMUP','EA2'],lclr=['r','b','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20dec14_20dec11_A0_cycle__step_3_all_avg_weight.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20dec14_20dec11_A0_cycle__step_3_rast.png]]
xlim((499e3,500e3))
savefig(gifpath()+'rastB.png') # [[./gif/20dec14_20dec11_A0_cycle__step_3_rastB.png]]

activity looks ok, including rates, but EA2 almost silent ... so not much benefit from having plasticity there ... 

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/20dec14_20dec11_A0_cycle__step_3__with_reward_input.mp4]]

looks ok but too shaky due to noise...

python -i simdat.py backupcfg/20dec11_A0_cycle__step_4_sim.json

EV1 0.45 Hz
EV1DE 0.0 Hz
EV1DNE 2.15 Hz
EV1DN 3.1 Hz
EV1DNW 0.0 Hz
EV1DW 0.0 Hz
EV1DSW 0.0 Hz
EV1DS 3.59 Hz
EV1DSE 1.16 Hz
EA 0.52 Hz
EA2 0.17 Hz
IA2 2.17 Hz
EMDOWN 1.24 Hz
EMUP 1.21 Hz
IM 8.26 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20dec14_20dec11_A0_cycle__step_4_perf.png]]

lfn = ['20dec11_A0_cycle__step_' + str(i) + '_' for i in range(5)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.5))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec14_20dec11_A0_cycle__step_4_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20dec14_20dec11_A0_cycle__step_4_perf_compareD.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,np.amax(pdf.time)),lpop=['EMDOWN','EMUP','EA2'],lclr=['r','b','g'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20dec14_20dec11_A0_cycle__step_4_all_avg_weight.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20dec14_20dec11_A0_cycle__step_4_rast.png]]
xlim((499e3,500e3))
savefig(gifpath()+'rastB.png') # [[./gif/20dec14_20dec11_A0_cycle__step_4_rastB.png]]
note that those firing rates in raster incude the whole simulation but the ones printed from simdat.py are
the last 1 s of simulation ... which has much lower average rates ... 

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/20dec14_20dec11_A0_cycle__step_4__with_reward_input.mp4]]

stopped this one for now ...

** check output from 20dec14_A0_gcp__step_0_

python -i simdat.py backupcfg/20dec14_A0_gcp__step_0_sim.json

EV1 0.45 Hz
EV1DE 0.07 Hz
EV1DNE 1.27 Hz
EV1DN 3.78 Hz
EV1DNW 0.48 Hz
EV1DW 0.0 Hz
EV1DSW 0.29 Hz
EV1DS 3.8 Hz
EV1DSE 1.48 Hz
EA 0.89 Hz
EA2 0.49 Hz
IA2 3.31 Hz
EMDOWN 1.4 Hz
EMUP 1.37 Hz
IM 7.65 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20dec14_20dec14_A0_gcp__step_0_perf.png]]

clf(); popwts = plotMeanWeights(pdf,gca(),msz=6,xl=(0,np.amax(pdf.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_avg_weight.png') # [[./gif/20dec14_20dec14_A0_gcp__step_0_all_avg_weight.png]]

still seems like too much divergence between population weights ... 

** next gcp - 20dec14_B0_gcp_ (targettedRL of 1)

python multistepSim.py sn.json 32 20 20dec14_B0_gcp_multi

started ~15:58 ...

** next sim on cycle - no targetted RL (20dec14_A0_cycle_) -->> crashed early - had bug/typo

try with EIPlast (EM->IM and EA2->IA2), recurrent in EA2, feedback from EM -> EA2, and
the usual feedforward ... 

        "RLconns": {
            "EIPlast": 1,
            "Visual": 0,
            "RecurrentDirNeurons": 0,
            "RecurrentLocNeurons": 0,
            "FeedForwardDirNtoA": 0,
            "FeedForwardLocNtoA": 0,
            "FeedForwardDirNtoA2": 0,
            "FeedForwardLocNtoA2": 0,	    
            "FeedForwardDirNtoM": 0,
            "FeedForwardLocNtoM": 0,
            "FeedForwardAtoM": 1,
            "FeedForwardAtoA2": 1,
            "FeedForwardA2toM": 1,
            "FeedbackLocNeurons": 0,
            "RecurrentMNeurons": 1,
            "RecurrentANeurons": 0,
            "RecurrentA2Neurons": 1,
            "FeedbackAtoDirN": 0,
            "FeedbackAtoLocN": 0,
	    "FeedbackMtoA": 0,
	    "FeedbackMtoA2": 1
        },

        "AMPAI": {
            "wbase": 5,
            "wmax": 20,
            "RLon": 1,
            "STDPon": 0,
            "RLlenhebb": 250,
            "RLlenanti": 250,
            "useRLexp": 1,
            "RLhebbwt": 0.05,
            "RLantiwt": 0.0,
            "hebbwt": 0,
            "antiwt": 0,
            "tauhebb": 10,
            "tauanti": 10,
            "RLwindhebb": 50,
            "softthresh": 0,
            "verbose": 0,
            "maxreward": 0.0
        },
        "AMPA": {
            "wbase": 0.16,
            "wmax": 16,
            "RLon": 1,
            "STDPon": 0,
            "RLlenhebb": 250,
            "RLlenanti": 250,
            "useRLexp": 1,
            "RLhebbwt": 0.005,
            "RLantiwt": 0,
            "hebbwt": 0.0,
            "antiwt": 0.0,
            "tauhebb": 10,
            "tauanti": 10,
            "RLwindhebb": 50,
            "softthresh": 0,
            "verbose": 0,
            "maxreward": 0.0
        },

python multistepSim.py sn.json 32 20 20dec14_A0_cycle_multi

started ~16:48 ... did not run properly

* 20dec15
** check output from 20dec14_B0_gcp__step_2_

python -i simdat.py backupcfg/20dec14_B0_gcp__step_2_sim.json

EV1 0.45 Hz
EV1DE 0.1 Hz
EV1DNE 1.27 Hz
EV1DN 3.82 Hz
EV1DNW 0.49 Hz
EV1DW 0.01 Hz
EV1DSW 0.24 Hz
EV1DS 3.81 Hz
EV1DSE 1.45 Hz
EA 0.91 Hz
EA2 0.51 Hz
IA2 3.5 Hz
EMDOWN 1.53 Hz
EMUP 1.46 Hz
IM 8.26 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20dec15_20dec14_B0_gcp__step_2_perf.png]]

lfn = ['20dec14_B0_gcp__step_' + str(i) + '_' for i in range(3)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.5))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec15_20dec14_B0_gcp__step_2_perf_all_steps_so_far.png]]
does not seem to be improving ... 

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,5),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20dec15_20dec14_B0_gcp__step_2_perf_compareD.png]]

pdfc = getconcatweightpdf(lfn)
clf(); popwts = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/20dec15_20dec14_B0_gcp__step_2_all_steps_avg_weight.png]]
less divergence than before ... note that this sim used targettedRL of 1 ... 
and even that produced divergence of weights ... maybe down moves happen to be more important ... but performance
does not seem to be increasing ...

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/20dec15_20dec14_B0_gcp__step_2__with_reward_input.mp4]]

so maybe noise is dominating network activity right now ... 

** had bug on sim running on cycle (restart as 20dec15_A0_cycle_)

python multistepSim.py sn.json 32 20 20dec15_A0_cycle_multi

** other sim on gcp (20dec15_A0_gcp_); lower noise, inc input to EA, low internal weights -->> stopped, no firing

less noise ... 

ok, reduced the noise - only using inhib noise with same weight as some of the
internal cmat strengths; also made sure that EA is firing properly - EA was not
getting enough activation ... 

python multistepSim.py sn.json 32 20 20dec15_A0_gcp_multi

started ~16:56 ...

no firing - stopping

** other sim on cycle - same as on gcp but with targetted

python multistepSim.py sn.json 32 20 20dec15_A0_cycle_multi

* 20dec16
** next sim on cycle (20dec16_A0_cycle_)
** next sim on gcp (20dec16_A0_gcp_)

python multistepSim.py sn.json 48 20 20dec15_B0_gcp_multi

never ran - was in middle of tuning

* 20dec17
** next sim on gcp - still tuning (20dec17_A0_gcp_)

reduced the number of neurons, changed weights and connections, added some STDP plasticity,
reduced, have feedback connections with plasticity (different depending on population), I->I
weights reduced to allow them to regulate the forward/backward propagating bursts, in case they
occur; not using targetted for this sim ... 

python multistepSim.py sn.json 32 20 20dec17_A0_gcp_multi

started ~13:40 ...

slow to run ... only up to ~270 s at 21:30 ... hit/miss is ~31/64 ... 
but EM firing rates seem too high -- ~300 spikes per 20 ms ... and that's for only
100 EM neurons ... took ~100 s before activity levels stayed persistently overactivated

need to tune net further ... 

** tuning net further on gcp (20dec17_D0_gcp_)

restored most of network size but reduced conn weights and prob in feedback dir
also increased number of IA interneurons ...

adjusted connectivity for E->I and I->E to have same conv for EA,EA2,EM, (for example EA->IA and IA->EA
have same number of inputs as EM->IM and IM->EM); only using RL for plasticity (no standard STDP)

still see some bursty behavior ... will see if gets too high over time ... 

trying with 250 s sims in multistep ...

python multistepSim.py sn.json 32 20 20dec17_D0_gcp_multi

started ~23:49 ...

* 20dec18
** check output from 20dec17_D0_gcp__step_1_ -->> doing something but activity too sparse

python -i simdat.py backupcfg/20dec17_D0_gcp__step_1_sim.json

EV1 0.36 Hz
EV1DE 0.11 Hz
EV1DNE 1.62 Hz
EV1DN 0.6 Hz
EV1DNW 0.44 Hz
EV1DW 0.03 Hz
EV1DSW 0.07 Hz
EV1DS 0.59 Hz
EV1DSE 1.7 Hz
EA 1.23 Hz
IA 18.4 Hz
EA2 0.95 Hz
IA2 4.24 Hz
EMDOWN 1.91 Hz
EMUP 1.91 Hz
IM 4.87 Hz

low overall firing rates - is activation sparse/bursty? will check ...

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20dec18_20dec17_D0_gcp__step_1_perf.png]]

lfn = ['20dec17_D0_gcp__step_' + str(i) + '_' for i in range(2)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.5))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec18_20dec17_D0_gcp__step_1_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,5),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20dec18_20dec17_D0_gcp__step_1_perf_compareD.png]]
no improvement - short sim - sparse firing

pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2'],lclr=['r','b','g'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/20dec18_20dec17_D0_gcp__step_1_all_steps_avg_weight.png]]

so weights to I neurons increasing too; and may provide balance to increase weights to E

clf(); drawraster(dspkT,dspkID); xlim((240e3,250e3))
savefig(gifpath()+'rast.png') # [[./gif/20dec18_20dec17_D0_gcp__step_1_rast.png]]
xlim((249e3,250e3))
savefig(gifpath()+'rastB.png') # [[./gif/20dec18_20dec17_D0_gcp__step_1_rastB.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/20dec18_20dec17_D0_gcp__step_1__with_reward_input.mp4]]

activity pretty sparse and as a result paddle barely ever moves

could see if increasing weights promote more moves later on add noise ... difficult to balance ... 

will try some noise ... 

** adjust sim on gcp (20dec18_A0_gcp_)

added some noise 2.5 weight, 100 Hz

a little better - less sparse firing but could still use 
adjustments

...

* 20dec23
** adjusting model - can use noise/other params from varm2d paper

http://it.neurosim.downstate.edu/pdfs/neymotin2013neco.pdf

table 4 shows firing rates were pretty low even after training - though training was shorter

so now including noise to all populations except for EV1 and EV1DX

* 20dec24
** changes from adjusting general model 

also setup to use AM2, NM2 for all E -> X connections
included LTS populations that target "dends" and use GA2 synapse
while original FS interneurons target "soma" and use GA synapse
there's a longer delay to "dend" (3-5 ms), and shorter delays to soma (1.8-2.2 ms)
all synapses with 2 are meant to simulate dend (longer delay and time constant)
adjusted the time constants to match the varm2d paper - longer for NM2
lengthened the tauRR to 8 ms for E and 1.5 ms for I neurons

new LTS interneuron populations: IAL, IA2L, IML
~31.25% of the interneurons in an area are LTS and remaining interneurons are FS

should also adjust to use conv instead of pmat ... otherwise more difficult to calibrate
to get similar number of inputs to each neuron 

in old models had used NMAMR of 0.1 (10% of AMPA weight); could use separate NetCon
for that or have an adjustment for that inside of the intf7.mod to avoid extra NetCons ... 
hmm, problem with that is noise inputs will also activate NMDA ... 

got decently low rates, with some noise and lowered the connectivity so that convergence
would be lower. EA has some oversynchrony but other populations not much. this could give
the model room to improve. 

check params in 
20dec24_A0_gcp_sim.json
20dec24_B0_gcp_sim.json
20dec24_C0_gcp_sim.json

also adjusted VD,VL->EA,EA2 weights to have 0 variability to make sure
no information lost, which could be important given the now lower 
convergence onto EA,EA2

increased tstepPerAction from 20 to 50 ... and RLlenhebb to 500 ... 

** multistep on gcp (20dec24_D0_gcp_)

not using targetted ... has RL plasticity in most of the pathways
each step will run for 500 s ... 

python multistepSim.py sn.json 32 20 20dec24_D0_gcp_multi

started ~15:26 ...

* 20dec28
** check output from 20dec24_D0_gcp_

python -i simdat.py backupcfg/20dec24_D0_gcp__step_19_sim.json

EV1 0.02 Hz
EV1DE 0.12 Hz
EV1DNE 0.38 Hz
EV1DN 0.45 Hz
EV1DNW 0.2 Hz
EV1DW 0.03 Hz
EV1DSW 0.1 Hz
EV1DS 0.44 Hz
EV1DSE 0.54 Hz
EA 3.41 Hz
IA 39.83 Hz
IAL 43.67 Hz
EA2 0.27 Hz
IA2 1.38 Hz
IA2L 1.94 Hz
EMDOWN 0.25 Hz
EMUP 0.25 Hz
IM 1.46 Hz
IML 4.3 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20dec28_20dec24_D0_gcp__step_19_perf.png]]

lfn = ['20dec24_D0_gcp__step_' + str(i) + '_' for i in range(20)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.75))
savefig(gifpath()+'perf_all_steps_so_far.png') 

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,5),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20dec28_20dec24_D0_gcp__step_19_perf_compareD.png]]

flat ...

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') [[./gif/20dec28_20dec24_D0_gcp__step_19_rast.png]]
xlim((499e3,500e3))
savefig(gifpath()+'rastB.png') # [[./gif/20dec28_20dec24_D0_gcp__step_19_rastB.png]]
sparse firing ... but at least no hyperexcitability emerges ... 

check weights ... 

lfn = ['20dec24_D0_gcp__step_17_', '20dec24_D0_gcp__step_18_', '20dec24_D0_gcp__step_19_']
pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2'],lclr=['r','b','g'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') 
[[./gif/20dec28_20dec24_D0_gcp__step_19_all_steps_avg_weight.png]]
looks like weights were not recorded properly??

popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weightB.png') 
[[./gif/20dec28_20dec24_D0_gcp__step_19_all_steps_avg_weightB.png]]

hmm, all weights at 0, even for EMDOWN and EMUP ?? not recording properly?

pdfc.columns # Index(['time', 'preid', 'postid', 'weight'], dtype='object')
len(pdfc) # 45745200

pdfs = pdfc[(pdfc.postid>=dstartidx['EMDOWN'])&(pdfc.postid<=dendidx['EMDOWN'])]
min(pdfs.weight),max(pdfs.weight),mean(pdfs.weight) # (0.0, 0.0, 0.0)

hmm...

ok, problem occurred because was saving netcon.weight[0] instead of netcon.weight[3]
which is where AM2 is located for the intf7 cells ... 

so, will adjust code, throw out the data and rerun ... 

** restart the multistep sim with weightIndex fix (20dec28_A0_gcp_) -->> found a few bugs

python multistepSim.py sn.json 32 20 20dec28_A0_gcp_multi

started ~11:21 ...

hmm, stdp.mod weight array only uses weight[0]

h.setpointer(singlesyn._ref_weight[0],'synweight',stdpmech) # Point the STDP mechanism to the connection weight

so would have to adjust the setpointer call to use the right weight index too ... ?

already have the fix to use weightIndex in /home/samnemo/netpyne/netpyne/cell/pointCell.py
h.setpointer(netcon._ref_weight[weightIndex], 'synweight', plastMech) # Associate the STDP adjuster with this weight
so should work ... 

** check 20dec28_A0_gcp__step_1_sim.json

python -i simdat.py backupcfg/20dec28_A0_gcp__step_1_sim.json

EV1 0.02 Hz
EV1DE 0.18 Hz
EV1DNE 0.28 Hz
EV1DN 0.5 Hz
EV1DNW 0.16 Hz
EV1DW 0.03 Hz
EV1DSW 0.11 Hz
EV1DS 0.5 Hz
EV1DSE 0.42 Hz
EA 2.34 Hz
IA 61.03 Hz
IAL 80.05 Hz
EA2 0.06 Hz
IA2 1.18 Hz
IA2L 1.64 Hz
EMDOWN 0.06 Hz
EMUP 0.05 Hz
IM 1.18 Hz
IML 1.98 Hz

EMDOWN,EMUP rates way too low ... 

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20dec29_20dec28_A0_gcp__step_1_perf.png]]
improving then dropped off?

lfn = ['20dec28_A0_gcp__step_' + str(i) + '_' for i in range(2)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.75))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec29_20dec28_A0_gcp__step_1_perf_all_steps_so_far.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20dec29_20dec28_A0_gcp__step_1_rast.png]]
xlim((499e3,500e3))
savefig(gifpath()+'rastB.png') # [[./gif/20dec29_20dec28_A0_gcp__step_1_rastB.png]]

lfn = ['20dec28_A0_gcp__step_0_', '20dec28_A0_gcp__step_1_']
pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/20dec29_20dec28_A0_gcp__step_1_all_steps_avg_weight.png]]

weights are increasing ... 
two problems: 1. excitatory weights drop down at t=500 s at the reload. must be a bug.
2. IA weights increase too much? leading to low EA rates and low rates elsewhere?

ylim((0,4))
savefig(gifpath()+'all_steps_avg_weightB.png') # [[./gif/20dec29_20dec28_A0_gcp__step_1_all_steps_avg_weightB.png]]
also, some of the I weights are not starting at right value ... ? IML starts too high - supposed to be ~0.98 average
but is closer to 1.95 (value of IM)  <<-- ok, fixed that...mistake in code:
from
          netParams.connParams[k]['weight'] = getInitWeight(cmat['EM']['IM']['AM2'] * cfg.EIGain)
to
          netParams.connParams[k]['weight'] = getInitWeight(cmat['EM'][poty]['AM2'] * cfg.EIGain)

but what is the issue with the reload? why only weights to E neurons drop to very low values after reload
and not the interneurons??

** debug multistep weight reload with short sim 

python multistepSim.py sn.json 32 2 20dec28_B0_gcp_multi

python -i simdat.py backupcfg/20dec28_B0_gcp__step_1_sim.json

lfn = ['20dec28_B0_gcp__step_0_', '20dec28_B0_gcp__step_1_']
pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # 
[[./gif/20dec29_20dec28_B0_gcp__step_1_all_steps_avg_weight.png]]

here's other bug
should change
  dSTDPparamsRL['AM2']=dSTDPparamsRL['AMPA']; dSTDPparamsRL['NM2']=dSTDPparamsRL['AMPA']
  dSTDPparams['AM2']=dSTDPparams['AMPA']; dSTDPparams['NM2']=dSTDPparams['AMPA']    
to
  dSTDPparamsRL['AM2']=dSTDPparamsRL['AMPA']; dSTDPparamsRL['NM2']=dSTDPparamsRL['NMDA']
  dSTDPparams['AM2']=dSTDPparams['AMPA']; dSTDPparams['NM2']=dSTDPparams['NMDA']  
(had accidentally set NMDA plasticity [which should be off] to AMPA [which is on])

python multistepSim.py sn.json 32 2 20dec28_C0_gcp_multi

python -i simdat.py backupcfg/20dec28_C0_gcp__step_1_sim.json

lfn = ['20dec28_C0_gcp__step_0_', '20dec28_C0_gcp__step_1_']
pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # 
[[./gif/20dec29_20dec28_C0_gcp__step_1_all_steps_avg_weight.png]]
ok, this time no drop in AM weights after restart (at 3 s)
(bug caused ampa weights to get set to NMDA weights on the reload)

** multistep sim on gcp (after weight reload fix and IML wt fix; 20dec28_D0_gcp_)

also, set the EI plast weight increases to be a little lower than before (0.02 same as increases for E->E)
[previously had EI weight increases at 0.05, but then looked like weights to IA increased too much)

python multistepSim.py sn.json 32 20 20dec28_D0_gcp_multi

started ~23:30 ...

* 20dec29
** check output from 20dec28_D0_gcp__step_2_ through 4 -->> improving but rates inc too much (interneurons stop keeping up) 

python -i simdat.py backupcfg/20dec28_D0_gcp__step_2_sim.json

EV1 0.02 Hz
EV1DE 0.08 Hz
EV1DNE 0.24 Hz
EV1DN 0.57 Hz
EV1DNW 0.16 Hz
EV1DW 0.03 Hz
EV1DSW 0.07 Hz
EV1DS 0.57 Hz
EV1DSE 0.34 Hz
EA 2.83 Hz
IA 64.96 Hz
IAL 82.81 Hz
EA2 0.43 Hz
IA2 1.71 Hz
IA2L 2.61 Hz
EMDOWN 0.5 Hz
EMUP 0.48 Hz
IM 3.37 Hz
IML 5.4 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/20dec29_20dec28_D0_gcp__step_2_perf.png]]

this looks strange - why no perf value from beginning? no hits or misses early on??

lfn = ['20dec28_D0_gcp__step_' + str(i) + '_' for i in range(3)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.75))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec29_20dec28_D0_gcp__step_2_perf_all_steps_so_far.png]]

perf increasing slowly

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20dec29_20dec28_D0_gcp__step_2_rast.png]]

pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/20dec29_20dec28_D0_gcp__step_2_all_steps_avg_weight.png]]

weights going up properly ... at least no bug

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/20dec29_20dec28_D0_gcp__step_2__with_reward_input.mp4]]

next step finished ... see if improved further ...

python -i simdat.py backupcfg/20dec28_D0_gcp__step_3_sim.json

EV1 0.02 Hz
EV1DE 0.09 Hz
EV1DNE 0.34 Hz
EV1DN 0.61 Hz
EV1DNW 0.11 Hz
EV1DW 0.03 Hz
EV1DSW 0.09 Hz
EV1DS 0.65 Hz
EV1DSE 0.36 Hz
EA 2.96 Hz
IA 88.06 Hz
IAL 111.99 Hz
EA2 0.73 Hz
IA2 2.96 Hz
IA2L 5.73 Hz
EMDOWN 0.96 Hz
EMUP 0.94 Hz
IM 12.17 Hz
IML 18.5 Hz

firing rates are up ... still reasonable ... 

ax=plotPerf(actreward,yl=(0,3))
savefig(gifpath()+'perf.png') # [[./gif/20dec29_20dec28_D0_gcp__step_3_perf.png]]
pretty good ... note that early part of sim is before any misses, that's why hit/miss ratio is not defined

lfn = ['20dec28_D0_gcp__step_' + str(i) + '_' for i in range(4)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.5))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec29_20dec28_D0_gcp__step_3_perf_all_steps_so_far.png]]

perf still may be increasing slowly ...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,5),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20dec29_20dec28_D0_gcp__step_3_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20dec29_20dec28_D0_gcp__step_3_rast.png]]
are these firing patterns already overly synchronized?

pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/20dec29_20dec28_D0_gcp__step_3_all_steps_avg_weight.png]]

any dep blockade?

clf(); subplot(2,1,1); 
drawcellVm(simConfig,tlim=(490e3,500e3),ldrawpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','g','b','c'])
subplot(2,1,2);
drawcellVm(simConfig,tlim=(490e3,500e3),ldrawpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','g','b','c','m','y'])
savefig(gifpath()+'Vm.png') # [[./gif/20dec29_20dec28_D0_gcp__step_3_Vm.png]]
yeah, looks like dep blockade emerging in some of the interneuron populations (once in a while)
so may have to reduce rate of learning for E -> I

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/20dec29_20dec28_D0_gcp__step_3__with_reward_input.mp4]]

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP','IM','IML']}
for clr,pop in zip(['r','b','g','c'],['EMDOWN','EMUP','IM','IML']): plot(dnspk[pop][0],dnspk[pop][1],clr)
xlim((0,totalDur)); ylim((0,10))

savefig(gifpath()+'firing_rates.png') # [[./gif/20dec29_20dec28_D0_gcp__step_3_firing_rates.png]]

rates going up for E and I, but much higher for I ... 

can let one more step finish but probably should reduce the RLhebbwt for AMPAI (E->I)
otherwise I will go into dep blockade and the circuit will malfunction ...

python -i simdat.py backupcfg/20dec28_D0_gcp__step_4_sim.json

EV1 0.02 Hz
EV1DE 0.05 Hz
EV1DNE 0.25 Hz
EV1DN 0.55 Hz
EV1DNW 0.16 Hz
EV1DW 0.02 Hz
EV1DSW 0.1 Hz
EV1DS 0.61 Hz
EV1DSE 0.28 Hz
EA 11.29 Hz
IA 95.21 Hz
IAL 126.68 Hz
EA2 8.9 Hz
IA2 31.7 Hz
IA2L 47.36 Hz
EMDOWN 35.62 Hz
EMUP 35.47 Hz
IM 40.31 Hz
IML 53.63 Hz

rates have gotten too high for EM neurons ... and IM,IML are barely keeping up, probably
due to depolarization blockade; so will have to adjust params and restart

ax=plotPerf(actreward,yl=(0,3))
savefig(gifpath()+'perf.png') # [[./gif/20dec29_20dec28_D0_gcp__step_4_perf.png]]

lfn = ['20dec28_D0_gcp__step_' + str(i) + '_' for i in range(5)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.5))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec30_20dec28_D0_gcp__step_4_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,5),lleg=lfn)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20dec30_20dec28_D0_gcp__step_4_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20dec30_20dec28_D0_gcp__step_4_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/20dec30_20dec28_D0_gcp__step_4_all_steps_avg_weight.png]]

clf(); subplot(2,1,1); 
drawcellVm(simConfig,tlim=(490e3,500e3),ldrawpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','g','b','c'])
subplot(2,1,2);
drawcellVm(simConfig,tlim=(490e3,500e3),ldrawpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','g','b','c','m','y'])
savefig(gifpath()+'Vm.png') # [[./gif/20dec30_20dec28_D0_gcp__step_4_Vm.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/20dec29_20dec28_D0_gcp__step_4__with_reward_input.mp4]]

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP','IM','IML']}
for clr,pop in zip(['r','b','g','c'],['EMDOWN','EMUP','IM','IML']): plot(dnspk[pop][0],dnspk[pop][1],clr)
xlim((0,totalDur)); ylim((0,175))

savefig(gifpath()+'firing_rates.png') # [[./gif/20dec29_20dec28_D0_gcp__step_4_firing_rates.png]]

** next sim on gcp to fix problems of previous (20dec29_A0_gcp_)

change reward codes to have more punishment...

    "rewardcodes": {
        "scorePoint": 0.0,
        "losePoint": 0.0,
        "followTarget": 0.1,
        "avoidTarget": -0.1,
        "hitBall": 1.0
    },


avoidTarget from -0.01 to -0.1
since there's noise driving firing symmetric punishment might not suppress activity too much ... 

reduce RLhebbwt for AMPAI to 0.0001 (that's AMPA to interneurons) and RLhebbwt for AMPA to 0.001 (that's AMPA to E neurons)
also reduce wmax for AMPAI to 9 and wmax for AMPA to 4.5 ... even 4.5 is pretty high and probably would lead to epileptic
activity, but will take a while to get there so can see how dynamics/perf progress meanwhile ... 

python multistepSim.py sn.json 32 20 20dec29_A0_gcp_multi

started ~22:23 ...

* 20dec30
** check output from 20dec29_A0_gcp__step_2_ -->> average weights decreasing; needs readjustment

python -i simdat.py backupcfg/20dec29_A0_gcp__step_2_sim.json

EV1 0.02 Hz
EV1DE 0.09 Hz
EV1DNE 0.35 Hz
EV1DN 0.57 Hz
EV1DNW 0.13 Hz
EV1DW 0.03 Hz
EV1DSW 0.12 Hz
EV1DS 0.58 Hz
EV1DSE 0.34 Hz
EA 4.58 Hz
IA 17.54 Hz
IAL 5.58 Hz
EA2 0.34 Hz
IA2 1.44 Hz
IA2L 1.99 Hz
EMDOWN 0.36 Hz
EMUP 0.36 Hz
IM 1.9 Hz
IML 2.57 Hz

ax=plotPerf(actreward,yl=(0,0.6))
savefig(gifpath()+'perf.png') # [[./gif/20dec30_20dec29_A0_gcp__step_2_perf.png]]

lfn = ['20dec29_A0_gcp__step_' + str(i) + '_' for i in range(3)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.5))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec30_20dec29_A0_gcp__step_2_perf_all_steps_so_far.png]]
not much improvement so far ... 

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20dec30_20dec29_A0_gcp__step_2_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20dec30_20dec29_A0_gcp__step_2_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/20dec30_20dec29_A0_gcp__step_2_all_steps_avg_weight.png]]
savefig(gifpath()+'all_steps_avg_weightB.png') # [[./gif/20dec30_20dec29_A0_gcp__step_2_all_steps_avg_weightB.png]]
hmm, now the weights are all decreasing, so it's unlikely to work ... decreasing weights probably caused by equal reward/punish signal ... 

clf(); subplot(2,1,1); 
drawcellVm(simConfig,tlim=(490e3,500e3),ldrawpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','g','b','c'])
subplot(2,1,2);
drawcellVm(simConfig,tlim=(490e3,500e3),ldrawpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','g','b','c','m','y'])
savefig(gifpath()+'Vm.png') # [[./gif/20dec30_20dec29_A0_gcp__step_2_Vm.png]]

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP','IM','IML']}
for clr,pop in zip(['r','b','g','c'],['EMDOWN','EMUP','IM','IML']): plot(dnspk[pop][0],dnspk[pop][1],clr)
xlim((0,totalDur)); ylim((0,10))

savefig(gifpath()+'firing_rates.png') # [[./gif/20dec30_20dec29_A0_gcp__step_2_firing_rates.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/20dec30_20dec29_A0_gcp__step_2__with_reward_input.mp4]]

** readjust rewards (20dec30_A0_gcp_)

cut the avoidTarget punishment value from -0.1 to -0.05

python multistepSim.py sn.json 32 20 20dec30_A0_gcp_multi

started ~10:45 ...

** smaller network? 20dec30_B0_gcp_

python multistepSim.py sn.json 30 20 20dec30_B0_gcp_multi

started ~11:28 ...

python -i simdat.py backupcfg/20dec30_B0_gcp__step_0_sim.json

EV1 0.02 Hz
EV1DE 0.04 Hz
EV1DNE 0.32 Hz
EV1DN 0.61 Hz
EV1DNW 0.08 Hz
EV1DW 0.0 Hz
EV1DSW 0.09 Hz
EV1DS 0.62 Hz
EV1DSE 0.44 Hz
EA 4.55 Hz
IA 17.35 Hz
IAL 5.8 Hz
EA2 0.34 Hz
IA2 1.43 Hz
IA2L 1.99 Hz
EMDOWN 0.36 Hz
EMUP 0.36 Hz
IM 1.9 Hz
IML 2.58 Hz

ax=plotPerf(actreward,yl=(0,0.6))
savefig(gifpath()+'perf.png') # [[./gif/20dec30_20dec30_B0_gcp__step_0_perf.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20dec30_20dec30_B0_gcp__step_0_rast.png]]

subplot(1,2,1); popwtsE = plotMeanWeights(pdf,gca(),msz=6,xl=(0,np.amax(pdf.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdf,gca(),msz=6,xl=(0,np.amax(pdf.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'avg_weight.png') # [[./gif/20dec30_20dec30_B0_gcp__step_0_avg_weight.png]]
weights are now going (slowly)
savefig(gifpath()+'avg_weightB.png') # [[./gif/20dec30_20dec30_B0_gcp__step_0_avg_weightB.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/20dec30_20dec30_B0_gcp__step_0__with_reward_input.mp4]]

* 20dec31
** check output from 20dec30_B0_gcp__step_5_

python -i simdat.py backupcfg/20dec30_B0_gcp__step_5_sim.json

EV1 0.02 Hz
EV1DE 0.16 Hz
EV1DNE 0.35 Hz
EV1DN 0.59 Hz
EV1DNW 0.06 Hz
EV1DW 0.01 Hz
EV1DSW 0.07 Hz
EV1DS 0.6 Hz
EV1DSE 0.48 Hz
EA 4.77 Hz
IA 18.45 Hz
IAL 6.42 Hz
EA2 0.38 Hz
IA2 1.47 Hz
IA2L 2.05 Hz
EMDOWN 0.4 Hz
EMUP 0.39 Hz
IM 2.0 Hz
IML 2.7 Hz

ax=plotPerf(actreward,yl=(0,0.6))
savefig(gifpath()+'perf.png') # [[./gif/20dec31_20dec30_B0_gcp__step_5_perf.png]]

lfn = ['20dec30_B0_gcp__step_' + str(i) + '_' for i in range(6)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1.25))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec31_20dec30_B0_gcp__step_5_perf_all_steps_so_far.png]]
do not see improvement ... 

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20dec31_20dec30_B0_gcp__step_5_perf_compareD.png]]
getting worse??

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20dec31_20dec30_B0_gcp__step_5_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/20dec31_20dec30_B0_gcp__step_5_all_steps_avg_weight.png]]
weights rising slowly...very slowly...

clf(); subplot(2,1,1); 
drawcellVm(simConfig,tlim=(490e3,500e3),ldrawpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','g','b','c'])
subplot(2,1,2);
drawcellVm(simConfig,tlim=(490e3,500e3),ldrawpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','g','b','c','m','y'])
savefig(gifpath()+'Vm.png') # [[./gif/20dec31_20dec30_B0_gcp__step_5_Vm.png]]

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP','IM','IML']}
for clr,pop in zip(['r','b','g','c'],['EMDOWN','EMUP','IM','IML']): plot(dnspk[pop][0],dnspk[pop][1],clr)
xlim((0,totalDur)); ylim((0,5))

savefig(gifpath()+'firing_rates.png') # [[./gif/20dec31_20dec30_B0_gcp__step_5_firing_rates.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/20dec31_20dec30_B0_gcp__step_5__with_reward_input.mp4]]

python -i simdat.py backupcfg/20dec30_B0_gcp__step_6_sim.json

EV1 0.02 Hz
EV1DE 0.1 Hz
EV1DNE 0.32 Hz
EV1DN 0.49 Hz
EV1DNW 0.13 Hz
EV1DW 0.02 Hz
EV1DSW 0.1 Hz
EV1DS 0.51 Hz
EV1DSE 0.47 Hz
EA 4.39 Hz
IA 16.85 Hz
IAL 5.6 Hz
EA2 0.34 Hz
IA2 1.44 Hz
IA2L 2.0 Hz
EMDOWN 0.36 Hz
EMUP 0.35 Hz
IM 1.91 Hz
IML 2.58 Hz

rates similar ... 

ax=plotPerf(actreward,yl=(0,0.7))
savefig(gifpath()+'perf.png') # [[./gif/20dec31_20dec30_B0_gcp__step_6_perf.png]]

perf looks better ... ? 

lfn = ['20dec30_B0_gcp__step_' + str(i) + '_' for i in range(7)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1.25))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec31_20dec30_B0_gcp__step_6_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20dec31_20dec30_B0_gcp__step_6_perf_compareD.png]]

similar to first step ... 


clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/20dec31_20dec30_B0_gcp__step_6_all_steps_avg_weight.png]]
weights still rising 

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/20dec31_20dec30_B0_gcp__step_6__with_reward_input.mp4]]

** check output from 20dec30_A0_gcp__step_1_ and step 2

python -i simdat.py backupcfg/20dec30_A0_gcp__step_1_sim.json

EV1 0.02 Hz
EV1DE 0.2 Hz
EV1DNE 0.38 Hz
EV1DN 0.5 Hz
EV1DNW 0.13 Hz
EV1DW 0.04 Hz
EV1DSW 0.06 Hz
EV1DS 0.5 Hz
EV1DSE 0.49 Hz
EA 4.78 Hz
IA 18.5 Hz
IAL 6.19 Hz
EA2 0.37 Hz
IA2 1.47 Hz
IA2L 2.03 Hz
EMDOWN 0.39 Hz
EMUP 0.39 Hz
IM 1.99 Hz
IML 2.67 Hz

firing rates are very close to those above ... strange, though same convergence in both models

ax=plotPerf(actreward,yl=(0,0.6))
savefig(gifpath()+'perf.png') # [[./gif/20dec31_20dec30_A0_gcp__step_1_perf.png]]
climbing up  ... 

lfn = ['20dec30_A0_gcp__step_' + str(i) + '_' for i in range(2)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec31_20dec30_A0_gcp__step_1_perf_all_steps_so_far.png]]
looks pretty flat ... 

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20dec31_20dec30_A0_gcp__step_1_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/20dec31_20dec30_A0_gcp__step_1_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/20dec31_20dec30_A0_gcp__step_1_all_steps_avg_weight.png]]
weights increasing slowly ... 

clf(); subplot(2,1,1); 
drawcellVm(simConfig,tlim=(490e3,500e3),ldrawpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','g','b','c'])
subplot(2,1,2);
drawcellVm(simConfig,tlim=(490e3,500e3),ldrawpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','g','b','c','m','y'])
savefig(gifpath()+'Vm.png') # [[./gif/20dec31_20dec30_A0_gcp__step_1_Vm.png]]

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP','IM','IML']}
for clr,pop in zip(['r','b','g','c'],['EMDOWN','EMUP','IM','IML']): plot(dnspk[pop][0],dnspk[pop][1],clr)
xlim((0,totalDur)); ylim((0,5))

savefig(gifpath()+'firing_rates.png') # [[./gif/20dec31_20dec30_A0_gcp__step_1_firing_rates.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/20dec31_20dec30_A0_gcp__step_1__with_reward_input.mp4]]

python -i simdat.py backupcfg/20dec30_A0_gcp__step_2_sim.json

EV1 0.02 Hz
EV1DE 0.12 Hz
EV1DNE 0.27 Hz
EV1DN 0.5 Hz
EV1DNW 0.21 Hz
EV1DW 0.03 Hz
EV1DSW 0.16 Hz
EV1DS 0.52 Hz
EV1DSE 0.38 Hz
EA 4.54 Hz
IA 17.8 Hz
IAL 5.87 Hz
EA2 0.36 Hz
IA2 1.46 Hz
IA2L 2.02 Hz
EMDOWN 0.38 Hz
EMUP 0.38 Hz
IM 2.0 Hz
IML 2.65 Hz

rates barely changed ... 

ax=plotPerf(actreward,yl=(0,0.75))
savefig(gifpath()+'perf.png') # [[./gif/20dec31_20dec30_A0_gcp__step_2_perf.png]]

lfn = ['20dec30_A0_gcp__step_' + str(i) + '_' for i in range(3)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/20dec31_20dec30_A0_gcp__step_2_perf_all_steps_so_far.png]]

improving??

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/20dec31_20dec30_A0_gcp__step_2_perf_compareD.png]]

does seem to have improved a little ... 

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/20dec31_20dec30_A0_gcp__step_2_all_steps_avg_weight.png]]
weights rising ... (had deleted files from server so that's why first 1000 s not shown)

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EMDOWN','EMUP','IM','IML']}
for clr,pop in zip(['r','b','g','c'],['EMDOWN','EMUP','IM','IML']): plot(dnspk[pop][0],dnspk[pop][1],clr)
xlim((0,totalDur)); ylim((0,8))

savefig(gifpath()+'firing_rates.png') # [[./gif/20dec31_20dec30_A0_gcp__step_2_firing_rates.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/20dec31_20dec30_A0_gcp__step_2__with_reward_input.mp4]]

** new (optional) rule to allow both targetted and non-targetted RL at same time (targettedRL == 4)

same rule as targettedRL == 3 but also when using this rule allow RL at non EM synapses with a discount factor (targettedRLDscntFctr)
and the opposite motor population still uses minus targettedRLOppFctr

** next sim on gcp (targettedRL==4; targetted with non-targetted combined) 20dec31_TARG4_gcp_

        "targettedRL": 4,
	"targettedRLOppFctr": 0.5,
	"targettedRLDscntFctr": 0.5,	

have these reward codes:
        "followTarget": 0.1,
        "avoidTarget": -0.01,
        "hitBall": 1.0

have the EA back to 1400 ... 
            "EA": 1400,
            "IA": 481,
	    "IAL": 219,

and the noise on ... 

AMPA and AMPAI RLhebbwt are still small ... 

python multistepSim.py sn.json 30 20 20dec31_TARG4_gcp_multi

started ~16:27 ...

** next sim on gcp (targettedRL==0; non-targetted) 20dec31_TARG0_gcp_

        "targettedRL": 0,

have these reward codes:
        "followTarget": 0.1,
        "avoidTarget": -0.01,
        "hitBall": 1.0

have the EA back to 1400 ... 
            "EA": 1400,
            "IA": 481,
	    "IAL": 219,

and the noise on ... 

AMPA and AMPAI RLhebbwt are still small ... 

python multistepSim.py sn.json 30 20 20dec31_TARG0_gcp_multi

started ~16:29 ...

** compare targ4 and targ0

python -i simdat.py backupcfg/20dec31_TARG4_gcp__step_0_sim.json

lfn = ['20dec31_TARG4_gcp__step_0_', '20dec31_TARG0_gcp__step_0_']
lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareT0T4.png') # [[./gif/21jan1_20dec31_TARG4_gcp__step_0_perf_compareT0T4.png]]

targ4 doing better than targ0
will targ4 do better than targ3?

* 21jan2
** check output on gcp

python -i simdat.py backupcfg/20dec31_TARG4_gcp__step_6_sim.json

EV1 0.02 Hz
EV1DE 0.15 Hz
EV1DNE 0.23 Hz
EV1DN 0.52 Hz
EV1DNW 0.12 Hz
EV1DW 0.0 Hz
EV1DSW 0.08 Hz
EV1DS 0.56 Hz
EV1DSE 0.45 Hz
EA 4.19 Hz
IA 20.68 Hz
IAL 9.4 Hz
EA2 0.33 Hz
IA2 1.44 Hz
IA2L 1.99 Hz
EMDOWN 0.34 Hz
EMUP 0.34 Hz
IM 1.88 Hz
IML 2.56 Hz

lfn = ['20dec31_TARG4_gcp__step_6_', '20dec31_TARG0_gcp__step_6_']
lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareT0T4.png') # [[./gif/21jan3_20dec31_TARG4_gcp__step_6_perf_compareT0T4.png]]

TARG4 and TARG0 do not look different 

the multistep TARG4 sim stopped after step 6 ... 

TARG0 got up to step 13 ... 

python -i simdat.py backupcfg/20dec31_TARG0_gcp__step_13_sim.json

EV1 0.02 Hz
EV1DE 0.09 Hz
EV1DNE 0.36 Hz
EV1DN 0.49 Hz
EV1DNW 0.16 Hz
EV1DW 0.02 Hz
EV1DSW 0.1 Hz
EV1DS 0.52 Hz
EV1DSE 0.43 Hz
EA 3.62 Hz
IA 30.24 Hz
IAL 27.15 Hz
EA2 0.31 Hz
IA2 1.42 Hz
IA2L 1.98 Hz
EMDOWN 0.33 Hz
EMUP 0.32 Hz
IM 1.9 Hz
IML 2.62 Hz

lfn = ['20dec31_TARG0_gcp__step_' + str(i) + '_' for i in range(14)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jan3_20dec31_TARG0_gcp__step_13_perf_all_steps_so_far.png]]
perf is flat or declining ...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jan3_20dec31_TARG0_gcp__step_13_perf_compareD.png]]
does not seem to be improving ... 

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png')

[[./gif/21jan3_20dec31_TARG0_gcp__step_13_all_steps_avg_weight.png]]

... since E->I weights increasing in parallel with E->E weights, the EM and other E rates are not rising ... 

but E -> I may be rising too quickly ... 

ax=plotPerf(actreward,yl=(0,0.75))
savefig(gifpath()+'perf.png') # [[./gif/21jan3_20dec31_TARG0_gcp__step_13_perf.png]]

python -i simdat.py backupcfg/20dec31_TARG4_gcp__step_6_sim.json

lfn = ['20dec31_TARG4_gcp__step_' + str(i) + '_' for i in range(7)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jan3_20dec31_TARG4_gcp__step_6_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jan3_20dec31_TARG4_gcp__step_6_perf_compareD.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21jan3_20dec31_TARG4_gcp__step_6_all_steps_avg_weight.png]]

** next sims on gcp -- higher conv

conv onto EA is probably too low - only 22 ... previously had ~10% from VL -> EA and same for VD -> EA

ok, increasing conv onto EA, EM, EA2, while reducing the weights, and retrying the two sets (targettedRL==0, targettedRL==4)

also have lower RLhebbwt for EIPlast compared to E->E... 

21jan2_TARG0_gcp_

python multistepSim.py sn.json 30 20 21jan2_TARG0_gcp_multi

started ~23:08 ...

and another with the targettedRL==4

21jan2_TARG4_gcp_

python multistepSim.py sn.json 30 20 21jan2_TARG4_gcp_multi

started ~23:09 ...

* 21jan5
** some more tuning (21jan5_TARG0_gcp_)

smaller net ... fewer EA neurons, intermediate conv and weights

python multistepSim.py sn.json 30 20 21jan5_TARG0_gcp_multi

started ~16:33

** compare with targettedRL==4 (21jan5_TARG4_gcp_)

python multistepSim.py sn.json 30 20 21jan5_TARG4_gcp_multi

started ~16:34 ...

* 21jan6
** check output on gcp -- no better
*** TARG0 step 2

python -i simdat.py backupcfg/21jan5_TARG0_gcp__step_2_sim.json

EV1 0.02 Hz
EA 1.83 Hz
IA 4.78 Hz
IAL 0.25 Hz
EA2 0.13 Hz
IA2 1.22 Hz
IA2L 1.75 Hz
EMDOWN 0.23 Hz
EMUP 0.23 Hz
IM 1.45 Hz
IML 2.15 Hz

why are the rates so low??

ax=plotPerf(actreward,yl=(0,0.75))
savefig(gifpath()+'perf.png') # [[./gif/21jan6_21jan5_TARG0_gcp__step_2_perf.png]]

lfn = ['21jan5_TARG0_gcp__step_' + str(i) + '_' for i in range(3)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jan6_21jan5_TARG0_gcp__step_2_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jan6_21jan5_TARG0_gcp__step_2_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21jan6_21jan5_TARG0_gcp__step_2_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21jan6_21jan5_TARG0_gcp__step_2_all_steps_avg_weight.png]]

lack of increase in rates/may be due to EIplast ... could turn that off or lower it further ... 

*** TARG4 step 2

python -i simdat.py backupcfg/21jan5_TARG4_gcp__step_2_sim.json

EV1 0.02 Hz
EA 1.79 Hz
IA 4.57 Hz
IAL 0.25 Hz
EA2 0.12 Hz
IA2 1.21 Hz
IA2L 1.74 Hz
EMDOWN 0.21 Hz
EMUP 0.21 Hz
IM 1.43 Hz
IML 2.13 Hz

ax=plotPerf(actreward,yl=(0,0.75))
savefig(gifpath()+'perf.png') # [[./gif/21jan6_21jan5_TARG4_gcp__step_2_perf.png]]
this one better than targ0

lfn = ['21jan5_TARG4_gcp__step_' + str(i) + '_' for i in range(3)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jan6_21jan5_TARG4_gcp__step_2_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jan6_21jan5_TARG4_gcp__step_2_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21jan6_21jan5_TARG4_gcp__step_2_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21jan6_21jan5_TARG4_gcp__step_2_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21jan6_21jan5_TARG4_gcp__step_2__with_reward_input.mp4]]

** next test 21jan6_TARG0_gcp_

try same but with EIPlast turned off ... 

*** TARG0

python multistepSim.py sn.json 30 20 21jan6_TARG0_gcp_multi

started ~16:45

*** TARG4

python multistepSim.py sn.json 30 20 21jan6_TARG4_gcp_multi

started ~16:46

* 21jan7
** check output on gcp -->> ?
*** TARG0 step 3

python -i simdat.py backupcfg/21jan6_TARG0_gcp__step_3_sim.json

EV1 0.02 Hz
EA 1.88 Hz
IA 4.54 Hz
IAL 0.28 Hz
EA2 0.13 Hz
IA2 1.23 Hz
IA2L 1.79 Hz
EMDOWN 0.25 Hz
EMUP 0.24 Hz
IM 1.47 Hz
IML 2.19 Hz

still very low rates ... 

ax=plotPerf(actreward,yl=(0,0.75))
savefig(gifpath()+'perf.png') # [[./gif/21jan7_21jan6_TARG0_gcp__step_3_perf.png]]

lfn = ['21jan6_TARG0_gcp__step_' + str(i) + '_' for i in range(4)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jan7_21jan6_TARG0_gcp__step_3_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jan7_21jan6_TARG0_gcp__step_3_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21jan7_21jan6_TARG0_gcp__step_3_rast.png]][[

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21jan7_21jan6_TARG0_gcp__step_3_all_steps_avg_weight.png]]

pretty slow rise in weights ... 

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21jan7_21jan6_TARG0_gcp__step_3__with_reward_input.mp4]]

*** TARG4 step 3

python -i simdat.py backupcfg/21jan6_TARG4_gcp__step_3_sim.json

EV1 0.02 Hz
EA 1.78 Hz
IA 4.31 Hz
IAL 0.24 Hz
EA2 0.12 Hz
IA2 1.21 Hz
IA2L 1.74 Hz
EMDOWN 0.22 Hz
EMUP 0.22 Hz
IM 1.43 Hz
IML 2.13 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/21jan7_21jan6_TARG4_gcp__step_3_perf.png]]
hmm, that looks better ... 

lfn = ['21jan6_TARG4_gcp__step_' + str(i) + '_' for i in range(4)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jan7_21jan6_TARG4_gcp__step_3_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jan7_21jan6_TARG4_gcp__step_3_perf_compareD.png]]
last step looks pretty good ... 

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21jan7_21jan6_TARG4_gcp__step_3_rast.png]]
... despite the low firing rates and noise

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21jan7_21jan6_TARG4_gcp__step_3_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21jan7_21jan6_TARG4_gcp__step_3__with_reward_input.mp4]]

*** TARG4 step 4

python -i simdat.py backupcfg/21jan6_TARG4_gcp__step_4_sim.json

EV1 0.02 Hz
EA 1.8 Hz
IA 4.37 Hz
IAL 0.25 Hz
EA2 0.12 Hz
IA2 1.21 Hz
IA2L 1.76 Hz
EMDOWN 0.22 Hz
EMUP 0.22 Hz
IM 1.43 Hz
IML 2.14 Hz

rates barely changed from previous step ...

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/21jan7_21jan6_TARG4_gcp__step_4_perf.png]]
perf still looks ok - thought not consistent

lfn = ['21jan6_TARG4_gcp__step_' + str(i) + '_' for i in range(5)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jan7_21jan6_TARG4_gcp__step_4_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jan7_21jan6_TARG4_gcp__step_4_perf_compareD.png]]
still looks ok overall

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21jan7_21jan6_TARG4_gcp__step_4_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21jan7_21jan6_TARG4_gcp__step_4_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21jan7_21jan6_TARG4_gcp__step_4__with_reward_input.mp4]]

* 21jan8
** check output on gcp -->> ?
*** TARG0 step 8

python -i simdat.py backupcfg/21jan6_TARG0_gcp__step_8_sim.json

EV1 0.02 Hz
EA 2.11 Hz
IA 5.07 Hz
IAL 0.49 Hz
EA2 0.26 Hz
IA2 1.39 Hz
IA2L 2.04 Hz
EMDOWN 0.35 Hz
EMUP 0.35 Hz
IM 1.68 Hz
IML 2.46 Hz

firing rates up a bit...

ax=plotPerf(actreward,yl=(0,0.75))
savefig(gifpath()+'perf.png') # [[./gif/21jan8_21jan6_TARG0_gcp__step_8_perf.png]]

lfn = ['21jan6_TARG0_gcp__step_' + str(i) + '_' for i in range(9)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jan8_21jan6_TARG0_gcp__step_8_perf_all_steps_so_far.png]]
this one not improving ... 

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jan8_21jan6_TARG0_gcp__step_8_perf_compareD.png]]
step 6 is best ... 

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21jan8_21jan6_TARG0_gcp__step_8_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21jan8_21jan6_TARG0_gcp__step_8_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21jan8_21jan6_TARG0_gcp__step_8__with_reward_input.mp4]]

*** TARG4 step 8

python -i simdat.py backupcfg/21jan6_TARG4_gcp__step_8_sim.json

EV1 0.02 Hz
EA 1.91 Hz
IA 4.62 Hz
IAL 0.31 Hz
EA2 0.15 Hz
IA2 1.25 Hz
IA2L 1.83 Hz
EMDOWN 0.24 Hz
EMUP 0.24 Hz
IM 1.47 Hz
IML 2.18 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/21jan8_21jan6_TARG4_gcp__step_8_perf.png]]
not bad ... 

lfn = ['21jan6_TARG4_gcp__step_' + str(i) + '_' for i in range(9)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jan8_21jan6_TARG4_gcp__step_8_perf_all_steps_so_far.png]]
this looks like it's rising...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jan8_21jan6_TARG4_gcp__step_8_perf_compareD.png]]
step 3 still may be best ... but there's some trend to better perf

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21jan8_21jan6_TARG4_gcp__step_8_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21jan8_21jan6_TARG4_gcp__step_8_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21jan8_21jan6_TARG4_gcp__step_8__with_reward_input.mp4]]
*** TARG4 step 9

python -i simdat.py backupcfg/21jan6_TARG4_gcp__step_9_sim.json

EV1 0.02 Hz
EA 1.85 Hz
IA 4.49 Hz
IAL 0.31 Hz
EA2 0.15 Hz
IA2 1.25 Hz
IA2L 1.84 Hz
EMDOWN 0.24 Hz
EMUP 0.24 Hz
IM 1.48 Hz
IML 2.19 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/21jan8_21jan6_TARG4_gcp__step_9_perf.png]]
looks worse now

lfn = ['21jan6_TARG4_gcp__step_' + str(i) + '_' for i in range(10)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jan8_21jan6_TARG4_gcp__step_9_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jan8_21jan6_TARG4_gcp__step_9_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21jan8_21jan6_TARG4_gcp__step_9_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21jan8_21jan6_TARG4_gcp__step_9_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21jan8_21jan6_TARG4_gcp__step_9__with_reward_input.mp4]]

not clear this sim improving anymore ... 

* 21jan11
** check output on gcp
*** TARG4 step 19

python -i simdat.py backupcfg/21jan6_TARG4_gcp__step_19_sim.json

EV1 0.02 Hz
EA 2.33 Hz
IA 5.66 Hz
IAL 0.7 Hz
EA2 0.38 Hz
IA2 1.54 Hz
IA2L 2.24 Hz
EMDOWN 0.37 Hz
EMUP 0.36 Hz
IM 1.74 Hz
IML 2.49 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/21jan11_21jan6_TARG4_gcp__step_19_perf.png]]

lfn = ['21jan6_TARG4_gcp__step_' + str(i) + '_' for i in range(20)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jan11_21jan6_TARG4_gcp__step_19_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jan11_21jan6_TARG4_gcp__step_19_perf_compareD.png]]

might be improving slowly -- see cumulative; but any individual step can be worse/better than previous/next ...
since rates still increasing could run further ... 

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21jan11_21jan6_TARG4_gcp__step_19_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21jan11_21jan6_TARG4_gcp__step_19_all_steps_avg_weight.png]]

step 12 may be best ... 

continue for now ... 

using 21jan6_TARG4_gcp__step_19_synWeights_final.pkl

new name
21jan11_TARG4_gcp_

    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/21jan6_TARG4_gcp__step_19_synWeights_final.pkl"
    },

python multistepSim.py sn.json 30 20 21jan11_TARG4_gcp_multi

started ~10:54 ...

** other sim (21jan11_TARG4_B_gcp_) ; lower the targettedRLDscntFctr for continuation

also reduce the amount that EA changes by and continue ?

change targettedRLDscntFctr from 0.5 to 0.05

python multistepSim.py sn.json 30 20 21jan11_TARG4_B_gcp_multi

started ~16:47 ...

* 21jan12
** check output on gcp
*** first check 21jan11_TARG4_gcp__step_4_

python -i simdat.py backupcfg/21jan11_TARG4_gcp__step_4_sim.json

EV1 0.01 Hz
EA 64.36 Hz
IA 111.98 Hz
IAL 79.54 Hz
EA2 52.79 Hz
IA2 138.86 Hz
IA2L 117.49 Hz
EMDOWN 36.34 Hz
EMUP 51.69 Hz
IM 89.91 Hz
IML 73.51 Hz

ok, these rates are too high ... should terminate this multistep sim

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/21jan12_21jan11_TARG4_gcp__step_4_perf.png]]

lfn = ['21jan6_TARG4_gcp__step_' + str(i) + '_' for i in range(20)]
for i in range(5): lfn.append('21jan11_TARG4_gcp__step_'+str(i)+'_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jan12_21jan11_TARG4_gcp__step_4_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jan12_21jan11_TARG4_gcp__step_4_perf_compareD.png]]

which is best?

lhits = []
for fn,pda in zip(lfn,lpda):
  cumHits, cumMissed, cumScore = getCumPerfCols(pda) 
  lhits.append(cumHits[-1]/cumMissed[-1])

clf(); plot(lhits,'ko',markersize=15); plot(lhits,'k',linewidth=4); xlabel('Step'); ylabel('Hit/Miss Ratio')
savefig(gifpath()+'HitMissratio_vs_step.png') # [[./gif/21jan12_21jan11_TARG4_gcp__step_4_HitMissratio_vs_step.png]]
lstep = arange(0,len(lpda),1)
pearsonr(lstep, lhits) # (0.13731313148497604, 0.5127719770765581)
weak positive correlation until final step
pearsonr(lstep[:-1], lhits[:-1]) # (0.3693313676770343, 0.0757054879080238)

second to last step may have best performance ... will look at that one

python -i simdat.py backupcfg/21jan11_TARG4_gcp__step_3_sim.json

EV1 0.02 Hz
EA 3.08 Hz
IA 7.48 Hz
IAL 1.47 Hz
EA2 1.17 Hz
IA2 2.79 Hz
IA2L 3.59 Hz
EMDOWN 0.73 Hz
EMUP 0.73 Hz
IM 2.65 Hz
IML 3.45 Hz

ax=plotPerf(actreward,yl=(0,2))
savefig(gifpath()+'perf.png') # [[./gif/21jan12_21jan11_TARG4_gcp__step_3_perf.png]]
looks mostly good for first half

lfn = ['21jan6_TARG4_gcp__step_' + str(i) + '_' for i in range(20)]
for i in range(4): lfn.append('21jan11_TARG4_gcp__step_'+str(i)+'_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jan12_21jan11_TARG4_gcp__step_3_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jan12_21jan11_TARG4_gcp__step_3_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21jan12_21jan11_TARG4_gcp__step_3_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21jan12_21jan11_TARG4_gcp__step_3_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21jan12_21jan11_TARG4_gcp__step_3__with_reward_input.mp4]]

*** check 21jan11_TARG4_B_gcp__step_3_

python -i simdat.py backupcfg/21jan11_TARG4_B_gcp__step_3_sim.json

EV1 0.02 Hz
EA 2.49 Hz
IA 6.0 Hz
IAL 0.81 Hz
EA2 0.46 Hz
IA2 1.64 Hz
IA2L 2.37 Hz
EMDOWN 0.45 Hz
EMUP 0.45 Hz
IM 1.91 Hz
IML 2.72 Hz

ax=plotPerf(actreward,yl=(0,4))
savefig(gifpath()+'perf.png') # [[./gif/21jan12_21jan11_TARG4_B_gcp__step_3_perf.png]]

lfn = ['21jan6_TARG4_gcp__step_' + str(i) + '_' for i in range(20)]
for i in range(4): lfn.append('21jan11_TARG4_B_gcp__step_'+str(i)+'_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jan12_21jan11_TARG4_B_gcp__step_3_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jan12_21jan11_TARG4_B_gcp__step_3_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21jan12_21jan11_TARG4_B_gcp__step_3_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21jan12_21jan11_TARG4_B_gcp__step_3_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21jan12_21jan11_TARG4_B_gcp__step_3__with_reward_input.mp4]]

*** then compare these:
21jan11_TARG4_B_gcp__step_3_
21jan11_TARG4_gcp__step_3_

* 21jan13
** check 21jan11_TARG4_B_gcp__step_10_

python -i simdat.py backupcfg/21jan11_TARG4_B_gcp__step_10_sim.json

EV1 0.02 Hz
EA 2.62 Hz
IA 6.32 Hz
IAL 0.9 Hz
EA2 0.54 Hz
IA2 1.75 Hz
IA2L 2.49 Hz
EMDOWN 0.81 Hz
EMUP 0.81 Hz
IM 2.9 Hz
IML 3.86 Hz

ax=plotPerf(actreward,yl=(0,2))
savefig(gifpath()+'perf.png') # [[./gif/21jan13_21jan11_TARG4_B_gcp__step_10_perf.png]]

lfn = ['21jan6_TARG4_gcp__step_' + str(i) + '_' for i in range(20)]
for i in range(11): lfn.append('21jan11_TARG4_B_gcp__step_'+str(i)+'_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jan13_21jan11_TARG4_B_gcp__step_10_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jan13_21jan11_TARG4_B_gcp__step_10_perf_compareD.png]]

does not seem to be improving ... 

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21jan13_21jan11_TARG4_B_gcp__step_10_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21jan13_21jan11_TARG4_B_gcp__step_10_all_steps_avg_weight.png]]

may as well continue some more to see if improves but no indication that's happening right now...

* 21apr14
** longer time constant help with less immediate reward?

much longer time constant ... 

use simulated env, turn off targeted, use long time constant (100 s), only have reward for hits

21apr14_TARG0_gcp_

./myrun 32 sn.json

python -i simdat.py backupcfg/21apr14_TARG0_gcp_sim.json

looks ok ... 

try a multistep sim ... each step 500 s ...

python multistepSim.py sn.json 30 20 21apr14_TARG0_gcp_multi

started ~21:49 ...

* 21apr15
** check output on gcp from 21apr14_TARG0_gcp__step_3_ -- might improve but gets epileptic

looks like getting epileptic after ~3 steps since did not include punishment signal

python -i simdat.py backupcfg/21apr14_TARG0_gcp__step_3_sim.json

EV1 0.02 Hz
EA 1.94 Hz
IA 4.68 Hz
IAL 0.31 Hz
EA2 0.38 Hz
IA2 1.47 Hz
IA2L 2.12 Hz
EMDOWN 0.63 Hz
EMUP 0.63 Hz
IM 2.16 Hz
IML 3.08 Hz

ax=plotPerf(actreward,yl=(0,0.6))
savefig(gifpath()+'perf.png') # [[./gif/21apr15_21apr14_TARG0_gcp__step_3_perf.png]]

lfn = ['21apr14_TARG0_gcp__step_' + str(i) + '_' for i in range(4)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,3))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr15_21apr14_TARG0_gcp__step_3_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr15_21apr14_TARG0_gcp__step_3_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr15_21apr14_TARG0_gcp__step_3_rast.png]]

up to there the rates were ok ... but in next step the rates got too high ... 

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') 
[[./gif/21apr15_21apr14_TARG0_gcp__step_3_all_steps_avg_weight.png]]

all weights going up ... need to counterbalance

** restart last multistep with some punishment for loss (21apr15_TARG0_A_gcp_)

and this one will have same long time constants for RL (100 s)

these reward codes:
    "rewardcodes": {
        "scorePoint": 0.0,
        "losePoint": -0.1,
        "followTarget": 0.0,
        "avoidTarget": 0.0,
        "hitBall": 1.0
    },

python multistepSim.py sn.json 30 20 21apr15_TARG0_A_gcp_multi

started ~13:31 ...

** run another with 50 s RL time constant (21apr15_TARG0_B_gcp_)

everything else the same as last multistep above (21apr15_TARG0_A_gcp_)

            "RLlenhebb": 50000

python multistepSim.py sn.json 30 20 21apr15_TARG0_B_gcp_multi

started ~13:40 ...

* 21apr16
** check output from 21apr15_TARG0_A_gcp__step_4_

this one has 100 s RL tau with non-targetted RL
and reward, punishment values for hit and miss:
    "rewardcodes": {
        "scorePoint": 0.0,
        "losePoint": -0.1,
        "followTarget": 0.0,
        "avoidTarget": 0.0,
        "hitBall": 1.0
    },


python -i simdat.py backupcfg/21apr15_TARG0_A_gcp__step_4_sim.json

EV1 0.02 Hz
EA 1.91 Hz
IA 4.57 Hz
IAL 0.28 Hz
EA2 0.28 Hz
IA2 1.36 Hz
IA2L 1.96 Hz
EMDOWN 0.52 Hz
EMUP 0.52 Hz
IM 1.86 Hz
IML 2.73 Hz

ax=plotPerf(actreward,yl=(0,0.6))
savefig(gifpath()+'perf.png') # [[./gif/21apr16_21apr15_TARG0_A_gcp__step_4_perf.png]]

lfn = ['21apr15_TARG0_A_gcp__step_' + str(i) + '_' for i in range(5)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,2))
savefig(gifpath()+'perf_all_steps_so_far.png') 
[[./gif/21apr16_21apr15_TARG0_A_gcp__step_4_perf_all_steps_so_far.png]]
may be improving slowly at the end - the first 500 s probably can be discarded...
savefig(gifpath()+'perf_all_steps_so_farB.png') 
[[./gif/21apr16_21apr15_TARG0_A_gcp__step_4_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') 
[[./gif/21apr16_21apr15_TARG0_A_gcp__step_4_perf_compareD.png]]
well, not too convincing yet ... will continue some more

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr16_21apr15_TARG0_A_gcp__step_4_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') 
[[./gif/21apr16_21apr15_TARG0_A_gcp__step_4_all_steps_avg_weight.png]]
weights going up, but less rapidly compared to sim with only reward ... 
will probably get epileptic sooner or later ... 

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr16_21apr15_TARG0_A_gcp__step_4__with_reward_input.mp4]]

watching video - activity does not appear random ... 

check output from a few steps later ... 

python -i simdat.py backupcfg/21apr15_TARG0_A_gcp__step_6_sim.json

EV1 0.02 Hz
EA 1.98 Hz
IA 4.76 Hz
IAL 0.35 Hz
EA2 0.56 Hz
IA2 1.71 Hz
IA2L 2.4 Hz
EMDOWN 2.09 Hz
EMUP 2.08 Hz
IM 3.96 Hz
IML 4.83 Hz

average rates got too high??

ax=plotPerf(actreward,yl=(0,0.6))
savefig(gifpath()+'perf.png') # [[./gif/21apr16_21apr15_TARG0_A_gcp__step_6_perf.png]]

lfn = ['21apr15_TARG0_A_gcp__step_' + str(i) + '_' for i in range(7)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,2))
savefig(gifpath()+'perf_all_steps_so_far.png') 
[[./gif/21apr16_21apr15_TARG0_A_gcp__step_6_perf_all_steps_so_far.png]]

savefig(gifpath()+'perf_all_steps_so_farB.png') 
[[./gif/21apr16_21apr15_TARG0_A_gcp__step_6_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') 
[[./gif/21apr16_21apr15_TARG0_A_gcp__step_6_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr16_21apr15_TARG0_A_gcp__step_6_rast.png]]
savefig(gifpath()+'rastB.png') # [[./gif/21apr16_21apr15_TARG0_A_gcp__step_6_rastB.png]]
rates here are ok, tending towards hypersychrnony, but stopped next step sim since rates got way too high

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') 
[[./gif/21apr16_21apr15_TARG0_A_gcp__step_6_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr16_21apr15_TARG0_A_gcp__step_6__with_reward_input.mp4]]

** check output from 21apr15_TARG0_B_gcp__step_4_

this one has 50 s RL tau with non-targetted RL
and reward, punishment values for hit and miss:
    "rewardcodes": {
        "scorePoint": 0.0,
        "losePoint": -0.1,
        "followTarget": 0.0,
        "avoidTarget": 0.0,
        "hitBall": 1.0
    },


python -i simdat.py backupcfg/21apr15_TARG0_B_gcp__step_4_sim.json

EV1 0.02 Hz
EA 1.91 Hz
IA 4.6 Hz
IAL 0.28 Hz
EA2 0.24 Hz
IA2 1.33 Hz
IA2L 1.91 Hz
EMDOWN 0.42 Hz
EMUP 0.42 Hz
IM 1.73 Hz
IML 2.54 Hz

rates are very slightly lower than the sim above with 100 s RL tau

ax=plotPerf(actreward,yl=(0,0.1))
savefig(gifpath()+'perf.png') # [[./gif/21apr16_21apr15_TARG0_B_gcp__step_4_perf.png]]

lfn = ['21apr15_TARG0_B_gcp__step_' + str(i) + '_' for i in range(5)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,2))
savefig(gifpath()+'perf_all_steps_so_far.png') 
[[./gif/21apr16_21apr15_TARG0_B_gcp__step_4_perf_all_steps_so_far.png]]
this one looks like decreasing gradually - also ignore first 500 s
savefig(gifpath()+'perf_all_steps_so_farB.png') 
[[./gif/21apr16_21apr15_TARG0_B_gcp__step_4_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') 
[[./gif/21apr16_21apr15_TARG0_B_gcp__step_4_perf_compareD.png]]
not clear yet...

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr16_21apr15_TARG0_B_gcp__step_4_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') 
[[./gif/21apr16_21apr15_TARG0_B_gcp__step_4_all_steps_avg_weight.png]]
average weights are pretty similar to the sim with longer tau (100 s)

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr16_21apr15_TARG0_B_gcp__step_4__with_reward_input.mp4]]

looks nonrandom but overall perf not as good as sim with 100 s tau so will discontinue this one further ... 

** other sim? 21apr16_TARG0_C_gcp_ -->> with larger miss punish value

could adjust architecture - denser connectivity?? or keep architecture, have 100 s RL tau,
and have equal negative weight for miss ... ?

for now will keep architecture and increase punishment weight to make sure network can
continue learning longer ... 

    "rewardcodes": {
        "scorePoint": 0.0,
        "losePoint": -0.15,
        "followTarget": 0.0,
        "avoidTarget": 0.0,
        "hitBall": 1.0
    },

python multistepSim.py sn.json 30 20 21apr16_TARG0_C_gcp_multi

started ~11:02 ... 

check interm output ... 

python -i simdat.py backupcfg/21apr16_TARG0_C_gcp__step_1_sim.json

EV1 0.02 Hz
EA 1.78 Hz
IA 4.32 Hz
IAL 0.24 Hz
EA2 0.13 Hz
IA2 1.22 Hz
IA2L 1.75 Hz
EMDOWN 0.24 Hz
EMUP 0.24 Hz
IM 1.46 Hz
IML 2.18 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/21apr16_21apr16_TARG0_C_gcp__step_1_perf.png]]

lfn = ['21apr16_TARG0_C_gcp__step_' + str(i) + '_' for i in range(2)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,2))
savefig(gifpath()+'perf_all_steps_so_far.png') 
[[./gif/21apr17_21apr16_TARG0_C_gcp__step_1_perf_all_steps_so_far.png]]

savefig(gifpath()+'perf_all_steps_so_farB.png') 
[[./gif/21apr17_21apr16_TARG0_C_gcp__step_1_perf_all_steps_so_farB.png]]

seems like improving...only 2 steps so far...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') 
[[./gif/21apr17_21apr16_TARG0_C_gcp__step_1_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr17_21apr16_TARG0_C_gcp__step_1_rast.png]]
good rates so far ~0.3 Hz for EM

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') 
[[./gif/21apr17_21apr16_TARG0_C_gcp__step_1_all_steps_avg_weight.png]]
weights increasing slowly ...

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr17_21apr16_TARG0_C_gcp__step_1__with_reward_input.mp4]]

** and another sim 21apr16_TARG0_D_gcp_ -->> with even larger miss punish value

increase punishment weight to make sure network can continue learning longer ... 

    "rewardcodes": {
        "scorePoint": 0.0,
        "losePoint": -0.2,
        "followTarget": 0.0,
        "avoidTarget": 0.0,
        "hitBall": 1.0
    },

python multistepSim.py sn.json 30 20 21apr16_TARG0_D_gcp_multi

started ~21:58 ...

* 21apr17
** check output from 21apr16_TARG0_C_gcp__step_7_ -->> epileptic - stopped

stopped step 8 since had developed hyperexcitability ... 

python -i simdat.py backupcfg/21apr16_TARG0_C_gcp__step_7_sim.json

EV1 0.02 Hz
EA 2.01 Hz
IA 4.87 Hz
IAL 0.38 Hz
EA2 0.53 Hz
IA2 1.68 Hz
IA2L 2.36 Hz
EMDOWN 3.61 Hz
EMUP 3.61 Hz
IM 4.74 Hz
IML 5.88 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[.gif/21apr18_21apr16_TARG0_C_gcp__step_7_perf.png]]
might have hyperexcit already in this step 7... 

lfn = ['21apr16_TARG0_C_gcp__step_' + str(i) + '_' for i in range(8)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,2))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr18_21apr16_TARG0_C_gcp__step_7_perf_all_steps_so_far.png]]

savefig(gifpath()+'perf_all_steps_so_farB.png') 
[[./gif/21apr18_21apr16_TARG0_C_gcp__step_7_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') 
[[./gif/21apr18_21apr16_TARG0_C_gcp__step_7_perf_compareD.png]]
not sure which step best ... 

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png')
[[./gif/21apr18_21apr16_TARG0_C_gcp__step_7_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') 
[[./gifpath()+'all_steps_avg_weight.png]]

once average weights get to ~0.8, becomes epileptic ... 

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr18_21apr16_TARG0_C_gcp__step_7__with_reward_input.mp4]]

** check output from 21apr16_TARG0_D_gcp__step_4_ -->> best from this set so far

python -i simdat.py backupcfg/21apr16_TARG0_D_gcp__step_4_sim.json

EA 1.89 Hz
IA 4.54 Hz
IAL 0.27 Hz
EA2 0.23 Hz
IA2 1.31 Hz
IA2L 1.89 Hz
EMDOWN 0.41 Hz
EMUP 0.4 Hz
IM 1.7 Hz
IML 2.5 Hz

ax=plotPerf(actreward,yl=(0,3))
savefig(gifpath()+'perf.png') # [[./gif/21apr18_21apr16_TARG0_D_gcp__step_4_perf.png]]
that's best perf seen so far for this set of sims ... with non targetted RL, no intermediate
rewards, and long RL tau

lfn = ['21apr16_TARG0_D_gcp__step_' + str(i) + '_' for i in range(5)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,2))
savefig(gifpath()+'perf_all_steps_so_far.png') 
[[./gif/21apr18_21apr16_TARG0_D_gcp__step_4_perf_all_steps_so_far.png]]

savefig(gifpath()+'perf_all_steps_so_farB.png') 
[[./gif/21apr18_21apr16_TARG0_D_gcp__step_4_perf_all_steps_so_farB.png]]
might still be improving ... 

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') 
[[./gif/21apr18_21apr16_TARG0_D_gcp__step_4_perf_compareD.png]]
step 4 is best so far ... 

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr18_21apr16_TARG0_D_gcp__step_4_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') 
[[./gif/21apr18_21apr16_TARG0_D_gcp__step_4_all_steps_avg_weight.png]]
weights going up and this will most likely get epileptic within a few steps ... 

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr18_21apr16_TARG0_D_gcp__step_4__with_reward_input.mp4]]

** start another sim with slightly more miss punish value 21apr17_TARG0_E_gcp_

    "rewardcodes": {
        "scorePoint": 0.0,
        "losePoint": -0.25,
        "followTarget": 0.0,
        "avoidTarget": 0.0,
        "hitBall": 1.0
    },

keep all else same, RL tau at 100 s ... and non targetted RL ... 

python multistepSim.py sn.json 30 20 21apr17_TARG0_E_gcp_multi

started ~21:31 ...

* 21apr18
** sim D also became hyperexcitable - so stopped on step 7
** sim E still running
** start another sim with slightly more miss punish value 21apr18_TARG0_F_gcp_

    "rewardcodes": {
        "scorePoint": 0.0,
        "losePoint": -0.3,
        "followTarget": 0.0,
        "avoidTarget": 0.0,
        "hitBall": 1.0
    },

keep all else same, RL tau at 100 s ... and non targetted RL ... 

python multistepSim.py sn.json 30 20 21apr18_TARG0_F_gcp_multi

started ~10:06 ...

* 21apr19
** check output from 21apr18_TARG0_F_gcp__step_4_ : -> weights decreasing -> too sparse activity

python -i simdat.py backupcfg/21apr18_TARG0_F_gcp__step_4_sim.json

EV1 0.02 Hz
EA 1.74 Hz
IA 4.26 Hz
IAL 0.23 Hz
EA2 0.1 Hz
IA2 1.2 Hz
IA2L 1.7 Hz
EMDOWN 0.18 Hz
EMUP 0.18 Hz
IM 1.38 Hz
IML 2.07 Hz

these firing rates lower than other sims...

ax=plotPerf(actreward,yl=(0,0.6))
savefig(gifpath()+'perf.png') # [[./gif/21apr19_21apr18_TARG0_F_gcp__step_4_perf.png]]

lfn = ['21apr18_TARG0_F_gcp__step_' + str(i) + '_' for i in range(5)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,2))
savefig(gifpath()+'perf_all_steps_so_far.png') 
[[./gif/21apr19_21apr18_TARG0_F_gcp__step_4_perf_all_steps_so_far.png]]
performance is dropping in this one - probably due to too much punishment and suppression
of E firing...
savefig(gifpath()+'perf_all_steps_so_farB.png') 
[[./gif/21apr19_21apr18_TARG0_F_gcp__step_4_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') 
[[./gif/21apr19_21apr18_TARG0_F_gcp__step_4_perf_compareD.png]]
yeah, step 0 does the best for this sim ... 

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr19_21apr18_TARG0_F_gcp__step_4_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') 
gifpath()+'all_steps_avg_weight.png'
[[./gif/21apr19_21apr18_TARG0_F_gcp__step_4_all_steps_avg_weight.png]]
here, the weights are generally decreasing ... may need some form of weight scaling
to preserve activity - as was suggested from prior simulations

** check output from 21apr17_TARG0_E_gcp__step_8_ -> some steps decent, eventually hyperexcit

python -i simdat.py backupcfg/21apr17_TARG0_E_gcp__step_8_sim.json

EV1 0.02 Hz
EA 1.91 Hz
IA 4.59 Hz
IAL 0.3 Hz
EA2 0.34 Hz
IA2 1.43 Hz
IA2L 2.05 Hz
EMDOWN 0.53 Hz
EMUP 0.52 Hz
IM 1.96 Hz
IML 2.86 Hz

ax=plotPerf(actreward,yl=(0,2))
savefig(gifpath()+'perf.png') # [[./gif/21apr19_21apr17_TARG0_E_gcp__step_8_perf.png]]
not terrible ... 

lfn = ['21apr17_TARG0_E_gcp__step_' + str(i) + '_' for i in range(9)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,2))
savefig(gifpath()+'perf_all_steps_so_far.png') 
[[./gif/21apr19_21apr17_TARG0_E_gcp__step_8_perf_all_steps_so_far.png]]

savefig(gifpath()+'perf_all_steps_so_farB.png') 
[[./gif/21apr19_21apr17_TARG0_E_gcp__step_8_perf_all_steps_so_farB.png]]
overall not changing much ... so far ... ? 

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') 
[[./gif/21apr19_21apr17_TARG0_E_gcp__step_8_perf_compareD.png]]

best ones from this sim (21apr17_TARG0_E_gcp_ similar but not as good to sims
in [[./gif/21apr18_21apr16_TARG0_D_gcp__step_4_perf_compareD.png]]  - 21apr16_TARG0_D_gcp_ -- so
not clear which one to use for paper)

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr19_21apr17_TARG0_E_gcp__step_8_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') 
[[./gif/21apr19_21apr17_TARG0_E_gcp__step_8_all_steps_avg_weight.png]]
between steps average weights going up sometimes, down sometimes, but overall trend is increasing

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr19_21apr17_TARG0_E_gcp__step_8__with_reward_input.mp4]]

this sim became hyperexcitable during step 11 ... 

** conn bug - HA pointed out

            "IA":{"EA":{"GA": 9.0,"conv": 22},
                  "IA":{"GA": 4.5,"conv": 31},
		  "IAL":{"GA": 4.5,"p": 17}},

IA -> IAL should use conv instead of p
that means p is probably all to all which explains low IAL firing rates
may want to fix for next steps ... or keep consistent with manuscript

** another sim (21apr19_TARG0_G_gcp_)

include EIplast to make sure activity does not get hyperexcitable - or some form of weight/rate balancing??

21apr16_TARG0_D_gcp__step_4_sim.json seemed to do best so far ... 

21apr19_TARG0_G_gcp_

if changing architecture/connectivity, will change the conn bug mentioned above to use conv instead of p : 
            "IA":{"EA":{"GA": 9.0,"conv": 22},
                  "IA":{"GA": 4.5,"conv": 31},
		  "IAL":{"GA": 4.5,"conv": 17}},  <<-- fix

basically that bug meant that IAL was firing much less (since IA->IAL was at 100%) and then EA had less feedback inhibition
which could lead to hyperexcit
as a result also could not support as much recurrent/feedback connectivity to EA ... so now trying with some more
recurrent connectivity in EA and higher weights for feedback connections
might lead to runaway excitation but the extra connections (doubled EA->EA conv) and stronger feedback connections
could allow storage of more info:

            "EA":{"EA":{"AM2": 0.5,"NM2": 0.01, "conv": 60},
                  "EA2":{"AM2": 0.5,"NM2": 0.01, "conv": 100},
                  "EM":{"AM2": 0.5,"NM2": 0.01, "conv": 100},
                  "IA":{"AM2": 1.95,"NM2":0.0195, "conv": 93},
		  "IAL":{"AM2": 0.98,"NM2":0.098, "conv": 110}},
            "EA2":{"EA":{"AM2": 0.5,"NM2": 0.01,"conv": 3},
                   "EA2":{"AM2": 0.5,"NM2": 0.01,"conv": 60},
                   "EM":{"AM2": 0.5,"NM2": 0.01,"conv": 60},
                   "IA2":{"AM2": 1.95,"NM2":0.0195,"conv": 93},
		   "IA2L":{"AM2": 0.98,"NM2":0.098,"conv": 110}},	    
            "EM":{"EM":{"AM2": 0.5,"NM2": 0.01,"conv": 60},
                  "EA":{"AM2": 0.5,"NM2": 0.01,"conv": 3},
                  "EA2":{"AM2": 0.5,"NM2": 0.01,"conv": 3},
                  "IRecip":{"AM2": 20,"NM2": 0,"conv": 18},
                  "IM":{"AM2": 1.95,"NM2":0.0195,"conv": 93},
		  "IML":{"AM2": 0.98,"NM2":0.098,"conv": 110}},

./myrun 30 sn.json

python -i simdat.py backupcfg/21apr19_TARG0_G_gcp_sim.json

ok ... at 10 s rates were ok 

and using these reward codes:

    "rewardcodes": {
        "scorePoint": 0.0,
        "losePoint": -0.2,
        "followTarget": 0.0,
        "avoidTarget": 0.0,
        "hitBall": 1.0
    },

python multistepSim.py sn.json 30 20 21apr19_TARG0_G_gcp_multi

started ~12:51 ...

** another sim (21apr19_TARG0_H_gcp_)

same as 21apr19_TARG0_G_gcp_ but with higher magnitude for point loss (losePoint==-0.25)

python multistepSim.py sn.json 30 20 21apr19_TARG0_H_gcp_multi

started ~22:39 ... 

* 21apr20
** check output from 21apr19_TARG0_G_gcp__step_3_ -->> may need more time/steps

python -i simdat.py backupcfg/21apr19_TARG0_G_gcp__step_3_sim.json

EV1 0.02 Hz
EA 1.88 Hz
IA 3.39 Hz
IAL 4.72 Hz
EA2 0.19 Hz
IA2 1.33 Hz
IA2L 1.97 Hz
EMDOWN 0.27 Hz
EMUP 0.27 Hz
IM 1.55 Hz
IML 2.26 Hz

ax=plotPerf(actreward,yl=(0,2))
savefig(gifpath()+'perf.png') # [[./gif/21apr20_21apr19_TARG0_G_gcp__step_3_perf.png]]

lfn = ['21apr19_TARG0_G_gcp__step_' + str(i) + '_' for i in range(4)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,2))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr20_21apr19_TARG0_G_gcp__step_3_perf_all_steps_so_far.png]]

savefig(gifpath()+'perf_all_steps_so_farB.png') 
[[./gif/21apr20_21apr19_TARG0_G_gcp__step_3_perf_all_steps_so_farB.png]]
unstable but might be decreasing near the end ...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') 
[[./gif/21apr20_21apr19_TARG0_G_gcp__step_3_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr20_21apr19_TARG0_G_gcp__step_3_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') 
[[./gif/21apr20_21apr19_TARG0_G_gcp__step_3_all_steps_avg_weight.png]]

here EA weights are highest ... in previous sims had EMUP,EMDOWN weights as highest ... will see where this goes ... 
might become epileptic faster with the higher recurrent connectivity in EA ... although the higher IAL activity
might prevent that

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr20_21apr19_TARG0_G_gcp__step_3__with_reward_input.mp4]]

** check output from 21apr19_TARG0_H_gcp__step_1_

python -i simdat.py backupcfg/21apr19_TARG0_H_gcp__step_1_sim.json

EV1 0.02 Hz
EA 1.84 Hz
IA 3.35 Hz
IAL 4.65 Hz
EA2 0.16 Hz
IA2 1.29 Hz
IA2L 1.9 Hz
EMDOWN 0.24 Hz
EMUP 0.24 Hz
IM 1.49 Hz
IML 2.19 Hz

ax=plotPerf(actreward,yl=(0,3))
savefig(gifpath()+'perf.png') # [[./gif/21apr20_21apr19_TARG0_H_gcp__step_1_perf.png]]

lfn = ['21apr19_TARG0_H_gcp__step_' + str(i) + '_' for i in range(2)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr20_21apr19_TARG0_H_gcp__step_1_perf_all_steps_so_far.png]]
probably needs more time...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr20_21apr19_TARG0_H_gcp__step_1_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr20_21apr19_TARG0_H_gcp__step_1_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr20_21apr19_TARG0_H_gcp__step_1_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr20_21apr19_TARG0_H_gcp__step_1__with_reward_input.mp4]]

* 21apr21
** check output from 21apr19_TARG0_G_gcp__step_10_ -->> not much prog, but some steps (8) decent

python -i simdat.py backupcfg/21apr19_TARG0_G_gcp__step_10_sim.json

EV1 0.02 Hz
EA 2.22 Hz
IA 3.87 Hz
IAL 5.34 Hz
EA2 0.5 Hz
IA2 2.01 Hz
IA2L 2.66 Hz
EMDOWN 0.77 Hz
EMUP 0.76 Hz
IM 2.44 Hz
IML 3.29 Hz

firing rates increased ...

ax=plotPerf(actreward,yl=(0,2))
savefig(gifpath()+'perf.png') # [[./gif/21apr21_21apr19_TARG0_G_gcp__step_10_perf.png]]
perf still looks unchanged

lfn = ['21apr19_TARG0_G_gcp__step_' + str(i) + '_' for i in range(11)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,2))
savefig(gifpath()+'perf_all_steps_so_far.png') 
[[./gif/21apr21_21apr19_TARG0_G_gcp__step_10_perf_all_steps_so_far.png]]

savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21apr21_21apr19_TARG0_G_gcp__step_10_perf_all_steps_so_farB.png]]
or is it rising vey slowly...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr21_21apr19_TARG0_G_gcp__step_10_perf_compareD.png]]
step 8 was pretty good...at least during the beginning but it then dropped off..

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr21_21apr19_TARG0_G_gcp__step_10_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') 
[[./gif/21apr21_21apr19_TARG0_G_gcp__step_10_all_steps_avg_weight.png]]
weights still increasing ... 

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr21_21apr19_TARG0_G_gcp__step_10__with_reward_input.mp4]]

** 21apr19_TARG0_G_gcp__step_11_ became epileptic - stopped it
** check output from 21apr19_TARG0_H_gcp__step_8_ -> not much (or any?) improvement -- stopped

python -i simdat.py backupcfg/21apr19_TARG0_H_gcp__step_8_sim.json

EV1 0.02 Hz
EA 1.96 Hz
IA 3.5 Hz
IAL 4.91 Hz
EA2 0.26 Hz
IA2 1.45 Hz
IA2L 2.09 Hz
EMDOWN 0.35 Hz
EMUP 0.35 Hz
IM 1.69 Hz
IML 2.42 Hz

rates increased a bit...

ax=plotPerf(actreward,yl=(0,3))
savefig(gifpath()+'perf.png') # [[./gif/21apr21_21apr19_TARG0_H_gcp__step_8_perf.png]]

lfn = ['21apr19_TARG0_H_gcp__step_' + str(i) + '_' for i in range(8)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') 
[[./gif/21apr21_21apr19_TARG0_H_gcp__step_8_perf_all_steps_so_far.png]]
does not look like improving - opposite - decreasing perf

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') 
[[./gif/21apr21_21apr19_TARG0_H_gcp__step_8_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') 
[[./gif/21apr21_21apr19_TARG0_H_gcp__step_8_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr21_21apr19_TARG0_H_gcp__step_8_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr21_21apr19_TARG0_H_gcp__step_8__with_reward_input.mp4]]

** next sim (21apr21_TARG0_I_gcp_) (10 s tau)

reduce RL tau to 10 s -- which is closer to the time it takes to go across the field?

adjust some of the architecture as well (reduce EA/EA weights, and feedback weights to how they
were - but also keeping the fix to IA -> IAL)

python multistepSim.py sn.json 30 20 21apr21_TARG0_I_gcp_multi

started ~16:58 ...

python -i simdat.py backupcfg/21apr21_TARG0_I_gcp__step_0_sim.json

EV1 0.02 Hz
EA 1.66 Hz
IA 3.06 Hz
IAL 4.22 Hz
EA2 0.11 Hz
IA2 1.2 Hz
IA2L 1.72 Hz
EMDOWN 0.19 Hz
EMUP 0.19 Hz
IM 1.4 Hz
IML 2.1 Hz

ax=plotPerf(actreward,yl=(0,3))

** next sim (21apr21_TARG0_J_gcp_) (5 s tau)

(buffer = s2)

(otherwise same as 21apr21_TARG0_I_gcp_)

python multistepSim.py sn.json 30 20 21apr21_TARG0_J_gcp_multi

started ~22:52 ...

* 21apr22
** check output from 21apr21_TARG0_I_gcp__step_3_

this is the sim with 10 s tau ...

python -i simdat.py backupcfg/21apr21_TARG0_I_gcp__step_3_sim.json

EV1 0.02 Hz
EA 1.73 Hz
IA 3.17 Hz
IAL 4.34 Hz
EA2 0.12 Hz
IA2 1.21 Hz
IA2L 1.73 Hz
EMDOWN 0.21 Hz
EMUP 0.21 Hz
IM 1.42 Hz
IML 2.12 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/21apr22_21apr21_TARG0_I_gcp__step_3_perf.png]]

lfn = ['21apr21_TARG0_I_gcp__step_' + str(i) + '_' for i in range(4)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr22_21apr21_TARG0_I_gcp__step_3_perf_all_steps_so_far.png]]
this might be improving ... 
ylim((0,0.6))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21apr22_21apr21_TARG0_I_gcp__step_3_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr22_21apr21_TARG0_I_gcp__step_3_perf_compareD.png]]
step 1 and 3 look pretty good

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr22_21apr21_TARG0_I_gcp__step_3_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr22_21apr21_TARG0_I_gcp__step_3_all_steps_avg_weight.png]]
weights increasing slowly ... 

make video from step 1 since that seemed best ...

python -i simdat.py backupcfg/21apr21_TARG0_I_gcp__step_1_sim.json

EV1 0.02 Hz
EA 1.65 Hz
IA 3.06 Hz
IAL 4.21 Hz
EA2 0.11 Hz
IA2 1.2 Hz
IA2L 1.72 Hz
EMDOWN 0.19 Hz
EMUP 0.19 Hz
IM 1.4 Hz
IML 2.1 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/21apr22_21apr21_TARG0_I_gcp__step_1_perf.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr22_21apr21_TARG0_I_gcp__step_1__with_reward_input.mp4]]

looks ok sometimes ... would do better if ball had slowest speed throughout ... 

** check output from 21apr21_TARG0_J_gcp__step_1_

python -i simdat.py backupcfg/21apr21_TARG0_J_gcp__step_1_sim.json

EV1 0.02 Hz
EA 1.67 Hz
IA 3.08 Hz
IAL 4.24 Hz
EA2 0.11 Hz
IA2 1.2 Hz
IA2L 1.72 Hz
EMDOWN 0.2 Hz
EMUP 0.2 Hz
IM 1.4 Hz
IML 2.1 Hz

ax=plotPerf(actreward,yl=(0,2))
savefig(gifpath()+'perf.png') # [[./gif/21apr22_21apr21_TARG0_J_gcp__step_1_perf.png]]

lfn = ['21apr21_TARG0_J_gcp__step_' + str(i) + '_' for i in range(2)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr22_21apr21_TARG0_J_gcp__step_1_perf_all_steps_so_far.png]]


lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr22_21apr21_TARG0_J_gcp__step_1_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr22_21apr21_TARG0_J_gcp__step_1_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr22_21apr21_TARG0_J_gcp__step_1_all_steps_avg_weight.png]]

weights rising even slower due to the 5 s tau (compared to 10 s tau of sim I directly above in notebook)

this one not performing as well ... will stop it

maybe worth comparing the 10 s tau in original architecture currently describe in manuscript...

** next sim 21apr22_TARG0_K_gcp_

would reducing some of the noise help?

remove noise from EA, EA2 ... but keep it for EMDOWN,EMUP and all interneurons
because removing/delaying spikes via noisy inhibition is not as corrupting to information
content as adding spikes via noisy excitation

use 10 s RL tau , no targetted RL

increase weights from EA -> EA2 so still get some firing of EA2:
EA":{"EA":{"AM2": 0.05,"NM2": 0.005, "conv": 30},
                  "EA2":{"AM2": 4,"NM2": 0.01, "conv": 100},

increase max weight for RL (RL AMPA wmax from 4 to 6)

./myrun 30 sn.json

python -i simdat.py backupcfg/21apr22_TARG0_K_gcp_sim.json

...


python multistepSim.py sn.json 30 20 21apr21_TARG0_K_gcp_multi

(shell buffer)

started ~12:46 ...

python -i simdat.py backupcfg/21apr22_TARG0_K_gcp__step_1_sim.json

EV1 0.02 Hz
EA 0.41 Hz
IA 1.52 Hz
IAL 2.1 Hz
EA2 0.17 Hz
IA2 1.38 Hz
IA2L 1.87 Hz
EMDOWN 0.15 Hz
EMUP 0.15 Hz
IM 1.33 Hz
IML 2.0 Hz

ax=plotPerf(actreward,yl=(0,2))
savefig(gifpath()+'perf.png') # [[./gif/21apr23_21apr22_TARG0_K_gcp__step_1_perf.png]]

lfn = ['21apr22_TARG0_K_gcp__step_' + str(i) + '_' for i in range(2)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr23_21apr22_TARG0_K_gcp__step_1_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr23_21apr22_TARG0_K_gcp__step_1_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr23_21apr22_TARG0_K_gcp__step_1_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr23_21apr22_TARG0_K_gcp__step_1_all_steps_avg_weight.png]]
hmm, these weights are moving too slowly . . . 

could increase weight change magnitude, tau, or increase weight to EA, since not receiving any noise now ...

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr23_21apr22_TARG0_K_gcp__step_1__with_reward_input.mp4]]

* 21apr23
** check output from 21apr21_TARG0_I_gcp__step_9_

python -i simdat.py backupcfg/21apr21_TARG0_I_gcp__step_9_sim.json

EV1 0.02 Hz
EA 1.7 Hz
IA 3.12 Hz
IAL 4.32 Hz
EA2 0.13 Hz
IA2 1.22 Hz
IA2L 1.76 Hz
EMDOWN 0.24 Hz
EMUP 0.23 Hz
IM 1.45 Hz
IML 2.16 Hz

ax=plotPerf(actreward,yl=(0,1.5))
savefig(gifpath()+'perf.png') # [[./gif/21apr23_21apr21_TARG0_I_gcp__step_9_perf.png]]
lookks better than others that have seen recently ... though fluctuates a lot

lfn = ['21apr21_TARG0_I_gcp__step_' + str(i) + '_' for i in range(10)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr23_21apr21_TARG0_I_gcp__step_9_perf_all_steps_so_far.png]]
cumulative is pretty flat ... 
ylim((0.25,0.36))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21apr23_21apr21_TARG0_I_gcp__step_9_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr23_21apr21_TARG0_I_gcp__step_9_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr23_21apr21_TARG0_I_gcp__step_9_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr23_21apr21_TARG0_I_gcp__step_9_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr23_21apr21_TARG0_I_gcp__step_9__with_reward_input.mp4]]

** check output from 21apr22_TARG0_K_gcp__step_4_

python -i simdat.py backupcfg/21apr22_TARG0_K_gcp__step_4_sim.json

EV1 0.02 Hz
EA 0.42 Hz
IA 1.54 Hz
IAL 2.12 Hz
EA2 0.21 Hz
IA2 1.48 Hz
IA2L 1.96 Hz
EMDOWN 0.15 Hz
EMUP 0.15 Hz
IM 1.33 Hz
IML 2.01 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/21apr23_21apr22_TARG0_K_gcp__step_4_perf.png]]
not terrible either ... 

lfn = ['21apr22_TARG0_K_gcp__step_' + str(i) + '_' for i in range(5)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr23_21apr22_TARG0_K_gcp__step_4_perf_all_steps_so_far.png]]
ylim((0.25,0.5))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21apr23_21apr22_TARG0_K_gcp__step_4_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr23_21apr22_TARG0_K_gcp__step_4_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr23_21apr22_TARG0_K_gcp__step_4_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr23_21apr22_TARG0_K_gcp__step_4_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr23_21apr22_TARG0_K_gcp__step_4__with_reward_input.mp4]]

* 21apr24
** check output from 21apr21_TARG0_I_gcp__step_17_

python -i simdat.py backupcfg/21apr21_TARG0_I_gcp__step_17_sim.json

EV1 0.02 Hz
EA 1.8 Hz
IA 3.28 Hz
IAL 4.55 Hz
EA2 0.19 Hz
IA2 1.29 Hz
IA2L 1.88 Hz
EMDOWN 0.31 Hz
EMUP 0.3 Hz
IM 1.57 Hz
IML 2.32 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/21apr25_21apr21_TARG0_I_gcp__step_17_perf.png]]
that looks decent - improving up to ~0.8 then stays ~there...

lfn = ['21apr21_TARG0_I_gcp__step_' + str(i) + '_' for i in range(18)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr25_21apr21_TARG0_I_gcp__step_17_perf_all_steps_so_far.png]]

ylim((0.25,0.4))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21apr25_21apr21_TARG0_I_gcp__step_17_perf_all_steps_so_farB.png]]

may still be improving ...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr25_21apr21_TARG0_I_gcp__step_17_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr25_21apr21_TARG0_I_gcp__step_17_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr25_21apr21_TARG0_I_gcp__step_17_all_steps_avg_weight.png]]
based on the weights, probably only a few more steps until reachers hyperexcitability...if does not reach
hyperexcitability, worth continuing this sim past 20 steps...

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr25_21apr21_TARG0_I_gcp__step_17__with_reward_input.mp4]]

looks decent a lot of the time - still noisy output of course ...

** check output from 21apr22_TARG0_K_gcp__step_12_

python -i simdat.py backupcfg/21apr22_TARG0_K_gcp__step_12_sim.json

EV1 0.02 Hz
EA 0.41 Hz
IA 1.53 Hz
IAL 2.11 Hz
EA2 0.21 Hz
IA2 1.5 Hz
IA2L 1.97 Hz
EMDOWN 0.15 Hz
EMUP 0.15 Hz
IM 1.34 Hz
IML 2.01 Hz

these rates have barely moved...

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/21apr25_21apr22_TARG0_K_gcp__step_12_perf.png]]

lfn = ['21apr22_TARG0_K_gcp__step_' + str(i) + '_' for i in range(13)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr25_21apr22_TARG0_K_gcp__step_12_perf_all_steps_so_far.png]]
ylim((0.25,0.5))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21apr25_21apr22_TARG0_K_gcp__step_12_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr25_21apr22_TARG0_K_gcp__step_12_perf_compareD.png]]
some of the steps are decent with some improvements, may need more time to improve further...especially
since the weights are changing so slowly...

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr25_21apr22_TARG0_K_gcp__step_12_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr25_21apr22_TARG0_K_gcp__step_12_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr25_21apr22_TARG0_K_gcp__step_12__with_reward_input.mp4]]
* 21apr25
** check output from 21apr21_TARG0_I_gcp__step_19_

python -i simdat.py backupcfg/21apr21_TARG0_I_gcp__step_19_sim.json

EV1 0.02 Hz
EA 1.79 Hz
IA 3.25 Hz
IAL 4.53 Hz
EA2 0.22 Hz
IA2 1.33 Hz
IA2L 1.93 Hz
EMDOWN 0.34 Hz
EMUP 0.33 Hz
IM 1.64 Hz
IML 2.4 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/21apr25_21apr21_TARG0_I_gcp__step_19_perf.png]]

lfn = ['21apr21_TARG0_I_gcp__step_' + str(i) + '_' for i in range(20)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr25_21apr21_TARG0_I_gcp__step_19_perf_all_steps_so_far.png]]

not as good as last one examined but still improving generally

ylim((0.25,0.4))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21apr25_21apr21_TARG0_I_gcp__step_19_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr25_21apr21_TARG0_I_gcp__step_19_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr25_21apr21_TARG0_I_gcp__step_19_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr25_21apr21_TARG0_I_gcp__step_19_all_steps_avg_weight.png]]

continue this one in a new multistepsim ...(buffer=s3)

cp backupcfg/21apr21_TARG0_I_gcp_sim.json sn.json
then adjust
    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/21apr21_TARG0_I_gcp__step_19_synWeights_final.pkl"
    },

and name to 21apr25_TARG0_I2_gcp_

python multistepSim.py sn.json 30 20 21apr25_TARG0_I2_gcp_multi

started ~9:35 ...

hmm, had a mistake in sn.json that the rewardcode for losePoint was -0.25 instead of -0.2

ok, fixed that and restarting ...

python multistepSim.py sn.json 30 20 21apr25_TARG0_I2_gcp_multi

started ~22:14 ...

(buffer=shell)

** check output from 21apr22_TARG0_K_gcp__step_19_

python -i simdat.py backupcfg/21apr22_TARG0_K_gcp__step_19_sim.json

EV1 0.02 Hz
EA 0.42 Hz
IA 1.54 Hz
IAL 2.14 Hz
EA2 0.26 Hz
IA2 1.57 Hz
IA2L 2.02 Hz
EMDOWN 0.16 Hz
EMUP 0.16 Hz
IM 1.34 Hz
IML 2.02 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/21apr26_21apr22_TARG0_K_gcp__step_19_perf.png]]

lfn = ['21apr22_TARG0_K_gcp__step_' + str(i) + '_' for i in range(20)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr26_21apr22_TARG0_K_gcp__step_19_perf_all_steps_so_far.png]]
ylim((0.25,0.5))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21apr26_21apr22_TARG0_K_gcp__step_19_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr26_21apr22_TARG0_K_gcp__step_19_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr26_21apr22_TARG0_K_gcp__step_19_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr26_21apr22_TARG0_K_gcp__step_19_all_steps_avg_weight.png]]

weights still barely moved ... 

will continue from here ... 

cp backupcfg/21apr22_TARG0_K_gcp_sim.json sn.json

then increase the wmax in RL AMPA to 6
change name to 
        "name": "21apr25_TARG0_K2_gcp_",
    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/21apr22_TARG0_K_gcp__step_19_synWeights_final.pkl"
    },
and duration to 500 s ...

python multistepSim.py sn.json 30 20 21apr25_TARG0_K2_gcp_multi

(buffer=s0)

started ~22:40 ...

* 21apr26
** check output from 21apr25_TARG0_I2_gcp__step_3_

python -i simdat.py backupcfg/21apr25_TARG0_I2_gcp__step_3_sim.json

EV1 0.02 Hz
EA 1.86 Hz
IA 3.35 Hz
IAL 4.7 Hz
EA2 0.32 Hz
IA2 1.47 Hz
IA2L 2.11 Hz
EMDOWN 0.49 Hz
EMUP 0.47 Hz
IM 1.9 Hz
IML 2.75 Hz

ax=plotPerf(actreward,yl=(0,1))
savefig(gifpath()+'perf.png') # [[./gif/21apr26_21apr25_TARG0_I2_gcp__step_3_perf.png]]
high performance for first 200 s but then drops down

lfn = ['21apr21_TARG0_I_gcp__step_' + str(i) + '_' for i in range(20)]
for i in range(4): lfn.append('21apr25_TARG0_I2_gcp__step_'+str(i)+'_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr26_21apr25_TARG0_I2_gcp__step_3_perf_all_steps_so_far.png]]
looks to be improving 
ylim((0.25,0.4))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21apr26_21apr25_TARG0_I2_gcp__step_3_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr26_21apr25_TARG0_I2_gcp__step_3_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr26_21apr25_TARG0_I2_gcp__step_3_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr26_21apr25_TARG0_I2_gcp__step_3_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr26_21apr25_TARG0_I2_gcp__step_3__with_reward_input.mp4]]

* 21apr27
** check output from 21apr25_TARG0_I2_gcp__step_7_

python -i simdat.py backupcfg/21apr25_TARG0_I2_gcp__step_7_sim.json

EV1 0.02 Hz
EA 1.79 Hz
IA 3.25 Hz
IAL 4.58 Hz
EA2 0.5 Hz
IA2 1.73 Hz
IA2L 2.45 Hz
EMDOWN 0.75 Hz
EMUP 0.7 Hz
IM 2.68 Hz
IML 3.55 Hz

firing rates getting high

ax=plotPerf(actreward,yl=(0,3.1))
savefig(gifpath()+'perf.png') # [[./gif/21apr27_21apr25_TARG0_I2_gcp__step_7_perf.png]]

lfn = ['21apr21_TARG0_I_gcp__step_' + str(i) + '_' for i in range(20)]
for i in range(8): lfn.append('21apr25_TARG0_I2_gcp__step_'+str(i)+'_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr27_21apr25_TARG0_I2_gcp__step_7_perf_all_steps_so_far.png]]
still looks to be improving 
ylim((0.25,0.415))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21apr27_21apr25_TARG0_I2_gcp__step_7_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') 
[[./gif/21apr27_21apr25_TARG0_I2_gcp__step_7_perf_compareD.png]]
still have some of those instances where performance high in beginning for a few hundred seconds and then decays gradually
but the first 200+ s looks good...

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr27_21apr25_TARG0_I2_gcp__step_7_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') 
[[./gif/21apr27_21apr25_TARG0_I2_gcp__step_7_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr27_21apr25_TARG0_I2_gcp__step_7__with_reward_input.mp4]]

** check output from 21apr25_TARG0_K2_gcp__step_7_

python -i simdat.py backupcfg/21apr25_TARG0_K2_gcp__step_7_sim.json

EV1 0.02 Hz
EA 0.41 Hz
IA 1.53 Hz
IAL 2.12 Hz
EA2 0.28 Hz
IA2 1.6 Hz
IA2L 2.06 Hz
EMDOWN 0.16 Hz
EMUP 0.16 Hz
IM 1.35 Hz
IML 2.02 Hz

ax=plotPerf(actreward,yl=(0,3.1))
savefig(gifpath()+'perf.png') # [[./gif/21apr27_21apr25_TARG0_K2_gcp__step_7_perf.png]]
this is not bad in beginning but high performance does not last as long as in the other sim
possibly due to lower firing rates (?) ... note that this sim has less noise

lfn = ['21apr22_TARG0_K_gcp__step_' + str(i) + '_' for i in range(20)]
for i in range(8): lfn.append('21apr25_TARG0_K2_gcp__step_'+str(i)+'_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr27_21apr25_TARG0_K2_gcp__step_7_perf_all_steps_so_far.png]]
this one not improving as much as I2 simulations above (or not at all?)
ylim((0.25,0.415))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21apr27_21apr25_TARG0_K2_gcp__step_7_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr27_21apr25_TARG0_K2_gcp__step_7_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr27_21apr25_TARG0_K2_gcp__step_7_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr27_21apr25_TARG0_K2_gcp__step_7_all_steps_avg_weight.png]]

this sim has a long way to go in terms of weights ... which means it could improve a lot more ... 

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr27_21apr25_TARG0_K2_gcp__step_7__with_reward_input.mp4]]

** check output from 21apr25_TARG0_I2_gcp__step_9_

looked like there was a period of hyperexcitability in step 9 and then
it went back to normal firing rates, but the performance degraded

python -i simdat.py backupcfg/21apr25_TARG0_I2_gcp__step_9_sim.json

EV1 0.02 Hz
EA 1.91 Hz
IA 3.59 Hz
IAL 4.83 Hz
EA2 0.9 Hz
IA2 3.33 Hz
IA2L 3.56 Hz
EMDOWN 10.78 Hz
EMUP 10.8 Hz
IM 11.52 Hz
IML 12.79 Hz

firing rates too high

ax=plotPerf(actreward,yl=(0,1.25))
savefig(gifpath()+'perf.png') # [[./gif/21apr27_21apr25_TARG0_I2_gcp__step_9_perf.png]]

lfn = ['21apr21_TARG0_I_gcp__step_' + str(i) + '_' for i in range(20)]
for i in range(10): lfn.append('21apr25_TARG0_I2_gcp__step_'+str(i)+'_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr27_21apr25_TARG0_I2_gcp__step_9_perf_all_steps_so_far.png]]
ylim((0.25,0.415))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21apr27_21apr25_TARG0_I2_gcp__step_9_perf_all_steps_so_farB.png]]
not sure improving anymore due to hyperexcit...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,4.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr27_21apr25_TARG0_I2_gcp__step_9_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr27_21apr25_TARG0_I2_gcp__step_9_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr27_21apr25_TARG0_I2_gcp__step_9_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr27_21apr25_TARG0_I2_gcp__step_9__with_reward_input.mp4]]

will stop this multistep sim since has reached hyperexcit ... 

will upload data to cycle and let K2 sim continue; 
in addition could try I2 with EIplast ... either from previous step(s) or from scratch ... 

** check output from 21apr25_TARG0_K2_gcp__step_9_

python -i simdat.py backupcfg/21apr25_TARG0_K2_gcp__step_9_sim.json

EV1 0.02 Hz
EA 0.42 Hz
IA 1.53 Hz
IAL 2.13 Hz
EA2 0.28 Hz
IA2 1.58 Hz
IA2L 2.06 Hz
EMDOWN 0.16 Hz
EMUP 0.16 Hz
IM 1.35 Hz
IML 2.03 Hz

ax=plotPerf(actreward,yl=(0,1.1))
savefig(gifpath()+'perf.png') # [[./gif/21apr27_21apr25_TARG0_K2_gcp__step_9_perf.png]]

lfn = ['21apr22_TARG0_K_gcp__step_' + str(i) + '_' for i in range(20)]
for i in range(10): lfn.append('21apr25_TARG0_K2_gcp__step_'+str(i)+'_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr27_21apr25_TARG0_K2_gcp__step_9_perf_all_steps_so_far.png]]
ylim((0.25,0.415))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21apr27_21apr25_TARG0_K2_gcp__step_9_perf_all_steps_so_farB.png]]
this one not making much progress...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr27_21apr25_TARG0_K2_gcp__step_9_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr27_21apr25_TARG0_K2_gcp__step_9_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr27_21apr25_TARG0_K2_gcp__step_9_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr27_21apr25_TARG0_K2_gcp__step_9__with_reward_input.mp4]]

** make an I3 sim -- with EIPlast?

hmm, adding new E->I plasticity might not work with current code ... ? 
looking at the code - should be possible to continue (resume sim to update the
weights, then continue forward using EIplast)

could use these as starting weights?
 data/21apr25_TARG0_I2_gcp__step_7_synWeights_final.pkl

but have to set the AMPAI weights carefully so they make sense ...wbase, wmax ...
also need the right rllenhebb and rlhebbwt ...RLlenhebb does not have to be same
value as for AMPA ...

cp backupcfg/21apr21_TARG0_I_gcp_sim.json sn.json
then adjust ...

    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/21apr25_TARG0_I2_gcp__step_7_synWeights_final.pkl"
    },
21apr27_TARG0_I3_gcp_

have setup AMPAI like this for now:
        "AMPAI": {
            "wbase": 0.4,
            "wmax": 6,
            "RLon": 1,
            "STDPon": 0,
            "RLlenhebb": 10000,
            "RLlenanti": 500,
            "useRLexp": 1,
            "RLhebbwt": 0.01,
            "RLantiwt": 0.0,
            "hebbwt": 0,
            "antiwt": 0,
            "tauhebb": 10,
            "tauanti": 10,
            "RLwindhebb": 50,
            "softthresh": 0,
            "verbose": 0,
            "maxreward": 0.0
        },
        "AMPA": {
            "wbase": 0.001,
            "wmax": 5,
            "RLon": 1,
            "STDPon": 0,
            "RLlenhebb": 10000,
            "RLlenanti": 500,
            "useRLexp": 1,
            "RLhebbwt": 0.01,
            "RLantiwt": 0,
            "hebbwt": 0.0,
            "antiwt": 0.0,
            "tauhebb": 10,
            "tauanti": 10,
            "RLwindhebb": 50,
            "softthresh": 0,
            "verbose": 0,
            "maxreward": 0.0
        },
so will use similar weight changes as AMPA ... because the network that resuming from is already
close to the point where it becomes hyperexcitable

(buffer=shell)

python multistepSim.py sn.json 30 20 21apr27_TARG0_I3_gcp_multi

started ~22:20 ...

* 21apr28
** check output from 21apr27_TARG0_I3_gcp__step_0_

python -i simdat.py backupcfg/21apr27_TARG0_I3_gcp__step_0_sim.json

EV1 0.02 Hz
EA 1.77 Hz
IA 3.32 Hz
IAL 4.8 Hz
EA2 0.54 Hz
IA2 1.83 Hz
IA2L 2.56 Hz
EMDOWN 0.93 Hz
EMUP 0.87 Hz
IM 3.28 Hz
IML 4.05 Hz

ax=plotPerf(actreward,yl=(0,3.1))
savefig(gifpath()+'perf.png') # [[./gif/21apr28_21apr27_TARG0_I3_gcp__step_0_perf.png]]

lfn = ['21apr21_TARG0_I_gcp__step_' + str(i) + '_' for i in range(20)]
for i in range(8): lfn.append('21apr25_TARG0_I2_gcp__step_'+str(i)+'_')
lfn.append('21apr27_TARG0_I3_gcp__step_0_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr28_21apr27_TARG0_I3_gcp__step_0_perf_all_steps_so_far.png]]
ylim((0.25,0.415))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21apr28_21apr27_TARG0_I3_gcp__step_0_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,4.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr28_21apr27_TARG0_I3_gcp__step_0_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr28_21apr27_TARG0_I3_gcp__step_0_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr28_21apr27_TARG0_I3_gcp__step_0_all_steps_avg_weight.png]]
ok, so the interneuron weights are increasing properly (note the 0 value is from before their weights were changing)

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)

hmm, had wrong losePoint value of -0.25; should be -0.2; will restart

and change name to 21apr28_TARG0_I3_gcp_

python multistepSim.py sn.json 30 20 21apr28_TARG0_I3_gcp_multi

started ~9:50 . . .

** check output from 21apr25_TARG0_K2_gcp__step_13_ -->> stopped: prog slow, perf decaying a bit

python -i simdat.py backupcfg/21apr25_TARG0_K2_gcp__step_13_sim.json

EV1 0.02 Hz
EA 0.42 Hz
IA 1.53 Hz
IAL 2.13 Hz
EA2 0.31 Hz
IA2 1.7 Hz
IA2L 2.13 Hz
EMDOWN 0.16 Hz
EMUP 0.16 Hz
IM 1.35 Hz
IML 2.03 Hz

ax=plotPerf(actreward,yl=(0,2.1))
savefig(gifpath()+'perf.png') # [[./gif/21apr28_21apr25_TARG0_K2_gcp__step_13_perf.png]]

lfn = ['21apr22_TARG0_K_gcp__step_' + str(i) + '_' for i in range(20)]
for i in range(14): lfn.append('21apr25_TARG0_K2_gcp__step_'+str(i)+'_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr28_21apr25_TARG0_K2_gcp__step_13_perf_all_steps_so_far.png]]
flat...or slightly decreasing
ylim((0.25,0.415))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21apr28_21apr25_TARG0_K2_gcp__step_13_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,4.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr28_21apr25_TARG0_K2_gcp__step_13_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr28_21apr25_TARG0_K2_gcp__step_13_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gifpath()+'all_steps_avg_weight.png']]

could continue some more but learning much slower than I,I2 model ..
stopped this ; last step completed was one 21apr25_TARG0_K2_gcp__step_13_

** other sim (21apr28_TARG0_L_gcp_) with lower noise (similar to 21apr22_TARG0_K_gcp_)

but with lower magnitude of losePoint (-0.1 instead of -0.2) so learning could progress more rapidly

cp backupcfg/21apr22_TARG0_K_gcp_sim.json sn.json

then adjust ...

could get rid of EA2, IA2, IA2L as well . . . ? ok - that way the EA2 weights wont have to start so high
and will run faster ... worth a try...

(buffer=s0)

python multistepSim.py sn.json 30 40 21apr28_TARG0_L_gcp_multi

started ~10:22 ...

** check output from 21apr28_TARG0_I3_gcp__step_0_

python -i simdat.py backupcfg/21apr28_TARG0_I3_gcp__step_0_sim.json

EV1 0.02 Hz
EA 1.75 Hz
IA 3.29 Hz
IAL 4.79 Hz
EA2 0.54 Hz
IA2 1.82 Hz
IA2L 2.57 Hz
EMDOWN 0.92 Hz
EMUP 0.86 Hz
IM 3.24 Hz
IML 4.03 Hz

ax=plotPerf(actreward,yl=(0,3.1))
savefig(gifpath()+'perf.png') # [[./gif/21apr28_21apr28_TARG0_I3_gcp__step_0_perf.png]]

lfn = ['21apr21_TARG0_I_gcp__step_' + str(i) + '_' for i in range(20)]
for i in range(8): lfn.append('21apr25_TARG0_I2_gcp__step_'+str(i)+'_')
lfn.append('21apr28_TARG0_I3_gcp__step_0_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr28_21apr28_TARG0_I3_gcp__step_0_perf_all_steps_so_far.png]]
ylim((0.25,0.415))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21apr28_21apr28_TARG0_I3_gcp__step_0_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,4.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr28_21apr28_TARG0_I3_gcp__step_0_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr28_21apr28_TARG0_I3_gcp__step_0_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr28_21apr28_TARG0_I3_gcp__step_0_all_steps_avg_weight.png]]
ok...weight to I increasing ...

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21apr28_21apr28_TARG0_I3_gcp__step_0__with_reward_input.mp4]]

** check output from 21apr28_TARG0_L_gcp__step_1_ 

python -i simdat.py backupcfg/21apr28_TARG0_L_gcp__step_1_sim.json

EV1 0.02 Hz
EA 0.42 Hz
IA 1.54 Hz
IAL 2.14 Hz
EMDOWN 0.14 Hz
EMUP 0.14 Hz
IM 1.31 Hz
IML 1.98 Hz

ax=plotPerf(actreward,yl=(0,1.1))
savefig(gifpath()+'perf.png') # [[./gif/21apr28_21apr28_TARG0_L_gcp__step_1_perf.png]]

lfn = ['21apr28_TARG0_L_gcp__step_' + str(i) + '_' for i in range(2)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr28_21apr28_TARG0_L_gcp__step_1_perf_all_steps_so_far.png]]
increasing ... 

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr28_21apr28_TARG0_L_gcp__step_1_perf_compareD.png]]
hmm ... not clear ... strange that first two trajectories are almost the same

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr28_21apr28_TARG0_L_gcp__step_1_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr28_21apr28_TARG0_L_gcp__step_1_all_steps_avg_weight.png]]
as before, with the other low noise sims, the weights for EMDOWN,EMUP are only changing very slowly...

* 21apr29
** check output from 21apr28_TARG0_I3_gcp__step_2_

python -i simdat.py backupcfg/21apr28_TARG0_I3_gcp__step_2_sim.json

EV1 0.02 Hz
EA 2.0 Hz
IA 4.24 Hz
IAL 6.38 Hz
EA2 1.17 Hz
IA2 4.9 Hz
IA2L 4.98 Hz
EMDOWN 30.12 Hz
EMUP 30.46 Hz
IM 21.63 Hz
IML 23.6 Hz

model has become hyperexcitable

ax=plotPerf(actreward,yl=(0,0.75))
savefig(gifpath()+'perf.png') # [[./gif/21apr29_21apr28_TARG0_I3_gcp__step_2_perf.png]]

lfn = ['21apr21_TARG0_I_gcp__step_' + str(i) + '_' for i in range(20)]
for i in range(8): lfn.append('21apr25_TARG0_I2_gcp__step_'+str(i)+'_')
for i in range(3): lfn.append('21apr28_TARG0_I3_gcp__step_'+str(i)+'_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr29_21apr28_TARG0_I3_gcp__step_2_perf_all_steps_so_far.png]]
ylim((0.25,0.415))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21apr29_21apr28_TARG0_I3_gcp__step_2_perf_all_steps_so_farB.png]]
note the drop at the end

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,4.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr29_21apr28_TARG0_I3_gcp__step_2_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr29_21apr28_TARG0_I3_gcp__step_2_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr29_21apr28_TARG0_I3_gcp__step_2_all_steps_avg_weight.png]]

stopped this sim due to hyperexcitability ... may want to start it from scratch using the EIplast ... 
or increase the magnitude of E -> I plasticity ... 

** check output from 21apr28_TARG0_L_gcp__step_9_ 

python -i simdat.py backupcfg/21apr28_TARG0_L_gcp__step_9_sim.json

EV1 0.02 Hz
EA 0.41 Hz
IA 1.52 Hz
IAL 2.12 Hz
EMDOWN 0.14 Hz
EMUP 0.14 Hz
IM 1.31 Hz
IML 1.99 Hz

ax=plotPerf(actreward,yl=(0,1.1))
savefig(gifpath()+'perf.png') # [[./gif/21apr29_21apr28_TARG0_L_gcp__step_9_perf.png]]

lfn = ['21apr28_TARG0_L_gcp__step_' + str(i) + '_' for i in range(10)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr29_21apr28_TARG0_L_gcp__step_9_perf_all_steps_so_far.png]]
this one seems not be be improving ... decaying

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr29_21apr28_TARG0_L_gcp__step_9_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr29_21apr28_TARG0_L_gcp__step_9_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') 
[[./gif/21apr29_21apr28_TARG0_L_gcp__step_9_all_steps_avg_weight.png]]
weights are clearly increasing ... but performance - not yet

** 21apr29_TARG0_I3_EIPlast_gcp_

same params as 21apr21_TARG0_I_gcp_ but also include EIPlast ... 
so basically same params as 21apr28_TARG0_I3_gcp__ but starting over (without resumesim)
since starting from scratch can reduce the amount of EIplast so dont end up causing dep blockade in interneurons

cp backupcfg/21apr27_TARG0_I3_gcp_sim.json sn.json

and then make modifications ... losePoint at -0.2

for AMPAI will have RLhebbwt at 0.001 and RLlenhebb at 500
(AMPA has RLhebbwt of 0.01 and RLlenhebb at 10000)
that way inhibition wont grow too quickly ... (higher firing rates of interneurons with some minor
EIPlast may be enough to prevent hyperexcitability and extend time that learning can take place over ... )

hmm...may instead resume from 21apr25_TARG0_I2_gcp__step_3_ (previously had resumed 4 steps later when the
weights were a little higher) ... maybe that will be enough to prevent hyperexcit ... 

    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/21apr25_TARG0_I2_gcp__step_3_synWeights_final.pkl"
    },

python multistepSim.py sn.json 30 40 21apr29_TARG0_I3_gcp_multi

started ~11:41 ...

(buffer=shell)

** stopped 21apr28_TARG0_L_gcp_

not improving quickly enough ... hopefully 21apr29_TARG0_I3_gcp_ will improve further

** also start 21apr29_TARG0_J_EIPlast_gcp_

this will use same params as 21apr29_TARG0_I3_gcp_ but will start from scratch

python multistepSim.py sn.json 30 40 21apr29_TARG0_J_EIPlast_gcp_multi

started ~11:49 ...

* 21apr30
** check output from 21apr29_TARG0_I3_EIPlast_gcp__step_3_

python -i simdat.py backupcfg/21apr29_TARG0_I3_EIPlast_gcp__step_3_sim.json

EV1 0.02 Hz
EA 1.78 Hz
IA 3.3 Hz
IAL 4.62 Hz
EA2 0.48 Hz
IA2 1.73 Hz
IA2L 2.43 Hz
EMDOWN 0.76 Hz
EMUP 0.71 Hz
IM 2.64 Hz
IML 3.49 Hz

ax=plotPerf(actreward,yl=(0,1.1))
savefig(gifpath()+'perf.png') # [[./gif/21apr30_21apr29_TARG0_I3_EIPlast_gcp__step_3_perf.png]]

lfn = ['21apr21_TARG0_I_gcp__step_' + str(i) + '_' for i in range(20)]
for i in range(4): lfn.append('21apr25_TARG0_I2_gcp__step_'+str(i)+'_')
for i in range(4): lfn.append('21apr29_TARG0_I3_EIPlast_gcp__step_'+str(i)+'_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr30_21apr29_TARG0_I3_EIPlast_gcp__step_3_perf_all_steps_so_far.png]]
ylim((0.25,0.415))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21apr30_21apr29_TARG0_I3_EIPlast_gcp__step_3_perf_all_steps_so_farB.png]]
looks like performance is decaying ... maybe too much EIPlast ... 

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,4.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr30_21apr29_TARG0_I3_EIPlast_gcp__step_3_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr30_21apr29_TARG0_I3_EIPlast_gcp__step_3_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr30_21apr29_TARG0_I3_EIPlast_gcp__step_3_all_steps_avg_weight.png]]
savefig(gifpath()+'all_steps_avg_weightB.png') # [[./gif/21apr30_21apr29_TARG0_I3_EIPlast_gcp__step_3_all_steps_avg_weightB.png]]
so E -> I weights are increasing...pretty slowly...maybe too slowly

** check output from 21apr29_TARG0_J_EIPlast_gcp__step_3_

python -i simdat.py backupcfg/21apr29_TARG0_J_EIPlast_gcp__step_3_sim.json

EV1 0.02 Hz
EA 1.71 Hz
IA 3.19 Hz
IAL 4.32 Hz
EA2 0.12 Hz
IA2 1.21 Hz
IA2L 1.74 Hz
EMDOWN 0.22 Hz
EMUP 0.21 Hz
IM 1.43 Hz
IML 2.13 Hz

ax=plotPerf(actreward,yl=(0,.81))
savefig(gifpath()+'perf.png') # [[./gif/21apr30_21apr29_TARG0_J_EIPlast_gcp__step_3_perf.png]]

lfn = ['21apr29_TARG0_J_EIPlast_gcp__step_' + str(i) + '_' for i in range(4)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.81))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr30_21apr29_TARG0_J_EIPlast_gcp__step_3_perf_all_steps_so_far.png]]
looks like decaying...?

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr30_21apr29_TARG0_J_EIPlast_gcp__step_3_perf_compareD.png]]
well, need more time to see...

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr30_21apr29_TARG0_J_EIPlast_gcp__step_3_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr30_21apr29_TARG0_J_EIPlast_gcp__step_3_all_steps_avg_weight.png]]

E -> I weights changing slowly ... may need more time to see if helps

** stopped 21apr29_TARG0_I3_EIPlast_gcp_

firing rates of E neurons were getting too high

will try another sim with higher AMPAI to prevent hyperexcitability ... 

** 21apr30_TARG0_I3_EIPlast_gcp_  , same as 21apr29_TARG0_I3_EIPlast_gcp_ but with higher AMPAI

        "name": "21apr30_TARG0_I3_EIPlast_gcp_",
    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/21apr25_TARG0_I2_gcp__step_3_synWeights_final.pkl"
    },

        "AMPAI": {
            "wbase": 0.4,
            "wmax": 6,
            "RLon": 1,
            "STDPon": 0,
            "RLlenhebb": 1000,
            "RLlenanti": 1000,
            "useRLexp": 1,
            "RLhebbwt": 0.01,
            "RLantiwt": 0.0,
            "hebbwt": 0,
            "antiwt": 0,
            "tauhebb": 10,
            "tauanti": 10,
            "RLwindhebb": 50,
            "softthresh": 0,
            "verbose": 0,
            "maxreward": 0.0
        },

python multistepSim.py sn.json 30 40 21apr30_TARG0_I3_EIPlast_gcp_multi

started ~13:44 ...

** check output from 21apr30_TARG0_I3_EIPlast_gcp__step_0_ -->> maybe back to improving?

python -i simdat.py backupcfg/21apr30_TARG0_I3_EIPlast_gcp__step_0_sim.json

EV1 0.02 Hz
EA 1.82 Hz
IA 3.37 Hz
IAL 4.7 Hz
EA2 0.34 Hz
IA2 1.51 Hz
IA2L 2.16 Hz
EMDOWN 0.51 Hz
EMUP 0.49 Hz
IM 1.98 Hz
IML 2.84 Hz

ax=plotPerf(actreward,yl=(0,1.1))
savefig(gifpath()+'perf.png') # [[./gif/21may1_21apr30_TARG0_I3_EIPlast_gcp__step_0_perf.png]]

lfn = ['21apr21_TARG0_I_gcp__step_' + str(i) + '_' for i in range(20)]
for i in range(4): lfn.append('21apr25_TARG0_I2_gcp__step_'+str(i)+'_')
for i in range(1): lfn.append('21apr30_TARG0_I3_EIPlast_gcp__step_'+str(i)+'_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may1_21apr30_TARG0_I3_EIPlast_gcp__step_0_perf_all_steps_so_far.png]]
ylim((0.25,0.4))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21may1_21apr30_TARG0_I3_EIPlast_gcp__step_0_perf_all_steps_so_farB.png]]
may be improving again now ... ? 

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,4.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may1_21apr30_TARG0_I3_EIPlast_gcp__step_0_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may1_21apr30_TARG0_I3_EIPlast_gcp__step_0_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may1_21apr30_TARG0_I3_EIPlast_gcp__step_0_all_steps_avg_weight.png]]
savefig(gifpath()+'all_steps_avg_weightB.png') # [[./gif/21may1_21apr30_TARG0_I3_EIPlast_gcp__step_0_all_steps_avg_weightB.png]]

it does look like the weights to interneurons are increasing more now ... so that may allow the network
to learn further ... need at least a few more steps to see...

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may1_21apr30_TARG0_I3_EIPlast_gcp__step_0__with_reward_input.mp4]]

** check output from 21apr29_TARG0_J_EIPlast_gcp__step_5_

python -i simdat.py backupcfg/21apr29_TARG0_J_EIPlast_gcp__step_5_sim.json

EV1 0.02 Hz
EA 1.7 Hz
IA 3.18 Hz
IAL 4.32 Hz
EA2 0.12 Hz
IA2 1.22 Hz
IA2L 1.75 Hz
EMDOWN 0.22 Hz
EMUP 0.22 Hz
IM 1.44 Hz
IML 2.15 Hz

ax=plotPerf(actreward,yl=(0,.81))
savefig(gifpath()+'perf.png') # [[./gif/21apr30_21apr29_TARG0_J_EIPlast_gcp__step_5_perf.png]]

lfn = ['21apr29_TARG0_J_EIPlast_gcp__step_' + str(i) + '_' for i in range(6)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.81))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21apr30_21apr29_TARG0_J_EIPlast_gcp__step_5_perf_all_steps_so_far.png]]
yeah, looks like decaying...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21apr30_21apr29_TARG0_J_EIPlast_gcp__step_5_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21apr30_21apr29_TARG0_J_EIPlast_gcp__step_5_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21apr30_21apr29_TARG0_J_EIPlast_gcp__step_5_all_steps_avg_weight.png]]

* 21may3
** check output from 21apr30_TARG0_I3_EIPlast_gcp__step_10_

python -i simdat.py backupcfg/21apr30_TARG0_I3_EIPlast_gcp__step_10_sim.json

EV1 0.02 Hz
EA 1.95 Hz
IA 4.14 Hz
IAL 6.72 Hz
EA2 1.2 Hz
IA2 4.77 Hz
IA2L 4.57 Hz
EMDOWN 25.31 Hz
EMUP 25.51 Hz
IM 24.58 Hz
IML 27.66 Hz

ax=plotPerf(actreward,yl=(0,1.1)) 
savefig(gifpath()+'perf.png') # [[./gif/21may3_21apr30_TARG0_I3_EIPlast_gcp__step_10_perf.png]]

lfn = ['21apr21_TARG0_I_gcp__step_' + str(i) + '_' for i in range(20)]
for i in range(4): lfn.append('21apr25_TARG0_I2_gcp__step_'+str(i)+'_')
for i in range(11): lfn.append('21apr30_TARG0_I3_EIPlast_gcp__step_'+str(i)+'_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may3_21apr30_TARG0_I3_EIPlast_gcp__step_10_perf_all_steps_so_far.png]]
ylim((0.25,0.4))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21may3_21apr30_TARG0_I3_EIPlast_gcp__step_10_perf_all_steps_so_farB.png]]

so it increased for a while after the inclusion of EIPlast but then started to decay ... due to hyperexcit

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,4.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may3_21apr30_TARG0_I3_EIPlast_gcp__step_10_perf_compareD.png]]
not sure any step better than 21apr25_TARG0_I2_gcp__step3_

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may3_21apr30_TARG0_I3_EIPlast_gcp__step_10_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may3_21apr30_TARG0_I3_EIPlast_gcp__step_10_all_steps_avg_weight.png]]

may as well stop this multistep sim -- became epileptic...? but in the currently running sim the rates seem
ok - sometimes - may oscillate between normal and epileptic dynamics, as the E->E and E->I weights change

stopped this one ... 

** check output from 21apr29_TARG0_J_EIPlast_gcp__step_14_

python -i simdat.py backupcfg/21apr29_TARG0_J_EIPlast_gcp__step_14_sim.json

EV1 0.02 Hz
EA 1.74 Hz
IA 3.26 Hz
IAL 4.5 Hz
EA2 0.17 Hz
IA2 1.28 Hz
IA2L 1.86 Hz
EMDOWN 0.28 Hz
EMUP 0.28 Hz
IM 1.54 Hz
IML 2.27 Hz

ax=plotPerf(actreward,yl=(0,0.71))
savefig(gifpath()+'perf.png') # [[./gif/21may3_21apr29_TARG0_J_EIPlast_gcp__step_14_perf.png]]

lfn = ['21apr29_TARG0_J_EIPlast_gcp__step_' + str(i) + '_' for i in range(15)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.81))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may3_21apr29_TARG0_J_EIPlast_gcp__step_14_perf_all_steps_so_far.png]]
ylim((.34,.42))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21may3_21apr29_TARG0_J_EIPlast_gcp__step_14_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may3_21apr29_TARG0_J_EIPlast_gcp__step_14_perf_compareD.png]]
step 11 looks best so far but the perf goes up and down with diff steps ... not clear it's moving
in right direction overall

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may3_21apr29_TARG0_J_EIPlast_gcp__step_14_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may3_21apr29_TARG0_J_EIPlast_gcp__step_14_all_steps_avg_weight.png]]

** discussion with MD & HA

altered actor/critic , TD learning as a network (rather than fixed external reward signal)

weights going up too much is also a problem in DL, sometimes use regularization (higher weight values contribute to loss)
or other  adjusmtents to keep them in bounds

different learning rates (lower in early layers, higher in deeper layers)

try first a simpler task - e.g. lunar lander (stateful - do not have to deal with all the visual feature
processing, just get handed the state vector and use it to learn a behavior/policy)

even DL takes a long time to train to good performance levels, so should not expect great
performance on our models with shorter training

** new sim 21may3_TARG0_N_gcp_

higher density of connections from EV1 to EA, from EA to EA2, from EA to EM

no noise to EA

non targetted 

no EIPlast ... 

python -i simdat.py backupcfg/21may3_TARG0_N_gcp_sim.json

ok, start a multistep ...

python multistepSim.py sn.json 30 40 21may3_TARG0_N_gcp_multi

started ~14:15 ...

** why does performance always decay in 2nd half of simulation?

is it random that hits ball in beginning ... or inputs/netstims not providing enough activation
as simulation progresses? or some other time constant involved?

python -i simdat.py backupcfg/21apr25_TARG0_I2_gcp__step_3_sim.json

EV1 0.02 Hz
EA 1.86 Hz
IA 3.35 Hz
IAL 4.7 Hz
EA2 0.32 Hz
IA2 1.47 Hz
IA2L 2.11 Hz
EMDOWN 0.49 Hz
EMUP 0.47 Hz
IM 1.9 Hz
IML 2.75 Hz

binsz = 1000
dnspk = {pop:getspikehist(dspkT[pop],dnumc[pop],binsz,totalDur) for pop in ['EV1','EA','EA2','EMDOWN','EMUP']}
for clr,pop in zip(['r','b','g','c','m'],['EV1','EA','EA2','EMDOWN','EMUP']): plot(dnspk[pop][0],dnspk[pop][1],clr)
xlim((0,totalDur)); ylim((0,3))

savefig(gifpath()+'firing_rates.png')
[[./gif/21may3_21apr25_TARG0_I2_gcp__step_3_firing_rates.png]]
rates look ~stable

ax=plotPerf(actreward,yl=(0,4.1))
savefig(gifpath()+'firing_ratesB.png') 
[[./gif/21may3_21apr25_TARG0_I2_gcp__step_3_firing_ratesB.png]]

could the initialization when there's a highly synchronous activation provide some benefit for network dynamics??

* 21may4
** check output from 21may3_TARG0_N_gcp__step_2_

python -i simdat.py backupcfg/21may3_TARG0_N_gcp__step_2_sim.json

EV1 0.02 Hz
EA 1.12 Hz
IA 2.54 Hz
IAL 3.3 Hz
EA2 0.18 Hz
IA2 1.27 Hz
IA2L 1.82 Hz
EMDOWN 0.26 Hz
EMUP 0.27 Hz
IM 1.55 Hz
IML 2.31 Hz

ax=plotPerf(actreward,yl=(0,1.1))
savefig(gifpath()+'perf.png') # [[./gif/21may4_21may3_TARG0_N_gcp__step_2_perf.png]]

lfn = ['21may3_TARG0_N_gcp__step_' + str(i) + '_' for i in range(3)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.81))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gifpath()+'perf_all_steps_so_far.png']]
this one worse than other recent sims...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may4_21may3_TARG0_N_gcp__step_2_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may4_21may3_TARG0_N_gcp__step_2_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may4_21may3_TARG0_N_gcp__step_2_all_steps_avg_weight.png]]

may need more activation in network...particularly for EV1 which had lower input weights from VL due
to higher convergence...

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may4_21may3_TARG0_N_gcp__step_2__with_reward_input.mp4]]

** check output from 21apr29_TARG0_J_EIPlast_gcp__step_18_

python -i simdat.py backupcfg/21apr29_TARG0_J_EIPlast_gcp__step_18_sim.json

EV1 0.02 Hz
EA 1.79 Hz
IA 3.33 Hz
IAL 4.64 Hz
EA2 0.21 Hz
IA2 1.32 Hz
IA2L 1.92 Hz
EMDOWN 0.33 Hz
EMUP 0.33 Hz
IM 1.62 Hz
IML 2.38 Hz

ax=plotPerf(actreward,yl=(0,1.505))
savefig(gifpath()+'perf.png') # [[./gif/21may4_21apr29_TARG0_J_EIPlast_gcp__step_18_perf.png]]

lfn = ['21apr29_TARG0_J_EIPlast_gcp__step_' + str(i) + '_' for i in range(19)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.81))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may4_21apr29_TARG0_J_EIPlast_gcp__step_18_perf_all_steps_so_far.png]]
ylim((.34,.42))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21may4_21apr29_TARG0_J_EIPlast_gcp__step_18_perf_all_steps_so_farB.png]]
perf may be going up slowly

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,3.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may4_21apr29_TARG0_J_EIPlast_gcp__step_18_perf_compareD.png]]
step 15 or 16 llook better than this latest step...

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may4_21apr29_TARG0_J_EIPlast_gcp__step_18_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may4_21apr29_TARG0_J_EIPlast_gcp__step_18_all_steps_avg_weight.png]]

python -i simdat.py backupcfg/21apr29_TARG0_J_EIPlast_gcp__step_16_sim.json

ax=plotPerf(actreward,yl=(0,2.1))
savefig(gifpath()+'perf.png') # [[./gif/21may4_21apr29_TARG0_J_EIPlast_gcp__step_16_perf.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may4_21apr29_TARG0_J_EIPlast_gcp__step_16__with_reward_input.mp4]]

** stop 21may3_TARG0_N_gcp_ -- probably need higher weight from VL -> EA
** updated sim for 21may4_TARG0_O_gcp_

increased number of VL -> EA (3200 vs last one which was 1600) but decreased
the weights (removed VL -> EA NMDA) to prevent hyperexcit; this way less likely
that the important visual info is not propagating in network

VL -> EA weights are static for now

also change losePoint from -0.2 to -0.15

python multistepSim.py sn.json 30 40 21may4_TARG0_O_gcp_multi

started ~11:52 ...

** check output from 21may4_TARG0_O_gcp__step_0_

python -i simdat.py backupcfg/21may4_TARG0_O_gcp__step_0_sim.json

EV1 0.02 Hz
EA 0.59 Hz
IA 1.84 Hz
IAL 2.44 Hz
EA2 0.12 Hz
IA2 1.21 Hz
IA2L 1.72 Hz
EMDOWN 0.18 Hz
EMUP 0.18 Hz
IM 1.4 Hz
IML 2.12 Hz

ax=plotPerf(actreward,yl=(0,1.01))
savefig(gifpath()+'perf.png') # [[./gif/21may5_21may4_TARG0_O_gcp__step_0_perf.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may5_21may4_TARG0_O_gcp__step_0_rast.png]]

clf(); pdfc = pdf
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'avg_weight.png') # [[./gif/21may5_21may4_TARG0_O_gcp__step_0_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may5_21may4_TARG0_O_gcp__step_0__with_reward_input.mp4]]
** stopped 21apr29_TARG0_J_EIPlast_gcp_

did not seem to be improving much ... 

** next updated sim 21may4_TARG0_P_gcp_

include plasticity from VL -> EA, EA2, EM

        "RLconns": {
            "EIPlast": 0,
            "Visual": 0,
            "RecurrentDirNeurons": 0,
            "RecurrentLocNeurons": 0,
            "FeedForwardDirNtoA": 0,
            "FeedForwardLocNtoA": 1,
            "FeedForwardDirNtoA2": 0,
            "FeedForwardLocNtoA2": 1,	    
            "FeedForwardDirNtoM": 0,
            "FeedForwardLocNtoM": 1,
            "FeedForwardAtoM": 1,
            "FeedForwardAtoA2": 1,
            "FeedForwardA2toM": 1,
            "FeedbackLocNeurons": 0,
            "RecurrentMNeurons": 1,
            "RecurrentANeurons": 1,
            "RecurrentA2Neurons": 1,
            "FeedbackAtoDirN": 0,
            "FeedbackAtoLocN": 0,
	    "FeedbackMtoA": 1,
	    "FeedbackMtoA2": 1,
	    "FeedbackA2toA": 1
        },

since those extra RL synapse connections take more time to calc
while allowing more flexibility will keep the older conv of VL -> EA of 640
not sure helpful to have potentially ambiguous (from perspective of decision/behavior)
information from VL -> EA but keeping the weights fixed is also not ideal . . . 

also had to set wmax for RL synapses higher to 25 (since VL -> EA AM weight starts at 12.5);
most weights will not get that high . . . 

python multistepSim.py sn.json 30 40 21may4_TARG0_P_gcp_multi

started ~23:51 ...

* 21may5
** check output from 21may4_TARG0_O_gcp__step_3_

python -i simdat.py backupcfg/21may4_TARG0_O_gcp__step_3_sim.json

EV1 0.02 Hz
EA 0.56 Hz
IA 1.79 Hz
IAL 2.38 Hz
EA2 0.12 Hz
IA2 1.22 Hz
IA2L 1.72 Hz
EMDOWN 0.18 Hz
EMUP 0.18 Hz
IM 1.42 Hz
IML 2.13 Hz

ax=plotPerf(actreward,yl=(0,1.01))
savefig(gifpath()+'perf.png') # [[./gif/21may5_21may4_TARG0_O_gcp__step_3_perf.png]]

lfn = ['21may4_TARG0_O_gcp__step_' + str(i) + '_' for i in range(4)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.81))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may5_21may4_TARG0_O_gcp__step_3_perf_all_steps_so_far.png]]
perf fluctuating ... 

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may5_21may4_TARG0_O_gcp__step_3_perf_compareD.png]]
step 2 best so far ... look at that one's raster/animation...

python -i simdat.py backupcfg/21may4_TARG0_O_gcp__step_2_sim.json

EV1 0.02 Hz
EA 0.58 Hz
IA 1.84 Hz
IAL 2.43 Hz
EA2 0.12 Hz
IA2 1.22 Hz
IA2L 1.73 Hz
EMDOWN 0.18 Hz
EMUP 0.19 Hz
IM 1.42 Hz
IML 2.14 Hz

ax=plotPerf(actreward,yl=(0,1.01))
savefig(gifpath()+'perf.png') # [[./gif/21may5_21may4_TARG0_O_gcp__step_2_perf.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may5_21may4_TARG0_O_gcp__step_2_rast.png]]
EA activity looks a little sparse ... partly because of increased number of inputs from VL->EA (3200) had to reduce
the weight  VL->EA to 5.5 AM2 weight, and removed  NMDA on that connection
and input weightvar of 0.5 with AM2 range of weights in (5.5-.5*5.5, 5.5+.5*5.5); no plasticity on the VL->EA
connection either ... could increase weights from VL->EA but dont want to lead to hyperexcitability...

lfn = ['21may4_TARG0_O_gcp__step_' + str(i) + '_' for i in range(4)]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may5_21may4_TARG0_O_gcp__step_2_all_steps_avg_weight.png]]
weight values increasing ... may need more time ... (as usual)

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may5_21may4_TARG0_O_gcp__step_2__with_reward_input.mp4]]

** 21may4_TARG0_P_gcp_ very slow almost 12 hours for 500 s

main computational cost is number of RL synapses, which is much higher in this sim 
since VL -> EA plastic

stopped for now ... adjust

** 21may5_TARG0_Q_gcp_

ok, cutting down the size of network to allow faster/longer sims with these
longer time constants ...

EA, EA2, EM all down to 100 with corresponding number of I, IL in each pop
increased VL -> EA conv from 640 to 1280 but kept weights same
also increased EA -> EA weights so dont start so low (to same values as EM->EM weights)

python multistepSim.py sn.json 30 40 21may4_TARG0_Q_gcp_multi

started ~12:05 ...

** stopped 21may4_TARG0_O_gcp_ -- may as well just run smaller network(s) for now
** check 21may5_TARG0_Q_gcp__step_10_ -->> some perf good but bursty/hyperxcit periodically->stop

python -i simdat.py backupcfg/21may5_TARG0_Q_gcp__step_10_sim.json

EV1 0.02 Hz
EA 1.92 Hz
IA 5.2 Hz
IAL 4.4 Hz
EA2 0.83 Hz
IA2 3.4 Hz
IA2L 3.28 Hz
EMDOWN 6.31 Hz
EMUP 6.31 Hz
IM 12.08 Hz
IML 15.33 Hz

ax=plotPerf(actreward,yl=(0,1.41))
savefig(gifpath()+'perf.png') # [[./gif/21may6_21may5_TARG0_Q_gcp__step_10_perf.png]]

rates are high but perf looks decent...

lfn = ['21may5_TARG0_Q_gcp__step_' + str(i) + '_' for i in range(11)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.81))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may6_21may5_TARG0_Q_gcp__step_10_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.41),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may6_21may5_TARG0_Q_gcp__step_10_perf_compareD.png]]

initial period has high perf but then decays as sim progresses - similar pattern seen before

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may6_21may5_TARG0_Q_gcp__step_10_rast.png]]
savefig(gifpath()+'rastB.png') # [[./gif/21may6_21may5_TARG0_Q_gcp__step_10_rastB.png]]

activity is too bursty - silent periods alternating with hyperexcitable activity ...
so should stop this simulation and perhaps restart with EIPlast ... or higher magnitude of losePoint

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may6_21may5_TARG0_Q_gcp__step_10_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may6_21may5_TARG0_Q_gcp__step_10__with_reward_input.mp4]]

** 21may5_TARG0_R_gcp_ -->> hyperexcitable after a few steps

same as 21may5_TARG0_Q_gcp_ except turned off inhib noise to EA2, EMDOWN, EMUP

in 5 s sim the rates of EA were ~2.8 Hz, EA2 and EM were ~1 Hz

this net may get to hyperexcit faster ... but balance of dynamics will lean a little
closer to intrinsic activity ... if hyperexcit emerges can reduce the excitatory noise 
or increase magnitude of losePoint

python multistepSim.py sn.json 30 40 21may4_TARG0_R_gcp_multi

started ~16:39 ... 

*** check output -->> even more hyperexcitable

python -i simdat.py backupcfg/21may5_TARG0_R_gcp__step_4_sim.json

EV1 0.02 Hz
EA 3.31 Hz
IA 10.3 Hz
IAL 6.88 Hz
EA2 5.13 Hz
IA2 24.5 Hz
IA2L 15.95 Hz
EMDOWN 91.93 Hz
EMUP 92.1 Hz
IM 82.57 Hz
IML 102.74 Hz

this sim is even more hyperexcitable ... due to no inhib noise

ax=plotPerf(actreward,yl=(0,1.01))
savefig(gifpath()+'perf.png') # [[./gif/21may6_21may5_TARG0_R_gcp__step_4_perf.png]]
and perf a lower

lfn = ['21may5_TARG0_R_gcp__step_' + str(i) + '_' for i in range(5)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,.81))
savefig(gifpath()+'perf_all_steps_so_far.png')
[[./gif/21may6_21may5_TARG0_R_gcp__step_4_perf_all_steps_so_far.png]]
time to stop this one too...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.41),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may6_21may5_TARG0_R_gcp__step_4_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may6_21may5_TARG0_R_gcp__step_4_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may6_21may5_TARG0_R_gcp__step_4_all_steps_avg_weight.png]]

** 21may5_TARG0_S_gcp_

same as 21may5_TARG0_Q_gcp_ but has higher magnitude for losePoint (-0.25 instead of -0.15)

(buffer=shell)
python multistepSim.py sn.json 30 40 21may5_TARG0_S_gcp_multi

started ~22:52 ...

** 21may5_TARG0_T_gcp_

same as 21may5_TARG0_Q_gcp_ but include EIPlast and losePoint of -0.25

(buffer=s0)
python multistepSim.py sn.json 30 40 21may5_TARG0_T_gcp_multi

started ~22:55 ...

* 21may6
** check 21may5_TARG0_S_gcp__step_12_

python -i simdat.py backupcfg/21may5_TARG0_S_gcp__step_12_sim.json

EV1 0.02 Hz
EA 1.71 Hz
IA 4.44 Hz
IAL 3.93 Hz
EA2 0.31 Hz
IA2 1.46 Hz
IA2L 2.07 Hz
EMDOWN 0.35 Hz
EMUP 0.34 Hz
IM 2.1 Hz
IML 2.55 Hz

rates all decent...

ax=plotPerf(actreward,yl=(0,0.66))
savefig(gifpath()+'perf.png') # [[./gif/21may6_21may5_TARG0_S_gcp__step_12_perf.png]]

lfn = ['21may5_TARG0_S_gcp__step_' + str(i) + '_' for i in range(13)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.1,.51))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may6_21may5_TARG0_S_gcp__step_12_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.51),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may6_21may5_TARG0_S_gcp__step_12_perf_compareD.png]]

step 7 best so far?

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may6_21may5_TARG0_S_gcp__step_12_rast.png]]
savefig(gifpath()+'rastB.png') # [[./gif/21may6_21may5_TARG0_S_gcp__step_12_rastB.png]]
some of the activity is still a little sparse...

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may6_21may5_TARG0_S_gcp__step_12_all_steps_avg_weight.png]]

may want to slow down learning rate (RLhebbwt) with each step ... maybe by 1-5%
that could be another way to prevent hyperexcit and convergence...

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may6_21may5_TARG0_S_gcp__step_12__with_reward_input.mp4]]

** check 21may5_TARG0_T_gcp__step_9_

python -i simdat.py backupcfg/21may5_TARG0_T_gcp__step_9_sim.json

EV1 0.02 Hz
EA 1.78 Hz
IA 5.25 Hz
IAL 4.51 Hz
EA2 0.2 Hz
IA2 1.29 Hz
IA2L 1.87 Hz
EMDOWN 0.23 Hz
EMUP 0.23 Hz
IM 1.57 Hz
IML 2.21 Hz

rates ok - a bit sparse

ax=plotPerf(actreward,yl=(0,0.66))
savefig(gifpath()+'perf.png') # [[./gif/21may6_21may5_TARG0_T_gcp__step_9_perf.png]]

lfn = ['21may5_TARG0_T_gcp__step_' + str(i) + '_' for i in range(10)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.1,.51))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may6_21may5_TARG0_T_gcp__step_9_perf_all_steps_so_far.png]]
looks like improving...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may6_21may5_TARG0_T_gcp__step_9_perf_compareD.png]]
or not...?

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may6_21may5_TARG0_T_gcp__step_9_rast.png]]
savefig(gifpath()+'rastB.png') # [[./gif/21may6_21may5_TARG0_T_gcp__step_9_rastB.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may6_21may5_TARG0_T_gcp__step_9_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may6_21may5_TARG0_T_gcp__step_9__with_reward_input.mp4]]

will let it run some more ... 

** check 21may5_TARG0_S_gcp__step_16_ -->> got hyperexcitable

python -i simdat.py backupcfg/21may5_TARG0_S_gcp__step_16_sim.json

EV1 0.02 Hz
EA 2.02 Hz
IA 5.72 Hz
IAL 4.63 Hz
EA2 1.05 Hz
IA2 4.51 Hz
IA2L 3.91 Hz
EMDOWN 8.72 Hz
EMUP 8.7 Hz
IM 15.2 Hz
IML 19.94 Hz

now reached hyperexcitability ... 

ax=plotPerf(actreward,yl=(0,0.66))
savefig(gifpath()+'perf.png') # [[./gif/21may6_21may5_TARG0_S_gcp__step_16_perf.png]]

lfn = ['21may5_TARG0_S_gcp__step_' + str(i) + '_' for i in range(17)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.1,.51))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may6_21may5_TARG0_S_gcp__step_16_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.51),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may6_21may5_TARG0_S_gcp__step_16_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may6_21may5_TARG0_S_gcp__step_16_rast.png]]

yeah, hyperexcit seen in bursts ... could turn down E noise?

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may6_21may5_TARG0_S_gcp__step_16_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may6_21may5_TARG0_S_gcp__step_16__with_reward_input.mp4]]

** check 21may5_TARG0_T_gcp__step_12_ -->> not much improvement

python -i simdat.py backupcfg/21may5_TARG0_T_gcp__step_12_sim.json

EV1 0.02 Hz
EA 1.77 Hz
IA 5.3 Hz
IAL 4.54 Hz
EA2 0.22 Hz
IA2 1.31 Hz
IA2L 1.89 Hz
EMDOWN 0.25 Hz
EMUP 0.24 Hz
IM 1.62 Hz
IML 2.26 Hz

ax=plotPerf(actreward,yl=(0,0.66))
savefig(gifpath()+'perf.png') # [[./gif/21may6_21may5_TARG0_T_gcp__step_12_perf.png]]

lfn = ['21may5_TARG0_T_gcp__step_' + str(i) + '_' for i in range(13)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.1,.51))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may6_21may5_TARG0_T_gcp__step_12_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may6_21may5_TARG0_T_gcp__step_12_perf_compareD.png]]

this one doesn't look like changing much ... will stop it
** 21may6_TARG0_S2_gcp_

python -i simdat.py backupcfg/21may5_TARG0_S_gcp__step_15_sim.json

EV1 0.02 Hz
EA 1.9 Hz
IA 4.95 Hz
IAL 4.29 Hz
EA2 0.62 Hz
IA2 2.24 Hz
IA2L 2.6 Hz
EMDOWN 1.38 Hz
EMUP 1.35 Hz
IM 6.08 Hz
IML 6.13 Hz

rates look ok ...

ax=plotPerf(actreward,yl=(0,1.1))
savefig(gifpath()+'perf.png') # [[./gif/21may6_21may5_TARG0_S_gcp__step_15_perf.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may6_21may5_TARG0_S_gcp__step_15_rast.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may6_21may5_TARG0_S_gcp__step_15__with_reward_input.mp4]]

lfn = ['21may5_TARG0_S_gcp__step_' + str(i) + '_' for i in range(16)]
clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may6_21may5_TARG0_S_gcp__step_15_all_steps_avg_weight.png]]

continue from 21may5_TARG0_S_gcp__step_15_ but first reduce E (AM2) noise rates to EM, EA2 from 200 Hz to 175 Hz

    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/21may5_TARG0_S_gcp__step_15_synWeights_final.pkl"
    },

./myrun 30 sn.json

python -i simdat.py backupcfg/21may6_TARG0_S2_gcp_sim.json

that produces sparser firing ... could also reduce the RLhebbwt for continuation ... will leave that for now ... 

(buffer=shell)
python multistepSim.py sn.json 30 15 21may6_TARG0_S2_gcp_multi

started ~15:49 ...

** 21may6_TARG0_S2B_gcp_

(same as 21may6_TARG0_S2_gcp_ except reduces AM2 noise even further)
continue from 21may5_TARG0_S_gcp__step_15_ but reduce E (AM2) noise rates to EM, EA2 from 200 Hz further to 150 Hz

    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/21may5_TARG0_S_gcp__step_15_synWeights_final.pkl"
    },

(buffer=s0)
python multistepSim.py sn.json 30 15 21may6_TARG0_S2B_gcp_multi

started ~16:00 ...

stopped this since almost always 0 firing ... could use 162 Hz instead of 150 and see if get a little more firing ... 

python multistepSim.py sn.json 30 15 21may6_TARG0_S2B_gcp_multi

started ~16:14 ...
** check 21may6_TARG0_S2_gcp__step_2_ and later steps

python -i simdat.py backupcfg/21may6_TARG0_S2_gcp__step_2_sim.json

EV1 0.01 Hz
EA 1.15 Hz
IA 3.54 Hz
IAL 3.33 Hz
EA2 0.45 Hz
IA2 2.5 Hz
IA2L 2.69 Hz
EMDOWN 3.58 Hz
EMUP 3.57 Hz
IM 7.18 Hz
IML 9.68 Hz

rates already so high?? means this last step not great...

ax=plotPerf(actreward,yl=(0,0.66))
savefig(gifpath()+'perf.png') # [[./gif/21may6_21may6_TARG0_S2_gcp__step_2_perf.png]]

lfn = ['21may5_TARG0_S_gcp__step_' + str(i) + '_' for i in range(17)]
for i in range(3): lfn.append('21may6_TARG0_S2_gcp__step_'+str(i) + '_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.1,.51))
plot([ax.get_xlim()[1]-3*500e3,ax.get_xlim()[1]-3*500e3],[0.1,0.5],'k--')
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may6_21may6_TARG0_S2_gcp__step_2_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.51),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may6_21may6_TARG0_S2_gcp__step_2_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may6_21may6_TARG0_S2_gcp__step_2_rast.png]]
very bursty, but mostly silent

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
ax=gca()
plot([ax.get_xlim()[1]-3*500e3,ax.get_xlim()[1]-3*500e3],[0.5,1.1],'k--')
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may6_21may6_TARG0_S2_gcp__step_2_all_steps_avg_weight.png]]
why did the weights drop after reload?? ah, loaded the steps past hyperexcit - also note that the network already
reached hyperexcit again ...even with the reduced AM2 noise input rates ...

did step 1 do better?

python -i simdat.py backupcfg/21may6_TARG0_S2_gcp__step_1_sim.json

EV1 0.01 Hz
EA 1.06 Hz
IA 3.24 Hz
IAL 3.15 Hz
EA2 0.36 Hz
IA2 2.06 Hz
IA2L 2.41 Hz
EMDOWN 1.91 Hz
EMUP 1.9 Hz
IM 5.14 Hz
IML 6.45 Hz

ax=plotPerf(actreward,yl=(0,2.1))
savefig(gifpath()+'perf.png') # [[./gif/21may6_21may6_TARG0_S2_gcp__step_1_perf.png]]
looks ok...

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may6_21may6_TARG0_S2_gcp__step_1_rast.png]]
pretty sparse activity ...

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may6_21may6_TARG0_S2_gcp__step_1__with_reward_input.mp4]]

may need to tweak the noise further -- better if it was adjusted automatically
 ... since on step 2 and 3 the rates are already getting too high -- bursty

video looks interesting - less moves/noise, but often moves in right direction - of course still missing too much

python -i simdat.py backupcfg/21may6_TARG0_S2_gcp__step_5_sim.json

EV1 0.01 Hz
EA 1.66 Hz
IA 5.94 Hz
IAL 4.51 Hz
EA2 1.35 Hz
IA2 7.6 Hz
IA2L 5.87 Hz
EMDOWN 19.16 Hz
EMUP 19.22 Hz
IM 21.9 Hz
IML 30.71 Hz

ax=plotPerf(actreward,yl=(0,0.71))
savefig(gifpath()+'perf.png') # [[./gif/21may7_21may6_TARG0_S2_gcp__step_5_perf.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may7_21may6_TARG0_S2_gcp__step_5_rast.png]]

lfn = ['21may5_TARG0_S_gcp__step_' + str(i) + '_' for i in range(16)]
for i in range(6): lfn.append('21may6_TARG0_S2_gcp__step_'+str(i) + '_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.1,.51))
plot([ax.get_xlim()[1]-6*500e3,ax.get_xlim()[1]-6*500e3],[0.1,0.5],'k--')
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may7_21may6_TARG0_S2_gcp__step_5_perf_all_steps_so_far.png]]
got worse after turning noise lower?
ylim((0.28,0.4))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21may7_21may6_TARG0_S2_gcp__step_5_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.51),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may7_21may6_TARG0_S2_gcp__step_5_perf_compareD.png]]

not sure getting better?, and looks hyperexcit with burstiness ... 

at step 6 it's even more hyperexcit with almost persistent firing ... so will stop this sim ... 

** check 21may6_TARG0_S2B_gcp__step_5_ 

python -i simdat.py backupcfg/21may6_TARG0_S2B_gcp__step_5_sim.json

EV1 0.01 Hz
EA 0.85 Hz
IA 2.95 Hz
IAL 2.96 Hz
EA2 0.33 Hz
IA2 2.23 Hz
IA2L 2.51 Hz
EMDOWN 3.02 Hz
EMUP 3.02 Hz
IM 5.69 Hz
IML 7.66 Hz

more reasonable average rates than S2 sim directly above ...

ax=plotPerf(actreward,yl=(0,0.71))
savefig(gifpath()+'perf.png') # [[./gif/21may7_21may6_TARG0_S2B_gcp__step_5_perf.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may7_21may6_TARG0_S2B_gcp__step_5_rast.png]]

lfn = ['21may5_TARG0_S_gcp__step_' + str(i) + '_' for i in range(16)]
for i in range(6): lfn.append('21may6_TARG0_S2B_gcp__step_'+str(i) + '_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.1,.51))
plot([ax.get_xlim()[1]-7*500e3,ax.get_xlim()[1]-7*500e3],[0.1,0.5],'k--')
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may7_21may6_TARG0_S2B_gcp__step_5_perf_all_steps_so_far.png]]
ylim((0.28,0.4))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21may7_21may6_TARG0_S2B_gcp__step_5_perf_all_steps_so_farB.png]]
looks like decaying since the noise reduction

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.51),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may7_21may6_TARG0_S2B_gcp__step_5_perf_compareD.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
ax=gca()
plot([ax.get_xlim()[1]-6*500e3,ax.get_xlim()[1]-6*500e3],[0.5,1.1],'k--')
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may7_21may6_TARG0_S2B_gcp__step_5_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may7_21may6_TARG0_S2B_gcp__step_5__with_reward_input.mp4]]
looks interesting ... less noisy but also sparser movements (as expected)

also getting more and more hyperexcitable in later steps ... but not yet to the same level as S2 sim in entry above

ok, stopped this one as well . . . 

** 21may6_TARG0_U_gcp_

reduce convergence ... 50 - 100 % convergence seems too high - forces too much synchronization
25% more reasonable ... 
increase feedback connectivity as well . . . (still lower than feedforward and recurrent)
increase magnitude of losePoint to -0.3
duration up to 1000 s ... since these sims run faster

python multistepSim.py sn.json 30 20 21may6_TARG0_U_gcp_multi

started ~23:45 ...

* 21may7
** check 21may6_TARG0_U_gcp__step_13_
  
python -i simdat.py backupcfg/21may6_TARG0_U_gcp__step_13_sim.json

EV1 0.01 Hz
EA 1.39 Hz
IA 3.93 Hz
IAL 3.41 Hz
EA2 0.06 Hz
IA2 1.14 Hz
IA2L 1.64 Hz
EMDOWN 0.06 Hz
EMUP 0.06 Hz
IM 1.21 Hz
IML 1.68 Hz

rates too low ...

ax=plotPerf(actreward,yl=(0,0.71))
savefig(gifpath()+'perf.png') # [[./gif/21may7_21may6_TARG0_U_gcp__step_13_perf.png]]

lfn = ['21may6_TARG0_U_gcp__step_' + str(i) + '_' for i in range(14)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.1,.51))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may7_21may6_TARG0_U_gcp__step_13_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,.51),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may7_21may6_TARG0_U_gcp__step_13_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may7_21may6_TARG0_U_gcp__step_13_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may7_21may6_TARG0_U_gcp__step_13_all_steps_avg_weight.png]]

step 5 did a little better ... maybe need lower magnitude of losePoint ... 
probable given that the weights were increasing then decreasing ..stopped this sim for now - will restart with diff params. 

python -i simdat.py backupcfg/21may6_TARG0_U_gcp__step_5_sim.json

EV1 0.01 Hz
EA 1.4 Hz
IA 3.98 Hz
IAL 3.41 Hz
EA2 0.06 Hz
IA2 1.14 Hz
IA2L 1.64 Hz
EMDOWN 0.06 Hz
EMUP 0.06 Hz
IM 1.21 Hz
IML 1.68 Hz

ax=plotPerf(actreward,yl=(0,0.71))
savefig(gifpath()+'perf.png') # [[./gif/21may7_21may6_TARG0_U_gcp__step_5_perf.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may7_21may6_TARG0_U_gcp__step_5_rast.png]]

** 21may7_TARG0_V_gcp_

./myrun 50 sn.json

python -i simdat.py backupcfg/21may7_TARG0_V_gcp_sim.json

adjusted connectivity ... a little more feedback conn; lower conv from VL to EA (for speed purposes),
and RL between VL and EA

python multistepSim.py sn.json 30 20 21may6_TARG0_V_gcp_multi

started ~13:36 ...

** 21may7_TARG0_W_gcp_

same as 21may7_TARG0_V_gcp_ but also include RLlenanti of 10 s with RLantiwt of -0.01 ... 

python multistepSim.py sn.json 30 20 21may6_TARG0_W_gcp_multi

started ~13:39 ...

** check 21may7_TARG0_V_gcp__step_1_
  
python -i simdat.py backupcfg/21may7_TARG0_V_gcp__step_1_sim.json

EV1 0.01 Hz
EA 0.22 Hz
IA 1.28 Hz
IAL 1.78 Hz
EA2 0.05 Hz
IA2 1.14 Hz
IA2L 1.63 Hz
EMDOWN 0.05 Hz
EMUP 0.05 Hz
IM 1.2 Hz
IML 1.66 Hz

ax=plotPerf(actreward,yl=(0,0.71))
savefig(gifpath()+'perf.png') # [[./gif/21may8_21may7_TARG0_V_gcp__step_1_perf.png]]
low perf...

lfn = ['21may7_TARG0_V_gcp__step_' + str(i) + '_' for i in range(2)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.1,.51))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may8_21may7_TARG0_V_gcp__step_1_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,.51),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') 

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') 

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') 

weights are changing way too slowly ... stopped for now ... will adjust

** 21may7_TARG0_X_gcp_

increase weights from VL -> EA to get more activity there
increase some of the feedback connectivity numbers and weights (~25 inputs and same weights as feedforward)
change losePoint to -0.1 ... 

./myrun 30 sn.json

python -i simdat.py backupcfg/21may7_TARG0_X_gcp_sim.json

python multistepSim.py sn.json 30 20 21may6_TARG0_X_gcp_multi

started ~21:57 ... 

** 21may7_TARG0_Y_gcp_

same as 21may7_TARG0_X_gcp_ but losePoint of -0.05

python multistepSim.py sn.json 30 20 21may6_TARG0_Y_gcp_multi

started ~22:00 . . . 

* 21may8
** check 21may7_TARG0_X_gcp__step_2_
  
python -i simdat.py backupcfg/21may7_TARG0_X_gcp__step_2_sim.json

EV1 0.01 Hz
EA 1.52 Hz
IA 3.54 Hz
IAL 3.49 Hz
EA2 0.06 Hz
IA2 1.15 Hz
IA2L 1.64 Hz
EMDOWN 0.06 Hz
EMUP 0.06 Hz
IM 1.21 Hz
IML 1.68 Hz

ax=plotPerf(actreward,yl=(0,0.71))
savefig(gifpath()+'perf.png') # [[./gif/21may8_21may7_TARG0_X_gcp__step_2_perf.png]]

perf decaying ... 

lfn = ['21may7_TARG0_X_gcp__step_' + str(i) + '_' for i in range(3)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.1,.51))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may8_21may7_TARG0_X_gcp__step_2_perf_all_steps_so_far.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may8_21may7_TARG0_X_gcp__step_2_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may8_21may7_TARG0_X_gcp__step_2_all_steps_avg_weight.png]]
savefig(gifpath()+'all_steps_avg_weightB.png') # [[./gif/21may8_21may7_TARG0_X_gcp__step_2_all_steps_avg_weightB.png]]
savefig(gifpath()+'all_steps_avg_weightC.png') # [[./gif/21may8_21may7_TARG0_X_gcp__step_2_all_steps_avg_weightC.png]]
weights look almost flat

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may8_21may7_TARG0_X_gcp__step_2__with_reward_input.mp4]]

** check 21may7_TARG0_Y_gcp__step_2_
  
python -i simdat.py backupcfg/21may7_TARG0_Y_gcp__step_2_sim.json

ax=plotPerf(actreward,yl=(0,0.71))
savefig(gifpath()+'perf.png') # [[./gif/21may8_21may7_TARG0_Y_gcp__step_2_perf.png]]


lfn = ['21may7_TARG0_Y_gcp__step_' + str(i) + '_' for i in range(3)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.1,.51))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may8_21may7_TARG0_Y_gcp__step_2_perf_all_steps_so_far.png]]

perf also decaying, but not as much

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may8_21may7_TARG0_Y_gcp__step_2_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may8_21may7_TARG0_Y_gcp__step_2_all_steps_avg_weight.png]]
weights also changing too slowly ...

** stop 21may7_TARG0_X_gcp_ and 21may7_TARG0_Y_gcp_ -- weights changing too slowly
** 21may8_TARG0_Z_gcp_

set RLhebbwt to 0.1 and losePoint to -0.025

try same sim with higher RLhebbwt

python multistepSim.py sn.json 30 20 21may8_TARG0_Z_gcp_multi

started ~11:07 ...

got hyperexcit after a few steps
adjust RLhebbwt to 0.05 and losePoint to -0.1

restarted ~17:42 ...

*** check 21may8_TARG0_Z_gcp__step_0_
  
python -i simdat.py backupcfg/21may8_TARG0_Z_gcp__step_0_sim.json

EV1 0.01 Hz
EA 1.49 Hz
IA 3.44 Hz
IAL 3.44 Hz
EA2 0.06 Hz
IA2 1.14 Hz
IA2L 1.64 Hz
EMDOWN 0.06 Hz
EMUP 0.06 Hz
IM 1.21 Hz
IML 1.68 Hz

ax=plotPerf(actreward,yl=(0,0.71))
savefig(gifpath()+'perf.png') # [[./gif/21may9_21may8_TARG0_Z_gcp__step_0_perf.png]]

lfn = ['21may8_TARG0_Z_gcp__step_' + str(i) + '_' for i in range(1)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.1,.51))
#savefig(gifpath()+'perf_all_steps_so_far.png') 

clf(); drawraster(dspkT,dspkID); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/21may9_21may8_TARG0_Z_gcp__step_0_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may9_21may8_TARG0_Z_gcp__step_0_all_steps_avg_weight.png]]

weights might be changing too slowly...

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may9_21may8_TARG0_Z_gcp__step_0__with_reward_input.mp4]]

but looking at video, seems the output activity is non-random ... 

** 21may8_TARG0_A_gcp_

same as 21may8_TARG0_Z_gcp_ but increase RLhebbwt to 0.2

python multistepSim.py sn.json 30 20 21may8_TARG0_A_gcp_multi

started ~11:08 ...

got hyperexcit after a few steps
adjust RLhebbwt to 0.075 and losePoint to -0.1

python multistepSim.py sn.json 30 20 21may8_TARG0_A_gcp_multi

restarted ~17:44 ...

*** check 21may8_TARG0_A_gcp__step_0_
  
python -i simdat.py backupcfg/21may8_TARG0_A_gcp__step_0_sim.json

EA 1.52 Hz
IA 3.49 Hz
IAL 3.46 Hz
EA2 0.06 Hz
IA2 1.15 Hz
IA2L 1.64 Hz
EMDOWN 0.06 Hz
EMUP 0.06 Hz
IM 1.21 Hz
IML 1.68 Hz

ax=plotPerf(actreward,yl=(0,0.71))
savefig(gifpath()+'perf.png') # [[./gif/21may9_21may8_TARG0_A_gcp__step_0_perf.png]]

lfn = ['21may8_TARG0_A_gcp__step_' + str(i) + '_' for i in range(1)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.1,.51))
#savefig(gifpath()+'perf_all_steps_so_far.png') 

clf(); drawraster(dspkT,dspkID); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/21may9_21may8_TARG0_A_gcp__step_0_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may9_21may8_TARG0_A_gcp__step_0_all_steps_avg_weight.png]]

weights here changing very slowly too . . . 

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may9_21may8_TARG0_A_gcp__step_0__with_reward_input.mp4]]

* 21may9
** check 21may8_TARG0_Z_gcp__step4_
  
python -i simdat.py backupcfg/21may8_TARG0_Z_gcp__step_4_sim.json

EV1 0.02 Hz
EA 86.91 Hz
IA 344.0 Hz
IAL 358.03 Hz
EA2 136.8 Hz
IA2 193.49 Hz
IA2L 173.54 Hz
EMDOWN 128.97 Hz
EMUP 129.67 Hz
IM 96.67 Hz
IML 108.81 Hz

already hyperexcit

ax=plotPerf(actreward,yl=(0,0.71))
savefig(gifpath()+'perf.png') # [[./gif/21may9_21may8_TARG0_Z_gcp__step_4_perf.png]]

lfn = ['21may8_TARG0_Z_gcp__step_' + str(i) + '_' for i in range(5)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.1,.51))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may9_21may8_TARG0_Z_gcp__step_4_perf_all_steps_so_far.png]]

#clf(); drawraster(dspkT,dspkID); xlim((990e3,1000e3))
#savefig(gifpath()+'rast.png') 

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,.51),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may9_21may8_TARG0_Z_gcp__step_4_perf_compareD.png]]

step 2,3 were improved compared to steps 0,1 but then got hyperexcitable

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') 
[[./gif/21may9_21may8_TARG0_Z_gcp__step_4_all_steps_avg_weight.png]]
savefig(gifpath()+'all_steps_avg_weightB.png') 
./gif/21may9_21may8_TARG0_Z_gcp__step_4_all_steps_avg_weightB.png]]

python -i simdat.py backupcfg/21may8_TARG0_Z_gcp__step_2_sim.json

EV1 0.01 Hz
EA 1.6 Hz
IA 3.66 Hz
IAL 3.66 Hz
EA2 0.09 Hz
IA2 1.24 Hz
IA2L 1.76 Hz
EMDOWN 0.09 Hz
EMUP 0.09 Hz
IM 1.29 Hz
IML 1.83 Hz

ax=plotPerf(actreward,yl=(0,1.1))
savefig(gifpath()+'perf.png') # [[./gif/21may9_21may8_TARG0_Z_gcp__step_2_perf.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may9_21may8_TARG0_Z_gcp__step_2__with_reward_input.mp4]]

so may need to adjust the reward / loss values and/or reduce feedback connection weights to see if can run
longer ... 

** check 21may8_TARG0_A_gcp__step_1_

the sim stopped during weight conversion ... so never finished step 1?
** 21may9_TARG0_B_gcp_

set RLhebbwt down to 0.025 ... and reduce VL -> EA2, EM to 0.01 (from 0.5)
and reduce starting feedback weights from 0.5 to 0.01 ... 

python multistepSim.py sn.json 30 20 21may9_TARG0_B_gcp_multi

started ~9:52 ...

*** check 21may9_TARG0_B_gcp__step_2_
  
python -i simdat.py backupcfg/21may9_TARG0_B_gcp__step_2_sim.json

EV1 0.01 Hz
EA 1.53 Hz
IA 3.53 Hz
IAL 3.49 Hz
EA2 0.06 Hz
IA2 1.14 Hz
IA2L 1.64 Hz
EMDOWN 0.06 Hz
EMUP 0.06 Hz
IM 1.21 Hz
IML 1.68 Hz

ax=plotPerf(actreward,yl=(0,0.71))
savefig(gifpath()+'perf.png') # [[./gif/21may10_21may9_TARG0_B_gcp__step_2_perf.png]]

lfn = ['21may9_TARG0_B_gcp__step_' + str(i) + '_' for i in range(3)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.1,.51))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may10_21may9_TARG0_B_gcp__step_2_perf_all_steps_so_far.png]]
getting worse perf with time?

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,.62),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may10_21may9_TARG0_B_gcp__step_2_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/21may10_21may9_TARG0_B_gcp__step_2_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may10_21may9_TARG0_B_gcp__step_2_all_steps_avg_weight.png]]
savefig(gifpath()+'all_steps_avg_weightB.png') # [[./gif/21may10_21may9_TARG0_B_gcp__step_2_all_steps_avg_weightB.png]]
savefig(gifpath()+'all_steps_avg_weightC.png') # [[./gif/21may10_21may9_TARG0_B_gcp__step_2_all_steps_avg_weightC.png]]

step 1 looked better in perf ... take a look at animation ... 

python -i simdat.py backupcfg/21may9_TARG0_B_gcp__step_1_sim.json

EV1 0.01 Hz
EA 1.49 Hz
IA 3.44 Hz
IAL 3.42 Hz
EA2 0.06 Hz
IA2 1.14 Hz
IA2L 1.64 Hz
EMDOWN 0.06 Hz
EMUP 0.06 Hz
IM 1.21 Hz
IML 1.68 Hz

ax=plotPerf(actreward,yl=(0,0.71))
savefig(gifpath()+'perf.png') # [[./gif/21may10_21may9_TARG0_B_gcp__step_1_perf.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may10_21may9_TARG0_B_gcp__step_1__with_reward_input.mp4]]

** 21may9_TARG0_C_gcp_

same as B but RLhebbwt of 0.05 ...

python multistepSim.py sn.json 30 20 21may9_TARG0_C_gcp_multi

started ~9:55 ... 

*** check 21may9_TARG0_C_gcp__step_2_
  
python -i simdat.py backupcfg/21may9_TARG0_C_gcp__step_2_sim.json

EA 1.55 Hz
IA 3.59 Hz
IAL 3.56 Hz
EA2 0.06 Hz
IA2 1.15 Hz
IA2L 1.64 Hz
EMDOWN 0.07 Hz
EMUP 0.06 Hz
IM 1.23 Hz
IML 1.69 Hz

ax=plotPerf(actreward,yl=(0,1.01))
savefig(gifpath()+'perf.png') # [[./gif/21may10_21may9_TARG0_C_gcp__step_2_perf.png]]

lfn = ['21may9_TARG0_C_gcp__step_' + str(i) + '_' for i in range(3)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.1,.51))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may10_21may9_TARG0_C_gcp__step_2_perf_all_steps_so_far.png]]

clf(); drawraster(dspkT,dspkID); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/21may10_21may9_TARG0_C_gcp__step_2_rast.png]]
savefig(gifpath()+'rastB.png') # [[./gif/21may10_21may9_TARG0_C_gcp__step_2_rastB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may10_21may9_TARG0_C_gcp__step_2_perf_compareD.png]]

step 2 best so far ...

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may10_21may9_TARG0_C_gcp__step_2_all_steps_avg_weight.png]]
savefig(gifpath()+'all_steps_avg_weightB.png') # [[./gif/21may10_21may9_TARG0_C_gcp__step_2_all_steps_avg_weightB.png]]
savefig(gifpath()+'all_steps_avg_weightC.png') # [[./gif/21may10_21may9_TARG0_C_gcp__step_2_all_steps_avg_weightC.png]]

weights are a little higher than for sim B (makes sense given higher value of RLhebbwt [0.05 in C vs 0.025 in B])

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may10_21may9_TARG0_C_gcp__step_2__with_reward_input.mp4]]

* 21may10
** check 21may9_TARG0_B_gcp__step_5_
  
python -i simdat.py backupcfg/21may9_TARG0_B_gcp__step_5_sim.json

EV1 0.01 Hz
EA 1.6 Hz
IA 3.65 Hz
IAL 3.64 Hz
EA2 0.07 Hz
IA2 1.16 Hz
IA2L 1.65 Hz
EMDOWN 0.07 Hz
EMUP 0.07 Hz
IM 1.28 Hz
IML 1.74 Hz

ax=plotPerf(actreward,yl=(0,1.01))
savefig(gifpath()+'perf.png') # [[./gif/21may10_21may9_TARG0_B_gcp__step_5_perf.png]]

lfn = ['21may9_TARG0_B_gcp__step_' + str(i) + '_' for i in range(6)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.1,.51))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may10_21may9_TARG0_B_gcp__step_5_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,.62),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may10_21may9_TARG0_B_gcp__step_5_perf_compareD.png]]
step 5 is ok except for the end ...

clf(); drawraster(dspkT,dspkID); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/21may10_21may9_TARG0_B_gcp__step_5_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may10_21may9_TARG0_B_gcp__step_5_all_steps_avg_weight.png]]
savefig(gifpath()+'all_steps_avg_weightB.png') # [[./gif/21may10_21may9_TARG0_B_gcp__step_5_all_steps_avg_weightB.png]]
savefig(gifpath()+'all_steps_avg_weightC.png') # [[./gif/21may10_21may9_TARG0_B_gcp__step_5_all_steps_avg_weightC.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may10_21may9_TARG0_B_gcp__step_5__with_reward_input.mp4]]

** check 21may9_TARG0_C_gcp__step_4_
  
python -i simdat.py backupcfg/21may9_TARG0_C_gcp__step_4_sim.json

EV1 0.01 Hz
EA 1.86 Hz
IA 4.3 Hz
IAL 4.05 Hz
EA2 0.08 Hz
IA2 1.22 Hz
IA2L 1.68 Hz
EMDOWN 0.1 Hz
EMUP 0.1 Hz
IM 1.43 Hz
IML 1.93 Hz

ax=plotPerf(actreward,yl=(0,1.01))
savefig(gifpath()+'perf.png') # [[./gif/21may10_21may9_TARG0_C_gcp__step_4_perf.png]]

lfn = ['21may9_TARG0_C_gcp__step_' + str(i) + '_' for i in range(5)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.1,.51))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may10_21may9_TARG0_C_gcp__step_4_perf_all_steps_so_far.png]]

clf(); drawraster(dspkT,dspkID); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/21may10_21may9_TARG0_C_gcp__step_4_rast.png]]
savefig(gifpath()+'rastB.png') # [[./gif/21may10_21may9_TARG0_C_gcp__step_4_rastB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may10_21may9_TARG0_C_gcp__step_4_perf_compareD.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may10_21may9_TARG0_C_gcp__step_4_all_steps_avg_weight.png]]
savefig(gifpath()+'all_steps_avg_weightB.png') # [[./gif/21may10_21may9_TARG0_C_gcp__step_4_all_steps_avg_weightB.png]]
savefig(gifpath()+'all_steps_avg_weightC.png') # [[./gif/21may10_21may9_TARG0_C_gcp__step_4_all_steps_avg_weightC.png]]

this sim got hyperexcitable in the next step
since EA driving everything else, could put a max weight value around 15.5

check next step to make sure cancelling this sim continuation... 

python -i simdat.py backupcfg/21may9_TARG0_C_gcp__step_5_sim.json

EV1 0.02 Hz
EA 107.15 Hz
IA 278.7 Hz
IAL 272.08 Hz
EA2 89.36 Hz
IA2 305.05 Hz
IA2L 292.52 Hz
EMDOWN 127.69 Hz
EMUP 128.34 Hz
IM 106.62 Hz
IML 100.77 Hz

ax=plotPerf(actreward,yl=(0,1.01))
savefig(gifpath()+'perf.png') # [[./gif/21may10_21may9_TARG0_C_gcp__step_5_perf.png]]

lfn = ['21may9_TARG0_C_gcp__step_' + str(i) + '_' for i in range(6)]
clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may10_21may9_TARG0_C_gcp__step_5_all_steps_avg_weight.png]]
savefig(gifpath()+'all_steps_avg_weightB.png') # [[./gif/21may10_21may9_TARG0_C_gcp__step_5_all_steps_avg_weightB.png]]
savefig(gifpath()+'all_steps_avg_weightC.png') # [[./gif/21may10_21may9_TARG0_C_gcp__step_5_all_steps_avg_weightC.png]]
yeah, the weights really took off at that last step ...

what about adding EIplast there to prevent hyperexcit?

** next sim  21may10_TARG0_D_gcp_

./myrun 30 sn.json

python -i simdat.py backupcfg/21may10_TARG0_D_gcp_sim.json

same as 21may9_TARG0_C_gcp_ but also include EIPlast ... 

python multistepSim.py sn.json 30 20 21may10_TARG0_D_gcp_multi

started ~1 pm ...

** check 21may9_TARG0_B_gcp__step_9_
  
python -i simdat.py backupcfg/21may9_TARG0_B_gcp__step_9_sim.json

EV1 0.01 Hz
EA 2.11 Hz
IA 4.67 Hz
IAL 4.36 Hz
EA2 0.12 Hz
IA2 1.54 Hz
IA2L 1.8 Hz
EMDOWN 0.18 Hz
EMUP 0.18 Hz
IM 1.95 Hz
IML 2.53 Hz

ax=plotPerf(actreward,yl=(0,1.01))
savefig(gifpath()+'perf.png') # [[./gif/21may11_21may9_TARG0_B_gcp__step_9_perf.png]]

lfn = ['21may9_TARG0_B_gcp__step_' + str(i) + '_' for i in range(10)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.1,.51))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may11_21may9_TARG0_B_gcp__step_9_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,.62),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may11_21may9_TARG0_B_gcp__step_9_perf_compareD.png]]

no better ... and next step got hyperexcitable so stopped it ...

clf(); drawraster(dspkT,dspkID); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/21may11_21may9_TARG0_B_gcp__step_9_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may11_21may9_TARG0_B_gcp__step_9_all_steps_avg_weight.png]]
savefig(gifpath()+'all_steps_avg_weightB.png') # [[./gif/21may11_21may9_TARG0_B_gcp__step_9_all_steps_avg_weightB.png]]
savefig(gifpath()+'all_steps_avg_weightC.png') # [[./gif/21may11_21may9_TARG0_B_gcp__step_9_all_steps_avg_weightC.png]]

# fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)

** check 21may10_TARG0_D_gcp__step_1_
  
python -i simdat.py backupcfg/21may10_TARG0_D_gcp__step_1_sim.json

EV1 0.01 Hz
EA 1.54 Hz
IA 3.98 Hz
IAL 3.96 Hz
EA2 0.06 Hz
IA2 1.15 Hz
IA2L 1.64 Hz
EMDOWN 0.06 Hz
EMUP 0.06 Hz
IM 1.22 Hz
IML 1.68 Hz

ax=plotPerf(actreward,yl=(0,1.01))
savefig(gifpath()+'perf.png') # [[./gif/21may11_21may10_TARG0_D_gcp__step_1_perf.png]]

lfn = ['21may10_TARG0_D_gcp__step_' + str(i) + '_' for i in range(2)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.1,.51))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may11_21may10_TARG0_D_gcp__step_1_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,.62),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may11_21may10_TARG0_D_gcp__step_1_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/21may11_21may10_TARG0_D_gcp__step_1_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may11_21may10_TARG0_D_gcp__step_1_all_steps_avg_weight.png]]

IA and IAL weights are going up too fast . . . 

** 21may10_TARG0_E_gcp_

./myrun 30 sn.json

python -i simdat.py backupcfg/21may10_TARG0_E_gcp_sim.json

go back to larger network ... with higher number of connections ... and some AM2 noise in EA ...
reduce feedback connection numbers a bit ... 
500 s step size ... RLhebbwt down to 0.01 ... no EIPlast, but including the plasticity
from VL -> EA ... 

python multistepSim.py sn.json 30 40 21may10_TARG0_E_gcp_multi

started ~23:32 ...

* 21may11
** check 21may10_TARG0_D_gcp__step_3_ -->> step 4 hyperexcit, stop it
  
step 4 already became hyperexcitable ... 

python -i simdat.py backupcfg/21may10_TARG0_D_gcp__step_3_sim.json

EV1 0.01 Hz
EA 1.71 Hz
IA 4.94 Hz
IAL 5.0 Hz
EA2 0.07 Hz
IA2 1.18 Hz
IA2L 1.66 Hz
EMDOWN 0.09 Hz
EMUP 0.09 Hz
IM 1.34 Hz
IML 1.84 Hz

ax=plotPerf(actreward,yl=(0,1.01))
savefig(gifpath()+'perf.png') # [[./gif/21may11_21may10_TARG0_D_gcp__step_3_perf.png]]

lfn = ['21may10_TARG0_D_gcp__step_' + str(i) + '_' for i in range(4)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.1,.51))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may11_21may10_TARG0_D_gcp__step_3_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may11_21may10_TARG0_D_gcp__step_3_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((990e3,1000e3))
savefig(gifpath()+'rast.png') # [[./gif/21may11_21may10_TARG0_D_gcp__step_3_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may11_21may10_TARG0_D_gcp__step_3_all_steps_avg_weight.png]]

get rid of / reduce feedback connections -- ? to prevent hyperexcit?

** 21may11_TARG0_F_gcp_ -->> stopped, will let larger network run instead

this is the smaller scale model
same as 21may10_TARG0_D_gcp_ but ... reduce feedback connection numbers and weights
and remove EIPlast ... 

./myrun 30 sn.json

python -i simdat.py backupcfg/21may11_TARG0_F_gcp_sim.json

python multistepSim.py sn.json 30 20 21may11_TARG0_F_gcp_multi

started ~12:09 ...

** check 21may10_TARG0_E_gcp__step_0_
  
python -i simdat.py backupcfg/21may10_TARG0_E_gcp__step_0_sim.json

EV1 0.02 Hz
EA 1.7 Hz
IA 3.12 Hz
IAL 4.29 Hz
EA2 0.11 Hz
IA2 1.2 Hz
IA2L 1.7 Hz
EMDOWN 0.2 Hz
EMUP 0.2 Hz
IM 1.4 Hz
IML 2.1 Hz

ax=plotPerf(actreward,yl=(0,1.21))
savefig(gifpath()+'perf.png') # [[./gif/21may11_21may10_TARG0_E_gcp__step_0_perf.png]]
hmm, a lot better than the small network ...

lfn = ['21may10_TARG0_E_gcp__step_' + str(i) + '_' for i in range(1)]
#pdac = getconcatactionreward(lfn)
#clf(); ax=plotPerf(pdac,yl=(0.1,.51))
#savefig(gifpath()+'perf_all_steps_so_far.png') 
#
#lpda = getindivactionreward(lfn)
#csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
#lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
#clf(); plotComparePerf(lpda,lclr,yl=(0,1.01),lleg=lfn,skipscore=True,skipfollow=True)
#savefig(gifpath()+'perf_compareD.png') 

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may11_21may10_TARG0_E_gcp__step_0_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may11_21may10_TARG0_E_gcp__step_0_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may11_21may10_TARG0_E_gcp__step_0__with_reward_input.mp4]]
** check 21may10_TARG0_E_gcp__step_1_
  
python -i simdat.py backupcfg/21may10_TARG0_E_gcp__step_1_sim.json

EV1 0.02 Hz
EA 1.7 Hz
IA 3.14 Hz
IAL 4.31 Hz
EA2 0.11 Hz
IA2 1.21 Hz
IA2L 1.71 Hz
EMDOWN 0.2 Hz
EMUP 0.2 Hz
IM 1.41 Hz
IML 2.11 Hz

ax=plotPerf(actreward,yl=(0,4.1))
savefig(gifpath()+'perf.png') # [[./gif/21may12_21may10_TARG0_E_gcp__step_1_perf.png]]

lfn = ['21may10_TARG0_E_gcp__step_' + str(i) + '_' for i in range(2)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,1.2))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may12_21may10_TARG0_E_gcp__step_1_perf_all_steps_so_far.png]]
hmm, looks like decaying ...??

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may12_21may10_TARG0_E_gcp__step_1_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may12_21may10_TARG0_E_gcp__step_1_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may12_21may10_TARG0_E_gcp__step_1_all_steps_avg_weight.png]]

perf decay after peak could be due to divergence in EM up and down weights ... will see how progresses ...

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may12_21may10_TARG0_E_gcp__step_1__with_reward_input.mp4]]

* 21may12
** check 21may10_TARG0_E_gcp__step_2_
  
python -i simdat.py backupcfg/21may10_TARG0_E_gcp__step_2_sim.json


EV1 0.02 Hz
EA 1.7 Hz
IA 3.13 Hz
IAL 4.29 Hz
EA2 0.12 Hz
IA2 1.21 Hz
IA2L 1.71 Hz
EMDOWN 0.21 Hz
EMUP 0.21 Hz
IM 1.42 Hz
IML 2.12 Hz

ax=plotPerf(actreward,yl=(0,.6))
savefig(gifpath()+'perf.png') # [[./gif/21may12_21may10_TARG0_E_gcp__step_2_perf.png]]
hmm, this step decidedly worse

lfn = ['21may10_TARG0_E_gcp__step_' + str(i) + '_' for i in range(3)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,1.2))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may12_21may10_TARG0_E_gcp__step_2_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may12_21may10_TARG0_E_gcp__step_2_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may12_21may10_TARG0_E_gcp__step_2_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may12_21may10_TARG0_E_gcp__step_2_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may12_21may10_TARG0_E_gcp__step_2__with_reward_input.mp4]]

* 21may13
** check 21may10_TARG0_E_gcp__step_4_
  
python -i simdat.py backupcfg/21may10_TARG0_E_gcp__step_4_sim.json

EV1 0.02 Hz
EA 1.81 Hz
IA 3.29 Hz
IAL 4.51 Hz
EA2 0.13 Hz
IA2 1.22 Hz
IA2L 1.74 Hz
EMDOWN 0.24 Hz
EMUP 0.24 Hz
IM 1.46 Hz
IML 2.17 Hz

ax=plotPerf(actreward,yl=(0,.6))
savefig(gifpath()+'perf.png') # [[./gif/21may13_21may10_TARG0_E_gcp__step_4_perf.png]]
worse

lfn = ['21may10_TARG0_E_gcp__step_' + str(i) + '_' for i in range(5)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,1.2))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may13_21may10_TARG0_E_gcp__step_4_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,4.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may13_21may10_TARG0_E_gcp__step_4_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may13_21may10_TARG0_E_gcp__step_4_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may13_21may10_TARG0_E_gcp__step_4_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may13_21may10_TARG0_E_gcp__step_4__with_reward_input.mp4]]

** stopped 21may10_TARG)_E_gcp_ -- perf decaying
** adjustments to 21may10_TARG0_E_gcp_

performance seems to be decaying after first few steps ... looking at movie of activity
seems to show that the movements are larger ... maybe too much noise ? could have a gradual
decay rate for the noise amplitude, but that's difficult to balance ... 

if noise is a problem - still unclear - could have a probability of random move
instead of synaptic noise ... 

ok, will try that with adjustment to stochMove ... 
with some low probability it will move randomly, otherwise will be deterministic ... could have the probability of random
move decrease over time ... 

21may13_TARG0_G_gcp_

./myrun 30 sn.json

python -i simdat.py backupcfg/21may13_TARG0_G_gcp_sim.json

hmm, gets all or nothing activity without the noise ... so will leave it on ... 

how about larger pop of EA and EA2 ... ? and no plast from loc neurons (EV1) to EA ... no feedback RL for now

python multistepSim.py sn.json 30 20 21may13_TARG0_G_gcp_multi

started ~16:58 ...

*** check

python -i simdat.py backupcfg/21may13_TARG0_G_gcp__step_0_sim.json

EV1 0.02 Hz
EA 1.64 Hz
IA 3.07 Hz
IAL 4.18 Hz
EA2 0.11 Hz
IA2 1.21 Hz
IA2L 1.71 Hz
EMDOWN 0.2 Hz
EMUP 0.2 Hz
IM 1.41 Hz
IML 2.1 Hz

ax=plotPerf(actreward,yl=(0,.6))
savefig(gifpath()+'perf.png') # [[./gif/21may14_21may13_TARG0_G_gcp__step_0_perf.png]]

lfn = ['21may13_TARG0_G_gcp__step_' + str(i) + '_' for i in range(1)]
#pdac = getconcatactionreward(lfn)
#clf(); ax=plotPerf(pdac,yl=(0.,1.2))
#savefig(gifpath()+'perf_all_steps_so_far.png') 

#lpda = getindivactionreward(lfn)
#csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
#lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
#clf(); plotComparePerf(lpda,lclr,yl=(0,4.01),lleg=lfn,skipscore=True,skipfollow=True)
#savefig(gifpath()+'perf_compareD.png') 

clf(); drawraster(dspkT,dspkID); xlim((490e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may14_21may13_TARG0_G_gcp__step_0_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may14_21may13_TARG0_G_gcp__step_0_all_steps_avg_weight.png]]

hmm, started -> EA2 weights lower than -> EM by accident ...

also have RLhebbwt of 0.05 which is probably too high ...

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may14_21may13_TARG0_G_gcp__step_0__with_reward_input.mp4]]

** added delay for STIMMOD -- more variance could reduce eventual hypersynch

between 3-10 instead of 1.8-2.2 seemed to reduce the giant hypersynch spike in beginning of sim

add this to the net in json:
        "delayMinSTIMMOD": 3,
        "delayMaxSTIMMOD": 10	

and put defaults in conf.py (old default was 1.8-2.2 ms)

** adjust weights/params (21may13_TARG0_H_gcp_)

        "delayMinSoma": 1.8,
        "delayMaxSoma": 2.2,	
        "delayMinDend": 3,
        "delayMaxDend": 12,
        "delayMinSTIMMOD": 3,
        "delayMaxSTIMMOD": 12

also lower weights ... less/no NMDA btwn E E neurons

./myrun 30 sn.json

python -i simdat.py backupcfg/21may13_TARG0_H_gcp_sim.json

python multistepSim.py sn.json 30 20 21may13_TARG0_H_gcp_multi

started ~23:06 ...

* 21may14
** check 21may13_TARG0_H_gcp__step_0_

python -i simdat.py backupcfg/21may13_TARG0_H_gcp__step_0_sim.json

EV1 0.02 Hz
EA 1.3 Hz
IA 2.48 Hz
IAL 3.57 Hz
EA2 0.05 Hz
IA2 1.17 Hz
IA2L 1.64 Hz
EMDOWN 0.05 Hz
EMUP 0.05 Hz
IM 1.22 Hz
IML 1.69 Hz

ax=plotPerf(actreward,yl=(0,2.01))
savefig(gifpath()+'perf.png') # [[./gif/21may14_21may13_TARG0_H_gcp__step_0_perf.png]]

lfn = ['21may13_TARG0_H_gcp__step_' + str(i) + '_' for i in range(1)]
#pdac = getconcatactionreward(lfn)
#clf(); ax=plotPerf(pdac,yl=(0.,1.2))
#savefig(gifpath()+'perf_all_steps_so_far.png') 

#lpda = getindivactionreward(lfn)
#csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
#lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
#clf(); plotComparePerf(lpda,lclr,yl=(0,4.01),lleg=lfn,skipscore=True,skipfollow=True)
#savefig(gifpath()+'perf_compareD.png') 

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may14_21may13_TARG0_H_gcp__step_0_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may14_21may13_TARG0_H_gcp__step_0_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may14_21may13_TARG0_H_gcp__step_0__with_reward_input.mp4]]
** check 21may13_TARG0_H_gcp__step_1_

python -i simdat.py backupcfg/21may13_TARG0_H_gcp__step_1_sim.json

EV1 0.02 Hz
EA 1.3 Hz
IA 2.48 Hz
IAL 3.57 Hz
EA2 0.05 Hz
IA2 1.17 Hz
IA2L 1.64 Hz
EMDOWN 0.05 Hz
EMUP 0.05 Hz
IM 1.22 Hz
IML 1.69 Hz

ax=plotPerf(actreward,yl=(0,2.01))
savefig(gifpath()+'perf.png') # [[./gif/21may14_21may13_TARG0_H_gcp__step_1_perf.png]]

rates and perf look almost identical to last step ... 

lfn = ['21may13_TARG0_H_gcp__step_' + str(i) + '_' for i in range(2)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,1.2))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may14_21may13_TARG0_H_gcp__step_1_perf_all_steps_so_far.png]]
yet cumulative looks very diff for first and 2nd half ... not a great measure

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,4.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may14_21may13_TARG0_H_gcp__step_1_perf_compareD.png]]
hmm, identical ... 

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may14_21may13_TARG0_H_gcp__step_1_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may14_21may13_TARG0_H_gcp__step_1_all_steps_avg_weight.png]]
weights changing so slowly and that's why get same perf ... weights also low/subthreshold ... 

#fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)

** simplePong.py -- use only 1 speed and remove top/bottom hit rule

just keep the changes in the development branch for now

adding these as params for simulatedEnvParams.
these were original:
        "possible_ball_dy" : [1,1,1,1,1,1,2,2,2,2,3,3,3],
	"possible_ball_dx": [1,1,1,1,1,1,2,2,2,2,3,3,3]	
to keep 1 slow speed, just put 1 for all values
        "possible_ball_dy" : [1,1,1,1,1,1,1,1,1,1,1,1,1],
	"possible_ball_dx": [1,1,1,1,1,1,1,1,1,1,1,1,1]	
and then just read that in simplePong.py

also put in original defaults in conf.py for consistency with older models/code:
    checkDefVal(dconf,'simulatedEnvParams',{})
    checkDefVal(dconf['simulatedEnvParams'], 'possible_ball_dy' : [1,1,1,1,1,1,2,2,2,2,3,3,3])
    checkDefVal(dconf['simulatedEnvParams'], 'possible_ball_dx' : [1,1,1,1,1,1,2,2,2,2,3,3,3])

and also 	"top_bottom_rule": 0
default will be 1 for consistency with old model/code ... and put that into conf.py as well

** 21may14_TARG0_I_gcp_

same as last sim but with bigger RLhebbwt ... should not get same trajectory 2x in a row ... 
also only using slowest ball speed and no top/bottom hit rule ... (see entry above)

./myrun 30 sn.json

python -i simdat.py backupcfg/21may14_TARG0_I_gcp_sim.json

python multistepSim.py sn.json 30 40 21may14_TARG0_I_gcp_multi

started ~12:41 ...

*** check 21may14_TARG0_I_gcp__step_0_

python -i simdat.py backupcfg/21may14_TARG0_I_gcp__step_0_sim.json

EV1 0.02 Hz
EA 1.1 Hz
IA 2.25 Hz
IAL 3.2 Hz
EA2 0.05 Hz
IA2 1.17 Hz
IA2L 1.64 Hz
EMDOWN 0.05 Hz
EMUP 0.05 Hz
IM 1.22 Hz
IML 1.69 Hz

ax=plotPerf(actreward,yl=(0,2.01))
savefig(gifpath()+'perf.png') # [[./gif/21may15_21may14_TARG0_I_gcp__step_0_perf.png]]

lfn = ['21may14_TARG0_I_gcp__step_' + str(i) + '_' for i in range(1)]
#pdac = getconcatactionreward(lfn)
#clf(); ax=plotPerf(pdac,yl=(0.,1.2))
#savefig(gifpath()+'perf_all_steps_so_far.png') 

#lpda = getindivactionreward(lfn)
#csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
#lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
#clf(); plotComparePerf(lpda,lclr,yl=(0,4.01),lleg=lfn,skipscore=True,skipfollow=True)
#savefig(gifpath()+'perf_compareD.png') 

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may15_21may14_TARG0_I_gcp__step_0_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may15_21may14_TARG0_I_gcp__step_0_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may15_21may14_TARG0_I_gcp__step_0__with_reward_input.mp4]]

* 21may15
** adjust sim -- 21may15_TARG0_J_gcp_

starting weights are too small -- 3 steps and nothing is changing in terms of firing rates

./myrun 30 sn.json

python -i simdat.py backupcfg/21may15_TARG0_J_gcp_sim.json

python multistepSim.py sn.json 30 40 21may15_TARG0_J_gcp_multi

started ~11

*** check 21may15_TARG0_J_gcp__step_1_

python -i simdat.py backupcfg/21may15_TARG0_J_gcp__step_1_sim.json

EV1 0.02 Hz
EA 1.12 Hz
IA 2.27 Hz
IAL 3.25 Hz
EA2 0.06 Hz
IA2 1.17 Hz
IA2L 1.64 Hz
EMDOWN 0.06 Hz
EMUP 0.06 Hz
IM 1.22 Hz
IML 1.7 Hz

ax=plotPerf(actreward,yl=(0,.51))
savefig(gifpath()+'perf.png') # [[./gif/21may16_21may15_TARG0_J_gcp__step_1_perf.png]]

lfn = ['21may15_TARG0_J_gcp__step_' + str(i) + '_' for i in range(2)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,2.1))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may16_21may15_TARG0_J_gcp__step_1_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,4.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may16_21may15_TARG0_J_gcp__step_1_perf_compareD.png]]

hmm, step 1 worse than step 0 ... do not see improvements ... ? 

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may16_21may15_TARG0_J_gcp__step_1_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may16_21may15_TARG0_J_gcp__step_1_all_steps_avg_weight.png]]

python -i simdat.py backupcfg/21may15_TARG0_J_gcp__step_0_sim.json

EV1 0.02 Hz
EA 1.11 Hz
IA 2.26 Hz
IAL 3.23 Hz
EA2 0.06 Hz
IA2 1.17 Hz
IA2L 1.64 Hz
EMDOWN 0.06 Hz
EMUP 0.06 Hz
IM 1.22 Hz
IML 1.69 Hz

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may16_21may15_TARG0_J_gcp__step_0__with_reward_input.mp4]]

** readjust (21may15_TARG0_K_gcp_)

put back the shorter delays from stim mod to EV1 ... 

even original 1.8 - 2.2 ms could be shortened ... since want EV1 to fire ~right away ... 
keep as it was anyway ... to test the larger network with the single speed ball and no top/bottom hit ... 

./myrun 30 sn.json

python -i simdat.py backupcfg/21may15_TARG0_K_gcp_sim.json

python multistepSim.py sn.json 30 40 21may15_TARG0_K_gcp_multi

started ~23:39 ...

* 21may16
** check 21may15_TARG0_K_gcp__step_1_

python -i simdat.py backupcfg/21may15_TARG0_K_gcp__step_1_sim.json

EV1 0.02 Hz
EA 1.31 Hz
IA 2.51 Hz
IAL 3.58 Hz
EA2 0.09 Hz
IA2 1.2 Hz
IA2L 1.71 Hz
EMDOWN 0.18 Hz
EMUP 0.19 Hz
IM 1.38 Hz
IML 2.05 Hz

ax=plotPerf(actreward,yl=(0,.51))
savefig(gifpath()+'perf.png') # [[./gif/21may16_21may15_TARG0_K_gcp__step_1_perf.png]]

lfn = ['21may15_TARG0_K_gcp__step_' + str(i) + '_' for i in range(2)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,1.01))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may16_21may15_TARG0_K_gcp__step_1_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,4.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may16_21may15_TARG0_K_gcp__step_1_perf_compareD.png]]

not doing too well yet ... will give it a few more steps

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may16_21may15_TARG0_K_gcp__step_1_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may16_21may15_TARG0_K_gcp__step_1_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may16_21may15_TARG0_K_gcp__step_1__with_reward_input.mp4]]

* 21may17
** check 21may15_TARG0_K_gcp__step_6_

python -i simdat.py backupcfg/21may15_TARG0_K_gcp__step_6_sim.json

EV1 0.02 Hz
EA 1.31 Hz
IA 2.53 Hz
IAL 3.59 Hz
EA2 0.09 Hz
IA2 1.2 Hz
IA2L 1.72 Hz
EMDOWN 0.19 Hz
EMUP 0.19 Hz
IM 1.39 Hz
IML 2.06 Hz

ax=plotPerf(actreward,yl=(0,.51))
savefig(gifpath()+'perf.png') # [[./gif/21may17_21may15_TARG0_K_gcp__step_6_perf.png]]

lfn = ['21may15_TARG0_K_gcp__step_' + str(i) + '_' for i in range(7)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,1.01))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may17_21may15_TARG0_K_gcp__step_6_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may17_21may15_TARG0_K_gcp__step_6_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may17_21may15_TARG0_K_gcp__step_6_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may17_21may15_TARG0_K_gcp__step_6_all_steps_avg_weight.png]]

weights changing only very slowly...

## fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)

** check 21may15_TARG0_K_gcp__step_7_

python -i simdat.py backupcfg/21may15_TARG0_K_gcp__step_7_sim.json

EV1 0.02 Hz
EA 1.29 Hz
IA 2.5 Hz
IAL 3.54 Hz
EA2 0.09 Hz
IA2 1.2 Hz
IA2L 1.72 Hz
EMDOWN 0.19 Hz
EMUP 0.19 Hz
IM 1.38 Hz
IML 2.06 Hz

ax=plotPerf(actreward,yl=(0,1.02))
savefig(gifpath()+'perf.png') # [[./gif/21may17_21may15_TARG0_K_gcp__step_7_perf.png]]

finally better??

lfn = ['21may15_TARG0_K_gcp__step_' + str(i) + '_' for i in range(8)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,1.01))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may17_21may15_TARG0_K_gcp__step_7_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may17_21may15_TARG0_K_gcp__step_7_perf_compareD.png]]
this step does seem better ... 

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may17_21may15_TARG0_K_gcp__step_7_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may17_21may15_TARG0_K_gcp__step_7_all_steps_avg_weight.png]]
EA weights getting noticeably higher...all pops have same shape (based on reward)

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may17_21may15_TARG0_K_gcp__step_7__with_reward_input.mp4]]

** other sim 21may17_TARG0_L_gcp_

include the dir selective neurons with the long tau RL ... for comparison
also reduce number of EA, EA2 ... 

./myrun 30 sn.json

python -i simdat.py backupcfg/21may17_TARG0_L_gcp_sim.json

(buffer=s0)

python multistepSim.py sn.json 30 40 21may17_TARG0_L_gcp_multi

started ~16:17 ...

* 21may18
** check 21may15_TARG0_K_gcp__step_10_

python -i simdat.py backupcfg/21may15_TARG0_K_gcp__step_10_sim.json

EV1 0.02 Hz
EA 1.31 Hz
IA 2.53 Hz
IAL 3.58 Hz
EA2 0.09 Hz
IA2 1.2 Hz
IA2L 1.72 Hz
EMDOWN 0.19 Hz
EMUP 0.19 Hz
IM 1.39 Hz
IML 2.06 Hz

ax=plotPerf(actreward,yl=(0,1.02))
savefig(gifpath()+'perf.png') # [[./gif/21may18_21may15_TARG0_K_gcp__step_10_perf.png]]
does not look better...

lfn = ['21may15_TARG0_K_gcp__step_' + str(i) + '_' for i in range(11)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,1.01))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may18_21may15_TARG0_K_gcp__step_10_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may18_21may15_TARG0_K_gcp__step_10_perf_compareD.png]]

step 7 was best so far ... 

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may18_21may15_TARG0_K_gcp__step_10_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may18_21may15_TARG0_K_gcp__step_10_all_steps_avg_weight.png]]
not sure why that dip in weights occurred (but then followed by a rise)

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may18_21may15_TARG0_K_gcp__step_10__with_reward_input.mp4]]

may want to reduce size of network to the same as used in 21may17_TARG0_L_gcp_ to see if that's a factor...

** check 21may17_TARG0_L_gcp__step_3_

python -i simdat.py backupcfg/21may17_TARG0_L_gcp__step_3_sim.json

EV1 0.02 Hz
EV1DE 0.0 Hz
EV1DNE 0.02 Hz
EV1DN 0.27 Hz
EV1DNW 0.01 Hz
EV1DW 0.0 Hz
EV1DSW 0.0 Hz
EV1DS 0.27 Hz
EV1DSE 0.03 Hz
EA 1.69 Hz
IA 3.62 Hz
IAL 4.32 Hz
EA2 0.15 Hz
IA2 1.27 Hz
IA2L 1.79 Hz
EMDOWN 0.53 Hz
EMUP 0.53 Hz
IM 1.91 Hz
IML 2.95 Hz

rates are better/higher than K sim above

ax=plotPerf(actreward,yl=(0,1.508))
savefig(gifpath()+'perf.png') # [[./gif/21may18_21may17_TARG0_L_gcp__step_3_perf.png]]

that one looks decent...

lfn = ['21may17_TARG0_L_gcp__step_' + str(i) + '_' for i in range(4)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may18_21may17_TARG0_L_gcp__step_3_perf_all_steps_so_far.png]]
might be improving near the end...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may18_21may17_TARG0_L_gcp__step_3_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may18_21may17_TARG0_L_gcp__step_3_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may18_21may17_TARG0_L_gcp__step_3_all_steps_avg_weight.png]]

larger increase of weights in this sim compared to K above ... not clear if it's due to the dir selective neurons or the different
size of the network

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may18_21may17_TARG0_L_gcp__step_3__with_reward_input.mp4]]

** check 21may17_TARG0_L_gcp__step_4_

python -i simdat.py backupcfg/21may17_TARG0_L_gcp__step_4_sim.json

EV1 0.02 Hz
EV1DE 0.0 Hz
EV1DNE 0.02 Hz
EV1DN 0.27 Hz
EV1DNW 0.01 Hz
EV1DW 0.0 Hz
EV1DSW 0.0 Hz
EV1DS 0.27 Hz
EV1DSE 0.03 Hz
EA 1.7 Hz
IA 3.59 Hz
IAL 4.33 Hz
EA2 0.15 Hz
IA2 1.25 Hz
IA2L 1.8 Hz
EMDOWN 0.39 Hz
EMUP 0.39 Hz
IM 1.7 Hz
IML 2.59 Hz

overall rates went down ... noticed some hyperexcitability in this step, right
after a reward was received...

ax=plotPerf(actreward,yl=(0,1.508))
savefig(gifpath()+'perf.png') # [[./gif/21may18_21may17_TARG0_L_gcp__step_4_perf.png]]

lfn = ['21may17_TARG0_L_gcp__step_' + str(i) + '_' for i in range(5)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may18_21may17_TARG0_L_gcp__step_4_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.508),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may18_21may17_TARG0_L_gcp__step_4_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may18_21may17_TARG0_L_gcp__step_4_rast.png]]
xlim((448e3,450e3))
savefig(gifpath()+'rastB.png') # [[./gif/21may18_21may17_TARG0_L_gcp__step_4_rastB.png]] <<-- some short-lived hyperexcit

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may18_21may17_TARG0_L_gcp__step_4_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may18_21may17_TARG0_L_gcp__step_4__with_reward_input.mp4]]


** check 21may17_TARG0_L_gcp__step_6_

python -i simdat.py backupcfg/21may17_TARG0_L_gcp__step_6_sim.json

EV1 0.02 Hz
EV1DE 0.0 Hz
EV1DNE 0.02 Hz
EV1DN 0.26 Hz
EV1DNW 0.01 Hz
EV1DW 0.0 Hz
EV1DSW 0.01 Hz
EV1DS 0.27 Hz
EV1DSE 0.03 Hz
EA 1.68 Hz
IA 3.55 Hz
IAL 4.3 Hz
EA2 0.16 Hz
IA2 1.25 Hz
IA2L 1.8 Hz
EMDOWN 0.27 Hz
EMUP 0.27 Hz
IM 1.57 Hz
IML 2.3 Hz

rates went down again

ax=plotPerf(actreward,yl=(0,1.508))
savefig(gifpath()+'perf.png') # [[./gif/21may19_21may17_TARG0_L_gcp__step_6_perf.png]]

lfn = ['21may17_TARG0_L_gcp__step_' + str(i) + '_' for i in range(7)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may19_21may17_TARG0_L_gcp__step_6_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.508),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may19_21may17_TARG0_L_gcp__step_6_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may19_21may17_TARG0_L_gcp__step_6_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may19_21may17_TARG0_L_gcp__step_6_all_steps_avg_weight.png]]

if weights are up, why are rates down? do not see evidence of depolarization blockade/hyperexcitability ... 
maybe due to more bursty firing, with longer gaps between bursts? 

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may19_21may17_TARG0_L_gcp__step_6__with_reward_input.mp4]]
** check 21may15_TARG0_K_gcp__step_12_

python -i simdat.py backupcfg/21may15_TARG0_K_gcp__step_12_sim.json

EV1 0.02 Hz
EA 1.33 Hz
IA 2.53 Hz
IAL 3.62 Hz
EA2 0.09 Hz
IA2 1.2 Hz
IA2L 1.73 Hz
EMDOWN 0.19 Hz
EMUP 0.19 Hz
IM 1.4 Hz
IML 2.07 Hz

rates barely changed ... EA a drop higher

ax=plotPerf(actreward,yl=(0,2.01))
savefig(gifpath()+'perf.png') # [[./gif/21may19_21may15_TARG0_K_gcp__step_12_perf.png]]
looks good for first 200 s but then decays towards poor performance for rest of duration...

lfn = ['21may15_TARG0_K_gcp__step_' + str(i) + '_' for i in range(13)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,1.01))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may19_21may15_TARG0_K_gcp__step_12_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may19_21may15_TARG0_K_gcp__step_12_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may19_21may15_TARG0_K_gcp__step_12_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may19_21may15_TARG0_K_gcp__step_12_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may19_21may15_TARG0_K_gcp__step_12__with_reward_input.mp4]]

* 21may19
** check 21may15_TARG0_K_gcp__step_14_

python -i simdat.py backupcfg/21may15_TARG0_K_gcp__step_14_sim.json

EV1 0.02 Hz
EA 1.32 Hz
IA 2.54 Hz
IAL 3.62 Hz
EA2 0.1 Hz
IA2 1.2 Hz
IA2L 1.73 Hz
EMDOWN 0.2 Hz
EMUP 0.19 Hz
IM 1.4 Hz
IML 2.07 Hz

rates pretty similar ... 

ax=plotPerf(actreward,yl=(0,1.65))
savefig(gifpath()+'perf.png') # [[./gif/21may19_21may15_TARG0_K_gcp__step_14_perf.png]]
that perf looks pretty good - stays greater or equal to 0.5 (after first hit); and much higher for a large portion

lfn = ['21may15_TARG0_K_gcp__step_' + str(i) + '_' for i in range(15)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,1.01))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may19_21may15_TARG0_K_gcp__step_14_perf_all_steps_so_far.png]]
cumulative masks some of that
ylim((0.2,0.4))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21may19_21may15_TARG0_K_gcp__step_14_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may19_21may15_TARG0_K_gcp__step_14_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may19_21may15_TARG0_K_gcp__step_14_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may19_21may15_TARG0_K_gcp__step_14_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may19_21may15_TARG0_K_gcp__step_14__with_reward_input.mp4]]

** check 21may17_TARG0_L_gcp__step_8_

python -i simdat.py backupcfg/21may17_TARG0_L_gcp__step_8_sim.json

EV1 0.02 Hz
EV1DE 0.0 Hz
EV1DNE 0.02 Hz
EV1DN 0.27 Hz
EV1DNW 0.01 Hz
EV1DW 0.0 Hz
EV1DSW 0.0 Hz
EV1DS 0.26 Hz
EV1DSE 0.03 Hz
EA 1.7 Hz
IA 3.65 Hz
IAL 4.34 Hz
EA2 0.18 Hz
IA2 1.31 Hz
IA2L 1.85 Hz
EMDOWN 0.83 Hz
EMUP 0.82 Hz
IM 2.23 Hz
IML 3.68 Hz

this time the rates have gone up

ax=plotPerf(actreward,yl=(0,0.51))
savefig(gifpath()+'perf.png') # [[./gif/21may19_21may17_TARG0_L_gcp__step_8_perf.png]]
but perf looks ~flat

lfn = ['21may17_TARG0_L_gcp__step_' + str(i) + '_' for i in range(9)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may19_21may17_TARG0_L_gcp__step_8_perf_all_steps_so_far.png]]
or slightly decreasing...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.508),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may19_21may17_TARG0_L_gcp__step_8_perf_compareD.png]]
step 6 still best ...

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may19_21may17_TARG0_L_gcp__step_8_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may19_21may17_TARG0_L_gcp__step_8_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may19_21may17_TARG0_L_gcp__step_8__with_reward_input.mp4]]

* 21may20
** check 21may15_TARG0_K_gcp__step_19_

python -i simdat.py backupcfg/21may15_TARG0_K_gcp__step_19_sim.json

EV1 0.02 Hz
EA 1.32 Hz
IA 2.53 Hz
IAL 3.61 Hz
EA2 0.1 Hz
IA2 1.2 Hz
IA2L 1.75 Hz
EMDOWN 0.2 Hz
EMUP 0.2 Hz
IM 1.41 Hz
IML 2.08 Hz

rates still ~same

ax=plotPerf(actreward,yl=(0,2.02))
savefig(gifpath()+'perf.png') # [[./gif/21may20_21may15_TARG0_K_gcp__step_19_perf.png]]
bad perf on this step

lfn = ['21may15_TARG0_K_gcp__step_' + str(i) + '_' for i in range(20)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,1.01))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may20_21may15_TARG0_K_gcp__step_19_perf_all_steps_so_far.png]]]]]
ylim((0.2,0.4))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21may20_21may15_TARG0_K_gcp__step_19_perf_all_steps_so_farB.png]]
some fluctuations...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may20_21may15_TARG0_K_gcp__step_19_perf_compareD.png]]
best one still step 14...

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may20_21may15_TARG0_K_gcp__step_19_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may20_21may15_TARG0_K_gcp__step_19_all_steps_avg_weight.png]]

#fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)

firing rates still have room to increase ... so perf should be able to improve further ... 

** check 21may17_TARG0_L_gcp__step_14_

python -i simdat.py backupcfg/21may17_TARG0_L_gcp__step_14_sim.json

EV1 0.02 Hz
EV1DE 0.0 Hz
EV1DNE 0.02 Hz
EV1DN 0.27 Hz
EV1DNW 0.01 Hz
EV1DW 0.0 Hz
EV1DSW 0.0 Hz
EV1DS 0.26 Hz
EV1DSE 0.03 Hz
EA 1.71 Hz
IA 3.7 Hz
IAL 4.36 Hz
EA2 0.23 Hz
IA2 1.36 Hz
IA2L 1.95 Hz
EMDOWN 0.73 Hz
EMUP 0.72 Hz
IM 2.16 Hz
IML 3.26 Hz

these firing rates lower...

ax=plotPerf(actreward,yl=(0,1.02))
savefig(gifpath()+'perf.png') # [[./gif/21may20_21may17_TARG0_L_gcp__step_14_perf.png]]

lfn = ['21may17_TARG0_L_gcp__step_' + str(i) + '_' for i in range(15)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may20_21may17_TARG0_L_gcp__step_14_perf_all_steps_so_far.png]]
still has the rise/decay in perf...similar to other sim...the losePoint weight might be too great...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.508),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may20_21may17_TARG0_L_gcp__step_14_perf_compareD.png]]
step 11 looks best so far...

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may20_21may17_TARG0_L_gcp__step_14_rast.png]]
some burstiness in raster...

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may20_21may17_TARG0_L_gcp__step_14_all_steps_avg_weight.png]]

check step 11 ... 

python -i simdat.py backupcfg/21may17_TARG0_L_gcp__step_11_sim.json

EV1 0.02 Hz
EV1DE 0.0 Hz
EV1DNE 0.02 Hz
EV1DN 0.27 Hz
EV1DNW 0.01 Hz
EV1DW 0.0 Hz
EV1DSW 0.0 Hz
EV1DS 0.26 Hz
EV1DSE 0.03 Hz
EA 1.75 Hz
IA 3.78 Hz
IAL 4.42 Hz
EA2 0.22 Hz
IA2 1.36 Hz
IA2L 1.92 Hz
EMDOWN 0.84 Hz
EMUP 0.84 Hz
IM 2.32 Hz
IML 3.58 Hz

these rates higher than step 14 ... indication of better perf/reward

ax=plotPerf(actreward,yl=(0,1.02))
savefig(gifpath()+'perf.png') # [[./gif/21may20_21may17_TARG0_L_gcp__step_11_perf.png]]

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may20_21may17_TARG0_L_gcp__step_11_rast.png]]
some burstiness in raster here too...but not out of control...

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may20_21may17_TARG0_L_gcp__step_11__with_reward_input.mp4]]

** set useSimulatedEnv to 2 to use full 'simulated' pong

  if useSimulatedEnv==1:
    from simplePong import simplePong
    env = simplePong()
  elif useSimulatedEnv==2:
    from simulatePongFull import simulatePong
    env = simulatePong()    
  else:
    ... the standard env ... (Pong)

** test full simulated Pong 21may20_TARG0_M_cycle_

"useSimulatedEnv": 2,

    "rewardcodes": {
        "scorePoint": 2.0,
        "losePoint": -0.25,
        "followTarget": 0.0,
        "avoidTarget": 0.0,
        "hitBall": 1.0
    },

and using single ball speed, top_bottom_rule == 0

./myrun 30 sn.json

python -i simdat.py backupcfg/21may20_TARG0_M_cycle_sim.json

compared to the 21may17_TARG0_L_gcp_ sim, here have to reduce the weights from VD -> EA, VL -> EA 
since the opponent racket contributes to extra acttivation in the network. this way, the EA rates
will be similar to the L network (w/o an opponent)

(buffer=shell)

python multistepSim.py sn.json 30 40 21may20_TARG0_M_cycle_multi

started ~13:04 ...

** check 21may17_TARG0_L_gcp__step_15_

python -i simdat.py backupcfg/21may17_TARG0_L_gcp__step_15_sim.json

EV1 0.02 Hz
EV1DE 0.0 Hz
EV1DNE 0.02 Hz
EV1DN 0.27 Hz
EV1DNW 0.01 Hz
EV1DW 0.0 Hz
EV1DSW 0.01 Hz
EV1DS 0.26 Hz
EV1DSE 0.03 Hz
EA 1.77 Hz
IA 3.86 Hz
IAL 4.51 Hz
EA2 0.27 Hz
IA2 1.5 Hz
IA2L 2.06 Hz
EMDOWN 1.81 Hz
EMUP 1.8 Hz
IM 3.39 Hz
IML 5.34 Hz

firing rates higher - hopefully not hyperexcitable

ax=plotPerf(actreward,yl=(0,2.01))
savefig(gifpath()+'perf.png') # [[./gif/21may20_21may17_TARG0_L_gcp__step_15_perf.png]]

pretty good perf most of the time

lfn = ['21may17_TARG0_L_gcp__step_' + str(i) + '_' for i in range(16)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,0.6))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may20_21may17_TARG0_L_gcp__step_15_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may20_21may17_TARG0_L_gcp__step_15_perf_compareD.png]]
looks better than step 11

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may20_21may17_TARG0_L_gcp__step_15_rast.png]]
raster still looks ok 

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may20_21may17_TARG0_L_gcp__step_15_all_steps_avg_weight.png]]

weights are getting high ... network probably will get hyperexcitable soon 

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may20_21may17_TARG0_L_gcp__step_15__with_reward_input.mp4]]

* 21may21
** check 21may15_TARG0_K_gcp__step_23_

python -i simdat.py backupcfg/21may15_TARG0_K_gcp__step_23_sim.json

EV1 0.02 Hz
EA 1.35 Hz
IA 2.57 Hz
IAL 3.67 Hz
EA2 0.1 Hz
IA2 1.21 Hz
IA2L 1.76 Hz
EMDOWN 0.21 Hz
EMUP 0.21 Hz
IM 1.42 Hz
IML 2.1 Hz

rates slightly increased

ax=plotPerf(actreward,yl=(0,2.02))
savefig(gifpath()+'perf.png') # [[./gif/21may21_21may15_TARG0_K_gcp__step_23_perf.png]]
not as bad as some of the previous steps...

lfn = ['21may15_TARG0_K_gcp__step_' + str(i) + '_' for i in range(24)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,1.01))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may21_21may15_TARG0_K_gcp__step_23_perf_all_steps_so_far.png]]
ylim((0.2,0.4))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21may21_21may15_TARG0_K_gcp__step_23_perf_all_steps_so_farB.png]]
seems to be increasing slowly over last few steps...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may21_21may15_TARG0_K_gcp__step_23_perf_compareD.png]]
step 14 still the best...

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may21_21may15_TARG0_K_gcp__step_23_rast.png]]

still have low firing rates, so there's room for perf improvement before hyperexcit...

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may21_21may15_TARG0_K_gcp__step_23_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may21_21may15_TARG0_K_gcp__step_23__with_reward_input.mp4]]

** check 21may17_TARG0_L_gcp__step_20_

python -i simdat.py backupcfg/21may17_TARG0_L_gcp__step_20_sim.json

EV1 0.02 Hz
EV1DE 0.0 Hz
EV1DNE 0.02 Hz
EV1DN 0.26 Hz
EV1DNW 0.01 Hz
EV1DW 0.0 Hz
EV1DSW 0.0 Hz
EV1DS 0.26 Hz
EV1DSE 0.03 Hz
EA 1.95 Hz
IA 4.51 Hz
IAL 4.96 Hz
EA2 0.81 Hz
IA2 2.66 Hz
IA2L 3.27 Hz
EMDOWN 30.72 Hz
EMUP 30.77 Hz
IM 26.87 Hz
IML 32.18 Hz

EM rates too high ... 

ax=plotPerf(actreward,yl=(0,2.01))
savefig(gifpath()+'perf.png') # [[./gif/21may21_21may17_TARG0_L_gcp__step_20_perf.png]]
but perf still pretty good...

lfn = ['21may17_TARG0_L_gcp__step_' + str(i) + '_' for i in range(21)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.25,0.51))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may21_21may17_TARG0_L_gcp__step_20_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,3.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may21_21may17_TARG0_L_gcp__step_20_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may21_21may17_TARG0_L_gcp__step_20_rast.png]]
xlim((496e3,498e3))
savefig(gifpath()+'rastB.png') # [[./gif/21may21_21may17_TARG0_L_gcp__step_20_rastB.png]]
xlim((494e3,496e3))
there is a lot of hyperexcitability ... sometimes lasts for a while ... worth checking the video ... 
savefig(gifpath()+'rastC.png') # [[./gif/21may21_21may17_TARG0_L_gcp__step_20_rastC.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may21_21may17_TARG0_L_gcp__step_20_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may21_21may17_TARG0_L_gcp__step_20__with_reward_input.mp4]]

** check 21may20_TARG0_M_cycle__step_5_ -->> looks ok but no point for now since cant score points

python -i simdat.py backupcfg/21may20_TARG0_M_cycle__step_5_sim.json

EV1 0.02 Hz
EV1DE 0.0 Hz
EV1DNE 0.02 Hz
EV1DN 0.37 Hz
EV1DNW 0.01 Hz
EV1DW 0.0 Hz
EV1DSW 0.02 Hz
EV1DS 0.36 Hz
EV1DSE 0.02 Hz
EA 1.66 Hz
IA 4.82 Hz
IAL 4.66 Hz
EA2 0.23 Hz
IA2 1.35 Hz
IA2L 1.91 Hz
EMDOWN 0.34 Hz
EMUP 0.34 Hz
IM 2.05 Hz
IML 2.61 Hz

ax=plotPerf(actreward,yl=(0,1.01))
savefig(gifpath()+'perf.png') # [[./gif/21may21_21may20_TARG0_M_cycle__step_5_perf.png]]

lfn = ['21may20_TARG0_M_cycle__step_' + str(i) + '_' for i in range(6)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.0,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may21_21may20_TARG0_M_cycle__step_5_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may21_21may20_TARG0_M_cycle__step_5_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may21_21may20_TARG0_M_cycle__step_5_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may21_21may20_TARG0_M_cycle__step_5_all_steps_avg_weight.png]]

python -i simdat.py backupcfg/21may20_TARG0_M_cycle__step_4_sim.json

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may21_21may20_TARG0_M_cycle__step_5__with_reward_input.mp4]]

** need to deal with hyperexcit issue

adjust score/lose values as weights/rate increase? add EIPlast ... ? 

** 21may21_TARG0_N_cycle_

does higher resolution for directional neurons help perf (80x80 instead of 20x20) ?

./myrun 30 sn.json

python -i simdat.py backupcfg/21may21_TARG0_N_cycle_sim.json

had to increase number of inputs from VD -> EA to ~preserve firing rates of EA and the info
they receive about motion ... (6400 vs 400 is 16X increase but same fraction of visual field
is occupied by objects...ideally would have same fraction of field covered but that leads to
hyperexcitability)

python multistepSim.py sn.json 30 40 21may21_TARG0_N_cycle_multi

started ~12:08 ...

** stopped 21may17_TARG0_L_gcp_ during step 21 since became too hyperexcitable

might still have room for improvement but may need an additional mechanism to prevent the hyperexcitability
 a. EIPlast 
 b. reducing/increasing excitatory noise as rates increase/decrease
 c. adjusting reward/punishment values as rates change

EIPlast is more expensive -- more synapses required
changing noise is possible but shifts excitability of neurons 
changing reward/punish values does not increase capacity of network

easiest is to try EIPlast ... 

can do same as 21may17_TARG0_L_gcp_ but with EIPlast ... 

21may21_TARG0_L_EIP_gcp_

./myrun 30 sn.json

python -i simdat.py backupcfg/21may21_TARG0_L_EIP_gcp_sim.json

python multistepSim.py sn.json 30 40 21may21_TARG0_L_EIP_gcp_multi

started ~14:00 ...

* 21may22
** check 21may15_TARG0_K_gcp__step_30_

python -i simdat.py backupcfg/21may15_TARG0_K_gcp__step_30_sim.json

EV1 0.02 Hz
EA 1.36 Hz
IA 2.58 Hz
IAL 3.71 Hz
EA2 0.11 Hz
IA2 1.22 Hz
IA2L 1.78 Hz
EMDOWN 0.22 Hz
EMUP 0.22 Hz
IM 1.43 Hz
IML 2.11 Hz

rates only went up a drop...

ax=plotPerf(actreward,yl=(0,2.02))
savefig(gifpath()+'perf.png') # [[./gif/21may23_21may15_TARG0_K_gcp__step_30_perf.png]]
low perf

lfn = ['21may15_TARG0_K_gcp__step_' + str(i) + '_' for i in range(31)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,1.01))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may23_21may15_TARG0_K_gcp__step_30_perf_all_steps_so_far.png]]
ylim((0.2,0.4))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21may23_21may15_TARG0_K_gcp__step_30_perf_all_steps_so_farB.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may23_21may15_TARG0_K_gcp__step_30_perf_compareD.png]]
step 14 still the best...

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may23_21may15_TARG0_K_gcp__step_30_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may23_21may15_TARG0_K_gcp__step_30_all_steps_avg_weight.png]]

## fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)

since perf not going anywhere, may adjust the losePoint (make it lower) and restart?? next step may be doing better, so will let it continue...
and the EA weights are getting close to EA2,EM levels, so soon EA2,EM should follow...

** check 21may21_TARG0_L_EIP_gcp__step_4_

python -i simdat.py backupcfg/21may21_TARG0_L_EIP_gcp__step_4_sim.json

EV1 0.02 Hz
EV1DE 0.0 Hz
EV1DNE 0.02 Hz
EV1DN 0.26 Hz
EV1DNW 0.0 Hz
EV1DW 0.0 Hz
EV1DSW 0.0 Hz
EV1DS 0.27 Hz
EV1DSE 0.03 Hz
EA 1.67 Hz
IA 3.62 Hz
IAL 4.3 Hz
EA2 0.16 Hz
IA2 1.26 Hz
IA2L 1.81 Hz
EMDOWN 0.42 Hz
EMUP 0.42 Hz
IM 1.74 Hz
IML 2.62 Hz

ax=plotPerf(actreward,yl=(0,2.01))
savefig(gifpath()+'perf.png') # [[./gif/21may23_21may21_TARG0_L_EIP_gcp__step_4_perf.png]]
low perf but early step...

lfn = ['21may21_TARG0_L_EIP_gcp__step_' + str(i) + '_' for i in range(5)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,3.01))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may23_21may21_TARG0_L_EIP_gcp__step_4_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may23_21may21_TARG0_L_EIP_gcp__step_4_perf_compareD.png]]
step 2 looks good...strange how the performance jumps up and down so much across the steps...

python -i simdat.py backupcfg/21may21_TARG0_L_EIP_gcp__step_2_sim.json

EV1 0.02 Hz
EV1DE 0.0 Hz
EV1DNE 0.02 Hz
EV1DN 0.27 Hz
EV1DNW 0.01 Hz
EV1DW 0.0 Hz
EV1DSW 0.01 Hz
EV1DS 0.27 Hz
EV1DSE 0.03 Hz
EA 1.68 Hz
IA 3.72 Hz
IAL 4.31 Hz
EA2 0.15 Hz
IA2 1.27 Hz
IA2L 1.8 Hz
EMDOWN 0.53 Hz
EMUP 0.53 Hz
IM 1.91 Hz
IML 2.98 Hz

ax=plotPerf(actreward,yl=(0,2.01))
savefig(gifpath()+'perf.png') # [[./gif/21may23_21may21_TARG0_L_EIP_gcp__step_2_perf.png]]

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may23_21may21_TARG0_L_EIP_gcp__step_2_rast.png]]

lfn = ['21may21_TARG0_L_EIP_gcp__step_' + str(i) + '_' for i in range(5)]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may23_21may21_TARG0_L_EIP_gcp__step_2_all_steps_avg_weight.png]]
savefig(gifpath()+'all_steps_avg_weightB.png') # [[./gif/21may23_21may21_TARG0_L_EIP_gcp__step_2_all_steps_avg_weightB.png]]
weights rising, then start to decay ... not clear which direction they'll go next ... possible that there's too much inhib
in the network via EIPlast and that suppresses the activity too much ... 

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may23_21may21_TARG0_L_EIP_gcp__step_2__with_reward_input.mp4]]
* 21may24
** check 21may15_TARG0_K_gcp__step_36_

python -i simdat.py backupcfg/21may15_TARG0_K_gcp__step_36_sim.json

EV1 0.02 Hz
EA 1.38 Hz
IA 2.63 Hz
IAL 3.79 Hz
EA2 0.13 Hz
IA2 1.25 Hz
IA2L 1.83 Hz
EMDOWN 0.23 Hz
EMUP 0.23 Hz
IM 1.46 Hz
IML 2.15 Hz

rates are a tiny bit higher

ax=plotPerf(actreward,yl=(0,2.02))
savefig(gifpath()+'perf.png') # [[./gif/21may24_21may15_TARG0_K_gcp__step_36_perf.png]]

has good levels of perf for first 300 s (1.0 and above), then drops to decent (~0.5)

lfn = ['21may15_TARG0_K_gcp__step_' + str(i) + '_' for i in range(37)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,1.01))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may24_21may15_TARG0_K_gcp__step_36_perf_all_steps_so_far.png]]
ylim((0.2,0.4))
savefig(gifpath()+'perf_all_steps_so_farB.png') # [[./gif/21may24_21may15_TARG0_K_gcp__step_36_perf_all_steps_so_farB.png]]
looks like it's rising near the end...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may24_21may15_TARG0_K_gcp__step_36_perf_compareD.png]]
some of the earlier steps look good too...

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may24_21may15_TARG0_K_gcp__step_36_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may24_21may15_TARG0_K_gcp__step_36_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may24_21may15_TARG0_K_gcp__step_36__with_reward_input.mp4]]

** check 21may21_TARG0_L_EIP_gcp__step_10_

python -i simdat.py backupcfg/21may21_TARG0_L_EIP_gcp__step_10_sim.json

EV1 0.02 Hz
EV1DE 0.0 Hz
EV1DNE 0.02 Hz
EV1DN 0.27 Hz
EV1DNW 0.01 Hz
EV1DW 0.0 Hz
EV1DSW 0.0 Hz
EV1DS 0.27 Hz
EV1DSE 0.03 Hz
EA 1.75 Hz
IA 3.85 Hz
IAL 4.49 Hz
EA2 0.21 Hz
IA2 1.33 Hz
IA2L 1.91 Hz
EMDOWN 0.55 Hz
EMUP 0.54 Hz
IM 1.98 Hz
IML 2.89 Hz

ax=plotPerf(actreward,yl=(0,2.01))
savefig(gifpath()+'perf.png') # [[./gif/21may24_21may21_TARG0_L_EIP_gcp__step_10_perf.png]]

lfn = ['21may21_TARG0_L_EIP_gcp__step_' + str(i) + '_' for i in range(11)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1.51))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may24_21may21_TARG0_L_EIP_gcp__step_10_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may24_21may21_TARG0_L_EIP_gcp__step_10_perf_compareD.png]]
earlier step decent...

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may24_21may21_TARG0_L_EIP_gcp__step_10_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may24_21may21_TARG0_L_EIP_gcp__step_10_all_steps_avg_weight.png]]

# fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)

** check 21may21_TARG0_N_cycle__step_18_

python -i simdat.py backupcfg/21may21_TARG0_N_cycle__step_18_sim.json

EV1 0.02 Hz
EV1DE 0.0 Hz
EV1DNE 0.0 Hz
EV1DN 0.04 Hz
EV1DNW 0.0 Hz
EV1DW 0.0 Hz
EV1DSW 0.0 Hz
EV1DS 0.04 Hz
EV1DSE 0.01 Hz
EA 1.36 Hz
IA 2.76 Hz
IAL 3.73 Hz
EA2 0.12 Hz
IA2 1.22 Hz
IA2L 1.77 Hz
EMDOWN 0.23 Hz
EMUP 0.23 Hz
IM 1.48 Hz
IML 2.15 Hz

ax=plotPerf(actreward,yl=(0,0.65))
savefig(gifpath()+'perf.png') # [[./gif/21may24_21may21_TARG0_N_cycle__step_18_perf.png]]

lfn = ['21may21_TARG0_N_cycle__step_' + str(i) + '_' for i in range(19)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.2,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may24_21may21_TARG0_N_cycle__step_18_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may24_21may21_TARG0_N_cycle__step_18_perf_compareD.png]]
step 6 or 7 looked best...

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may24_21may21_TARG0_N_cycle__step_18_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may24_21may21_TARG0_N_cycle__step_18_all_steps_avg_weight.png]]

## fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)

** population of noise neurons -> or simpler?

noise neurons would get inputs from noisy netstims and project to other populations with plastic synapses
the synapses would get modulated with RL plasticity but with the opposite sign compared to the non-noise RL synapses
that way, as behavior is learned, the noise is reduced

perhaps simpler approach more effective (w/o RL) ... 

** check 21may15_TARG0_K_gcp__step_39_  

python -i simdat.py backupcfg/21may15_TARG0_K_gcp__step_39_sim.json

EV1 0.02 Hz
EA 1.4 Hz
IA 2.65 Hz
IAL 3.81 Hz
EA2 0.13 Hz
IA2 1.26 Hz
IA2L 1.84 Hz
EMDOWN 0.24 Hz
EMUP 0.24 Hz
IM 1.47 Hz
IML 2.16 Hz

again, rates are only a tiny bit higher

ax=plotPerf(actreward,yl=(0,2.02))
savefig(gifpath()+'perf.png') # [[./gif/21may25_21may15_TARG0_K_gcp__step_39_perf.png]]

perf low this step

lfn = ['21may15_TARG0_K_gcp__step_' + str(i) + '_' for i in range(40)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,1.01))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may25_21may15_TARG0_K_gcp__step_39_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may25_21may15_TARG0_K_gcp__step_39_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may25_21may15_TARG0_K_gcp__step_39_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may25_21may15_TARG0_K_gcp__step_39_all_steps_avg_weight.png]]

# fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)

** 21may15_TARG0_K_gcp_ multistep finished 40 steps, can continue as 21may24_TARG0_K2_gcp_

cp backupcfg/21may15_TARG0_K_gcp_sim.json ./sn.json

then adjust to resume sim from
data/21may15_TARG0_K_gcp__step_39_synWeights_final.pkl

and name to 21may24_TARG0_K2_gcp_
and make sure duration = 500e3

python multistepSim.py sn.json 30 40 21may24_TARG0_K2_gcp_multi

started ~22:22 ...

* 21may25
** check 21may24_TARG0_K2_gcp__step_1_  

python -i simdat.py backupcfg/21may24_TARG0_K2_gcp__step_0_sim.json

EV1 0.02 Hz
EA 1.41 Hz
IA 2.67 Hz
IAL 3.83 Hz
EA2 0.14 Hz
IA2 1.26 Hz
IA2L 1.85 Hz
EMDOWN 0.25 Hz
EMUP 0.24 Hz
IM 1.47 Hz
IML 2.17 Hz

ax=plotPerf(actreward,yl=(0,2.02))
savefig(gifpath()+'perf.png') # [[./gif/21may25_21may24_TARG0_K2_gcp__step_0_perf.png]]

lfn = ['21may15_TARG0_K_gcp__step_' + str(i) + '_' for i in range(40)]
for i in range(2): lfn.append('21may24_TARG0_K2_gcp__step_'+str(i)+'_')

pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.2,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may25_21may24_TARG0_K2_gcp__step_0_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may25_21may24_TARG0_K2_gcp__step_0_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may25_21may24_TARG0_K2_gcp__step_0_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may25_21may24_TARG0_K2_gcp__step_0_all_steps_avg_weight.png]]

# fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)

** check 21may21_TARG0_L_EIP_gcp__step_14_

python -i simdat.py backupcfg/21may21_TARG0_L_EIP_gcp__step_14_sim.json

EV1 0.02 Hz
EV1DE 0.0 Hz
EV1DNE 0.02 Hz
EV1DN 0.27 Hz
EV1DNW 0.01 Hz
EV1DW 0.0 Hz
EV1DSW 0.0 Hz
EV1DS 0.26 Hz
EV1DSE 0.03 Hz
EA 1.72 Hz
IA 3.92 Hz
IAL 4.58 Hz
EA2 0.37 Hz
IA2 1.67 Hz
IA2L 2.29 Hz
EMDOWN 3.43 Hz
EMUP 3.41 Hz
IM 5.16 Hz
IML 7.3 Hz

rates high

ax=plotPerf(actreward,yl=(0,2.01))
savefig(gifpath()+'perf.png') # [[./gif/21may25_21may21_TARG0_L_EIP_gcp__step_14_perf.png]]
perf good in first 200 s

lfn = ['21may21_TARG0_L_EIP_gcp__step_' + str(i) + '_' for i in range(15)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1.51))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may25_21may21_TARG0_L_EIP_gcp__step_14_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may25_21may21_TARG0_L_EIP_gcp__step_14_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may25_21may21_TARG0_L_EIP_gcp__step_14_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may25_21may21_TARG0_L_EIP_gcp__step_14_all_steps_avg_weight.png]]

plotHitMiss(actreward,asratio=False,asbin=False,ax=gca())

lhit,lmiss = [],[]
for pda in lpda: 
  hit,miss = plotHitMiss(pda,asratio=False,asbin=False,ax=gca())
  lhit.append(hit); lmiss.append(miss)

plot(lhit,'r'); plot(lhit,'ro')
plot(lmiss,'g'); plot(lmiss,'go')
savefig(gifpath()+'hit_miss_total.png') # [[./gif/21may25_21may21_TARG0_L_EIP_gcp__step_14_hit_miss_total.png]]
not much of a trend, except for at the end - hits (red) are increasing a little (but not maximum number of hits - which occurred
in step 2)
np.argmax(lhit) # 2
np.argmin(lmiss) # 2

plot(np.array(lhit)/lmiss,'k'); plot(np.array(lhit)/lmiss,'ko')
xlabel('Step'); ylabel('Hit/miss ratio')
savefig(gifpath()+'hit_miss_ratio.png') # [[./gif/21may25_21may21_TARG0_L_EIP_gcp__step_14_hit_miss_ratio.png]]

easier to interpret that rather than cumulative hit/miss over time for each step

# fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)

** check 21may21_TARG0_N_cycle__step_24_

python -i simdat.py backupcfg/21may21_TARG0_N_cycle__step_24_sim.json

EV1 0.02 Hz
EV1DE 0.0 Hz
EV1DNE 0.01 Hz
EV1DN 0.04 Hz
EV1DNW 0.0 Hz
EV1DW 0.0 Hz
EV1DSW 0.0 Hz
EV1DS 0.04 Hz
EV1DSE 0.01 Hz
EA 1.38 Hz
IA 2.8 Hz
IAL 3.77 Hz
EA2 0.14 Hz
IA2 1.27 Hz
IA2L 1.83 Hz
EMDOWN 0.54 Hz
EMUP 0.53 Hz
IM 1.89 Hz
IML 2.93 Hz

ax=plotPerf(actreward,yl=(0,0.65))
savefig(gifpath()+'perf.png') # [[./gif/21may25_21may21_TARG0_N_cycle__step_24_perf.png]]

lfn = ['21may21_TARG0_N_cycle__step_' + str(i) + '_' for i in range(25)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.2,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may25_21may21_TARG0_N_cycle__step_24_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may25_21may21_TARG0_N_cycle__step_24_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may25_21may21_TARG0_N_cycle__step_24_rast.png]]

lhit,lmiss = [],[]
for pda in lpda: 
  hit,miss = plotHitMiss(pda,asratio=False,asbin=False,ax=gca())
  lhit.append(hit); lmiss.append(miss)

plot(lhit,'r'); plot(lhit,'ro')
plot(lmiss,'g'); plot(lmiss,'go')
savefig(gifpath()+'hit_miss_total.png') # [[./gif/21may25_21may21_TARG0_N_cycle__step_24_hit_miss_total.png]]
np.argmax(lhit), np.argmin(lmiss) # (6, 6)

cla(); lrat = plotHitMissRatioPerStep(lpda)
savefig(gifpath()+'hit_miss_ratio.png') # [[./gif/21may25_21may21_TARG0_N_cycle__step_24_hit_miss_ratio.png]]
np.argmax(lrat) # 6
lrat[6] # 0.6129032258064516

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may25_21may21_TARG0_N_cycle__step_24_all_steps_avg_weight.png]]

## fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)

** stopped 21may24_TARG0_K2_gcp_ -- had wrong losePoint value (-0.1 instead of -0.25)
** start 21may25_TARG0_K2_gcp_

python multistepSim.py sn.json 30 40 21may25_TARG0_K2_gcp_multi

started ~21:12 ...

* 21may26
** check 21may25_TARG0_K2_gcp__step_1_   , 21may15_TARG0_K_gcp__step_31_ best so far (0.88 at end)

python -i simdat.py backupcfg/21may25_TARG0_K2_gcp__step_1_sim.json

EV1 0.02 Hz
EA 1.39 Hz
IA 2.65 Hz
IAL 3.8 Hz
EA2 0.14 Hz
IA2 1.26 Hz
IA2L 1.85 Hz
EMDOWN 0.25 Hz
EMUP 0.24 Hz
IM 1.48 Hz
IML 2.16 Hz

ax=plotPerf(actreward,yl=(0,2.02))
savefig(gifpath()+'perf.png') # [[./gif/21may26_21may25_TARG0_K2_gcp__step_1_perf.png]]

lfn = ['21may15_TARG0_K_gcp__step_' + str(i) + '_' for i in range(40)]
for i in range(2): lfn.append('21may25_TARG0_K2_gcp__step_'+str(i)+'_')

pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.2,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may26_21may25_TARG0_K2_gcp__step_1_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may26_21may25_TARG0_K2_gcp__step_1_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may26_21may25_TARG0_K2_gcp__step_1_rast.png]]

cla(); lrat = plotHitMissRatioPerStep(lpda)
savefig(gifpath()+'hit_miss_ratio.png') # [[./gif/21may26_21may25_TARG0_K2_gcp__step_1_hit_miss_ratio.png]]
no clear progression but step 31 has good hit/miss ratio ... ~0.9
np.argmax(lrat) # 31
lrat[np.argmax(lrat)] # 0.88

should take a look at that one ... 

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may26_21may25_TARG0_K2_gcp__step_1_all_steps_avg_weight.png]]

python -i simdat.py backupcfg/21may15_TARG0_K_gcp__step_31_sim.json

EV1 0.02 Hz
EA 1.33 Hz
IA 2.56 Hz
IAL 3.66 Hz
EA2 0.11 Hz
IA2 1.23 Hz
IA2L 1.79 Hz
EMDOWN 0.22 Hz
EMUP 0.22 Hz
IM 1.43 Hz
IML 2.11 Hz

ax=plotPerf(actreward,yl=(0,1.7))
savefig(gifpath()+'perf.png') # [[./gif/21may26_21may15_TARG0_K_gcp__step_31_perf.png]]

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may26_21may15_TARG0_K_gcp__step_31_rast.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may26_21may15_TARG0_K_gcp__step_31__with_reward_input.mp4]]

** check 21may21_TARG0_L_EIP_gcp__step_18_ -->> super hyperexcitable; stopped for now

python -i simdat.py backupcfg/21may21_TARG0_L_EIP_gcp__step_18_sim.json

EV1 0.02 Hz
EV1DE 0.0 Hz
EV1DNE 0.02 Hz
EV1DN 0.26 Hz
EV1DNW 0.01 Hz
EV1DW 0.0 Hz
EV1DSW 0.0 Hz
EV1DS 0.26 Hz
EV1DSE 0.03 Hz
EA 1.9 Hz
IA 4.51 Hz
IAL 5.01 Hz
EA2 0.74 Hz
IA2 2.5 Hz
IA2L 3.02 Hz
EMDOWN 24.86 Hz
EMUP 24.88 Hz
IM 22.99 Hz
IML 28.67 Hz

rates too high...

ax=plotPerf(actreward,yl=(0,2.01))
savefig(gifpath()+'perf.png') # [[./gif/21may26_21may21_TARG0_L_EIP_gcp__step_18_perf.png]]
perf low

lfn = ['21may21_TARG0_L_EIP_gcp__step_' + str(i) + '_' for i in range(19)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0,1.51))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may26_21may21_TARG0_L_EIP_gcp__step_18_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may26_21may21_TARG0_L_EIP_gcp__step_18_perf_compareD.png]]

cla(); lrat = plotHitMissRatioPerStep(lpda)
savefig(gifpath()+'hit_miss_ratio.png') # [[./gif/21may26_21may21_TARG0_L_EIP_gcp__step_18_hit_miss_ratio.png]]
np.argmax(lrat) # 2
lrat[np.argmax(lrat)] # 0.6896551724137931

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may26_21may21_TARG0_L_EIP_gcp__step_18_rast.png]]
xlim((100e3,102e3))
savefig(gifpath()+'rastB.png') # [[./gif/21may26_21may21_TARG0_L_EIP_gcp__step_18_rastB.png]] <<-- that super-hyper-excitable
spiking pattern will not perform well

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,2,1); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP','EA','EA2'],lclr=['r','b','g','c'],plotindiv=False)
subplot(1,2,2); popwtsI = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['IA','IM','IA2','IAL','IML','IA2L'],lclr=['r','b','g','c','m','y'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may26_21may21_TARG0_L_EIP_gcp__step_18_all_steps_avg_weight.png]]

# fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)

** check 21may21_TARG0_N_cycle__step_29_

python -i simdat.py backupcfg/21may21_TARG0_N_cycle__step_29_sim.json

EV1 0.02 Hz
EV1DE 0.0 Hz
EV1DNE 0.01 Hz
EV1DN 0.04 Hz
EV1DNW 0.0 Hz
EV1DW 0.0 Hz
EV1DSW 0.0 Hz
EV1DS 0.04 Hz
EV1DSE 0.01 Hz
EA 1.42 Hz
IA 2.87 Hz
IAL 3.89 Hz
EA2 0.17 Hz
IA2 1.33 Hz
IA2L 1.9 Hz
EMDOWN 0.78 Hz
EMUP 0.77 Hz
IM 2.21 Hz
IML 3.45 Hz

ax=plotPerf(actreward,yl=(0,2.02))
savefig(gifpath()+'perf.png') # [[./gif/21may26_21may21_TARG0_N_cycle__step_29_perf.png]]

lfn = ['21may21_TARG0_N_cycle__step_' + str(i) + '_' for i in range(30)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.2,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may26_21may21_TARG0_N_cycle__step_29_perf_all_steps_so_far.png]]
perf looks like generally rising near the end...

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may26_21may21_TARG0_N_cycle__step_29_perf_compareD.png]]

cla(); lrat = plotHitMissRatioPerStep(lpda)
savefig(gifpath()+'hit_miss_ratio.png') # [[./gif/21may26_21may21_TARG0_N_cycle__step_29_hit_miss_ratio.png]]
np.argmax(lrat) # 6
lrat[6] # 0.6129032258064516
step 6 still best ... 

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may26_21may21_TARG0_N_cycle__step_29_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may26_21may21_TARG0_N_cycle__step_29_all_steps_avg_weight.png]]

## fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
** 21may26_TARG0_O_gcp_  -- test even larger EA(2400),EA2(1200) 

interneurons in A, A2 layers increased accordingly...kept convergence same (so that means information
is a little sparser)

./myrun 30 sn.json

python -i simdat.py backupcfg/21may26_TARG0_O_gcp_sim.json

python multistepSim.py sn.json 30 40 21may26_TARG0_O_gcp_multi

started ~12:53 

* 21may27
** check 21may25_TARG0_K2_gcp__step_6_   K step 31 still best, but recent steps decent too

python -i simdat.py backupcfg/21may25_TARG0_K2_gcp__step_6_sim.json

EV1 0.02 Hz
EA 1.41 Hz
IA 2.68 Hz
IAL 3.84 Hz
EA2 0.15 Hz
IA2 1.28 Hz
IA2L 1.88 Hz
EMDOWN 0.27 Hz
EMUP 0.26 Hz
IM 1.5 Hz
IML 2.2 Hz

ax=plotPerf(actreward,yl=(0,2.02))
savefig(gifpath()+'perf.png') # [[./gif/21may27_21may25_TARG0_K2_gcp__step_6_perf.png]]

lfn = ['21may15_TARG0_K_gcp__step_' + str(i) + '_' for i in range(40)]
for i in range(7): lfn.append('21may25_TARG0_K2_gcp__step_'+str(i)+'_')

pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.2,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may27_21may25_TARG0_K2_gcp__step_6_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may27_21may25_TARG0_K2_gcp__step_6_perf_compareD.png]]
step 31 still best ... 

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may27_21may25_TARG0_K2_gcp__step_6_rast.png]]

cla(); lrat = plotHitMissRatioPerStep(lpda)
savefig(gifpath()+'hit_miss_ratio.png') # [[./gif/21may27_21may25_TARG0_K2_gcp__step_6_hit_miss_ratio.png]]
step 31 still best but some of the recent steps are almost as good (~0.67)...model still has room for improvement
np.argmax(lrat) # 31
lrat[np.argmax(lrat)] # 0.88

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may27_21may25_TARG0_K2_gcp__step_6_all_steps_avg_weight.png]]

# fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
** check 21may26_TARG0_O_cycle__step_1_

python -i simdat.py backupcfg/21may26_TARG0_O_gcp__step_1_sim.json

EV1 0.02 Hz
EA 1.3 Hz
IA 2.52 Hz
IAL 3.59 Hz
EA2 0.09 Hz
IA2 1.2 Hz
IA2L 1.71 Hz
EMDOWN 0.18 Hz
EMUP 0.18 Hz
IM 1.38 Hz
IML 2.05 Hz

ax=plotPerf(actreward,yl=(0,1.01))
savefig(gifpath()+'perf.png') # [[./gif/21may27_21may26_TARG0_O_gcp__step_1_perf.png]]

lfn = ['21may26_TARG0_O_gcp__step_' + str(i) + '_' for i in range(2)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,1.01))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may27_21may26_TARG0_O_gcp__step_1_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,1.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may27_21may26_TARG0_O_gcp__step_1_perf_compareD.png]]

cla(); lrat = plotHitMissRatioPerStep(lpda)
savefig(gifpath()+'hit_miss_ratio.png') # [[./gif/21may27_21may26_TARG0_O_gcp__step_1_hit_miss_ratio.png]]
need more steps to see progress...first step already looked decent...

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may27_21may26_TARG0_O_gcp__step_1_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may27_21may26_TARG0_O_gcp__step_1_all_steps_avg_weight.png]]

python -i simdat.py backupcfg/21may26_TARG0_O_gcp__step_0_sim.json

EV1 0.02 Hz
EA 1.3 Hz
IA 2.52 Hz
IAL 3.59 Hz
EA2 0.09 Hz
IA2 1.2 Hz
IA2L 1.71 Hz
EMDOWN 0.18 Hz
EMUP 0.18 Hz
IM 1.38 Hz
IML 2.05 Hz

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may27_21may26_TARG0_O_gcp__step_0__with_reward_input.mp4]]

** check 21may21_TARG0_N_cycle__step_35_ -->> step 32 looks good (~0.95 at end)

python -i simdat.py backupcfg/21may21_TARG0_N_cycle__step_35_sim.json

EV1 0.02 Hz
EV1DE 0.0 Hz
EV1DNE 0.0 Hz
EV1DN 0.04 Hz
EV1DNW 0.0 Hz
EV1DW 0.0 Hz
EV1DSW 0.0 Hz
EV1DS 0.04 Hz
EV1DSE 0.01 Hz
EA 1.45 Hz
IA 2.94 Hz
IAL 3.98 Hz
EA2 0.25 Hz
IA2 1.47 Hz
IA2L 2.06 Hz
EMDOWN 1.75 Hz
EMUP 1.73 Hz
IM 3.17 Hz
IML 4.99 Hz

ax=plotPerf(actreward,yl=(0,1.01))
savefig(gifpath()+'perf.png') # [[./gif/21may27_21may21_TARG0_N_cycle__step_35_perf.png]]

lfn = ['21may21_TARG0_N_cycle__step_' + str(i) + '_' for i in range(36)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.2,0.425))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may27_21may21_TARG0_N_cycle__step_35_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may27_21may21_TARG0_N_cycle__step_35_perf_compareD.png]]
hmm, one of those steps looks very good...

cla(); lrat = plotHitMissRatioPerStep(lpda)
savefig(gifpath()+'hit_miss_ratio.png') # [[./gif/21may27_21may21_TARG0_N_cycle__step_35_hit_miss_ratio.png]]
np.argmax(lrat) # 32
lrat[np.argmax(lrat)] # 0.9583333333333334
hmm, that's better than the other model (K gcp) ... check that step (32)

python -i simdat.py backupcfg/21may21_TARG0_N_cycle__step_32_sim.json

EV1 0.02 Hz
EV1DE 0.0 Hz
EV1DNE 0.0 Hz
EV1DN 0.04 Hz
EV1DNW 0.0 Hz
EV1DW 0.0 Hz
EV1DSW 0.0 Hz
EV1DS 0.04 Hz
EV1DSE 0.01 Hz
EA 1.43 Hz
IA 2.94 Hz
IAL 3.93 Hz
EA2 0.21 Hz
IA2 1.41 Hz
IA2L 1.98 Hz
EMDOWN 1.43 Hz
EMUP 1.42 Hz
IM 2.9 Hz
IML 4.67 Hz

ax=plotPerf(actreward,yl=(0,5.05))
savefig(gifpath()+'perf.png') # [[./gif/21may27_21may21_TARG0_N_cycle__step_32_perf.png]]

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may27_21may21_TARG0_N_cycle__step_32_rast.png]]
savefig(gifpath()+'rastB.png') # [[./gif/21may27_21may21_TARG0_N_cycle__step_32_rastB.png]]

lfn = ['21may21_TARG0_N_cycle__step_' + str(i) + '_' for i in range(36)]
clf(); pdfc = getconcatweightpdf(lfn,usefinal=True)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may27_21may21_TARG0_N_cycle__step_32_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21may27_21may21_TARG0_N_cycle__step_32__with_reward_input.mp4]]

* 21may28
** check 21may21_TARG0_N_cycle__step_39_ -->> finished for now

python -i simdat.py backupcfg/21may21_TARG0_N_cycle__step_39_sim.json


EV1 0.02 Hz
EV1DE 0.0 Hz
EV1DNE 0.0 Hz
EV1DN 0.04 Hz
EV1DNW 0.0 Hz
EV1DW 0.0 Hz
EV1DSW 0.0 Hz
EV1DS 0.04 Hz
EV1DSE 0.01 Hz
EA 1.54 Hz
IA 3.22 Hz
IAL 4.31 Hz
EA2 0.45 Hz
IA2 1.86 Hz
IA2L 2.64 Hz
EMDOWN 3.64 Hz
EMUP 3.62 Hz
IM 5.01 Hz
IML 7.14 Hz

rates getting too high...

ax=plotPerf(actreward,yl=(0,1.01))
savefig(gifpath()+'perf.png') # [[./gif/21may28_21may21_TARG0_N_cycle__step_39_perf.png]]

lfn = ['21may21_TARG0_N_cycle__step_' + str(i) + '_' for i in range(40)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.2,0.43))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may28_21may21_TARG0_N_cycle__step_39_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may28_21may21_TARG0_N_cycle__step_39_perf_compareD.png]]

cla(); lrat = plotHitMissRatioPerStep(lpda)
savefig(gifpath()+'hit_miss_ratio.png') # [[./gif/21may28_21may21_TARG0_N_cycle__step_39_hit_miss_ratio.png]]
np.argmax(lrat) # 32
lrat[np.argmax(lrat)] # 0.9583333333333334

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may28_21may21_TARG0_N_cycle__step_39_rast.png]]
savefig(gifpath()+'rastB.png') # [[./gif/21may28_21may21_TARG0_N_cycle__step_39_rastB.png]]

clf(); pdfc = getconcatweightpdf(lfn,usefinal=True)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may28_21may21_TARG0_N_cycle__step_39_all_steps_avg_weight.png]]

# fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)

40 steps finished ... not clear if worth continuing w/o adjusting noise dynamically ... 

** check 21may25_TARG0_K2_gcp__step_10_ -->> no max perf better yet

python -i simdat.py backupcfg/21may25_TARG0_K2_gcp__step_10_sim.json

EV1 0.02 Hz
EA 1.46 Hz
IA 2.74 Hz
IAL 3.95 Hz
EA2 0.17 Hz
IA2 1.32 Hz
IA2L 1.92 Hz
EMDOWN 0.28 Hz
EMUP 0.27 Hz
IM 1.54 Hz
IML 2.25 Hz

rates are a drop higher...

ax=plotPerf(actreward,yl=(0,1.01))
savefig(gifpath()+'perf.png') # [[./gif/21may28_21may25_TARG0_K2_gcp__step_10_perf.png]]

decent...

lfn = ['21may15_TARG0_K_gcp__step_' + str(i) + '_' for i in range(40)]
for i in range(11): lfn.append('21may25_TARG0_K2_gcp__step_'+str(i)+'_')

pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.2,0.4))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may28_21may25_TARG0_K2_gcp__step_10_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may28_21may25_TARG0_K2_gcp__step_10_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may28_21may25_TARG0_K2_gcp__step_10_rast.png]]

cla(); lrat = plotHitMissRatioPerStep(lpda)
savefig(gifpath()+'hit_miss_ratio.png') # [[./gif/21may28_21may25_TARG0_K2_gcp__step_10_hit_miss_ratio.png]]
np.argmax(lrat) # 31
lrat[np.argmax(lrat)] # 0.88
still no sim better than max perf ... but the low rates in EM allow further improvement...

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may28_21may25_TARG0_K2_gcp__step_10_all_steps_avg_weight.png]]

# fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
** check 21may26_TARG0_O_cycle__step_4_

python -i simdat.py backupcfg/21may26_TARG0_O_gcp__step_4_sim.json

EV1 0.02 Hz
EA 1.31 Hz
IA 2.52 Hz
IAL 3.6 Hz
EA2 0.09 Hz
IA2 1.2 Hz
IA2L 1.72 Hz
EMDOWN 0.19 Hz
EMUP 0.19 Hz
IM 1.39 Hz
IML 2.06 Hz

ax=plotPerf(actreward,yl=(0,1.01))
savefig(gifpath()+'perf.png') # [[./gif/21may28_21may26_TARG0_O_gcp__step_4_perf.png]]

note that early perf values that are high are ~meaningless since the vertical step sizes
are large due to smaller duration of time (inaccurate until long term)

lfn = ['21may26_TARG0_O_gcp__step_' + str(i) + '_' for i in range(5)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,1.01))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21may28_21may26_TARG0_O_gcp__step_4_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21may28_21may26_TARG0_O_gcp__step_4_perf_compareD.png]]

cla(); lrat = plotHitMissRatioPerStep(lpda)
savefig(gifpath()+'hit_miss_ratio.png') # [[./gif/21may28_21may26_TARG0_O_gcp__step_4_hit_miss_ratio.png]]

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21may28_21may26_TARG0_O_gcp__step_4_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21may28_21may26_TARG0_O_gcp__step_4_all_steps_avg_weight.png]]

# fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)

* 21jun1
** check 21may25_TARG0_K2_gcp__step_28_

python -i simdat.py backupcfg/21may25_TARG0_K2_gcp__step_28_sim.json

EV1 0.02 Hz
EA 1.56 Hz
IA 2.94 Hz
IAL 4.23 Hz
EA2 0.49 Hz
IA2 1.86 Hz
IA2L 2.57 Hz
EMDOWN 0.85 Hz
EMUP 0.8 Hz
IM 2.69 Hz
IML 3.5 Hz

rates are noticeably higher but not hyperexcitable...

ax=plotPerf(actreward,yl=(0,2.05))
savefig(gifpath()+'perf.png') # [[./gif/21jun1_21may25_TARG0_K2_gcp__step_28_perf.png]]

lfn = ['21may15_TARG0_K_gcp__step_' + str(i) + '_' for i in range(40)]
for i in range(29): lfn.append('21may25_TARG0_K2_gcp__step_'+str(i)+'_')

pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.2,0.45))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jun1_21may25_TARG0_K2_gcp__step_28_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jun1_21may25_TARG0_K2_gcp__step_28_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21jun1_21may25_TARG0_K2_gcp__step_28_rast.png]]

cla(); lrat = plotHitMissRatioPerStep(lpda)
savefig(gifpath()+'hit_miss_ratio.png') # [[./gif/21jun1_21may25_TARG0_K2_gcp__step_28_hit_miss_ratio.png]]
np.argmax(lrat) # 31
lrat[np.argmax(lrat)] # 0.88
still no better than step 31 but there's an upward trend visible...in hit/miss ratio over step and cumulative...

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21jun1_21may25_TARG0_K2_gcp__step_28_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21jun1_21may25_TARG0_K2_gcp__step_28__with_reward_input.mp4]]
** check 21may26_TARG0_O_cycle__step_16_

python -i simdat.py backupcfg/21may26_TARG0_O_gcp__step_16_sim.json

EV1 0.02 Hz
EA 1.35 Hz
IA 2.57 Hz
IAL 3.69 Hz
EA2 0.1 Hz
IA2 1.21 Hz
IA2L 1.74 Hz
EMDOWN 0.21 Hz
EMUP 0.21 Hz
IM 1.41 Hz
IML 2.09 Hz

ax=plotPerf(actreward,yl=(0,0.82))
savefig(gifpath()+'perf.png') # [[./gif/21jun1_21may26_TARG0_O_gcp__step_16_perf.png]]

lfn = ['21may26_TARG0_O_gcp__step_' + str(i) + '_' for i in range(17)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,1.01))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jun1_21may26_TARG0_O_gcp__step_16_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jun1_21may26_TARG0_O_gcp__step_16_perf_compareD.png]]

cla(); lrat = plotHitMissRatioPerStep(lpda)
savefig(gifpath()+'hit_miss_ratio.png') # [[./gif/21jun1_21may26_TARG0_O_gcp__step_16_hit_miss_ratio.png]]
step 15 best so far...

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21jun1_21may26_TARG0_O_gcp__step_16_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21jun1_21may26_TARG0_O_gcp__step_16_all_steps_avg_weight.png]]

python -i simdat.py backupcfg/21may26_TARG0_O_gcp__step_15_sim.json

EV1 0.02 Hz
EA 1.35 Hz
IA 2.57 Hz
IAL 3.68 Hz
EA2 0.1 Hz
IA2 1.21 Hz
IA2L 1.74 Hz
EMDOWN 0.2 Hz
EMUP 0.2 Hz
IM 1.4 Hz
IML 2.08 Hz

ax=plotPerf(actreward,yl=(0,0.82))
savefig(gifpath()+'perf.png') # [[./gif/21jun1_21may26_TARG0_O_gcp__step_15_perf.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
 [[./gif/21jun1_21may26_TARG0_O_gcp__step_15__with_reward_input.mp4]]

* 21jun2
** check 21may25_TARG0_K2_gcp__step_32_ -->> stopped after step 33, hyperexcit

python -i simdat.py backupcfg/21may25_TARG0_K2_gcp__step_32_sim.json

EV1 0.02 Hz
EA 1.79 Hz
IA 3.37 Hz
IAL 4.64 Hz
EA2 0.98 Hz
IA2 3.64 Hz
IA2L 3.84 Hz
EMDOWN 14.29 Hz
EMUP 14.33 Hz
IM 13.92 Hz
IML 14.92 Hz

rates probably too high ... step 33 has hyperexcit

ax=plotPerf(actreward,yl=(0,2.05))
savefig(gifpath()+'perf.png') # [[./gif/21jun2_21may25_TARG0_K2_gcp__step_32_perf.png]]

yeah, bad perf ...

lfn = ['21may15_TARG0_K_gcp__step_' + str(i) + '_' for i in range(40)]
for i in range(33): lfn.append('21may25_TARG0_K2_gcp__step_'+str(i)+'_')

pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.2,0.45))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jun2_21may25_TARG0_K2_gcp__step_32_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.01),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jun2_21may25_TARG0_K2_gcp__step_32_perf_compareD.png]]

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21jun2_21may25_TARG0_K2_gcp__step_32_rast.png]]

cla(); lrat = plotHitMissRatioPerStep(lpda)
savefig(gifpath()+'hit_miss_ratio.png') # [[./gif/21jun2_21may25_TARG0_K2_gcp__step_32_hit_miss_ratio.png]]
np.argmax(lrat) # 31
lrat[np.argmax(lrat)] # 0.88

still none better than step 31 ... will need to adjust noise dynamically to allow continuation ... 

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21jun2_21may25_TARG0_K2_gcp__step_32_all_steps_avg_weight.png]]

# fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)

** check 21may26_TARG0_O_cycle__step_19_

python -i simdat.py backupcfg/21may26_TARG0_O_gcp__step_19_sim.json

EV1 0.02 Hz
EA 1.36 Hz
IA 2.58 Hz
IAL 3.72 Hz
EA2 0.1 Hz
IA2 1.21 Hz
IA2L 1.76 Hz
EMDOWN 0.21 Hz
EMUP 0.21 Hz
IM 1.41 Hz
IML 2.09 Hz

ax=plotPerf(actreward,yl=(0,2.1))
savefig(gifpath()+'perf.png') # [[./gif/21jun2_21may26_TARG0_O_gcp__step_19_perf.png]]

lfn = ['21may26_TARG0_O_gcp__step_' + str(i) + '_' for i in range(20)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.,1.01))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jun2_21may26_TARG0_O_gcp__step_19_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jun2_21may26_TARG0_O_gcp__step_19_perf_compareD.png]]

cla(); lrat = plotHitMissRatioPerStep(lpda)
savefig(gifpath()+'hit_miss_ratio.png') # [[./gif/21jun2_21may26_TARG0_O_gcp__step_19_hit_miss_ratio.png]]
step 15 still best so far...

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21jun2_21may26_TARG0_O_gcp__step_19_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21jun2_21may26_TARG0_O_gcp__step_19_all_steps_avg_weight.png]]

# fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)

this simulation still has a long way to go ... 

** dh code optimization for getSpikesWithInterval

dh pointed out problem with getSpikesWithInterval, since all spikes are checked
which takes longer and longer as the simulation progresses

original code is:

def getSpikesWithInterval (trange = None, neuronal_pop = None):
  if len(neuronal_pop) < 1: return 0.0
  spkts = sim.simData['spkt']
  spkids = sim.simData['spkid']
  pop_spikes = 0
  if len(spkts)>0:
    for i in range(len(spkids)):
      if trange[0] <= spkts[i] <= trange[1] and spkids[i] in neuronal_pop:
        pop_spikes += 1
  return pop_spikes

here's his replacement:

def getSpikesWithInterval(trange=None, neuronal_pop=None):
  if len(neuronal_pop) < 1:
    return 0.0
  spkts = sim.simData['spkt']
  spkids = sim.simData['spkid']
  pop_spikes = dict([(v,0) for v in set(neuronal_pop.values())])
  if len(spkts) > 0:
    for idx in range(len(spkids)):
      i = len(spkids) - 1 - idx
      if trange[0] <= spkts[i] <= trange[1] and spkids[i] in neuronal_pop:
        pop_spikes[neuronal_pop[spkids[i]]] += 1
      if trange[0] > spkts[i]:
        break
  return pop_spikes

however, that new code has different return type - dictionary, with number of spikes
in a population indexed by neuronal ID, so make sure to adjust call code

DH code is here: https://github.com/NathanKlineInstitute/netpyne-STDP

* 21jun7
** check 21may26_TARG0_O_gcp__step_36_

python -i simdat.py backupcfg/21may26_TARG0_O_gcp__step_36_sim.json

EV1 0.02 Hz
EA 1.43 Hz
IA 2.69 Hz
IAL 3.89 Hz
EA2 0.15 Hz
IA2 1.28 Hz
IA2L 1.87 Hz
EMDOWN 0.26 Hz
EMUP 0.26 Hz
IM 1.49 Hz
IML 2.19 Hz

rates still low

ax=plotPerf(actreward,yl=(0,2.1))
savefig(gifpath()+'perf.png') # [[./gif/21jun7_21may26_TARG0_O_gcp__step_36_perf.png]]

perf decent ...

lfn = ['21may26_TARG0_O_gcp__step_' + str(i) + '_' for i in range(37)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.35,0.45))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jun7_21may26_TARG0_O_gcp__step_36_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jun7_21may26_TARG0_O_gcp__step_36_perf_compareD.png]]

cla(); lrat = plotHitMissRatioPerStep(lpda)
savefig(gifpath()+'hit_miss_ratio.png') # [[./gif/21jun7_21may26_TARG0_O_gcp__step_36_hit_miss_ratio.png]]
now step 25 and 32 are better than 15 ... but still not better than the smaller network ...
np.argmax(lrat) # 32
lrat[np.argmax(lrat)] # 0.7777777777777778 (close to smaller network which had 0.88 best)

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21jun7_21may26_TARG0_O_gcp__step_36_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21jun7_21may26_TARG0_O_gcp__step_36_all_steps_avg_weight.png]]

# fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)

* 21jun8
** check 21may26_TARG0_O_gcp__step_39_ -->> last step; continue as 21jun8_TARG0_O2_gcp_

python -i simdat.py backupcfg/21may26_TARG0_O_gcp__step_39_sim.json

EV1 0.02 Hz
EA 1.44 Hz
IA 2.72 Hz
IAL 3.92 Hz
EA2 0.16 Hz
IA2 1.3 Hz
IA2L 1.89 Hz
EMDOWN 0.27 Hz
EMUP 0.27 Hz
IM 1.52 Hz
IML 2.21 Hz

and again, rates still low

ax=plotPerf(actreward,yl=(0,2.1))
savefig(gifpath()+'perf.png') # [[./gif/21jun8_21may26_TARG0_O_gcp__step_39_perf.png]]
bad perf this step...

lfn = ['21may26_TARG0_O_gcp__step_' + str(i) + '_' for i in range(40)]
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.35,0.45))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jun8_21may26_TARG0_O_gcp__step_39_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jun8_21may26_TARG0_O_gcp__step_39_perf_compareD.png]]

cla(); lrat = plotHitMissRatioPerStep(lpda)
savefig(gifpath()+'hit_miss_ratio.png') # [[./gif/21jun8_21may26_TARG0_O_gcp__step_39_hit_miss_ratio.png]]
np.argmax(lrat) # 32
lrat[np.argmax(lrat)] # 0.7777777777777778
step 32 still best so far ...

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21jun8_21may26_TARG0_O_gcp__step_39_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21jun8_21may26_TARG0_O_gcp__step_39_all_steps_avg_weight.png]]

# fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)

since this was the last step of multistep sim, continue as 21jun8_TARG0_O2_gcp_

    "simtype": {
        "ResumeSim": 1,
        "ResumeSimFromFile": "data/21may26_TARG0_O_gcp__step_39_synWeights_final.pkl"
    },

python multistepSim.py sn.json 30 40 21jun8_TARG0_O2_gcp_multi

started ~10:29 ...

* 21jun9
** check 21jun8_TARG0_O2_gcp__step_2_ -->> step 32 still best so far, room to improve

python -i simdat.py backupcfg/21jun8_TARG0_O2_gcp__step_2_sim.json

EV1 0.02 Hz
EA 1.47 Hz
IA 2.75 Hz
IAL 3.98 Hz
EA2 0.17 Hz
IA2 1.31 Hz
IA2L 1.91 Hz
EMDOWN 0.28 Hz
EMUP 0.27 Hz
IM 1.53 Hz
IML 2.24 Hz

ax=plotPerf(actreward,yl=(0,2.1))
savefig(gifpath()+'perf.png') # [[./gif/21jun9_21jun8_TARG0_O2_gcp__step_2_perf.png]]

lfn = ['21may26_TARG0_O_gcp__step_' + str(i) + '_' for i in range(40)]
for i in range(3): lfn.append('21jun8_TARG0_O2_gcp__step_'+str(i)+'_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.35,0.45))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jun9_21jun8_TARG0_O2_gcp__step_2_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jun9_21jun8_TARG0_O2_gcp__step_2_perf_compareD.png]]

cla(); lrat = plotHitMissRatioPerStep(lpda)
savefig(gifpath()+'hit_miss_ratio.png') # [[./gif/21jun9_21jun8_TARG0_O2_gcp__step_2_hit_miss_ratio.png]]
np.argmax(lrat) # 32
lrat[np.argmax(lrat)] # 0.7777777777777778

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21jun9_21jun8_TARG0_O2_gcp__step_2_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21jun9_21jun8_TARG0_O2_gcp__step_2_all_steps_avg_weight.png]]

# fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)

given low firing rates, still has room to improve...

* 21jun10
** check 21jun8_TARG0_O2_gcp__step_5_ -->> this one looks better (final hit/miss ratio = 1.1)

python -i simdat.py backupcfg/21jun8_TARG0_O2_gcp__step_5_sim.json

EV1 0.02 Hz
EA 1.48 Hz
IA 2.76 Hz
IAL 4.01 Hz
EA2 0.18 Hz
IA2 1.33 Hz
IA2L 1.95 Hz
EMDOWN 0.3 Hz
EMUP 0.29 Hz
IM 1.57 Hz
IML 2.28 Hz

ax=plotPerf(actreward,yl=(0,2.1))
savefig(gifpath()+'perf.png') # [[./gif/21jun10_21jun8_TARG0_O2_gcp__step_5_perf.png]]

lfn = ['21may26_TARG0_O_gcp__step_' + str(i) + '_' for i in range(40)]
for i in range(6): lfn.append('21jun8_TARG0_O2_gcp__step_'+str(i)+'_')
pdac = getconcatactionreward(lfn)
clf(); ax=plotPerf(pdac,yl=(0.35,0.45))
savefig(gifpath()+'perf_all_steps_so_far.png') # [[./gif/21jun10_21jun8_TARG0_O2_gcp__step_5_perf_all_steps_so_far.png]]

lpda = getindivactionreward(lfn)
csm=cm.ScalarMappable(cmap=cm.jet); csm.set_clim((0,1));
lclr = [csm.to_rgba(float(i)/(len(lpda))) for i in range(len(lpda))]
clf(); plotComparePerf(lpda,lclr,yl=(0,2.1),lleg=lfn,skipscore=True,skipfollow=True)
savefig(gifpath()+'perf_compareD.png') # [[./gif/21jun10_21jun8_TARG0_O2_gcp__step_5_perf_compareD.png]]

cla(); lrat = plotHitMissRatioPerStep(lpda)
savefig(gifpath()+'hit_miss_ratio.png') # [[./gif/21jun10_21jun8_TARG0_O2_gcp__step_5_hit_miss_ratio.png]]
np.argmax(lrat) # 45
lrat[np.argmax(lrat)] # 1.0909090909090908

this is best step so far ...

clf(); drawraster(dspkT,dspkID); xlim((498e3,500e3))
savefig(gifpath()+'rast.png') # [[./gif/21jun10_21jun8_TARG0_O2_gcp__step_5_rast.png]]

clf(); pdfc = getconcatweightpdf(lfn)
subplot(1,3,1); popwtsEA = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA'],lclr=['g'],plotindiv=False)
subplot(1,3,2); popwtsEA2 = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EA2'],lclr=['c'],plotindiv=False)
subplot(1,3,3); popwtsE = plotMeanWeights(pdfc,gca(),msz=6,xl=(0,np.amax(pdfc.time)),lpop=['EMDOWN','EMUP'],lclr=['r','b'],plotindiv=False)
savefig(gifpath()+'all_steps_avg_weight.png') # [[./gif/21jun10_21jun8_TARG0_O2_gcp__step_5_all_steps_avg_weight.png]]

fig=animInput(InputImages,gifpath()+'_with_reward_input.mp4',actreward=actreward)
[[./gif/21jun10_21jun8_TARG0_O2_gcp__step_5__with_reward_input.mp4]]
** ENoise population

could test a dynamically regulated noise population; it would provide noise to the other populations and it would be
regulated opposite to normal RL. so when the network performs well, the ENoise -> Other population weights decrease (noise goes down)
and when network performs poorly, the ENoise -> Other population weights increase (noise goes up)

that way could avoid adding extra instrumentation for noise regulation 

test on laptop first with a small network ... 

population will be called EN for short ... Noise in RLCONNS specifies whether to use the RL there
control would be to keep RL off and have weights of Noise -> EA, EA2, EM fixed

./myrun 8 sn.json

python -i simdat.py backupcfg/21jun10_N_lp_sim.json

