*19nov7
**I ran a simulation with overlapped field of view i.e. every neuron in layer V1 received input from 25 neurons in a topological manner.
**I tested a couple of initial weights to see how the synaptic weights evolve
***The results are very similar (by eye balling) when initial weight is 0.001 vs 0.0012
****I feel that the topological mapping from layer R to layer V1 would not be a useful strategy at this time because i think that having biological realism in model will require completeness too to make the model useful. And with just a couple of layers to encode image sequences, having topological mapping limits the capacity of the network to encode the changes in virtual game environment and later associate actions to the sequence of images.
samn 10:23 AM
why does topology limit capacity of network to encode changes and associate actions?
10:24 AM
can objects be represented without topology?
Haroon Anwar 10:24 AM
because a couple of layers would not allow merging localized information into spatial sequences
10:24 AM
“can objects be represented without topology?” - no
samn 10:25 AM
how many layers are needed to merge local info into spatial sequence?
Haroon Anwar 10:26 AM
not sure…. would guess 3-4 or so
samn 10:26 AM
can try that then
10:26 AM
and have a variable control whether to use topological mapping
Haroon Anwar 10:27 AM
i am not against topological mapping….just trying to think the potential issues as we build up network
samn 10:27 AM
it would be interesting if the system worked without topological mapping, but also surprising
10:27 AM
since you would think it needs some representation of space including positioning of objects
Haroon Anwar 10:28 AM
i like to make things as biological as possible but then it also require completeness and we dont know how much detail would be enough to capture something at biological level
samn 10:28 AM
if pixels from two rackets are activated with same neurons, how is the neuronal representation separated?
10:28 AM
i'm not sure if we need completeness for what we are doing. besides that, we will never have completeness
Haroon Anwar 10:28 AM
thats an interesting point
10:28 AM
completeness for a task
samn 10:28 AM
ic
Haroon Anwar 10:29 AM
like we talked about layers
samn 10:29 AM
right, we don't know how much detail needed
10:29 AM
can only guess/hypothesize until we have a way to test the system
Haroon Anwar 10:30 AM
when things are merged into a single or two layers and everything is connected to everything, the network can be trained to do a task without making sense
10:30 AM
just increase the number of neurons and connections in the middle layer and it does the magic
samn 10:30 AM
that would be fine too
10:30 AM
even that with more realistic neurons is a step towards more realism
10:30 AM
but my sense is that topology is important for reason mentioned above
Haroon Anwar 10:31 AM
“but my sense is that topology is important for reason mentioned above” - cant agree more…
samn 10:31 AM
you should try both ways
**** 1 Possible solution: "The role of competitive inhibition and top-down feedback in binding during object recognition"
*****In this regard, use Bhezhenov strategy.
****Another issue in the way the model is setup for learning is: hardly a couple of successful events occur (i.e. the player hits the ball with the racket). I wonder what will be a better strategy to overcome this problem.
10:07 AM
not immediate problem but it will be a problem
samn 10:07 AM
can you clarify the problem?
Haroon Anwar 10:07 AM
and we need to find a solution for this
10:07 AM
ok
10:07 AM
in game there are 2 players
10:08 AM
game allows access to 1 player
10:08 AM
its actions and reward
10:08 AM
within each episode, if the player plays randomly, it hardly plays a correct move and gets rewarded
10:14 AM
the player using random strategy gets rewarded, but less than a player with a good strategy
Haroon Anwar 10:14 AM
yes
samn 10:14 AM
and the random strategy also produces punishment too
Haroon Anwar 10:15 AM
i am not sure about that….
10:15 AM
i just noticed reward to be 0 or 1
samn 10:16 AM
well, we will have to build in some punishment too
10:16 AM
for all games they only use 0 or 1 ?
Haroon Anwar 10:16 AM
not sure
10:16 AM
need to check that
samn 10:16 AM
we could make rules such as if no reward for a while, produce a punishment
Haroon Anwar 10:16 AM
i see
samn 10:17 AM
but hopefully they have explicit punishments already. yeah, good to think about different approaches for those issues
Haroon Anwar 10:17 AM
OK
10:17 AM
but i was thinking, how we learn is not only by getting results of our actions
10:18 AM
but also looking at others, how they play
samn 10:18 AM
true
Haroon Anwar 10:18 AM
and try to learn some rules
samn 10:18 AM
there's something called teacher-based learning
10:18 AM
imitation, etc.
Haroon Anwar 10:18 AM
ok
samn 10:19 AM
can try some of that as well...e.g. produce a population of models, transfer some weights from strong models to weaker models
10:19 AM
in that case it's similar to evolution
Haroon Anwar 10:19 AM
yes. so all of these are possible strategies. that can be pursued in parallel
samn 10:19 AM
for more complicated teacher learning have to develop an algorithm that can observe and copy
Haroon Anwar 10:20 AM
agree… but will also need access to rewards and association to actions of other player
samn 10:20 AM
yeah
****Can agent learn about good actions from the computer (i.e. the other player)? A couple of problems in that regard are lack of access to the information regarding the other player's actions and reward.
**To Do List: 1. Include inhibition in the model. 2. Implement a strategy for STDP where the strength of synapses slowly decay over time unless it hits a threshold, in which case, it stays strengthened.
*19nov8
**To Do List (side tracked): 1. Include inhibition in the model. 2. Before implementing homeostatic STDP, implement Bhezhenov model. This model should exist in parallel. 3. Implement simplified motor cortex and use reward based STDP to train it. 4. Implement homeostatic STDP
***PROBLEM UNDERSTANDING BAZHENOV ARCHITECTURE- disuccion with same
****Haroon Anwar 9:53 AM
it says every neuron send an excitatory and inhibitory synapse to 9 neurons
samn 9:53 AM
that's strange
samn 9:53 AM
we of course don't have to follow his paper exactly
Haroon Anwar 9:53 AM
read figure 1 legend
samn 9:53 AM
it's just a general framework, which we've developed similarly previously too
Haroon Anwar 9:54 AM
i understand that. but just trying to understand what they did
samn 9:54 AM
they tried to balance the output by having feedforward inhibition?
Haroon Anwar 9:54 AM
i thought may be i dont understand English
samn 9:54 AM
ic
9:54 AM
you probably understand, but their rule does seem unusual
Haroon Anwar 9:55 AM
so same neuron excites postsynaptic neuron and inhibits too
9:55 AM
but then there has to be some rule to have a balanced excitation
9:55 AM
so its not real inhibition as in biological network
samn 9:56 AM
they might have different delays and time constants, as well as how far it spreads spatially
Haroon Anwar 9:56 AM
its balancing inhibition
samn 9:56 AM
let me read more of the details
Haroon Anwar 9:56 AM
please
samn 10:00 AM
"Output balancing.
Our previous study revealed the importance of balancing the strength of the output synapses [30]. In this new study, implementation of the output part of synaptic balancing was to reduce the rate of synaptic growth in the neurons that already had high total synaptic output. This effectively prevented a very small number of neurons from controlling the entire network. Thus, for each middle-layer cell, increments of the strength of outgoing synapses resulting from rewarded STDP events were divided by the ratio of the current sum of synaptic outputs to the initial sum of synaptic outputs of the same cells (see Methods). The result was that synapses originating from the neurons with many strong outputs were not able to increase their synaptic strength as quickly as synapses from the neurons with a weak output. This gave a competitive advantage to the later neurons. It helped to control synaptic output, thus preventing over-representation by the cells whose activities were most often correlated with the rewards (see S1 Fig). The performance of the full model simulated without this rule is shown by the red line in Fig 3."
10:00 AM
so they increment the input synapse of cells that already have high weights by a smaller increment?
10:00 AM
sorry, the output
10:00 AM
synapses
Haroon Anwar 10:01 AM
but how does inhibition play role in that
samn 10:01 AM
yeah, it doesn't mention inhibition there
10:01 AM
where was the inhibition mentioned?
Haroon Anwar 10:01 AM
in the architecture
samn 10:02 AM
ic, Feedforward synaptic inhibition was implemented in the model (see Methods) and was necessary for optimal behavior of the network. Thus each layer projecting excitatory connections to the following layer was also projecting inhibition and the total strength of inhibition was equal to the total strength of excitation.
Haroon Anwar 10:02 AM
yes that too
10:02 AM
dont understand the role of this inhibition
samn 10:03 AM
some way to maintain sparse firing and prevent incorrect output
Haroon Anwar 10:03 AM
i see
samn 10:04 AM
they don't seem to explain too much at finer level of detail
Haroon Anwar 10:04 AM
no
samn 10:04 AM
we could test that later on. see how individual synapses being turned on or off impact very specific behaviors
Haroon Anwar 10:04 AM
ok
samn 10:04 AM
or groups of synapses
10:05 AM
did you see the mod file i had to maintaining a target firing rate? it's just one way to have homeostatic weights
10:05 AM
i mean homeostatic synaptic scaling
10:05 AM
/u/samn/syscale
Haroon Anwar 10:05 AM
so for now, previously i was thinking about having inhibition driven by inhibitory neurons
10:05 AM
no
10:05 AM
can you send me that
samn 10:06 AM
yeah, i agree we should keep inhibitory and excitatory neurons separate

 *** Do we need inhibition to be cell based (inhibition implements contrast enhancement or define receptive fields) or region based (with some temporal difference different hierarchical regions inhibit other regions)?
 ***for connectivity could have broad inputs to interneurons, with some spatial dependence on prbability too
 ***factors for connectivity: how strongly the E cells are activated will determine how strongly the I cells have to get activated
spatial dependence of E -> E wiring will influence spatial dependence of E -> I and I -> I and I -> E wiring
for now i would make it parameterized so you can play with it and see what works
***O-Reilly model uses k-winner-take-all competitive inhibition:
****Input; V1 - 3600 neurons; V2/V4 (overlapping field of views) - 2800 neurons that receive from 320 neighboring V1 neurons; IT - 200 neurons - receive inputs from 2800 neurons; Feedforward - 80-90%; Feedback between adjacent - 10-20%; k-winner take all inhibitory competition rule — k most active units remain active over time. each layer has different k, but is generally in the range of 10-20% of neurons in the layer.
***for network balacing use sam's homeostatic synaptic scaling

*19nov12
**Things to do today: 
***1. to implement inhibition, use gabaa syn model. 
***2. drive inhibitory neurons using hh model but with higher firing rate then excitatory neurons.
***3. Extend Bazhenov architecture to O'Reilly architecture (Front. Psych. 2012 paper):
****Input; V1 - 3600 neurons; V2/V4 (overlapping field of views) - 2800 neurons that receive from 320 neighboring V1 neurons; IT - 200 neurons - receive inputs from 2800 neurons; Feedforward - 80-90%; Feedback between adjacent - 10-20%; k-winner take all inhibitory competition rule — k most active units remain active over time. each layer has different k, but is generally in the range of 10-20% of neurons in the layer.
****Base on O'Reilly's architecture: try using R: 6400, V1: 6400, each neuron in V1 receive input from overlapping 25 neurons in R. 1600 neurons in V2/V4. each neuron in V2/V4 receives 25 neurons from V1. 400 neurons in IT with each neuron receiving inputs from 25 neurons in V2/V4. 

*19nov13
*** Based on the paper "Recruitment of inhibition and excitation across mouse visual cortex depends on the hierarchy of interconnecting areas by Rinaldo David D’Souza1*, Andrew Max Meier1, Pawan Bista1, Quanxin Wang2, Andreas Burkhalter1"
****In L2/3 FF (V1->PM) pathway, EPSC recorded from PV cells were larger than those from Pyr cells.
****FF excitation of inhibitory PV neurons relative to neighboring Pyr neuron is stronger than FB excitation of PV neurons. In both cases PV excitation is stronger than Pyr excitation.
****Larger EPSC in PV cells could be a result of either higher density of excitatory input (higher weight of synaptic connections) or due to larger area over which individual PV cells are contacted by inter areal projections, or both.
****The difference in relative excitation of PV and Pyr was bigger in FF(V1->PM) than in FF(LM->PM: the pathway is V1->LM->PM). 
****in contrast, the difference was smaller in FB (PM->V1) than FB(LM->V1).
****Rules are different in L5.

*19nov14
**Implemented divergent connectivity function
**Included inhibitory neurons: 1600 InV1, 400 InV4 and 100 InIT. These neurons are driven by excitation from R, V1 and V4 respectively.
***for all pre(E) to post(I), the overlap is different: 15x15 for R to InV1, 25x25 for V1 to InV4 and 25x25 for V4 to InIT.
**Feedback inhibition implemented: InV1 inhibit neurons in R, InV4 inhibit neurons in V1 and InIT inhibit neurons in V4.
***for all pre(I) to post(E), the overlap is 5x5 neurons i.e. every post synaptic neuron receives inhibition from 25 neighboring neurons. 
**To DO: add poisson noise to inhibitory neurons so that the neurons are close to threshold. this is to increase firing rate of inhibitory neurons.

*19nov15
**Run the simulation for 10s with same firing rate for both excitatory and inhibitory neurons. Only save the raster.
**Add noise stim to inhibitory neurons to increase their firing rates and run the simulation.
**I had only feedback inhibition and feedforward excitation. Now i have included feedforward inhibition as well as feedbackward excitation.
***QUESTION: Is there any evidence of feedforward inhibition and feedbackward excitation in cortex? any biological numbers for such connectivity?
**To do: implement local inhibition- previously we had only feedforward and feedbackward inhibition.
***What are the rules for local inhibition in terms of receptive fields.

*19nov18
**Ran simulation for 10 sec with strong feedback excitation (weight of 0.02)-- observed high firing rates for excitatory and inhibtory neurons (just obseration)
**Ran simulation for 10 sec without feedback excitation-- observed firing rates (R = 0.686, V1 = 1.96, V4 = 3.75, IT = 11.7, IV1 = 21.2, IV4 = 11, IIT = 15.2 Hz)
**Ran simulation for 10 sec with weaker feedback excitation (weight of 0.002)-- observed firing rates (R = 0.7, V1 = 2.5, V4 = 4.85, IT = 11.9, IV1 = 21.2, IV4 = 11.2, IIT = 14.2 Hz)
**Running simulation for 20 sec with weaker feedback excitation (weight of 0.002) and saving at 2 ms instead of 0.2 ms
**Include local inhibition and excitation.

*19nov19
**Include local inhibition and excitation (using some general statistics).

**19nov20
**Tried installing atari environment for gym open ai on neurosim, but due to dependencies could not succeeded. 
**Tried installing atari environment for gym open ai on KONG, which worked but netpyne didn't work becaue NEURON is not installed with python3.
***pip install gym --user
***pip install atari-py --user
***Contacted ARCS for help in installing NEURON with python3
** Tried again installing atari environment for gym open ai on neurosim: tried on no.neurosim.downstate.edu
***pip3 install gym --user (it worked)
***pip3 install atari-py --user (it worked)
**Running trainSmartAgent.py on neurosim. (it could not run render therefore i commented out render command)
**Compare neurosim vs personal magic


***NEUROSIM
Creating network of 7 cell populations on 1 hosts...
  Number of cells on node 0: 16900 
  Done; cell creation time = 2.68 s.
Making connections...
  Number of connections on node 0: 2318471 
  Done; cell connection time = 430.00 s.
Adding stims...
  Number of stims on node 0: 8500 
  Done; cell stims creation time = 1.27 s.


***Personal Mac
Creating network of 7 cell populations on 1 hosts...
  Number of cells on node 0: 16900 
  Done; cell creation time = 1.61 s.
Making connections...
  Number of connections on node 0: 2318471 
  Done; cell connection time = 325.40 s.
Adding stims...
  Number of stims on node 0: 8500 
  Done; cell stims creation time = 0.82 s.

*19nov21
***To run simulation on neurosim- always use py3env to use python3.
***To run simulation in parallel using 8 cores on neurosim - use mpirun -n 8 python trainSmartAgent.py
***run time on neurosim using 8 cores - Done; run time = 5936.18 s; real-time ratio: 0.00.
***One problem remains: Plotting raster plot.
***Additional analyses to include: evolving spike rates and .....

*19nov26
**Yesterday, I made changes in the script to save the firing times of all cells.
**Salva told me that we can only use .pkl or .json to save data from plotRaster
***e.g. simConfig.analysis['plotRaster'] = {'popRates':'overlay','saveData':'RasterData.pkl','showFig':True}

*19dec4
**Yesterday, I ran analyzeSpikeRate.py on neurosim to analyze population average firing rates. I ntoiced extremely high values for frequencies, which was due to a bug in the code.
**Today, i fixed the code and reran on neurosim. Firing rate of all populations rose initially and then decayed to a stable firing rate. This analysis was done on 100 s of simulation.
**Nest step is to implement motor cortex. First, i will keep the motor cortex in my model simple.
**Two layers: 
**Input layer with 100 excitatory neurons and 25 inhibitory neurons.
**Output layer with 4 excitatory neurons only.
**Feedforward [IT to MI]: 25 E to 1 E, 225 E to 1 I, 25 I to 1 I, 
**Feedbackward [MI to IT]: 1 E to 9 E, 1 I to 25 E, No I to I
**Feedforward [MI to MO]: 400 E to 1 E (all to all by using probability of connection 1)
**Feedbackward [MO to MI]: 1 E to 121 E 
**There was a bug in connParams. Fixed now.

*19dec5
Analyzing...
  Cells: 17404
  Connections: 3189957 (183.29 per cell)
  Spikes: 770534 (4.43 Hz)
  Simulated time: 10.0 s; 1 workers
  Run time: 1838.15 s
Saving output as model_output.pkl ... 
Finished saving!
  Done; saving time = 995.82 s.
Plotting raster...
Saving figure data as RasterData.pkl ... 
  Done; plotting time = 98.44 s

Total time = 3753.03 s

*19dec6
**Sam suggested: May be should increase number of neurons in motor output layer (MO).
**Change MO from 2x2(4) to 10x10(100)
**Increase number of MO neurons from 4 to 100. Also changed the connectivity from MO to MI and MI to MO.
**Ran the simulation after changing MO as described above. Below are some runtime stats.
Analyzing...
  Cells: 17500
  Connections: 3212180 (183.55 per cell)
  Spikes: 762715 (4.36 Hz)
  Simulated time: 10.0 s; 1 workers
  Run time: 1810.90 s
  Done; saving time = 0.22 s.
Plotting raster...
Saving figure data as RasterData.pkl ... 
  Done; plotting time = 92.46 s
**Replace connections between Visual Cortex and Motor Cortex from STDP to Reward-based STDP.
**Keeping connections within every layer of Motor Cortex standard STDP.

*19dec10
**function playGame is modified to take a list of actions (5 actions) and returns rewards (5 rewards) associated with those actions.
**generate actions based on activity of MO.

*19dec11
**record firing rate of populations of neurons for 20 ms and use that rate to generate actions.
***100 MO neurons are divided into 50 neurons for Right-move(up) and 50 neurons for left-move(down) action.
***Those 50 neurons are further divided into groups of 10 neurons with each group respoisnble for 1 actions out of a sequence of 5 actions.

*19dec12
**Error detected in code in function playGame.

*19dec13
**Fixed the error and reran the simulation.
**action is generated based on activitiy of MO.
**RL code included---mainly modified from Salva's RL model. I don't understand rank and pc.broadcast related script.
**Still need to test the code.
**When i tested the code, i noticed that the firing rate of neuronal population generating actions was 0 most of the times.
**The reason might be that the connection weights reduced to 0 but have not checked that yet.
**So after discussing with Sam, I have made a list of things to test with the model as Below:
1. turn off the -1 and only use 0 or 1, what happens?
2. compare the results of full model simulation with the simulation after completing tuning off reward, punishment.
3. compare the results of full model simulation with the simulation after completely turning off STDP.
4. compare the results of full model simulation with the simulation after using RL-STDP for all synapses.
5. Can do 2 phase learning: phase 1 for STDP between visual layers. training is terminated when the firing rates become stable. Then use those weights for visual connections and train RL-STDP connections.
6. For different configurations, play with starting weights by increasing.
7. could try saving weights from visual learning, then restore them into the network, and continue from there with RL

Also for later he suggested: for the longer term should think about how to avoid "catastrophic forgetting" <- which is what that guy hananel mentioned - when certain neural networks have to learn > 1 thing, the new info/memory/task sometimes interferes with the previously learned. i think the bazhenov model/paper mentions that problem with a solution too (might involve homeostatic plasticity)

*19dec16
**implemented a function to record RL and NonRL weights separately and save at different cellular resolution.
**For every simulation, run for 100 sec, record weights for every 10th neuron.
***A few observations:
1. A lot of time steps, the firing rate of output neurons is 0HZ.
2. When the firing rate is 0 Hz, the action is "Don't move". So most of the times the racket is not moving.
***Find out why the firing rate of output layer is 0?
**While running the simulation, i could not save weights..... need debugging.

*19dec17
**Start debugging the code to save weights.
***I noticed that i was not passing argument sim to the function saveWeights(sim). I made this correction and now rerunning the simulation.
***Another problem detected: precision of t such that it never gives DT%1000==0


*19dec19
**On neurosim: Save the rasterdata and weights for bothRLandNonRL case.
**On neurosim: Run the simulation with only RL. i.e. turn RLon = 1 in STDPparams.
**Reduced model has 1102 neurons and 50260 connections (45.61 per cell)
***1. Reduced model with both RL and nonRL. Also no movement if firing rate of R neuron is equal to firing rate of L neuron.
***2. Reduced model with only RL for all neurons. Also no movement if firing rate of R neuron is equal to firing rate of L neuron.
***3. Reduced model with only RL for all neurons. Also no movement if firing rate of R neuron is equal to firing rate of L neuron.
***1.2. Reduced model with both RL and nonRL. Move randomly if firing rate of R neuron is equal to firing rate of L neuron.
***1.3. RECORD actions and rewards.

*19dec23
**Ran 100 sec simulation of reduced model with recording actions and rewards.
**actions were chosen based on the firing rate of MO neurons except when the firing rate was not decisive.

*19dec24
**run 100 sec simulation of reduced model with recording actions and rewards.
**assign reward = 1 if its 0. and 0 if its 1.

*19dec26
**run 100 sec simulation of reduced model with no actions but randomly generated rewards for RL.
***I want to see how does the network behave if the environment does not change after 1st episode (_NoAction.py). 
****e.g. how NonRL weights evolve: this will give some hint on whether change in NonRL is random or because of the image sequences.
****e.g. how RL weights evolve: this will be random or not.

*19dec30
**Problems:
***I told Sam about my frustration with the reward system in the game i.e. Model gets +1 only if the computer/other player makes a mistake. He argued that Model can get +1 also when It plays a good move. But I said that at this point model is not at that cognitive level to acieve that kind of smartness. Though I am not convinced that model will ever do that, can still hope for that.
***Sam was concerned about sudden drop of weights. I told him that is because of so many -1s. He suggested that I might mask -1 in the beginning and also slow down the change in weight due to -1.
***I will use a threshold for weights to activate punishment in RL.
***I will also decrease the change in weight due to punishment in RL.
***The other problem I observed was that the weights keep increasing even in the absense of new scenes. I think this will make difficult for model to learn much about the game environment as most of the activity is intrinsic (not evoked by the image).
***Sam wants me to save movies and also plot activity of output motor neurons.
**Before I do anything I discussed with Sam, I will implement my idea: GUIDE MODEL TO PLAY THE GAME BASED ON VECTOR ALGEBRA. (local dir: SMARTAgent_Reduced_12302019)
***GUIDE MODEL TO PLAY THE GAME BASED ON VECTOR ALGEBRA ---> Done. Running now.
***Change fixed number of trials to complete episodes i.e. number of trials until one of the players score 20. use 'done' and also record total episodes.

*19dec31
**The simulation I ran with VECTOR ALGEBRA using 2 different values of RLhebbwt (0.001 and 0.0001) were done. But I realized i made a mistake in RL signal i.e. i used 0 as +1.
**I will re run these simulations and also record activity of the motor neurons.

    #I don't understand the code below. Copied from Salva's RL model
    vec = h.Vector()
    if sim.rank == 0:
        rewards, epCount = sim.SMARTAgent.playGame(actions, epCount)
        critic = sum(rewards) # get critic signal (-1, 0 or 1)
        sim.pc.broadcast(vec.from_python([critic]), 0) # convert python list to hoc vector for broadcast data received from arm
    else: # other workers
        sim.pc.broadcast(vec, 0)
        critic = vec.to_python()[0] #till here I dont understand


**running reduced model with VECTOR ALEBRA and recording RLWeights, NonRLWeights, ActionsAndRewards, FiringRate of MotorNeurons in MO, binned 20 ms, ActionsPerEpisode

*20jan2
**I created a folder 'SMARTAgent_Reduced_12302019/Dec31' and saved the output files and analysis of the simulation ran on Dec31. The simulation was run using RLparams as
STDPparamsRL = {'hebbwt': 0.00001, 'antiwt':-0.00001, 'wmax': 50, 'RLon': 1 , 'RLhebbwt': 0.0001, 'RLantiwt': -0.000,
        'tauhebb': 10, 'RLwindhebb': 50, 'useRLexp': 0, 'softthresh': 0, 'verbose':0} ---> check RLdescription.txt
**create a new dir 'SMARTAgent_Reduced_12302019/Jan2_0' and run simulation with STDPparamsRL = {'hebbwt': 0.00001, 'antiwt':-0.00001, 'wmax': 50, 'RLon': 1 , 'RLhebbwt': 0.001, 'RLantiwt': -0.000,
        'tauhebb': 10, 'RLwindhebb': 50, 'useRLexp': 0, 'softthresh': 0, 'verbose':0} in folder 'SMARTAgent_Reduced_12302019'
**create a new dir 'SMARTAgent_Reduced_12302019/Jan2' and run another simulation with STDPparamsRL = {'hebbwt': 0.00001, 'antiwt':-0.00001, 'wmax': 50, 'RLon': 1 , 'RLhebbwt': 0.001, 'RLantiwt': -0.0001,
        'tauhebb': 10, 'RLwindhebb': 50, 'useRLexp': 0, 'softthresh': 0, 'verbose':0}
**create a new dir 'SMARTAgent_Reduced_12302019/Jan2_1' and run another simulation with STDPparamsRL = {'hebbwt': 0.00001, 'antiwt':-0.00001, 'wmax': 50, 'RLon': 1 , 'RLhebbwt': 0.01, 'RLantiwt': -0.0001,
        'tauhebb': 10, 'RLwindhebb': 50, 'useRLexp': 0, 'softthresh': 0, 'verbose':0}

*20jan3
**create a new dir 'SMARTAgent_Reduced_12302019/Jan3' and run another simulation with STDPparamsRL = {'hebbwt': 0.00001, 'antiwt':-0.00001, 'wmax': 50, 'RLon': 1 , 'RLhebbwt': 0.001, 'RLantiwt': -0.00001,
        'tauhebb': 10, 'RLwindhebb': 50, 'useRLexp': 0, 'softthresh': 0, 'verbose':0}
**create a new dir 'SMARTAgent_Reduced_12302019/Jan3_1' and run another simulation with STDPparamsRL = {'hebbwt': 0.0001, 'antiwt':-0.00001, 'wmax': 50, 'RLon': 1 , 'RLhebbwt': 0.001, 'RLantiwt': -0.00001,
        'tauhebb': 10, 'RLwindhebb': 50, 'useRLexp': 0, 'softthresh': 0, 'verbose':0}
**Some ideas to test: 
***1. decrease inhibition (i think right now the activity is too sparse to have eligibitly established).
***2. To have better chances of learning, increase the window so that the chances for eligibility increases.
**create a new dir 'SMARTAgent_Reduced_12302019/Jan3_2' and run another simulation with same parameters as the simulation in Jan3_1. Additionally, only use +1 (line 734). Run for 10sec (line 589)
***Though there were only two +1 rewards, the weight kept increasing. So rerun the simulation with +1 and 0.

*20jan6
**creating 2 cell model 'SMARTAgent_2Cell_01062020' to understand and debug RL-model.

*20jan7
**running 2 cell model showed that:
1)RL weight change must be smaller or equal to the hebb weight change otherwise too many punishments reduce the weight to 0.
2)with RL = 1 and hebbwt assigned, the model implements hebb stdp and RL, both.
**running reduced model simulation with RL weight change adjusted to hebbwt in 'SMARTAgent_Reduced_12302019/Jan7' using 
STDPparamsRL = {'hebbwt': 0.00001, 'antiwt':-0.0000, 'wmax': 50, 'RLon': 1 , 'RLhebbwt': 0.00001, 'RLantiwt': -0.000,
        'tauhebb': 10, 'RLwindhebb': 50, 'useRLexp': 0, 'softthresh': 0, 'verbose':0} 
**running reduced model simulation with RL weight change adjusted to hebbwt in 'SMARTAgent_Reduced_12302019/Jan7_1' using 
STDPparamsRL = {'hebbwt': 0.00001, 'antiwt':-0.0000, 'wmax': 50, 'RLon': 1 , 'RLhebbwt': 0.00005, 'RLantiwt': -0.000,
        'tauhebb': 10, 'RLwindhebb': 50, 'useRLexp': 0, 'softthresh': 0, 'verbose':0}
**running reduced model simulation with RL weight change adjusted to hebbwt in 'SMARTAgent_Reduced_12302019/Jan7_2' using
STDPparamsRL = {'hebbwt': 0.00001, 'antiwt':-0.0000, 'wmax': 50, 'RLon': 1 , 'RLhebbwt': 0.0001, 'RLantiwt': -0.000,
        'tauhebb': 10, 'RLwindhebb': 50, 'useRLexp': 0, 'softthresh': 0, 'verbose':0}

*20jan9
**Do we need STDP between neurons in visual cortex? May be not. As there is an existing topological map, activation of neurons in V1 will encode spatial information about the visual space. and neurons in V4 and IT will encode associations between objects in visual scenes.
**run reduced model without nonRL-STDP.
**running reduced model simulation without nonRL-STDP in 'SMARTAgent_Reduced_12302019/Jan9'.
**D1R-expressing medium spiny neurons reinforce, while D2R-expressing MSNs encode punsihment. High concentrations of DA preferentially activate D1R-expressing direct pathway neurons, while low level of DA preferentially activates D2R expressing indirect pathway neurons.
**Kravitz and Kreitzer suggest LTP of the direct pathway and LTD of the indirect pathway mediates reinforcement, whereas LTP of the indirect pathway and LTD of direct pathway mediates punishment in substentia niagra compacta (SNc) neurons. 
**STDP works good.
**Reward based weight adjustment looks weird:
example 1:
t=500.600000 (BEFORE) tlaspre=499.200000, tlastpost=400.000000, flag=0.000000, w=-1.000000, deltaw=0.000000 
t=500.600000 (AFTER) tlaspre=499.200000, tlastpost=500.600000, flag=0.000000, w=-1.000000, deltaw=0.000000 

t= 520.0000000000497 - adjusting weights based on RL critic value: -1
t=520.000000, RL-hebb =0.001000, deltaw=-0.001000 
t=520.000000, RL-antihebb =0.000000, deltaw=-0.001000 
RL event: t = 520.000000 ms; reinf = -1.000000; RLhebbwt = 0.001000; RLlenhebb = 100.000000; tlasthebbelig = 500.600000; deltaw = -0.001000

example 2:
t=780.200000 (BEFORE) tlaspre=758.000000, tlastpost=779.000000, flag=0.000000, w=1.000000, deltaw=0.000000 
t=780.200000 (AFTER) tlaspre=780.200000, tlastpost=779.000000, flag=0.000000, w=1.000000, deltaw=0.000000

t=798.800000 (BEFORE) tlaspre=780.200000, tlastpost=779.000000, flag=0.000000, w=1.000000, deltaw=0.000000 
t=798.800000 (AFTER) tlaspre=798.800000, tlastpost=779.000000, flag=0.000000, w=1.000000, deltaw=0.000000 
eligibility established -- see above and now reward/punishment delivered at time 800ms -- see below

t= 800.0000000001133 - adjusting weights based on RL critic value: -1
t=800.000000, RL-hebb =0.001000, deltaw=-0.001000 
t=800.000000, RL-antihebb =-0.000200, deltaw=-0.000800 
RL event: t = 800.000000 ms; reinf = -1.000000; RLhebbwt = 0.001000; RLlenhebb = 100.000000; tlasthebbelig = 779.000000; deltaw = -0.000800

example 3:
t=801.200000 (BEFORE) tlaspre=798.800000, tlastpost=779.000000, flag=0.000000, w=-1.000000, deltaw=0.000000 
t=801.200000 (AFTER) tlaspre=798.800000, tlastpost=801.200000, flag=0.000000, w=-1.000000, deltaw=0.000000 

t=818.000000 (BEFORE) tlaspre=798.800000, tlastpost=801.200000, flag=0.000000, w=1.000000, deltaw=0.000000 
t=818.000000 (AFTER) tlaspre=818.000000, tlastpost=801.200000, flag=0.000000, w=1.000000, deltaw=0.000000

t= 820.0000000001179 - adjusting weights based on RL critic value: -1
t=820.000000, RL-hebb =0.001000, deltaw=-0.001000 
t=820.000000, RL-antihebb =-0.000200, deltaw=-0.000800 
RL event: t = 820.000000 ms; reinf = -1.000000; RLhebbwt = 0.001000; RLlenhebb = 100.000000; tlasthebbelig = 801.200000; deltaw = -0.000800

example 4:
t=940.800000 (BEFORE) tlaspre=923.800000, tlastpost=881.000000, flag=0.000000, w=1.000000, deltaw=0.000000 
t=940.800000 (AFTER) tlaspre=940.800000, tlastpost=881.000000, flag=0.000000, w=1.000000, deltaw=0.000000

t=944.800000 (BEFORE) tlaspre=940.800000, tlastpost=881.000000, flag=0.000000, w=-1.000000, deltaw=0.000000 
t=944.800000 (AFTER) tlaspre=940.800000, tlastpost=944.800000, flag=0.000000, w=-1.000000, deltaw=0.000000

t=959.400000 (BEFORE) tlaspre=940.800000, tlastpost=944.800000, flag=0.000000, w=1.000000, deltaw=0.000000 
t=959.400000 (AFTER) tlaspre=959.400000, tlastpost=944.800000, flag=0.000000, w=1.000000, deltaw=0.000000

t= 960.0000000001497 - adjusting weights based on RL critic value: -1
t=960.000000, RL-hebb =0.001000, deltaw=-0.001000 
t=960.000000, RL-antihebb =0.000000, deltaw=-0.001000 
RL event: t = 960.000000 ms; reinf = -1.000000; RLhebbwt = 0.001000; RLlenhebb = 100.000000; tlasthebbelig = 944.800000; deltaw = -0.001000

example 5:

t=1059.400000 (BEFORE) tlaspre=1038.400000, tlastpost=1032.400000, flag=0.000000, w=-1.000000, deltaw=0.000000 
t=1059.400000 (AFTER) tlaspre=1038.400000, tlastpost=1059.400000, flag=0.000000, w=-1.000000, deltaw=0.000000 

t= 1080.0000000001132 - adjusting weights based on RL critic value: 1
t=1080.000000, RL-hebb =0.001000, deltaw=0.001000 
t=1080.000000, RL-antihebb =-0.000200, deltaw=0.000800 
RL event: t = 1080.000000 ms; reinf = 1.000000; RLhebbwt = 0.001000; RLlenhebb = 100.000000; tlasthebbelig = 1059.400000; deltaw = 0.000800


another example with more information: (both tlasthebbelig and tlastantielig)

t= 860.000000000127 - adjusting weights based on RL critic value: 1
t=860.000000, RL-hebb =0.001000, deltaw=0.001000 
t=860.000000, RL-antihebb =-0.000200, deltaw=0.000800 
RL event: t = 860.000000 ms; reinf = 1.000000; RLhebbwt = 0.001000; RLlenhebb = 100.000000; tlasthebbelig = 839.000000; tlastantielig = 840.400000; deltaw = 0.000800


**Still unsure how tlasthebbelig and tlastantielig set. Now I understand. It's explained below, with RLon = 1 and STDPon = 0
***eligibility is establised by comparing times of pre- and post-synaptic spikes.
*** the function receives w. if w>=0, its a presynaptic spike. if w<0 its postsynaptic spike.
*** if presynaptic spike at time t, it will look at the time of last postsynaptic spike. and therefore look for antihebbian eligibility.
*** if postsynaptic spike at time t, it will look at the time of last presynaptic spike and therefore look for hebbian eligibility.

**In the example below 2 spike events were printed

***spike event 1:
t=1253.600000 (BEFORE) tlaspre=1232.600000, tlastpost=1219.600000, tlasthebbelig=1219.600000, tlastantielig=-1.000000, flag=0.000000, w=-1.000000, deltaw=0.000000 
t=1253.600000 (AFTER) tlaspre=1232.600000, tlastpost=1253.600000, tlasthebbelig=1253.600000, tlastantielig=-1.000000, flag=0.000000, w=-1.000000, deltaw=0.000000 

--at time 1253.6 ms, a postsynaptic spike occurs (because w = -1), therefore the mechanism compares time of last presynaptic spike which is 1232.6 ms
--the time difference between current postsynaptic spike and last presynaptic spike is 20 ms. 
--tpost-tpre (20 ms) is less than 100 ms therefore the eligibilty trace is activated at 1253.6 ms for hebbian plasticity.

***spike event 2:
t=1259.000000 (BEFORE) tlaspre=1232.600000, tlastpost=1253.600000, tlasthebbelig=1253.600000, tlastantielig=-1.000000, flag=0.000000, w=1.000000, deltaw=0.000000 
t=1259.000000 (AFTER) tlaspre=1259.000000, tlastpost=1253.600000, tlasthebbelig=1253.600000, tlastantielig=1259.000000, flag=0.000000, w=1.000000, deltaw=0.000000

--at time 1259 ms, a presynaptic spike accurs (because w = 1), therefore the mechanism compares time of last postsynaptic spike which is 1253.6 ms.
-- the time difference between current presynaptic spike and last postsynaptic spike is 5.4 ms.
--tpre-tpost (5.4 ms) is less than 10 ms therefore the eligibility trace is activated at 1259.0 ms for antihebbian plasticity.

*** a reward/punishment arrives at 1260 ms

t= 1259.9999999999495 - adjusting weights based on RL critic value: 1
t=1260.000000, RL-hebb =0.001000, deltaw=0.001000 
t=1260.000000, RL-antihebb =-0.000200, deltaw=0.000800 
RL event: t = 1260.000000 ms; reinf = 1.000000; RLhebbwt = 0.001000; RLlenhebb = 100.000000; tlasthebbelig = 1253.600000; tlastantielig = 1259.000000; deltaw = 0.000800

-- at time 1260 ms, eligibility for both hebbian and antihebbian were active (hebbian was active till 1353.6 ms and antihebb was active till 1359 ms).
-- since its a reward... it will implement positive reinforcement.
-- if it was a negative, both hebbian and antihebbian plasticities will be reversed.

** right now the window for hebbian plasticity is 100 ms where as antihebbian plasticity is 10 ms.
** the eligibility for both hebbian and anithebbian stays active for 100 ms.

**What happens when both RLon and STDPon are 1. See the example below.

t=47.200000 (AFTER) tlaspre=25.800000, tlastpost=47.200000, tlasthebbelig=47.200000, tlastantielig=-1.000000, flag=0.000000, w=-1.000000, deltaw=0.000000 
t=48.200000 (BEFORE) tlaspre=25.800000, tlastpost=47.200000, tlasthebbelig=47.200000, tlastantielig=-1.000000, flag=-1.000000, w=-1.000000, deltaw=0.000000 
Hebbian STDP event: t = 48.200000 ms; tlastpre = 25.800000; w = -1.000000; deltaw = 0.000118

t= 60.00000000000058 - adjusting weights based on RL critic value: -1
t=60.000000, RL-hebb =0.001000, deltaw=-0.001000 
t=60.000000, RL-antihebb =0.000000, deltaw=-0.001000 
RL event: t = 60.000000 ms; reinf = -1.000000; RLhebbwt = 0.001000; RLlenhebb = 100.000000; tlasthebbelig = 47.200000; tlastantielig = -1.000000; deltaw = -0.001000

**Sent 2 messages (Slack) to Sam on Jan10,2020 for discussion
Message 1:
While building SmartAgent model, i incorporated stdp.mod from RL_arm model 
(https://github.com/Neurosim-lab/netpyne/blob/development/examples/RL_arm/params.py)
and used the parameters: 
STDPparams = {'hebbwt': 0.00001, 'antiwt':-0.00001, 'wmax': 50, 'RLon': 1 , 'RLhebbwt': 0.001, 'RLantiwt': -0.000, \
    'tauhebb': 10, 'RLwindhebb': 50, 'useRLexp': 0, 'softthresh': 0, 'verbose':0}.
As earlier, i didn't carefully looked at all these parameters and didn't try to understand the meaning of each of these
parameters, while running a reduced verson of SmartAgent, I noticed a drop in the activity of postsynaptic neurons which 
were connected with presynaptic neurons using STDPparams as declared above. on dissecting these mechanisms, i found out:
1. It was using STDP-based and RL-based weight adjustments. It was because, by default STDPon is set to 1 and I didn't set STDPon to 0.
1.1. Before I further dive into the working of the mechanisms, i wonder why this choice was made? I am not against using this strategy 
but want to understand biological rationale behind this choice
2. The second set of parameters, i wondered about were 'RLhebbwt': 0.001, 'RLantiwt': -0.000.
2.1. RLhebbwt defines the change in weight, when RLon is 1 and hebbeligibilty is active. 
2.1.1 hebbeligibility is active for 100 ms if postsynaptic neuron fires within 50 ms ('RLwindhebb': 50) of presynaptic neuron. by default RLwindhebb is 10 ms.  
2.1.2 when there is a reward (+1), and hebbelegibility is active for less than 100 ms, the weight increases.
2.1.3 when there is a punishment (-1), and hebbelegibility is active for less than 100 ms, the weight decreases.
2.2. RLantiwt defines the change in weight, when RLon is 1 and antieligibility is active.
2.2.1. antieligibility is active for 100 ms if presynaptic neuron fires after postsynaptic neuron within 10 ms. (default: 'RLwindanti': 10) 
2.2.2. when there is a reward (+1), and antieligibility is active for less than 100 ms, the weight decreases.
2.2.3. when there is a punishment (-1), and antieligibility is active for less than 100 ms, the weight increases.
2.2.4. However, this mechanism is inactive because RLantiwt': -0.000.
2.2.5. So the question is why was it set to be inactive? Should I use it? What is the biological relevance of this mechanism?
3. The biggest issue in my model is that because the postsynaptic neurons are driven by presynaptic neurons, 
if the connection weight drops to 0, the postsynaptic neurons become inactive. Probably, need to have some baseline activity in the model for all neurons.

Message 2: 
Also just for discussion, if there is a topologically mapped neurons across multiple layers, i have been wondering why would we need STDP to encode spatial information. Same question from other side: how would STDP help encode visual information, all i can think (also see in the model) of is that it increase firing rate globally. I understand the basic concept but cant wrap my head around how this can be useful. Of course, i am trying both ways i.e. with STDP (adjustable weights) and without STDP (fixed weights) in Visual cortex.

*20jan13
**Things to do:
***Develop analytical tools/scripts to dissect the circuit to see how the activity is encoded hierarchically. V1 vs V4 vs IT etc
***Add noise to the Motor neurons so that these neurons can fire in the absence of synaptic input. This will give a chance to recover if the connection weights are depressed to 0.
***Remove STDP in Visual areas.
***what is the firing rate of neurons and their population in the absence of plasticity?
***How to have a better control over the racket movements in the aigame?

*20jan14
**add background noise firing rate with noise to excitatory cells.
netParams.stimSourceParams['ebkg'] = {'type': 'NetStim', 'rate': 5, 'noise': 0.3}
netParams.stimTargetParams['ebkg->all'] = {'source': 'ebkg', 'conds': {'cellType': ['EV1','EV4','EIT', 'EMI', 'EMO']}, 'weight': 0.01, 'delay': 'max(1, normal(5,2))', 'synMech': 'AMPA'}  
**In folder 'SMARTAgent_Reduced_01142020/AllConns0' set weights of all connections to 0 to see the background activity of the network i.e. R will fire based on the input and E cells will fire based on ebkg and i cells will fire based on bkg.
**In folder 'SMARTAgent_Reduced_01142020/AllConns0ExceptReccurent' set wights of all connections to 0 except recurrent connections and background activity as in the above case.
**In folder 'SMARTAgent_Reduced_01142020/AllConns0ExceptFeedForwardExcit' set weights of all connections to 0 except feedforward excitatory connections and background activity.
**When compared AllConns0 with AllConns0ExceptRecurrent, found no difference. Rerunning ALlConns0ExceptRecurrent with higher connection strength (0.0001 --> 0.001) 

*20jan15
**For 'SMARTAgent_Reduced_01142020/AllConns0ExceptFeedForwardExcit', we had used weight of 0.002 and had run simulation for 100 sec.
*** Comparing the firing rate to the baseline, it seemed that 0.002 was high. 
***So for comparison at different values for weights, i reran the simulation for 10 sec with 0.002.
***Running simulation for 10 sec with weight of 0.001 and 0.0005

*20jan16
**worked on plotting neural activity to show spatial patterns of neurons activated in diffent layers.
**finished in matlab and started implementing in python.

*20jan17
**finished plotting neural activity to show spatial patterns of neurons activated in different layers.
**found that: 
1) The activity didnt propagate across the layers faithfully. Rather only noise was seen across layers.
2) Sam thinks that noise is good however, the activity should be propagated across layers faithfully.
2.1) For propagation, he suggested may be we should increase the strength of the connections.
2.2) I think the limitation is time step for playing game i.e. 20 ms. it allows only to detect 50Hz stimulation, any input driving lower frequency will not bre represented.
2.2.1) Solution could be shifting either the activiation curve to increase firing rates or increase the time step for playing game. If we increase step to 100 ms. this will allow to encode atleast 10Hz input.
3) Also for comparison, Sam suggested that we should also plot the actual input image.

*20jan20
**Implemented saving input frames to the model.
**Now can show the input images together with model's spatial activity of neuron in each layer.

*20jan23
**In folder 'SMARTAgent_Reduced_01232020/AllConns0' --- set all conn weights 0 and see the effect of noise in each area.
***Saw all populations firing at baseline rate except MO. Found that MIi was plotted instead of MO. Fixed now.
**In folder 'SMARTAgent_Reduced_01232020/AllConns0ExceptFeedForwardExcit'
***The inhibition rate was similar to the simulation when there were no connections. Increased e.g. V1-->InV1 0.0001 to 0.001
****0.001 seems insufficient as only InV1 firing rate increases.
***Try increasing to 0.002 and then to 0.004 and so on.
***Seems like the problem is not with the weight of connections but the connection probability.

*20jan24
***Increase connection probability for within area Exct-->Inhib from 0.02 to 0.2 and keep strength 0.002
****Strength of 0.002 was too high for IV1 and IV4. Rerunning with strength of 0.001 and prob Conn 0.23
***The lowest number of neuron in any area is 9. So i decided to choose 0.23 as connection probability so that atleast I get 2 connections
****Both increasing weight and prob connections do not work for all the areas. If presynaptic area has too many neurons then using same prob for that area will connect a lots of presynaptic neuron with each postsynaptic neuron.
****A quick fix to this problem might be to have a fixed convergence on to postsynaptic area. I choose 9. (SMARTAgent_Reduced_01232020/AllConns0ExceptFeedForwardExcit/ChangeProb2Convergence/)
***Using convergence of 9 instead of conn prob of 0.02 or 0.23 seems to work better. Now increasing weight from 0.001 to 0.002
**Now fix inhibition within area. (SMARTAgent_Reduced_01232020/FFExcitAndWithinAreaInhibition)
***change 'probability': 0.02 to 'divergence': 9
***change 'weight': 0.0001 to 'weight': 0.001 in subfolder 0_001; to 'weight': 0.002 in subfolder 0_002 and 0_005.

*20jan27
**I was using convergence and divergence factor of 9 for connectivity from E to I and I to E within layers that we decided to change.
**I changed E to I and I to E connectivity using spatial overlap of 9 (3x3 in square window) for E to I within layers and 25 (5x5 in square window) for I to E within layers.
**Now I will test the connections and strength.
***To see if the connections list are generated as expected or not, I printed the lists as below
List MI to InMI
[[0, 0], [1, 0], [5, 0], [6, 0], [0, 1], [1, 1], [2, 1], [5, 1], [6, 1], [7, 1], 
[2, 2], [3, 2], [4, 2], [7, 2], [8, 2], [9, 2], [2, 3], [3, 3], [4, 3], [7, 3], [8, 3], [9, 3], [12, 3], [13, 3], [14, 3], 
[3, 4], [4, 4], [8, 4], [9, 4], [13, 4], [14, 4], [5, 5], [6, 5], [7, 5], [10, 5], [11, 5], [12, 5], [15, 5], [16, 5], [17, 5], 
[10, 6], [11, 6], [12, 6], [15, 6], [16, 6], [17, 6], [20, 6], [21, 6], [22, 6], [11, 7], [12, 7], [13, 7], [16, 7], [17, 7], [18, 7], [21, 7], [22, 7], [23, 7], 
[13, 8], [14, 8], [18, 8], [19, 8], [23, 8], [24, 8]]
List InMI to MI
[[0, 0], [1, 0], [2, 0], [3, 0], [4, 0], [5, 0], [6, 0], [7, 0], [8, 0], [0, 1], [1, 1], [2, 1], [3, 1], [4, 1], [5, 1], [6, 1], [7, 1], [8, 1], 
[0, 2], [1, 2], [2, 2], [3, 2], [4, 2], [5, 2], [6, 2], [7, 2], [8, 2], [0, 3], [1, 3], [2, 3], [3, 3], [4, 3], [5, 3], [6, 3], [7, 3], [8, 3], 
[0, 4], [1, 4], [2, 4], [3, 4], [4, 4], [5, 4], [6, 4], [7, 4], [8, 4], [0, 5], [1, 5], [2, 5], [3, 5], [4, 5], [5, 5], [6, 5], [7, 5], [8, 5], 
[0, 6], [1, 6], [2, 6], [3, 6], [4, 6], [5, 6], [6, 6], [7, 6], [8, 6], [0, 7], [1, 7], [2, 7], [3, 7], [4, 7], [5, 7], [6, 7], [7, 7], [8, 7], 
[0, 8], [1, 8], [2, 8], [3, 8], [4, 8], [5, 8], [6, 8], [7, 8], [8, 8]]

**Found wrong connections in List MI to InMI.
**Fixed the bug. Hopefully it is fixed. Atleast for this case:
List MI to InMI
[[0, 0], [1, 0], [5, 0], [6, 0], [1, 1], [2, 1], [3, 1], [6, 1], [7, 1], [8, 1], 
[3, 2], [4, 2], [8, 2], [9, 2], [5, 3], [6, 3], [10, 3], [11, 3], [15, 3], [16, 3], 
[6, 4], [7, 4], [8, 4], [11, 4], [12, 4], [13, 4], [16, 4], [17, 4], [18, 4], 
[8, 5], [9, 5], [13, 5], [14, 5], [18, 5], [19, 5], [15, 6], [16, 6], [20, 6], [21, 6], 
[16, 7], [17, 7], [18, 7], [21, 7], [22, 7], [23, 7], [18, 8], [19, 8], [23, 8], [24, 8]]

**Found wrong connections in List InMI to MI.
**Fixed the bug. Hopefully it is fixed.

MI to InMI
[[0, 0], [1, 0], [5, 0], [6, 0], [1, 1], [2, 1], [3, 1], [6, 1], [7, 1], [8, 1], 
[3, 2], [4, 2], [8, 2], [9, 2], [5, 3], [6, 3], [10, 3], [11, 3], [15, 3], [16, 3], 
[6, 4], [7, 4], [8, 4], [11, 4], [12, 4], [13, 4], [16, 4], [17, 4], [18, 4], 
[8, 5], [9, 5], [13, 5], [14, 5], [18, 5], [19, 5], [15, 6], [16, 6], [20, 6], [21, 6], 
[16, 7], [17, 7], [18, 7], [21, 7], [22, 7], [23, 7], [18, 8], [19, 8], [23, 8], [24, 8]]
InMI to MI
[[0, 0], [0, 1], [0, 2], [0, 5], [0, 6], [0, 7], [0, 10], [0, 11], [0, 12], [1, 0], 
[1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [1, 9], [1, 10], [1, 11], [1, 12], [1, 13], [1, 14], 
[2, 2], [2, 3], [2, 4], [2, 7], [2, 8], [2, 9], [2, 12], [2, 13], [2, 14], 
[3, 0], [3, 1], [3, 2], [3, 5], [3, 6], [3, 7], [3, 10], [3, 11], [3, 12], [3, 15], [3, 16], [3, 17], [3, 20], [3, 21], [3, 22], 
[4, 0], [4, 1], [4, 2], [4, 3], [4, 4], [4, 5], [4, 6], [4, 7], [4, 8], [4, 9], [4, 10], [4, 11], [4, 12], [4, 13], [4, 14], [4, 15], [4, 16], [4, 17], [4, 18], [4, 19], [4, 20], [4, 21], [4, 22], [4, 23], [4, 24], 
[5, 2], [5, 3], [5, 4], [5, 7], [5, 8], [5, 9], [5, 12], [5, 13], [5, 14], [5, 17], [5, 18], [5, 19], [5, 22], [5, 23], [5, 24], 
[6, 10], [6, 11], [6, 12], [6, 15], [6, 16], [6, 17], [6, 20], [6, 21], [6, 22], 
[7, 10], [7, 11], [7, 12], [7, 13], [7, 14], [7, 15], [7, 16], [7, 17], [7, 18], [7, 19], [7, 20], [7, 21], [7, 22], [7, 23], [7, 24], 
[8, 12], [8, 13], [8, 14], [8, 17], [8, 18], [8, 19], [8, 22], [8, 23], [8, 24]]

**print the following connections: Feedforward E->E, Within layer E->I and I->E.

*20jan28
**testing the connectivity----

E to V1
[[0, 0], [1, 0], [2, 0], [20, 0], [21, 0], [22, 0], [40, 0], [41, 0], [42, 0], [0, 1], [1, 1], [2, 1], [3, 1], [20, 1], [21, 1], [22, 1], [23, 1], [40, 1], [41, 1], [42, 1], [43, 1], [0, 2], [1, 2], [2, 2], [3, 2], [4, 2], [20, 2], [21, 2], [22, 2], [23, 2], [24, 2], [40, 2], [41, 2], [42, 2], [43, 2], [44, 2], [1, 3], [2, 3], [3, 3], [4, 3], [5, 3], [21, 3], [22, 3], [23, 3], [24, 3], [25, 3], [41, 3], [42, 3], [43, 3], [44, 3], [45, 3], [2, 4], [3, 4], [4, 4], [5, 4], [6, 4], [22, 4], [23, 4], [24, 4], [25, 4], [26, 4], [42, 4], [43, 4], [44, 4], [45, 4], [46, 4], [3, 5], [4, 5], [5, 5], [6, 5], [7, 5], [23, 5], [24, 5], [25, 5], [26, 5], [27, 5], [43, 5], [44, 5], [45, 5], [46, 5], [47, 5], [4, 6], [5, 6], [6, 6], [7, 6], [8, 6], [24, 6], [25, 6], [26, 6], [27, 6], [28, 6], [44, 6], [45, 6], [46, 6], [47, 6], [48, 6], [5, 7], [6, 7], [7, 7], [8, 7], [9, 7], [25, 7], [26, 7], [27, 7], [28, 7], [29, 7], [45, 7], [46, 7], [47, 7], [48, 7], [49, 7], [6, 8], [7, 8], [8, 8], [9, 8], [10, 8], [26, 8], [27, 8], [28, 8], [29, 8], [30, 8], [46, 8], [47, 8], [48, 8], [49, 8], [50, 8], [7, 9], [8, 9], [9, 9], [10, 9], [11, 9], [27, 9], [28, 9], [29, 9], [30, 9], [31, 9], [47, 9], [48, 9], [49, 9], [50, 9], [51, 9], [8, 10], [9, 10], [10, 10], [11, 10], [12, 10], [28, 10], [29, 10], [30, 10], [31, 10], [32, 10], [48, 10], [49, 10], [50, 10], [51, 10], [52, 10], [9, 11], [10, 11], [11, 11], [12, 11], [13, 11], [29, 11], [30, 11], [31, 11], [32, 11], [33, 11], [49, 11], [50, 11], [51, 11], [52, 11], [53, 11], [10, 12], [11, 12], [12, 12], [13, 12], [14, 12], [30, 12], [31, 12], [32, 12], [33, 12], [34, 12], [50, 12], [51, 12], [52, 12], [53, 12], [54, 12], [11, 13], [12, 13], [13, 13], [14, 13], [15, 13], [31, 13], [32, 13], [33, 13], [34, 13], [35, 13], [51, 13], [52, 13], [53, 13], [54, 13], [55, 13], [12, 14], [13, 14], [14, 14], [15, 14], [16, 14], [32, 14], [33, 14], [34, 14], [35, 14], [36, 14], [52, 14], [53, 14], [54, 14], [55, 14], [56, 14], [13, 15], [14, 15], [15, 15], [16, 15], [17, 15], [33, 15], [34, 15], [35, 15], [36, 15], [37, 15], [53, 15], [54, 15], [55, 15], [56, 15], [57, 15], [14, 16], [15, 16], [16, 16], [17, 16], [18, 16], [34, 16], [35, 16], [36, 16], [37, 16], [38, 16], [54, 16], [55, 16], [56, 16], [57, 16], [58, 16], [15, 17], [16, 17], [17, 17], [18, 17], [19, 17], [35, 17], [36, 17], [37, 17], [38, 17], [39, 17], [55, 17], [56, 17], [57, 17], [58, 17], [59, 17], [16, 18], [17, 18], [18, 18], [19, 18], [36, 18], [37, 18], [38, 18], [39, 18], [56, 18], [57, 18], [58, 18], [59, 18], [17, 19], [18, 19], [19, 19], [37, 19], [38, 19], [39, 19], [57, 19], [58, 19], [59, 19], [0, 20], [1, 20], [2, 20], [20, 20], [21, 20], [22, 20], [40, 20], [41, 20], [42, 20], [60, 20], [61, 20], [62, 20], [0, 21], [1, 21], [2, 21], [3, 21], [20, 21], [21, 21], [22, 21], [23, 21], [40, 21], [41, 21], [42, 21], [43, 21], [60, 21], [61, 21], [62, 21], [63, 21], [0, 22], [1, 22], [2, 22], [3, 22], [4, 22], [20, 22], [21, 22], [22, 22], [23, 22], [24, 22], [40, 22], [41, 22], [42, 22], [43, 22], [44, 22], [60, 22], [61, 22], [62, 22], [63, 22], [64, 22], [1, 23], [2, 23], [3, 23], [4, 23], [5, 23], [21, 23], [22, 23], [23, 23], [24, 23], [25, 23], [41, 23], [42, 23], [43, 23], [44, 23], [45, 23], [61, 23], [62, 23], [63, 23], [64, 23], [65, 23], [2, 24], [3, 24], [4, 24], [5, 24], [6, 24], [22, 24], [23, 24], [24, 24], [25, 24], [26, 24], [42, 24], [43, 24], [44, 24], [45, 24], [46, 24], [62, 24], [63, 24], [64, 24], [65, 24], [66, 24], [3, 25], [4, 25], [5, 25], [6, 25], [7, 25], [23, 25], [24, 25], [25, 25], [26, 25], [27, 25], [43, 25], [44, 25], [45, 25], [46, 25], [47, 25], [63, 25], [64, 25], [65, 25], [66, 25], [67, 25], [4, 26], [5, 26], [6, 26], [7, 26], [8, 26], [24, 26], [25, 26], [26, 26], [27, 26], [28, 26], [44, 26], [45, 26], [46, 26], [47, 26], [48, 26], [64, 26], [65, 26], [66, 26], [67, 26], [68, 26], [5, 27], [6, 27], [7, 27], [8, 27], [9, 27], [25, 27], [26, 27], [27, 27], [28, 27], [29, 27], [45, 27], [46, 27], [47, 27], [48, 27], [49, 27], [65, 27], [66, 27], [67, 27], [68, 27], [69, 27], [6, 28], [7, 28], [8, 28], [9, 28], [10, 28], [26, 28], [27, 28], [28, 28], [29, 28], [30, 28], [46, 28], [47, 28], [48, 28], [49, 28], [50, 28], [66, 28], [67, 28], [68, 28], [69, 28], [70, 28], [7, 29], [8, 29], [9, 29], [10, 29], [11, 29], [27, 29], [28, 29], [29, 29], [30, 29], [31, 29], [47, 29], [48, 29], [49, 29], [50, 29], [51, 29], [67, 29], [68, 29], [69, 29], [70, 29], [71, 29], [8, 30], [9, 30], [10, 30], [11, 30], [12, 30], [28, 30], [29, 30], [30, 30], [31, 30], [32, 30], [48, 30], [49, 30], [50, 30], [51, 30], [52, 30], [68, 30], [69, 30], [70, 30], [71, 30], [72, 30], [9, 31], [10, 31], [11, 31], [12, 31], [13, 31], [29, 31], [30, 31], [31, 31], [32, 31], [33, 31], [49, 31], [50, 31], [51, 31], [52, 31], [53, 31], [69, 31], [70, 31], [71, 31], [72, 31], [73, 31], [10, 32], [11, 32], [12, 32], [13, 32], [14, 32], [30, 32], [31, 32], [32, 32], [33, 32], [34, 32], [50, 32], [51, 32], [52, 32], [53, 32], [54, 32], [70, 32], [71, 32], [72, 32], [73, 32], [74, 32], [11, 33], [12, 33], [13, 33], [14, 33], [15, 33], [31, 33], [32, 33], [33, 33], [34, 33], [35, 33], [51, 33], [52, 33], [53, 33], [54, 33], [55, 33], [71, 33], [72, 33], [73, 33], [74, 33], [75, 33], [12, 34], [13, 34], [14, 34], [15, 34], [16, 34], [32, 34], [33, 34], [34, 34], [35, 34], [36, 34], [52, 34], [53, 34], [54, 34], [55, 34], [56, 34], [72, 34], [73, 34], [74, 34], [75, 34], [76, 34], [13, 35], [14, 35], [15, 35], [16, 35], [17, 35], [33, 35], [34, 35], [35, 35], [36, 35], [37, 35], [53, 35], [54, 35], [55, 35], [56, 35], [57, 35], [73, 35], [74, 35], [75, 35], [76, 35], [77, 35], [14, 36], [15, 36], [16, 36], [17, 36], [18, 36], [34, 36], [35, 36], [36, 36], [37, 36], [38, 36], [54, 36], [55, 36], [56, 36], [57, 36], [58, 36], [74, 36], [75, 36], [76, 36], [77, 36], [78, 36], [15, 37], [16, 37], [17, 37], [18, 37], [19, 37], [35, 37], [36, 37], [37, 37], [38, 37], [39, 37], [55, 37], [56, 37], [57, 37], [58, 37], [59, 37], [75, 37], [76, 37], [77, 37], [78, 37], [79, 37], [16, 38], [17, 38], [18, 38], [19, 38], [36, 38], [37, 38], [38, 38], [39, 38], [56, 38], [57, 38], [58, 38], [59, 38], [76, 38], [77, 38], [78, 38], [79, 38], [17, 39], [18, 39], [19, 39], [37, 39], [38, 39], [39, 39], [57, 39], [58, 39], [59, 39], [77, 39], [78, 39], [79, 39], [0, 40], [1, 40], [2, 40], [20, 40], [21, 40], [22, 40], [40, 40], [41, 40], [42, 40], [60, 40], [61, 40], [62, 40], [80, 40], [81, 40], [82, 40], [0, 41], [1, 41], [2, 41], [3, 41], [20, 41], [21, 41], [22, 41], [23, 41], [40, 41], [41, 41], [42, 41], [43, 41], [60, 41], [61, 41], [62, 41], [63, 41], [80, 41], [81, 41], [82, 41], [83, 41], [0, 42], [1, 42], [2, 42], [3, 42], [4, 42], [20, 42], [21, 42], [22, 42], [23, 42], [24, 42], [40, 42], [41, 42], [42, 42], [43, 42], [44, 42], [60, 42], [61, 42], [62, 42], [63, 42], [64, 42], [80, 42], [81, 42], [82, 42], [83, 42], [84, 42], [1, 43], [2, 43], [3, 43], [4, 43], [5, 43], [21, 43], [22, 43], [23, 43], [24, 43], [25, 43], [41, 43], [42, 43], [43, 43], [44, 43], [45, 43], [61, 43], [62, 43], [63, 43], [64, 43], [65, 43], [81, 43], [82, 43], [83, 43], [84, 43], [85, 43], [2, 44], [3, 44], [4, 44], [5, 44], [6, 44], [22, 44], [23, 44], [24, 44], [25, 44], [26, 44], [42, 44], [43, 44], [44, 44], [45, 44], [46, 44], [62, 44], [63, 44], [64, 44], [65, 44], [66, 44], [82, 44], [83, 44], [84, 44], [85, 44], [86, 44], [3, 45], [4, 45], [5, 45], [6, 45], [7, 45], [23, 45], [24, 45], [25, 45], [26, 45], [27, 45], [43, 45], [44, 45], [45, 45], [46, 45], [47, 45], [63, 45], [64, 45], [65, 45], [66, 45], [67, 45], [83, 45], [84, 45], [85, 45], [86, 45], [87, 45], [4, 46], [5, 46], [6, 46], [7, 46], [8, 46], [24, 46], [25, 46], [26, 46], [27, 46], [28, 46], [44, 46], [45, 46], [46, 46], [47, 46], [48, 46], [64, 46], [65, 46], [66, 46], [67, 46], [68, 46], [84, 46], [85, 46], [86, 46], [87, 46], [88, 46], [5, 47], [6, 47], [7, 47], [8, 47], [9, 47], [25, 47], [26, 47], [27, 47], [28, 47], [29, 47], [45, 47], [46, 47], [47, 47], [48, 47], [49, 47], [65, 47], [66, 47], [67, 47], [68, 47], [69, 47], [85, 47], [86, 47], [87, 47], [88, 47], [89, 47], [6, 48], [7, 48], [8, 48], [9, 48], [10, 48], [26, 48], [27, 48], [28, 48], [29, 48], [30, 48], [46, 48], [47, 48], [48, 48], [49, 48], [50, 48], [66, 48], [67, 48], [68, 48], [69, 48], [70, 48], [86, 48], [87, 48], [88, 48], [89, 48], [90, 48], [7, 49], [8, 49], [9, 49], [10, 49], [11, 49], [27, 49], [28, 49], [29, 49], [30, 49], [31, 49], [47, 49], [48, 49], [49, 49], [50, 49], [51, 49], [67, 49], [68, 49], [69, 49], [70, 49], [71, 49], [87, 49], [88, 49], [89, 49], [90, 49], [91, 49], [8, 50], [9, 50], [10, 50], [11, 50], [12, 50], [28, 50], [29, 50], [30, 50], [31, 50], [32, 50], [48, 50], [49, 50], [50, 50], [51, 50], [52, 50], [68, 50], [69, 50], [70, 50], [71, 50], [72, 50], [88, 50], [89, 50], [90, 50], [91, 50], [92, 50], [9, 51], [10, 51], [11, 51], [12, 51], [13, 51], [29, 51], [30, 51], [31, 51], [32, 51], [33, 51], [49, 51], [50, 51], [51, 51], [52, 51], [53, 51], [69, 51], [70, 51], [71, 51], [72, 51], [73, 51], [89, 51], [90, 51], [91, 51], [92, 51], [93, 51], [10, 52], [11, 52], [12, 52], [13, 52], [14, 52], [30, 52], [31, 52], [32, 52], [33, 52], [34, 52], [50, 52], [51, 52], [52, 52], [53, 52], [54, 52], [70, 52], [71, 52], [72, 52], [73, 52], [74, 52], [90, 52], [91, 52], [92, 52], [93, 52], [94, 52], [11, 53], [12, 53], [13, 53], [14, 53], [15, 53], [31, 53], [32, 53], [33, 53], [34, 53], [35, 53], [51, 53], [52, 53], [53, 53], [54, 53], [55, 53], [71, 53], [72, 53], [73, 53], [74, 53], [75, 53], [91, 53], [92, 53], [93, 53], [94, 53], [95, 53], [12, 54], [13, 54], [14, 54], [15, 54], [16, 54], [32, 54], [33, 54], [34, 54], [35, 54], [36, 54], [52, 54], [53, 54], [54, 54], [55, 54], [56, 54], [72, 54], [73, 54], [74, 54], [75, 54], [76, 54], [92, 54], [93, 54], [94, 54], [95, 54], [96, 54], [13, 55], [14, 55], [15, 55], [16, 55], [17, 55], [33, 55], [34, 55], [35, 55], [36, 55], [37, 55], [53, 55], [54, 55], [55, 55], [56, 55], [57, 55], [73, 55], [74, 55], [75, 55], [76, 55], [77, 55], [93, 55], [94, 55], [95, 55], [96, 55], [97, 55], [14, 56], [15, 56], [16, 56], [17, 56], [18, 56], [34, 56], [35, 56], [36, 56], [37, 56], [38, 56], [54, 56], [55, 56], [56, 56], [57, 56], [58, 56], [74, 56], [75, 56], [76, 56], [77, 56], [78, 56], [94, 56], [95, 56], [96, 56], [97, 56], [98, 56], [15, 57], [16, 57], [17, 57], [18, 57], [19, 57], [35, 57], [36, 57], [37, 57], [38, 57], [39, 57], [55, 57], [56, 57], [57, 57], [58, 57], [59, 57], [75, 57], [76, 57], [77, 57], [78, 57], [79, 57], [95, 57], [96, 57], [97, 57], [98, 57], [99, 57], [16, 58], [17, 58], [18, 58], [19, 58], [36, 58], [37, 58], [38, 58], [39, 58], [56, 58], [57, 58], [58, 58], [59, 58], [76, 58], [77, 58], [78, 58], [79, 58], [96, 58], [97, 58], [98, 58], [99, 58], [17, 59], [18, 59], [19, 59], [37, 59], [38, 59], [39, 59], [57, 59], [58, 59], [59, 59], [77, 59], [78, 59], [79, 59], [97, 59], [98, 59], [99, 59], [20, 60], [21, 60], [22, 60], [40, 60], [41, 60], [42, 60], [60, 60], [61, 60], [62, 60], [80, 60], [81, 60], [82, 60], [100, 60], [101, 60], [102, 60], [20, 61], [21, 61], [22, 61], [23, 61], [40, 61], [41, 61], [42, 61], [43, 61], [60, 61], [61, 61], [62, 61], [63, 61], [80, 61], [81, 61], [82, 61], [83, 61], [100, 61], [101, 61], [102, 61], [103, 61], [20, 62], [21, 62], [22, 62], [23, 62], [24, 62], [40, 62], [41, 62], [42, 62], [43, 62], [44, 62], [60, 62], [61, 62], [62, 62], [63, 62], [64, 62], [80, 62], [81, 62], [82, 62], [83, 62], [84, 62], [100, 62], [101, 62], [102, 62], [103, 62], [104, 62], [21, 63], [22, 63], [23, 63], [24, 63], [25, 63], [41, 63], [42, 63], [43, 63], [44, 63], [45, 63], [61, 63], [62, 63], [63, 63], [64, 63], [65, 63], [81, 63], [82, 63], [83, 63], [84, 63], [85, 63], [101, 63], [102, 63], [103, 63], [104, 63], [105, 63], [22, 64], [23, 64], [24, 64], [25, 64], [26, 64], [42, 64], [43, 64], [44, 64], [45, 64], [46, 64], [62, 64], [63, 64], [64, 64], [65, 64], [66, 64], [82, 64], [83, 64], [84, 64], [85, 64], [86, 64], [102, 64], [103, 64], [104, 64], [105, 64], [106, 64], [23, 65], [24, 65], [25, 65], [26, 65], [27, 65], [43, 65], [44, 65], [45, 65], [46, 65], [47, 65], [63, 65], [64, 65], [65, 65], [66, 65], [67, 65], [83, 65], [84, 65], [85, 65], [86, 65], [87, 65], [103, 65], [104, 65], [105, 65], [106, 65], [107, 65], [24, 66], [25, 66], [26, 66], [27, 66], [28, 66], [44, 66], [45, 66], [46, 66], [47, 66], [48, 66], [64, 66], [65, 66], [66, 66], [67, 66], [68, 66], [84, 66], [85, 66], [86, 66], [87, 66], [88, 66], [104, 66], [105, 66], [106, 66], [107, 66], [108, 66], [25, 67], [26, 67], [27, 67], [28, 67], [29, 67], [45, 67], [46, 67], [47, 67], [48, 67], [49, 67], [65, 67], [66, 67], [67, 67], [68, 67], [69, 67], [85, 67], [86, 67], [87, 67], [88, 67], [89, 67], [105, 67], [106, 67], [107, 67], [108, 67], [109, 67], [26, 68], [27, 68], [28, 68], [29, 68], [30, 68], [46, 68], [47, 68], [48, 68], [49, 68], [50, 68], [66, 68], [67, 68], [68, 68], [69, 68], [70, 68], [86, 68], [87, 68], [88, 68], [89, 68], [90, 68], [106, 68], [107, 68], [108, 68], [109, 68], [110, 68], [27, 69], [28, 69], [29, 69], [30, 69], [31, 69], [47, 69], [48, 69], [49, 69], [50, 69], [51, 69], [67, 69], [68, 69], [69, 69], [70, 69], [71, 69], [87, 69], [88, 69], [89, 69], [90, 69], [91, 69], [107, 69], [108, 69], [109, 69], [110, 69], [111, 69], [28, 70], [29, 70], [30, 70], [31, 70], [32, 70], [48, 70], [49, 70], [50, 70], [51, 70], [52, 70], [68, 70], [69, 70], [70, 70], [71, 70], [72, 70], [88, 70], [89, 70], [90, 70], [91, 70], [92, 70], [108, 70], [109, 70], [110, 70], [111, 70], [112, 70], [29, 71], [30, 71], [31, 71], [32, 71], [33, 71], [49, 71], [50, 71], [51, 71], [52, 71], [53, 71], [69, 71], [70, 71], [71, 71], [72, 71], [73, 71], [89, 71], [90, 71], [91, 71], [92, 71], [93, 71], [109, 71], [110, 71], [111, 71], [112, 71], [113, 71], [30, 72], [31, 72], [32, 72], [33, 72], [34, 72], [50, 72], [51, 72], [52, 72], [53, 72], [54, 72], [70, 72], [71, 72], [72, 72], [73, 72], [74, 72], [90, 72], [91, 72], [92, 72], [93, 72], [94, 72], [110, 72], [111, 72], [112, 72], [113, 72], [114, 72], [31, 73], [32, 73], [33, 73], [34, 73], [35, 73], [51, 73], [52, 73], [53, 73], [54, 73], [55, 73], [71, 73], [72, 73], [73, 73], [74, 73], [75, 73], [91, 73], [92, 73], [93, 73], [94, 73], [95, 73], [111, 73], [112, 73], [113, 73], [114, 73], [115, 73], [32, 74], [33, 74], [34, 74], [35, 74], [36, 74], [52, 74], [53, 74], [54, 74], [55, 74], [56, 74], [72, 74], [73, 74], [74, 74], [75, 74], [76, 74], [92, 74], [93, 74], [94, 74], [95, 74], [96, 74], [112, 74], [113, 74], [114, 74], [115, 74], [116, 74], [33, 75], [34, 75], [35, 75], [36, 75], [37, 75], [53, 75], [54, 75], [55, 75], [56, 75], [57, 75], [73, 75], [74, 75], [75, 75], [76, 75], [77, 75], [93, 75], [94, 75], [95, 75], [96, 75], [97, 75], [113, 75], [114, 75], [115, 75], [116, 75], [117, 75], [34, 76], [35, 76], [36, 76], [37, 76], [38, 76], [54, 76], [55, 76], [56, 76], [57, 76], [58, 76], [74, 76], [75, 76], [76, 76], [77, 76], [78, 76], [94, 76], [95, 76], [96, 76], [97, 76], [98, 76], [114, 76], [115, 76], [116, 76], [117, 76], [118, 76], [35, 77], [36, 77], [37, 77], [38, 77], [39, 77], [55, 77], [56, 77], [57, 77], [58, 77], [59, 77], [75, 77], [76, 77], [77, 77], [78, 77], [79, 77], [95, 77], [96, 77], [97, 77], [98, 77], [99, 77], [115, 77], [116, 77], [117, 77], [118, 77], [119, 77], [36, 78], [37, 78], [38, 78], [39, 78], [56, 78], [57, 78], [58, 78], [59, 78], [76, 78], [77, 78], [78, 78], [79, 78], [96, 78], [97, 78], [98, 78], [99, 78], [116, 78], [117, 78], [118, 78], [119, 78], [37, 79], [38, 79], [39, 79], [57, 79], [58, 79], [59, 79], [77, 79], [78, 79], [79, 79], [97, 79], [98, 79], [99, 79], [117, 79], [118, 79], [119, 79], [40, 80], [41, 80], [42, 80], [60, 80], [61, 80], [62, 80], [80, 80], [81, 80], [82, 80], [100, 80], [101, 80], [102, 80], [120, 80], [121, 80], [122, 80], [40, 81], [41, 81], [42, 81], [43, 81], [60, 81], [61, 81], [62, 81], [63, 81], [80, 81], [81, 81], [82, 81], [83, 81], [100, 81], [101, 81], [102, 81], [103, 81], [120, 81], [121, 81], [122, 81], [123, 81], [40, 82], [41, 82], [42, 82], [43, 82], [44, 82], [60, 82], [61, 82], [62, 82], [63, 82], [64, 82], [80, 82], [81, 82], [82, 82], [83, 82], [84, 82], [100, 82], [101, 82], [102, 82], [103, 82], [104, 82], [120, 82], [121, 82], [122, 82], [123, 82], [124, 82], [41, 83], [42, 83], [43, 83], [44, 83], [45, 83], [61, 83], [62, 83], [63, 83], [64, 83], [65, 83], [81, 83], [82, 83], [83, 83], [84, 83], [85, 83], [101, 83], [102, 83], [103, 83], [104, 83], [105, 83], [121, 83], [122, 83], [123, 83], [124, 83], [125, 83], [42, 84], [43, 84], [44, 84], [45, 84], [46, 84], [62, 84], [63, 84], [64, 84], [65, 84], [66, 84], [82, 84], [83, 84], [84, 84], [85, 84], [86, 84], [102, 84], [103, 84], [104, 84], [105, 84], [106, 84], [122, 84], [123, 84], [124, 84], [125, 84], [126, 84], [43, 85], [44, 85], [45, 85], [46, 85], [47, 85], [63, 85], [64, 85], [65, 85], [66, 85], [67, 85], [83, 85], [84, 85], [85, 85], [86, 85], [87, 85], [103, 85], [104, 85], [105, 85], [106, 85], [107, 85], [123, 85], [124, 85], [125, 85], [126, 85], [127, 85], [44, 86], [45, 86], [46, 86], [47, 86], [48, 86], [64, 86], [65, 86], [66, 86], [67, 86], [68, 86], [84, 86], [85, 86], [86, 86], [87, 86], [88, 86], [104, 86], [105, 86], [106, 86], [107, 86], [108, 86], [124, 86], [125, 86], [126, 86], [127, 86], [128, 86], [45, 87], [46, 87], [47, 87], [48, 87], [49, 87], [65, 87], [66, 87], [67, 87], [68, 87], [69, 87], [85, 87], [86, 87], [87, 87], [88, 87], [89, 87], [105, 87], [106, 87], [107, 87], [108, 87], [109, 87], [125, 87], [126, 87], [127, 87], [128, 87], [129, 87], [46, 88], [47, 88], [48, 88], [49, 88], [50, 88], [66, 88], [67, 88], [68, 88], [69, 88], [70, 88], [86, 88], [87, 88], [88, 88], [89, 88], [90, 88], [106, 88], [107, 88], [108, 88], [109, 88], [110, 88], [126, 88], [127, 88], [128, 88], [129, 88], [130, 88], [47, 89], [48, 89], [49, 89], [50, 89], [51, 89], [67, 89], [68, 89], [69, 89], [70, 89], [71, 89], [87, 89], [88, 89], [89, 89], [90, 89], [91, 89], [107, 89], [108, 89], [109, 89], [110, 89], [111, 89], [127, 89], [128, 89], [129, 89], [130, 89], [131, 89], [48, 90], [49, 90], [50, 90], [51, 90], [52, 90], [68, 90], [69, 90], [70, 90], [71, 90], [72, 90], [88, 90], [89, 90], [90, 90], [91, 90], [92, 90], [108, 90], [109, 90], [110, 90], [111, 90], [112, 90], [128, 90], [129, 90], [130, 90], [131, 90], [132, 90], [49, 91], [50, 91], [51, 91], [52, 91], [53, 91], [69, 91], [70, 91], [71, 91], [72, 91], [73, 91], [89, 91], [90, 91], [91, 91], [92, 91], [93, 91], [109, 91], [110, 91], [111, 91], [112, 91], [113, 91], [129, 91], [130, 91], [131, 91], [132, 91], [133, 91], [50, 92], [51, 92], [52, 92], [53, 92], [54, 92], [70, 92], [71, 92], [72, 92], [73, 92], [74, 92], [90, 92], [91, 92], [92, 92], [93, 92], [94, 92], [110, 92], [111, 92], [112, 92], [113, 92], [114, 92], [130, 92], [131, 92], [132, 92], [133, 92], [134, 92], [51, 93], [52, 93], [53, 93], [54, 93], [55, 93], [71, 93], [72, 93], [73, 93], [74, 93], [75, 93], [91, 93], [92, 93], [93, 93], [94, 93], [95, 93], [111, 93], [112, 93], [113, 93], [114, 93], [115, 93], [131, 93], [132, 93], [133, 93], [134, 93], [135, 93], [52, 94], [53, 94], [54, 94], [55, 94], [56, 94], [72, 94], [73, 94], [74, 94], [75, 94], [76, 94], [92, 94], [93, 94], [94, 94], [95, 94], [96, 94], [112, 94], [113, 94], [114, 94], [115, 94], [116, 94], [132, 94], [133, 94], [134, 94], [135, 94], [136, 94], [53, 95], [54, 95], [55, 95], [56, 95], [57, 95], [73, 95], [74, 95], [75, 95], [76, 95], [77, 95], [93, 95], [94, 95], [95, 95], [96, 95], [97, 95], [113, 95], [114, 95], [115, 95], [116, 95], [117, 95], [133, 95], [134, 95], [135, 95], [136, 95], [137, 95], [54, 96], [55, 96], [56, 96], [57, 96], [58, 96], [74, 96], [75, 96], [76, 96], [77, 96], [78, 96], [94, 96], [95, 96], [96, 96], [97, 96], [98, 96], [114, 96], [115, 96], [116, 96], [117, 96], [118, 96], [134, 96], [135, 96], [136, 96], [137, 96], [138, 96], [55, 97], [56, 97], [57, 97], [58, 97], [59, 97], [75, 97], [76, 97], [77, 97], [78, 97], [79, 97], [95, 97], [96, 97], [97, 97], [98, 97], [99, 97], [115, 97], [116, 97], [117, 97], [118, 97], [119, 97], [135, 97], [136, 97], [137, 97], [138, 97], [139, 97], [56, 98], [57, 98], [58, 98], [59, 98], [76, 98], [77, 98], [78, 98], [79, 98], [96, 98], [97, 98], [98, 98], [99, 98], [116, 98], [117, 98], [118, 98], [119, 98], [136, 98], [137, 98], [138, 98], [139, 98], [57, 99], [58, 99], [59, 99], [77, 99], [78, 99], [79, 99], [97, 99], [98, 99], [99, 99], [117, 99], [118, 99], [119, 99], [137, 99], [138, 99], [139, 99], [60, 100], [61, 100], [62, 100], [80, 100], [81, 100], [82, 100], [100, 100], [101, 100], [102, 100], [120, 100], [121, 100], [122, 100], [140, 100], [141, 100], [142, 100], [60, 101], [61, 101], [62, 101], [63, 101], [80, 101], [81, 101], [82, 101], [83, 101], [100, 101], [101, 101], [102, 101], [103, 101], [120, 101], [121, 101], [122, 101], [123, 101], [140, 101], [141, 101], [142, 101], [143, 101], [60, 102], [61, 102], [62, 102], [63, 102], [64, 102], [80, 102], [81, 102], [82, 102], [83, 102], [84, 102], [100, 102], [101, 102], [102, 102], [103, 102], [104, 102], [120, 102], [121, 102], [122, 102], [123, 102], [124, 102], [140, 102], [141, 102], [142, 102], [143, 102], [144, 102], [61, 103], [62, 103], [63, 103], [64, 103], [65, 103], [81, 103], [82, 103], [83, 103], [84, 103], [85, 103], [101, 103], [102, 103], [103, 103], [104, 103], [105, 103], [121, 103], [122, 103], [123, 103], [124, 103], [125, 103], [141, 103], [142, 103], [143, 103], [144, 103], [145, 103], [62, 104], [63, 104], [64, 104], [65, 104], [66, 104], [82, 104], [83, 104], [84, 104], [85, 104], [86, 104], [102, 104], [103, 104], [104, 104], [105, 104], [106, 104], [122, 104], [123, 104], [124, 104], [125, 104], [126, 104], [142, 104], [143, 104], [144, 104], [145, 104], [146, 104], [63, 105], [64, 105], [65, 105], [66, 105], [67, 105], [83, 105], [84, 105], [85, 105], [86, 105], [87, 105], [103, 105], [104, 105], [105, 105], [106, 105], [107, 105], [123, 105], [124, 105], [125, 105], [126, 105], [127, 105], [143, 105], [144, 105], [145, 105], [146, 105], [147, 105], [64, 106], [65, 106], [66, 106], [67, 106], [68, 106], [84, 106], [85, 106], [86, 106], [87, 106], [88, 106], [104, 106], [105, 106], [106, 106], [107, 106], [108, 106], [124, 106], [125, 106], [126, 106], [127, 106], [128, 106], [144, 106], [145, 106], [146, 106], [147, 106], [148, 106], [65, 107], [66, 107], [67, 107], [68, 107], [69, 107], [85, 107], [86, 107], [87, 107], [88, 107], [89, 107], [105, 107], [106, 107], [107, 107], [108, 107], [109, 107], [125, 107], [126, 107], [127, 107], [128, 107], [129, 107], [145, 107], [146, 107], [147, 107], [148, 107], [149, 107], [66, 108], [67, 108], [68, 108], [69, 108], [70, 108], [86, 108], [87, 108], [88, 108], [89, 108], [90, 108], [106, 108], [107, 108], [108, 108], [109, 108], [110, 108], [126, 108], [127, 108], [128, 108], [129, 108], [130, 108], [146, 108], [147, 108], [148, 108], [149, 108], [150, 108], [67, 109], [68, 109], [69, 109], [70, 109], [71, 109], [87, 109], [88, 109], [89, 109], [90, 109], [91, 109], [107, 109], [108, 109], [109, 109], [110, 109], [111, 109], [127, 109], [128, 109], [129, 109], [130, 109], [131, 109], [147, 109], [148, 109], [149, 109], [150, 109], [151, 109], [68, 110], [69, 110], [70, 110], [71, 110], [72, 110], [88, 110], [89, 110], [90, 110], [91, 110], [92, 110], [108, 110], [109, 110], [110, 110], [111, 110], [112, 110], [128, 110], [129, 110], [130, 110], [131, 110], [132, 110], [148, 110], [149, 110], [150, 110], [151, 110], [152, 110], [69, 111], [70, 111], [71, 111], [72, 111], [73, 111], [89, 111], [90, 111], [91, 111], [92, 111], [93, 111], [109, 111], [110, 111], [111, 111], [112, 111], [113, 111], [129, 111], [130, 111], [131, 111], [132, 111], [133, 111], [149, 111], [150, 111], [151, 111], [152, 111], [153, 111], [70, 112], [71, 112], [72, 112], [73, 112], [74, 112], [90, 112], [91, 112], [92, 112], [93, 112], [94, 112], [110, 112], [111, 112], [112, 112], [113, 112], [114, 112], [130, 112], [131, 112], [132, 112], [133, 112], [134, 112], [150, 112], [151, 112], [152, 112], [153, 112], [154, 112], [71, 113], [72, 113], [73, 113], [74, 113], [75, 113], [91, 113], [92, 113], [93, 113], [94, 113], [95, 113], [111, 113], [112, 113], [113, 113], [114, 113], [115, 113], [131, 113], [132, 113], [133, 113], [134, 113], [135, 113], [151, 113], [152, 113], [153, 113], [154, 113], [155, 113], [72, 114], [73, 114], [74, 114], [75, 114], [76, 114], [92, 114], [93, 114], [94, 114], [95, 114], [96, 114], [112, 114], [113, 114], [114, 114], [115, 114], [116, 114], [132, 114], [133, 114], [134, 114], [135, 114], [136, 114], [152, 114], [153, 114], [154, 114], [155, 114], [156, 114], [73, 115], [74, 115], [75, 115], [76, 115], [77, 115], [93, 115], [94, 115], [95, 115], [96, 115], [97, 115], [113, 115], [114, 115], [115, 115], [116, 115], [117, 115], [133, 115], [134, 115], [135, 115], [136, 115], [137, 115], [153, 115], [154, 115], [155, 115], [156, 115], [157, 115], [74, 116], [75, 116], [76, 116], [77, 116], [78, 116], [94, 116], [95, 116], [96, 116], [97, 116], [98, 116], [114, 116], [115, 116], [116, 116], [117, 116], [118, 116], [134, 116], [135, 116], [136, 116], [137, 116], [138, 116], [154, 116], [155, 116], [156, 116], [157, 116], [158, 116], [75, 117], [76, 117], [77, 117], [78, 117], [79, 117], [95, 117], [96, 117], [97, 117], [98, 117], [99, 117], [115, 117], [116, 117], [117, 117], [118, 117], [119, 117], [135, 117], [136, 117], [137, 117], [138, 117], [139, 117], [155, 117], [156, 117], [157, 117], [158, 117], [159, 117], [76, 118], [77, 118], [78, 118], [79, 118], [96, 118], [97, 118], [98, 118], [99, 118], [116, 118], [117, 118], [118, 118], [119, 118], [136, 118], [137, 118], [138, 118], [139, 118], [156, 118], [157, 118], [158, 118], [159, 118], [77, 119], [78, 119], [79, 119], [97, 119], [98, 119], [99, 119], [117, 119], [118, 119], [119, 119], [137, 119], [138, 119], [139, 119], [157, 119], [158, 119], [159, 119], [80, 120], [81, 120], [82, 120], [100, 120], [101, 120], [102, 120], [120, 120], [121, 120], [122, 120], [140, 120], [141, 120], [142, 120], [160, 120], [161, 120], [162, 120], [80, 121], [81, 121], [82, 121], [83, 121], [100, 121], [101, 121], [102, 121], [103, 121], [120, 121], [121, 121], [122, 121], [123, 121], [140, 121], [141, 121], [142, 121], [143, 121], [160, 121], [161, 121], [162, 121], [163, 121], [80, 122], [81, 122], [82, 122], [83, 122], [84, 122], [100, 122], [101, 122], [102, 122], [103, 122], [104, 122], [120, 122], [121, 122], [122, 122], [123, 122], [124, 122], [140, 122], [141, 122], [142, 122], [143, 122], [144, 122], [160, 122], [161, 122], [162, 122], [163, 122], [164, 122], [81, 123], [82, 123], [83, 123], [84, 123], [85, 123], [101, 123], [102, 123], [103, 123], [104, 123], [105, 123], [121, 123], [122, 123], [123, 123], [124, 123], [125, 123], [141, 123], [142, 123], [143, 123], [144, 123], [145, 123], [161, 123], [162, 123], [163, 123], [164, 123], [165, 123], [82, 124], [83, 124], [84, 124], [85, 124], [86, 124], [102, 124], [103, 124], [104, 124], [105, 124], [106, 124], [122, 124], [123, 124], [124, 124], [125, 124], [126, 124], [142, 124], [143, 124], [144, 124], [145, 124], [146, 124], [162, 124], [163, 124], [164, 124], [165, 124], [166, 124], [83, 125], [84, 125], [85, 125], [86, 125], [87, 125], [103, 125], [104, 125], [105, 125], [106, 125], [107, 125], [123, 125], [124, 125], [125, 125], [126, 125], [127, 125], [143, 125], [144, 125], [145, 125], [146, 125], [147, 125], [163, 125], [164, 125], [165, 125], [166, 125], [167, 125], [84, 126], [85, 126], [86, 126], [87, 126], [88, 126], [104, 126], [105, 126], [106, 126], [107, 126], [108, 126], [124, 126], [125, 126], [126, 126], [127, 126], [128, 126], [144, 126], [145, 126], [146, 126], [147, 126], [148, 126], [164, 126], [165, 126], [166, 126], [167, 126], [168, 126], [85, 127], [86, 127], [87, 127], [88, 127], [89, 127], [105, 127], [106, 127], [107, 127], [108, 127], [109, 127], [125, 127], [126, 127], [127, 127], [128, 127], [129, 127], [145, 127], [146, 127], [147, 127], [148, 127], [149, 127], [165, 127], [166, 127], [167, 127], [168, 127], [169, 127], [86, 128], [87, 128], [88, 128], [89, 128], [90, 128], [106, 128], [107, 128], [108, 128], [109, 128], [110, 128], [126, 128], [127, 128], [128, 128], [129, 128], [130, 128], [146, 128], [147, 128], [148, 128], [149, 128], [150, 128], [166, 128], [167, 128], [168, 128], [169, 128], [170, 128], [87, 129], [88, 129], [89, 129], [90, 129], [91, 129], [107, 129], [108, 129], [109, 129], [110, 129], [111, 129], [127, 129], [128, 129], [129, 129], [130, 129], [131, 129], [147, 129], [148, 129], [149, 129], [150, 129], [151, 129], [167, 129], [168, 129], [169, 129], [170, 129], [171, 129], [88, 130], [89, 130], [90, 130], [91, 130], [92, 130], [108, 130], [109, 130], [110, 130], [111, 130], [112, 130], [128, 130], [129, 130], [130, 130], [131, 130], [132, 130], [148, 130], [149, 130], [150, 130], [151, 130], [152, 130], [168, 130], [169, 130], [170, 130], [171, 130], [172, 130], [89, 131], [90, 131], [91, 131], [92, 131], [93, 131], [109, 131], [110, 131], [111, 131], [112, 131], [113, 131], [129, 131], [130, 131], [131, 131], [132, 131], [133, 131], [149, 131], [150, 131], [151, 131], [152, 131], [153, 131], [169, 131], [170, 131], [171, 131], [172, 131], [173, 131], [90, 132], [91, 132], [92, 132], [93, 132], [94, 132], [110, 132], [111, 132], [112, 132], [113, 132], [114, 132], [130, 132], [131, 132], [132, 132], [133, 132], [134, 132], [150, 132], [151, 132], [152, 132], [153, 132], [154, 132], [170, 132], [171, 132], [172, 132], [173, 132], [174, 132], [91, 133], [92, 133], [93, 133], [94, 133], [95, 133], [111, 133], [112, 133], [113, 133], [114, 133], [115, 133], [131, 133], [132, 133], [133, 133], [134, 133], [135, 133], [151, 133], [152, 133], [153, 133], [154, 133], [155, 133], [171, 133], [172, 133], [173, 133], [174, 133], [175, 133], [92, 134], [93, 134], [94, 134], [95, 134], [96, 134], [112, 134], [113, 134], [114, 134], [115, 134], [116, 134], [132, 134], [133, 134], [134, 134], [135, 134], [136, 134], [152, 134], [153, 134], [154, 134], [155, 134], [156, 134], [172, 134], [173, 134], [174, 134], [175, 134], [176, 134], [93, 135], [94, 135], [95, 135], [96, 135], [97, 135], [113, 135], [114, 135], [115, 135], [116, 135], [117, 135], [133, 135], [134, 135], [135, 135], [136, 135], [137, 135], [153, 135], [154, 135], [155, 135], [156, 135], [157, 135], [173, 135], [174, 135], [175, 135], [176, 135], [177, 135], [94, 136], [95, 136], [96, 136], [97, 136], [98, 136], [114, 136], [115, 136], [116, 136], [117, 136], [118, 136], [134, 136], [135, 136], [136, 136], [137, 136], [138, 136], [154, 136], [155, 136], [156, 136], [157, 136], [158, 136], [174, 136], [175, 136], [176, 136], [177, 136], [178, 136], [95, 137], [96, 137], [97, 137], [98, 137], [99, 137], [115, 137], [116, 137], [117, 137], [118, 137], [119, 137], [135, 137], [136, 137], [137, 137], [138, 137], [139, 137], [155, 137], [156, 137], [157, 137], [158, 137], [159, 137], [175, 137], [176, 137], [177, 137], [178, 137], [179, 137], [96, 138], [97, 138], [98, 138], [99, 138], [116, 138], [117, 138], [118, 138], [119, 138], [136, 138], [137, 138], [138, 138], [139, 138], [156, 138], [157, 138], [158, 138], [159, 138], [176, 138], [177, 138], [178, 138], [179, 138], [97, 139], [98, 139], [99, 139], [117, 139], [118, 139], [119, 139], [137, 139], [138, 139], [139, 139], [157, 139], [158, 139], [159, 139], [177, 139], [178, 139], [179, 139], [100, 140], [101, 140], [102, 140], [120, 140], [121, 140], [122, 140], [140, 140], [141, 140], [142, 140], [160, 140], [161, 140], [162, 140], [180, 140], [181, 140], [182, 140], [100, 141], [101, 141], [102, 141], [103, 141], [120, 141], [121, 141], [122, 141], [123, 141], [140, 141], [141, 141], [142, 141], [143, 141], [160, 141], [161, 141], [162, 141], [163, 141], [180, 141], [181, 141], [182, 141], [183, 141], [100, 142], [101, 142], [102, 142], [103, 142], [104, 142], [120, 142], [121, 142], [122, 142], [123, 142], [124, 142], [140, 142], [141, 142], [142, 142], [143, 142], [144, 142], [160, 142], [161, 142], [162, 142], [163, 142], [164, 142], [180, 142], [181, 142], [182, 142], [183, 142], [184, 142], [101, 143], [102, 143], [103, 143], [104, 143], [105, 143], [121, 143], [122, 143], [123, 143], [124, 143], [125, 143], [141, 143], [142, 143], [143, 143], [144, 143], [145, 143], [161, 143], [162, 143], [163, 143], [164, 143], [165, 143], [181, 143], [182, 143], [183, 143], [184, 143], [185, 143], [102, 144], [103, 144], [104, 144], [105, 144], [106, 144], [122, 144], [123, 144], [124, 144], [125, 144], [126, 144], [142, 144], [143, 144], [144, 144], [145, 144], [146, 144], [162, 144], [163, 144], [164, 144], [165, 144], [166, 144], [182, 144], [183, 144], [184, 144], [185, 144], [186, 144], [103, 145], [104, 145], [105, 145], [106, 145], [107, 145], [123, 145], [124, 145], [125, 145], [126, 145], [127, 145], [143, 145], [144, 145], [145, 145], [146, 145], [147, 145], [163, 145], [164, 145], [165, 145], [166, 145], [167, 145], [183, 145], [184, 145], [185, 145], [186, 145], [187, 145], [104, 146], [105, 146], [106, 146], [107, 146], [108, 146], [124, 146], [125, 146], [126, 146], [127, 146], [128, 146], [144, 146], [145, 146], [146, 146], [147, 146], [148, 146], [164, 146], [165, 146], [166, 146], [167, 146], [168, 146], [184, 146], [185, 146], [186, 146], [187, 146], [188, 146], [105, 147], [106, 147], [107, 147], [108, 147], [109, 147], [125, 147], [126, 147], [127, 147], [128, 147], [129, 147], [145, 147], [146, 147], [147, 147], [148, 147], [149, 147], [165, 147], [166, 147], [167, 147], [168, 147], [169, 147], [185, 147], [186, 147], [187, 147], [188, 147], [189, 147], [106, 148], [107, 148], [108, 148], [109, 148], [110, 148], [126, 148], [127, 148], [128, 148], [129, 148], [130, 148], [146, 148], [147, 148], [148, 148], [149, 148], [150, 148], [166, 148], [167, 148], [168, 148], [169, 148], [170, 148], [186, 148], [187, 148], [188, 148], [189, 148], [190, 148], [107, 149], [108, 149], [109, 149], [110, 149], [111, 149], [127, 149], [128, 149], [129, 149], [130, 149], [131, 149], [147, 149], [148, 149], [149, 149], [150, 149], [151, 149], [167, 149], [168, 149], [169, 149], [170, 149], [171, 149], [187, 149], [188, 149], [189, 149], [190, 149], [191, 149], [108, 150], [109, 150], [110, 150], [111, 150], [112, 150], [128, 150], [129, 150], [130, 150], [131, 150], [132, 150], [148, 150], [149, 150], [150, 150], [151, 150], [152, 150], [168, 150], [169, 150], [170, 150], [171, 150], [172, 150], [188, 150], [189, 150], [190, 150], [191, 150], [192, 150], [109, 151], [110, 151], [111, 151], [112, 151], [113, 151], [129, 151], [130, 151], [131, 151], [132, 151], [133, 151], [149, 151], [150, 151], [151, 151], [152, 151], [153, 151], [169, 151], [170, 151], [171, 151], [172, 151], [173, 151], [189, 151], [190, 151], [191, 151], [192, 151], [193, 151], [110, 152], [111, 152], [112, 152], [113, 152], [114, 152], [130, 152], [131, 152], [132, 152], [133, 152], [134, 152], [150, 152], [151, 152], [152, 152], [153, 152], [154, 152], [170, 152], [171, 152], [172, 152], [173, 152], [174, 152], [190, 152], [191, 152], [192, 152], [193, 152], [194, 152], [111, 153], [112, 153], [113, 153], [114, 153], [115, 153], [131, 153], [132, 153], [133, 153], [134, 153], [135, 153], [151, 153], [152, 153], [153, 153], [154, 153], [155, 153], [171, 153], [172, 153], [173, 153], [174, 153], [175, 153], [191, 153], [192, 153], [193, 153], [194, 153], [195, 153], [112, 154], [113, 154], [114, 154], [115, 154], [116, 154], [132, 154], [133, 154], [134, 154], [135, 154], [136, 154], [152, 154], [153, 154], [154, 154], [155, 154], [156, 154], [172, 154], [173, 154], [174, 154], [175, 154], [176, 154], [192, 154], [193, 154], [194, 154], [195, 154], [196, 154], [113, 155], [114, 155], [115, 155], [116, 155], [117, 155], [133, 155], [134, 155], [135, 155], [136, 155], [137, 155], [153, 155], [154, 155], [155, 155], [156, 155], [157, 155], [173, 155], [174, 155], [175, 155], [176, 155], [177, 155], [193, 155], [194, 155], [195, 155], [196, 155], [197, 155], [114, 156], [115, 156], [116, 156], [117, 156], [118, 156], [134, 156], [135, 156], [136, 156], [137, 156], [138, 156], [154, 156], [155, 156], [156, 156], [157, 156], [158, 156], [174, 156], [175, 156], [176, 156], [177, 156], [178, 156], [194, 156], [195, 156], [196, 156], [197, 156], [198, 156], [115, 157], [116, 157], [117, 157], [118, 157], [119, 157], [135, 157], [136, 157], [137, 157], [138, 157], [139, 157], [155, 157], [156, 157], [157, 157], [158, 157], [159, 157], [175, 157], [176, 157], [177, 157], [178, 157], [179, 157], [195, 157], [196, 157], [197, 157], [198, 157], [199, 157], [116, 158], [117, 158], [118, 158], [119, 158], [136, 158], [137, 158], [138, 158], [139, 158], [156, 158], [157, 158], [158, 158], [159, 158], [176, 158], [177, 158], [178, 158], [179, 158], [196, 158], [197, 158], [198, 158], [199, 158], [117, 159], [118, 159], [119, 159], [137, 159], [138, 159], [139, 159], [157, 159], [158, 159], [159, 159], [177, 159], [178, 159], [179, 159], [197, 159], [198, 159], [199, 159], [120, 160], [121, 160], [122, 160], [140, 160], [141, 160], [142, 160], [160, 160], [161, 160], [162, 160], [180, 160], [181, 160], [182, 160], [200, 160], [201, 160], [202, 160], [120, 161], [121, 161], [122, 161], [123, 161], [140, 161], [141, 161], [142, 161], [143, 161], [160, 161], [161, 161], [162, 161], [163, 161], [180, 161], [181, 161], [182, 161], [183, 161], [200, 161], [201, 161], [202, 161], [203, 161], [120, 162], [121, 162], [122, 162], [123, 162], [124, 162], [140, 162], [141, 162], [142, 162], [143, 162], [144, 162], [160, 162], [161, 162], [162, 162], [163, 162], [164, 162], [180, 162], [181, 162], [182, 162], [183, 162], [184, 162], [200, 162], [201, 162], [202, 162], [203, 162], [204, 162], [121, 163], [122, 163], [123, 163], [124, 163], [125, 163], [141, 163], [142, 163], [143, 163], [144, 163], [145, 163], [161, 163], [162, 163], [163, 163], [164, 163], [165, 163], [181, 163], [182, 163], [183, 163], [184, 163], [185, 163], [201, 163], [202, 163], [203, 163], [204, 163], [205, 163], [122, 164], [123, 164], [124, 164], [125, 164], [126, 164], [142, 164], [143, 164], [144, 164], [145, 164], [146, 164], [162, 164], [163, 164], [164, 164], [165, 164], [166, 164], [182, 164], [183, 164], [184, 164], [185, 164], [186, 164], [202, 164], [203, 164], [204, 164], [205, 164], [206, 164], [123, 165], [124, 165], [125, 165], [126, 165], [127, 165], [143, 165], [144, 165], [145, 165], [146, 165], [147, 165], [163, 165], [164, 165], [165, 165], [166, 165], [167, 165], [183, 165], [184, 165], [185, 165], [186, 165], [187, 165], [203, 165], [204, 165], [205, 165], [206, 165], [207, 165], [124, 166], [125, 166], [126, 166], [127, 166], [128, 166], [144, 166], [145, 166], [146, 166], [147, 166], [148, 166], [164, 166], [165, 166], [166, 166], [167, 166], [168, 166], [184, 166], [185, 166], [186, 166], [187, 166], [188, 166], [204, 166], [205, 166], [206, 166], [207, 166], [208, 166], [125, 167], [126, 167], [127, 167], [128, 167], [129, 167], [145, 167], [146, 167], [147, 167], [148, 167], [149, 167], [165, 167], [166, 167], [167, 167], [168, 167], [169, 167], [185, 167], [186, 167], [187, 167], [188, 167], [189, 167], [205, 167], [206, 167], [207, 167], [208, 167], [209, 167], [126, 168], [127, 168], [128, 168], [129, 168], [130, 168], [146, 168], [147, 168], [148, 168], [149, 168], [150, 168], [166, 168], [167, 168], [168, 168], [169, 168], [170, 168], [186, 168], [187, 168], [188, 168], [189, 168], [190, 168], [206, 168], [207, 168], [208, 168], [209, 168], [210, 168], [127, 169], [128, 169], [129, 169], [130, 169], [131, 169], [147, 169], [148, 169], [149, 169], [150, 169], [151, 169], [167, 169], [168, 169], [169, 169], [170, 169], [171, 169], [187, 169], [188, 169], [189, 169], [190, 169], [191, 169], [207, 169], [208, 169], [209, 169], [210, 169], [211, 169], [128, 170], [129, 170], [130, 170], [131, 170], [132, 170], [148, 170], [149, 170], [150, 170], [151, 170], [152, 170], [168, 170], [169, 170], [170, 170], [171, 170], [172, 170], [188, 170], [189, 170], [190, 170], [191, 170], [192, 170], [208, 170], [209, 170], [210, 170], [211, 170], [212, 170], [129, 171], [130, 171], [131, 171], [132, 171], [133, 171], [149, 171], [150, 171], [151, 171], [152, 171], [153, 171], [169, 171], [170, 171], [171, 171], [172, 171], [173, 171], [189, 171], [190, 171], [191, 171], [192, 171], [193, 171], [209, 171], [210, 171], [211, 171], [212, 171], [213, 171], [130, 172], [131, 172], [132, 172], [133, 172], [134, 172], [150, 172], [151, 172], [152, 172], [153, 172], [154, 172], [170, 172], [171, 172], [172, 172], [173, 172], [174, 172], [190, 172], [191, 172], [192, 172], [193, 172], [194, 172], [210, 172], [211, 172], [212, 172], [213, 172], [214, 172], [131, 173], [132, 173], [133, 173], [134, 173], [135, 173], [151, 173], [152, 173], [153, 173], [154, 173], [155, 173], [171, 173], [172, 173], [173, 173], [174, 173], [175, 173], [191, 173], [192, 173], [193, 173], [194, 173], [195, 173], [211, 173], [212, 173], [213, 173], [214, 173], [215, 173], [132, 174], [133, 174], [134, 174], [135, 174], [136, 174], [152, 174], [153, 174], [154, 174], [155, 174], [156, 174], [172, 174], [173, 174], [174, 174], [175, 174], [176, 174], [192, 174], [193, 174], [194, 174], [195, 174], [196, 174], [212, 174], [213, 174], [214, 174], [215, 174], [216, 174], [133, 175], [134, 175], [135, 175], [136, 175], [137, 175], [153, 175], [154, 175], [155, 175], [156, 175], [157, 175], [173, 175], [174, 175], [175, 175], [176, 175], [177, 175], [193, 175], [194, 175], [195, 175], [196, 175], [197, 175], [213, 175], [214, 175], [215, 175], [216, 175], [217, 175], [134, 176], [135, 176], [136, 176], [137, 176], [138, 176], [154, 176], [155, 176], [156, 176], [157, 176], [158, 176], [174, 176], [175, 176], [176, 176], [177, 176], [178, 176], [194, 176], [195, 176], [196, 176], [197, 176], [198, 176], [214, 176], [215, 176], [216, 176], [217, 176], [218, 176], [135, 177], [136, 177], [137, 177], [138, 177], [139, 177], [155, 177], [156, 177], [157, 177], [158, 177], [159, 177], [175, 177], [176, 177], [177, 177], [178, 177], [179, 177], [195, 177], [196, 177], [197, 177], [198, 177], [199, 177], [215, 177], [216, 177], [217, 177], [218, 177], [219, 177], [136, 178], [137, 178], [138, 178], [139, 178], [156, 178], [157, 178], [158, 178], [159, 178], [176, 178], [177, 178], [178, 178], [179, 178], [196, 178], [197, 178], [198, 178], [199, 178], [216, 178], [217, 178], [218, 178], [219, 178], [137, 179], [138, 179], [139, 179], [157, 179], [158, 179], [159, 179], [177, 179], [178, 179], [179, 179], [197, 179], [198, 179], [199, 179], [217, 179], [218, 179], [219, 179], [140, 180], [141, 180], [142, 180], [160, 180], [161, 180], [162, 180], [180, 180], [181, 180], [182, 180], [200, 180], [201, 180], [202, 180], [220, 180], [221, 180], [222, 180], [140, 181], [141, 181], [142, 181], [143, 181], [160, 181], [161, 181], [162, 181], [163, 181], [180, 181], [181, 181], [182, 181], [183, 181], [200, 181], [201, 181], [202, 181], [203, 181], [220, 181], [221, 181], [222, 181], [223, 181], [140, 182], [141, 182], [142, 182], [143, 182], [144, 182], [160, 182], [161, 182], [162, 182], [163, 182], [164, 182], [180, 182], [181, 182], [182, 182], [183, 182], [184, 182], [200, 182], [201, 182], [202, 182], [203, 182], [204, 182], [220, 182], [221, 182], [222, 182], [223, 182], [224, 182], [141, 183], [142, 183], [143, 183], [144, 183], [145, 183], [161, 183], [162, 183], [163, 183], [164, 183], [165, 183], [181, 183], [182, 183], [183, 183], [184, 183], [185, 183], [201, 183], [202, 183], [203, 183], [204, 183], [205, 183], [221, 183], [222, 183], [223, 183], [224, 183], [225, 183], [142, 184], [143, 184], [144, 184], [145, 184], [146, 184], [162, 184], [163, 184], [164, 184], [165, 184], [166, 184], [182, 184], [183, 184], [184, 184], [185, 184], [186, 184], [202, 184], [203, 184], [204, 184], [205, 184], [206, 184], [222, 184], [223, 184], [224, 184], [225, 184], [226, 184], [143, 185], [144, 185], [145, 185], [146, 185], [147, 185], [163, 185], [164, 185], [165, 185], [166, 185], [167, 185], [183, 185], [184, 185], [185, 185], [186, 185], [187, 185], [203, 185], [204, 185], [205, 185], [206, 185], [207, 185], [223, 185], [224, 185], [225, 185], [226, 185], [227, 185], [144, 186], [145, 186], [146, 186], [147, 186], [148, 186], [164, 186], [165, 186], [166, 186], [167, 186], [168, 186], [184, 186], [185, 186], [186, 186], [187, 186], [188, 186], [204, 186], [205, 186], [206, 186], [207, 186], [208, 186], [224, 186], [225, 186], [226, 186], [227, 186], [228, 186], [145, 187], [146, 187], [147, 187], [148, 187], [149, 187], [165, 187], [166, 187], [167, 187], [168, 187], [169, 187], [185, 187], [186, 187], [187, 187], [188, 187], [189, 187], [205, 187], [206, 187], [207, 187], [208, 187], [209, 187], [225, 187], [226, 187], [227, 187], [228, 187], [229, 187], [146, 188], [147, 188], [148, 188], [149, 188], [150, 188], [166, 188], [167, 188], [168, 188], [169, 188], [170, 188], [186, 188], [187, 188], [188, 188], [189, 188], [190, 188], [206, 188], [207, 188], [208, 188], [209, 188], [210, 188], [226, 188], [227, 188], [228, 188], [229, 188], [230, 188], [147, 189], [148, 189], [149, 189], [150, 189], [151, 189], [167, 189], [168, 189], [169, 189], [170, 189], [171, 189], [187, 189], [188, 189], [189, 189], [190, 189], [191, 189], [207, 189], [208, 189], [209, 189], [210, 189], [211, 189], [227, 189], [228, 189], [229, 189], [230, 189], [231, 189], [148, 190], [149, 190], [150, 190], [151, 190], [152, 190], [168, 190], [169, 190], [170, 190], [171, 190], [172, 190], [188, 190], [189, 190], [190, 190], [191, 190], [192, 190], [208, 190], [209, 190], [210, 190], [211, 190], [212, 190], [228, 190], [229, 190], [230, 190], [231, 190], [232, 190], [149, 191], [150, 191], [151, 191], [152, 191], [153, 191], [169, 191], [170, 191], [171, 191], [172, 191], [173, 191], [189, 191], [190, 191], [191, 191], [192, 191], [193, 191], [209, 191], [210, 191], [211, 191], [212, 191], [213, 191], [229, 191], [230, 191], [231, 191], [232, 191], [233, 191], [150, 192], [151, 192], [152, 192], [153, 192], [154, 192], [170, 192], [171, 192], [172, 192], [173, 192], [174, 192], [190, 192], [191, 192], [192, 192], [193, 192], [194, 192], [210, 192], [211, 192], [212, 192], [213, 192], [214, 192], [230, 192], [231, 192], [232, 192], [233, 192], [234, 192], [151, 193], [152, 193], [153, 193], [154, 193], [155, 193], [171, 193], [172, 193], [173, 193], [174, 193], [175, 193], [191, 193], [192, 193], [193, 193], [194, 193], [195, 193], [211, 193], [212, 193], [213, 193], [214, 193], [215, 193], [231, 193], [232, 193], [233, 193], [234, 193], [235, 193], [152, 194], [153, 194], [154, 194], [155, 194], [156, 194], [172, 194], [173, 194], [174, 194], [175, 194], [176, 194], [192, 194], [193, 194], [194, 194], [195, 194], [196, 194], [212, 194], [213, 194], [214, 194], [215, 194], [216, 194], [232, 194], [233, 194], [234, 194], [235, 194], [236, 194], [153, 195], [154, 195], [155, 195], [156, 195], [157, 195], [173, 195], [174, 195], [175, 195], [176, 195], [177, 195], [193, 195], [194, 195], [195, 195], [196, 195], [197, 195], [213, 195], [214, 195], [215, 195], [216, 195], [217, 195], [233, 195], [234, 195], [235, 195], [236, 195], [237, 195], [154, 196], [155, 196], [156, 196], [157, 196], [158, 196], [174, 196], [175, 196], [176, 196], [177, 196], [178, 196], [194, 196], [195, 196], [196, 196], [197, 196], [198, 196], [214, 196], [215, 196], [216, 196], [217, 196], [218, 196], [234, 196], [235, 196], [236, 196], [237, 196], [238, 196], [155, 197], [156, 197], [157, 197], [158, 197], [159, 197], [175, 197], [176, 197], [177, 197], [178, 197], [179, 197], [195, 197], [196, 197], [197, 197], [198, 197], [199, 197], [215, 197], [216, 197], [217, 197], [218, 197], [219, 197], [235, 197], [236, 197], [237, 197], [238, 197], [239, 197], [156, 198], [157, 198], [158, 198], [159, 198], [176, 198], [177, 198], [178, 198], [179, 198], [196, 198], [197, 198], [198, 198], [199, 198], [216, 198], [217, 198], [218, 198], [219, 198], [236, 198], [237, 198], [238, 198], [239, 198], [157, 199], [158, 199], [159, 199], [177, 199], [178, 199], [179, 199], [197, 199], [198, 199], [199, 199], [217, 199], [218, 199], [219, 199], [237, 199], [238, 199], [239, 199], [160, 200], [161, 200], [162, 200], [180, 200], [181, 200], [182, 200], [200, 200], [201, 200], [202, 200], [220, 200], [221, 200], [222, 200], [240, 200], [241, 200], [242, 200], [160, 201], [161, 201], [162, 201], [163, 201], [180, 201], [181, 201], [182, 201], [183, 201], [200, 201], [201, 201], [202, 201], [203, 201], [220, 201], [221, 201], [222, 201], [223, 201], [240, 201], [241, 201], [242, 201], [243, 201], [160, 202], [161, 202], [162, 202], [163, 202], [164, 202], [180, 202], [181, 202], [182, 202], [183, 202], [184, 202], [200, 202], [201, 202], [202, 202], [203, 202], [204, 202], [220, 202], [221, 202], [222, 202], [223, 202], [224, 202], [240, 202], [241, 202], [242, 202], [243, 202], [244, 202], [161, 203], [162, 203], [163, 203], [164, 203], [165, 203], [181, 203], [182, 203], [183, 203], [184, 203], [185, 203], [201, 203], [202, 203], [203, 203], [204, 203], [205, 203], [221, 203], [222, 203], [223, 203], [224, 203], [225, 203], [241, 203], [242, 203], [243, 203], [244, 203], [245, 203], [162, 204], [163, 204], [164, 204], [165, 204], [166, 204], [182, 204], [183, 204], [184, 204], [185, 204], [186, 204], [202, 204], [203, 204], [204, 204], [205, 204], [206, 204], [222, 204], [223, 204], [224, 204], [225, 204], [226, 204], [242, 204], [243, 204], [244, 204], [245, 204], [246, 204], [163, 205], [164, 205], [165, 205], [166, 205], [167, 205], [183, 205], [184, 205], [185, 205], [186, 205], [187, 205], [203, 205], [204, 205], [205, 205], [206, 205], [207, 205], [223, 205], [224, 205], [225, 205], [226, 205], [227, 205], [243, 205], [244, 205], [245, 205], [246, 205], [247, 205], [164, 206], [165, 206], [166, 206], [167, 206], [168, 206], [184, 206], [185, 206], [186, 206], [187, 206], [188, 206], [204, 206], [205, 206], [206, 206], [207, 206], [208, 206], [224, 206], [225, 206], [226, 206], [227, 206], [228, 206], [244, 206], [245, 206], [246, 206], [247, 206], [248, 206], [165, 207], [166, 207], [167, 207], [168, 207], [169, 207], [185, 207], [186, 207], [187, 207], [188, 207], [189, 207], [205, 207], [206, 207], [207, 207], [208, 207], [209, 207], [225, 207], [226, 207], [227, 207], [228, 207], [229, 207], [245, 207], [246, 207], [247, 207], [248, 207], [249, 207], [166, 208], [167, 208], [168, 208], [169, 208], [170, 208], [186, 208], [187, 208], [188, 208], [189, 208], [190, 208], [206, 208], [207, 208], [208, 208], [209, 208], [210, 208], [226, 208], [227, 208], [228, 208], [229, 208], [230, 208], [246, 208], [247, 208], [248, 208], [249, 208], [250, 208], [167, 209], [168, 209], [169, 209], [170, 209], [171, 209], [187, 209], [188, 209], [189, 209], [190, 209], [191, 209], [207, 209], [208, 209], [209, 209], [210, 209], [211, 209], [227, 209], [228, 209], [229, 209], [230, 209], [231, 209], [247, 209], [248, 209], [249, 209], [250, 209], [251, 209], [168, 210], [169, 210], [170, 210], [171, 210], [172, 210], [188, 210], [189, 210], [190, 210], [191, 210], [192, 210], [208, 210], [209, 210], [210, 210], [211, 210], [212, 210], [228, 210], [229, 210], [230, 210], [231, 210], [232, 210], [248, 210], [249, 210], [250, 210], [251, 210], [252, 210], [169, 211], [170, 211], [171, 211], [172, 211], [173, 211], [189, 211], [190, 211], [191, 211], [192, 211], [193, 211], [209, 211], [210, 211], [211, 211], [212, 211], [213, 211], [229, 211], [230, 211], [231, 211], [232, 211], [233, 211], [249, 211], [250, 211], [251, 211], [252, 211], [253, 211], [170, 212], [171, 212], [172, 212], [173, 212], [174, 212], [190, 212], [191, 212], [192, 212], [193, 212], [194, 212], [210, 212], [211, 212], [212, 212], [213, 212], [214, 212], [230, 212], [231, 212], [232, 212], [233, 212], [234, 212], [250, 212], [251, 212], [252, 212], [253, 212], [254, 212], [171, 213], [172, 213], [173, 213], [174, 213], [175, 213], [191, 213], [192, 213], [193, 213], [194, 213], [195, 213], [211, 213], [212, 213], [213, 213], [214, 213], [215, 213], [231, 213], [232, 213], [233, 213], [234, 213], [235, 213], [251, 213], [252, 213], [253, 213], [254, 213], [255, 213], [172, 214], [173, 214], [174, 214], [175, 214], [176, 214], [192, 214], [193, 214], [194, 214], [195, 214], [196, 214], [212, 214], [213, 214], [214, 214], [215, 214], [216, 214], [232, 214], [233, 214], [234, 214], [235, 214], [236, 214], [252, 214], [253, 214], [254, 214], [255, 214], [256, 214], [173, 215], [174, 215], [175, 215], [176, 215], [177, 215], [193, 215], [194, 215], [195, 215], [196, 215], [197, 215], [213, 215], [214, 215], [215, 215], [216, 215], [217, 215], [233, 215], [234, 215], [235, 215], [236, 215], [237, 215], [253, 215], [254, 215], [255, 215], [256, 215], [257, 215], [174, 216], [175, 216], [176, 216], [177, 216], [178, 216], [194, 216], [195, 216], [196, 216], [197, 216], [198, 216], [214, 216], [215, 216], [216, 216], [217, 216], [218, 216], [234, 216], [235, 216], [236, 216], [237, 216], [238, 216], [254, 216], [255, 216], [256, 216], [257, 216], [258, 216], [175, 217], [176, 217], [177, 217], [178, 217], [179, 217], [195, 217], [196, 217], [197, 217], [198, 217], [199, 217], [215, 217], [216, 217], [217, 217], [218, 217], [219, 217], [235, 217], [236, 217], [237, 217], [238, 217], [239, 217], [255, 217], [256, 217], [257, 217], [258, 217], [259, 217], [176, 218], [177, 218], [178, 218], [179, 218], [196, 218], [197, 218], [198, 218], [199, 218], [216, 218], [217, 218], [218, 218], [219, 218], [236, 218], [237, 218], [238, 218], [239, 218], [256, 218], [257, 218], [258, 218], [259, 218], [177, 219], [178, 219], [179, 219], [197, 219], [198, 219], [199, 219], [217, 219], [218, 219], [219, 219], [237, 219], [238, 219], [239, 219], [257, 219], [258, 219], [259, 219], [180, 220], [181, 220], [182, 220], [200, 220], [201, 220], [202, 220], [220, 220], [221, 220], [222, 220], [240, 220], [241, 220], [242, 220], [260, 220], [261, 220], [262, 220], [180, 221], [181, 221], [182, 221], [183, 221], [200, 221], [201, 221], [202, 221], [203, 221], [220, 221], [221, 221], [222, 221], [223, 221], [240, 221], [241, 221], [242, 221], [243, 221], [260, 221], [261, 221], [262, 221], [263, 221], [180, 222], [181, 222], [182, 222], [183, 222], [184, 222], [200, 222], [201, 222], [202, 222], [203, 222], [204, 222], [220, 222], [221, 222], [222, 222], [223, 222], [224, 222], [240, 222], [241, 222], [242, 222], [243, 222], [244, 222], [260, 222], [261, 222], [262, 222], [263, 222], [264, 222], [181, 223], [182, 223], [183, 223], [184, 223], [185, 223], [201, 223], [202, 223], [203, 223], [204, 223], [205, 223], [221, 223], [222, 223], [223, 223], [224, 223], [225, 223], [241, 223], [242, 223], [243, 223], [244, 223], [245, 223], [261, 223], [262, 223], [263, 223], [264, 223], [265, 223], [182, 224], [183, 224], [184, 224], [185, 224], [186, 224], [202, 224], [203, 224], [204, 224], [205, 224], [206, 224], [222, 224], [223, 224], [224, 224], [225, 224], [226, 224], [242, 224], [243, 224], [244, 224], [245, 224], [246, 224], [262, 224], [263, 224], [264, 224], [265, 224], [266, 224], [183, 225], [184, 225], [185, 225], [186, 225], [187, 225], [203, 225], [204, 225], [205, 225], [206, 225], [207, 225], [223, 225], [224, 225], [225, 225], [226, 225], [227, 225], [243, 225], [244, 225], [245, 225], [246, 225], [247, 225], [263, 225], [264, 225], [265, 225], [266, 225], [267, 225], [184, 226], [185, 226], [186, 226], [187, 226], [188, 226], [204, 226], [205, 226], [206, 226], [207, 226], [208, 226], [224, 226], [225, 226], [226, 226], [227, 226], [228, 226], [244, 226], [245, 226], [246, 226], [247, 226], [248, 226], [264, 226], [265, 226], [266, 226], [267, 226], [268, 226], [185, 227], [186, 227], [187, 227], [188, 227], [189, 227], [205, 227], [206, 227], [207, 227], [208, 227], [209, 227], [225, 227], [226, 227], [227, 227], [228, 227], [229, 227], [245, 227], [246, 227], [247, 227], [248, 227], [249, 227], [265, 227], [266, 227], [267, 227], [268, 227], [269, 227], [186, 228], [187, 228], [188, 228], [189, 228], [190, 228], [206, 228], [207, 228], [208, 228], [209, 228], [210, 228], [226, 228], [227, 228], [228, 228], [229, 228], [230, 228], [246, 228], [247, 228], [248, 228], [249, 228], [250, 228], [266, 228], [267, 228], [268, 228], [269, 228], [270, 228], [187, 229], [188, 229], [189, 229], [190, 229], [191, 229], [207, 229], [208, 229], [209, 229], [210, 229], [211, 229], [227, 229], [228, 229], [229, 229], [230, 229], [231, 229], [247, 229], [248, 229], [249, 229], [250, 229], [251, 229], [267, 229], [268, 229], [269, 229], [270, 229], [271, 229], [188, 230], [189, 230], [190, 230], [191, 230], [192, 230], [208, 230], [209, 230], [210, 230], [211, 230], [212, 230], [228, 230], [229, 230], [230, 230], [231, 230], [232, 230], [248, 230], [249, 230], [250, 230], [251, 230], [252, 230], [268, 230], [269, 230], [270, 230], [271, 230], [272, 230], [189, 231], [190, 231], [191, 231], [192, 231], [193, 231], [209, 231], [210, 231], [211, 231], [212, 231], [213, 231], [229, 231], [230, 231], [231, 231], [232, 231], [233, 231], [249, 231], [250, 231], [251, 231], [252, 231], [253, 231], [269, 231], [270, 231], [271, 231], [272, 231], [273, 231], [190, 232], [191, 232], [192, 232], [193, 232], [194, 232], [210, 232], [211, 232], [212, 232], [213, 232], [214, 232], [230, 232], [231, 232], [232, 232], [233, 232], [234, 232], [250, 232], [251, 232], [252, 232], [253, 232], [254, 232], [270, 232], [271, 232], [272, 232], [273, 232], [274, 232], [191, 233], [192, 233], [193, 233], [194, 233], [195, 233], [211, 233], [212, 233], [213, 233], [214, 233], [215, 233], [231, 233], [232, 233], [233, 233], [234, 233], [235, 233], [251, 233], [252, 233], [253, 233], [254, 233], [255, 233], [271, 233], [272, 233], [273, 233], [274, 233], [275, 233], [192, 234], [193, 234], [194, 234], [195, 234], [196, 234], [212, 234], [213, 234], [214, 234], [215, 234], [216, 234], [232, 234], [233, 234], [234, 234], [235, 234], [236, 234], [252, 234], [253, 234], [254, 234], [255, 234], [256, 234], [272, 234], [273, 234], [274, 234], [275, 234], [276, 234], [193, 235], [194, 235], [195, 235], [196, 235], [197, 235], [213, 235], [214, 235], [215, 235], [216, 235], [217, 235], [233, 235], [234, 235], [235, 235], [236, 235], [237, 235], [253, 235], [254, 235], [255, 235], [256, 235], [257, 235], [273, 235], [274, 235], [275, 235], [276, 235], [277, 235], [194, 236], [195, 236], [196, 236], [197, 236], [198, 236], [214, 236], [215, 236], [216, 236], [217, 236], [218, 236], [234, 236], [235, 236], [236, 236], [237, 236], [238, 236], [254, 236], [255, 236], [256, 236], [257, 236], [258, 236], [274, 236], [275, 236], [276, 236], [277, 236], [278, 236], [195, 237], [196, 237], [197, 237], [198, 237], [199, 237], [215, 237], [216, 237], [217, 237], [218, 237], [219, 237], [235, 237], [236, 237], [237, 237], [238, 237], [239, 237], [255, 237], [256, 237], [257, 237], [258, 237], [259, 237], [275, 237], [276, 237], [277, 237], [278, 237], [279, 237], [196, 238], [197, 238], [198, 238], [199, 238], [216, 238], [217, 238], [218, 238], [219, 238], [236, 238], [237, 238], [238, 238], [239, 238], [256, 238], [257, 238], [258, 238], [259, 238], [276, 238], [277, 238], [278, 238], [279, 238], [197, 239], [198, 239], [199, 239], [217, 239], [218, 239], [219, 239], [237, 239], [238, 239], [239, 239], [257, 239], [258, 239], [259, 239], [277, 239], [278, 239], [279, 239], [200, 240], [201, 240], [202, 240], [220, 240], [221, 240], [222, 240], [240, 240], [241, 240], [242, 240], [260, 240], [261, 240], [262, 240], [280, 240], [281, 240], [282, 240], [200, 241], [201, 241], [202, 241], [203, 241], [220, 241], [221, 241], [222, 241], [223, 241], [240, 241], [241, 241], [242, 241], [243, 241], [260, 241], [261, 241], [262, 241], [263, 241], [280, 241], [281, 241], [282, 241], [283, 241], [200, 242], [201, 242], [202, 242], [203, 242], [204, 242], [220, 242], [221, 242], [222, 242], [223, 242], [224, 242], [240, 242], [241, 242], [242, 242], [243, 242], [244, 242], [260, 242], [261, 242], [262, 242], [263, 242], [264, 242], [280, 242], [281, 242], [282, 242], [283, 242], [284, 242], [201, 243], [202, 243], [203, 243], [204, 243], [205, 243], [221, 243], [222, 243], [223, 243], [224, 243], [225, 243], [241, 243], [242, 243], [243, 243], [244, 243], [245, 243], [261, 243], [262, 243], [263, 243], [264, 243], [265, 243], [281, 243], [282, 243], [283, 243], [284, 243], [285, 243], [202, 244], [203, 244], [204, 244], [205, 244], [206, 244], [222, 244], [223, 244], [224, 244], [225, 244], [226, 244], [242, 244], [243, 244], [244, 244], [245, 244], [246, 244], [262, 244], [263, 244], [264, 244], [265, 244], [266, 244], [282, 244], [283, 244], [284, 244], [285, 244], [286, 244], [203, 245], [204, 245], [205, 245], [206, 245], [207, 245], [223, 245], [224, 245], [225, 245], [226, 245], [227, 245], [243, 245], [244, 245], [245, 245], [246, 245], [247, 245], [263, 245], [264, 245], [265, 245], [266, 245], [267, 245], [283, 245], [284, 245], [285, 245], [286, 245], [287, 245], [204, 246], [205, 246], [206, 246], [207, 246], [208, 246], [224, 246], [225, 246], [226, 246], [227, 246], [228, 246], [244, 246], [245, 246], [246, 246], [247, 246], [248, 246], [264, 246], [265, 246], [266, 246], [267, 246], [268, 246], [284, 246], [285, 246], [286, 246], [287, 246], [288, 246], [205, 247], [206, 247], [207, 247], [208, 247], [209, 247], [225, 247], [226, 247], [227, 247], [228, 247], [229, 247], [245, 247], [246, 247], [247, 247], [248, 247], [249, 247], [265, 247], [266, 247], [267, 247], [268, 247], [269, 247], [285, 247], [286, 247], [287, 247], [288, 247], [289, 247], [206, 248], [207, 248], [208, 248], [209, 248], [210, 248], [226, 248], [227, 248], [228, 248], [229, 248], [230, 248], [246, 248], [247, 248], [248, 248], [249, 248], [250, 248], [266, 248], [267, 248], [268, 248], [269, 248], [270, 248], [286, 248], [287, 248], [288, 248], [289, 248], [290, 248], [207, 249], [208, 249], [209, 249], [210, 249], [211, 249], [227, 249], [228, 249], [229, 249], [230, 249], [231, 249], [247, 249], [248, 249], [249, 249], [250, 249], [251, 249], [267, 249], [268, 249], [269, 249], [270, 249], [271, 249], [287, 249], [288, 249], [289, 249], [290, 249], [291, 249], [208, 250], [209, 250], [210, 250], [211, 250], [212, 250], [228, 250], [229, 250], [230, 250], [231, 250], [232, 250], [248, 250], [249, 250], [250, 250], [251, 250], [252, 250], [268, 250], [269, 250], [270, 250], [271, 250], [272, 250], [288, 250], [289, 250], [290, 250], [291, 250], [292, 250], [209, 251], [210, 251], [211, 251], [212, 251], [213, 251], [229, 251], [230, 251], [231, 251], [232, 251], [233, 251], [249, 251], [250, 251], [251, 251], [252, 251], [253, 251], [269, 251], [270, 251], [271, 251], [272, 251], [273, 251], [289, 251], [290, 251], [291, 251], [292, 251], [293, 251], [210, 252], [211, 252], [212, 252], [213, 252], [214, 252], [230, 252], [231, 252], [232, 252], [233, 252], [234, 252], [250, 252], [251, 252], [252, 252], [253, 252], [254, 252], [270, 252], [271, 252], [272, 252], [273, 252], [274, 252], [290, 252], [291, 252], [292, 252], [293, 252], [294, 252], [211, 253], [212, 253], [213, 253], [214, 253], [215, 253], [231, 253], [232, 253], [233, 253], [234, 253], [235, 253], [251, 253], [252, 253], [253, 253], [254, 253], [255, 253], [271, 253], [272, 253], [273, 253], [274, 253], [275, 253], [291, 253], [292, 253], [293, 253], [294, 253], [295, 253], [212, 254], [213, 254], [214, 254], [215, 254], [216, 254], [232, 254], [233, 254], [234, 254], [235, 254], [236, 254], [252, 254], [253, 254], [254, 254], [255, 254], [256, 254], [272, 254], [273, 254], [274, 254], [275, 254], [276, 254], [292, 254], [293, 254], [294, 254], [295, 254], [296, 254], [213, 255], [214, 255], [215, 255], [216, 255], [217, 255], [233, 255], [234, 255], [235, 255], [236, 255], [237, 255], [253, 255], [254, 255], [255, 255], [256, 255], [257, 255], [273, 255], [274, 255], [275, 255], [276, 255], [277, 255], [293, 255], [294, 255], [295, 255], [296, 255], [297, 255], [214, 256], [215, 256], [216, 256], [217, 256], [218, 256], [234, 256], [235, 256], [236, 256], [237, 256], [238, 256], [254, 256], [255, 256], [256, 256], [257, 256], [258, 256], [274, 256], [275, 256], [276, 256], [277, 256], [278, 256], [294, 256], [295, 256], [296, 256], [297, 256], [298, 256], [215, 257], [216, 257], [217, 257], [218, 257], [219, 257], [235, 257], [236, 257], [237, 257], [238, 257], [239, 257], [255, 257], [256, 257], [257, 257], [258, 257], [259, 257], [275, 257], [276, 257], [277, 257], [278, 257], [279, 257], [295, 257], [296, 257], [297, 257], [298, 257], [299, 257], [216, 258], [217, 258], [218, 258], [219, 258], [236, 258], [237, 258], [238, 258], [239, 258], [256, 258], [257, 258], [258, 258], [259, 258], [276, 258], [277, 258], [278, 258], [279, 258], [296, 258], [297, 258], [298, 258], [299, 258], [217, 259], [218, 259], [219, 259], [237, 259], [238, 259], [239, 259], [257, 259], [258, 259], [259, 259], [277, 259], [278, 259], [279, 259], [297, 259], [298, 259], [299, 259], [220, 260], [221, 260], [222, 260], [240, 260], [241, 260], [242, 260], [260, 260], [261, 260], [262, 260], [280, 260], [281, 260], [282, 260], [300, 260], [301, 260], [302, 260], [220, 261], [221, 261], [222, 261], [223, 261], [240, 261], [241, 261], [242, 261], [243, 261], [260, 261], [261, 261], [262, 261], [263, 261], [280, 261], [281, 261], [282, 261], [283, 261], [300, 261], [301, 261], [302, 261], [303, 261], [220, 262], [221, 262], [222, 262], [223, 262], [224, 262], [240, 262], [241, 262], [242, 262], [243, 262], [244, 262], [260, 262], [261, 262], [262, 262], [263, 262], [264, 262], [280, 262], [281, 262], [282, 262], [283, 262], [284, 262], [300, 262], [301, 262], [302, 262], [303, 262], [304, 262], [221, 263], [222, 263], [223, 263], [224, 263], [225, 263], [241, 263], [242, 263], [243, 263], [244, 263], [245, 263], [261, 263], [262, 263], [263, 263], [264, 263], [265, 263], [281, 263], [282, 263], [283, 263], [284, 263], [285, 263], [301, 263], [302, 263], [303, 263], [304, 263], [305, 263], [222, 264], [223, 264], [224, 264], [225, 264], [226, 264], [242, 264], [243, 264], [244, 264], [245, 264], [246, 264], [262, 264], [263, 264], [264, 264], [265, 264], [266, 264], [282, 264], [283, 264], [284, 264], [285, 264], [286, 264], [302, 264], [303, 264], [304, 264], [305, 264], [306, 264], [223, 265], [224, 265], [225, 265], [226, 265], [227, 265], [243, 265], [244, 265], [245, 265], [246, 265], [247, 265], [263, 265], [264, 265], [265, 265], [266, 265], [267, 265], [283, 265], [284, 265], [285, 265], [286, 265], [287, 265], [303, 265], [304, 265], [305, 265], [306, 265], [307, 265], [224, 266], [225, 266], [226, 266], [227, 266], [228, 266], [244, 266], [245, 266], [246, 266], [247, 266], [248, 266], [264, 266], [265, 266], [266, 266], [267, 266], [268, 266], [284, 266], [285, 266], [286, 266], [287, 266], [288, 266], [304, 266], [305, 266], [306, 266], [307, 266], [308, 266], [225, 267], [226, 267], [227, 267], [228, 267], [229, 267], [245, 267], [246, 267], [247, 267], [248, 267], [249, 267], [265, 267], [266, 267], [267, 267], [268, 267], [269, 267], [285, 267], [286, 267], [287, 267], [288, 267], [289, 267], [305, 267], [306, 267], [307, 267], [308, 267], [309, 267], [226, 268], [227, 268], [228, 268], [229, 268], [230, 268], [246, 268], [247, 268], [248, 268], [249, 268], [250, 268], [266, 268], [267, 268], [268, 268], [269, 268], [270, 268], [286, 268], [287, 268], [288, 268], [289, 268], [290, 268], [306, 268], [307, 268], [308, 268], [309, 268], [310, 268], [227, 269], [228, 269], [229, 269], [230, 269], [231, 269], [247, 269], [248, 269], [249, 269], [250, 269], [251, 269], [267, 269], [268, 269], [269, 269], [270, 269], [271, 269], [287, 269], [288, 269], [289, 269], [290, 269], [291, 269], [307, 269], [308, 269], [309, 269], [310, 269], [311, 269], [228, 270], [229, 270], [230, 270], [231, 270], [232, 270], [248, 270], [249, 270], [250, 270], [251, 270], [252, 270], [268, 270], [269, 270], [270, 270], [271, 270], [272, 270], [288, 270], [289, 270], [290, 270], [291, 270], [292, 270], [308, 270], [309, 270], [310, 270], [311, 270], [312, 270], [229, 271], [230, 271], [231, 271], [232, 271], [233, 271], [249, 271], [250, 271], [251, 271], [252, 271], [253, 271], [269, 271], [270, 271], [271, 271], [272, 271], [273, 271], [289, 271], [290, 271], [291, 271], [292, 271], [293, 271], [309, 271], [310, 271], [311, 271], [312, 271], [313, 271], [230, 272], [231, 272], [232, 272], [233, 272], [234, 272], [250, 272], [251, 272], [252, 272], [253, 272], [254, 272], [270, 272], [271, 272], [272, 272], [273, 272], [274, 272], [290, 272], [291, 272], [292, 272], [293, 272], [294, 272], [310, 272], [311, 272], [312, 272], [313, 272], [314, 272], [231, 273], [232, 273], [233, 273], [234, 273], [235, 273], [251, 273], [252, 273], [253, 273], [254, 273], [255, 273], [271, 273], [272, 273], [273, 273], [274, 273], [275, 273], [291, 273], [292, 273], [293, 273], [294, 273], [295, 273], [311, 273], [312, 273], [313, 273], [314, 273], [315, 273], [232, 274], [233, 274], [234, 274], [235, 274], [236, 274], [252, 274], [253, 274], [254, 274], [255, 274], [256, 274], [272, 274], [273, 274], [274, 274], [275, 274], [276, 274], [292, 274], [293, 274], [294, 274], [295, 274], [296, 274], [312, 274], [313, 274], [314, 274], [315, 274], [316, 274], [233, 275], [234, 275], [235, 275], [236, 275], [237, 275], [253, 275], [254, 275], [255, 275], [256, 275], [257, 275], [273, 275], [274, 275], [275, 275], [276, 275], [277, 275], [293, 275], [294, 275], [295, 275], [296, 275], [297, 275], [313, 275], [314, 275], [315, 275], [316, 275], [317, 275], [234, 276], [235, 276], [236, 276], [237, 276], [238, 276], [254, 276], [255, 276], [256, 276], [257, 276], [258, 276], [274, 276], [275, 276], [276, 276], [277, 276], [278, 276], [294, 276], [295, 276], [296, 276], [297, 276], [298, 276], [314, 276], [315, 276], [316, 276], [317, 276], [318, 276], [235, 277], [236, 277], [237, 277], [238, 277], [239, 277], [255, 277], [256, 277], [257, 277], [258, 277], [259, 277], [275, 277], [276, 277], [277, 277], [278, 277], [279, 277], [295, 277], [296, 277], [297, 277], [298, 277], [299, 277], [315, 277], [316, 277], [317, 277], [318, 277], [319, 277], [236, 278], [237, 278], [238, 278], [239, 278], [256, 278], [257, 278], [258, 278], [259, 278], [276, 278], [277, 278], [278, 278], [279, 278], [296, 278], [297, 278], [298, 278], [299, 278], [316, 278], [317, 278], [318, 278], [319, 278], [237, 279], [238, 279], [239, 279], [257, 279], [258, 279], [259, 279], [277, 279], [278, 279], [279, 279], [297, 279], [298, 279], [299, 279], [317, 279], [318, 279], [319, 279], [240, 280], [241, 280], [242, 280], [260, 280], [261, 280], [262, 280], [280, 280], [281, 280], [282, 280], [300, 280], [301, 280], [302, 280], [320, 280], [321, 280], [322, 280], [240, 281], [241, 281], [242, 281], [243, 281], [260, 281], [261, 281], [262, 281], [263, 281], [280, 281], [281, 281], [282, 281], [283, 281], [300, 281], [301, 281], [302, 281], [303, 281], [320, 281], [321, 281], [322, 281], [323, 281], [240, 282], [241, 282], [242, 282], [243, 282], [244, 282], [260, 282], [261, 282], [262, 282], [263, 282], [264, 282], [280, 282], [281, 282], [282, 282], [283, 282], [284, 282], [300, 282], [301, 282], [302, 282], [303, 282], [304, 282], [320, 282], [321, 282], [322, 282], [323, 282], [324, 282], [241, 283], [242, 283], [243, 283], [244, 283], [245, 283], [261, 283], [262, 283], [263, 283], [264, 283], [265, 283], [281, 283], [282, 283], [283, 283], [284, 283], [285, 283], [301, 283], [302, 283], [303, 283], [304, 283], [305, 283], [321, 283], [322, 283], [323, 283], [324, 283], [325, 283], [242, 284], [243, 284], [244, 284], [245, 284], [246, 284], [262, 284], [263, 284], [264, 284], [265, 284], [266, 284], [282, 284], [283, 284], [284, 284], [285, 284], [286, 284], [302, 284], [303, 284], [304, 284], [305, 284], [306, 284], [322, 284], [323, 284], [324, 284], [325, 284], [326, 284], [243, 285], [244, 285], [245, 285], [246, 285], [247, 285], [263, 285], [264, 285], [265, 285], [266, 285], [267, 285], [283, 285], [284, 285], [285, 285], [286, 285], [287, 285], [303, 285], [304, 285], [305, 285], [306, 285], [307, 285], [323, 285], [324, 285], [325, 285], [326, 285], [327, 285], [244, 286], [245, 286], [246, 286], [247, 286], [248, 286], [264, 286], [265, 286], [266, 286], [267, 286], [268, 286], [284, 286], [285, 286], [286, 286], [287, 286], [288, 286], [304, 286], [305, 286], [306, 286], [307, 286], [308, 286], [324, 286], [325, 286], [326, 286], [327, 286], [328, 286], [245, 287], [246, 287], [247, 287], [248, 287], [249, 287], [265, 287], [266, 287], [267, 287], [268, 287], [269, 287], [285, 287], [286, 287], [287, 287], [288, 287], [289, 287], [305, 287], [306, 287], [307, 287], [308, 287], [309, 287], [325, 287], [326, 287], [327, 287], [328, 287], [329, 287], [246, 288], [247, 288], [248, 288], [249, 288], [250, 288], [266, 288], [267, 288], [268, 288], [269, 288], [270, 288], [286, 288], [287, 288], [288, 288], [289, 288], [290, 288], [306, 288], [307, 288], [308, 288], [309, 288], [310, 288], [326, 288], [327, 288], [328, 288], [329, 288], [330, 288], [247, 289], [248, 289], [249, 289], [250, 289], [251, 289], [267, 289], [268, 289], [269, 289], [270, 289], [271, 289], [287, 289], [288, 289], [289, 289], [290, 289], [291, 289], [307, 289], [308, 289], [309, 289], [310, 289], [311, 289], [327, 289], [328, 289], [329, 289], [330, 289], [331, 289], [248, 290], [249, 290], [250, 290], [251, 290], [252, 290], [268, 290], [269, 290], [270, 290], [271, 290], [272, 290], [288, 290], [289, 290], [290, 290], [291, 290], [292, 290], [308, 290], [309, 290], [310, 290], [311, 290], [312, 290], [328, 290], [329, 290], [330, 290], [331, 290], [332, 290], [249, 291], [250, 291], [251, 291], [252, 291], [253, 291], [269, 291], [270, 291], [271, 291], [272, 291], [273, 291], [289, 291], [290, 291], [291, 291], [292, 291], [293, 291], [309, 291], [310, 291], [311, 291], [312, 291], [313, 291], [329, 291], [330, 291], [331, 291], [332, 291], [333, 291], [250, 292], [251, 292], [252, 292], [253, 292], [254, 292], [270, 292], [271, 292], [272, 292], [273, 292], [274, 292], [290, 292], [291, 292], [292, 292], [293, 292], [294, 292], [310, 292], [311, 292], [312, 292], [313, 292], [314, 292], [330, 292], [331, 292], [332, 292], [333, 292], [334, 292], [251, 293], [252, 293], [253, 293], [254, 293], [255, 293], [271, 293], [272, 293], [273, 293], [274, 293], [275, 293], [291, 293], [292, 293], [293, 293], [294, 293], [295, 293], [311, 293], [312, 293], [313, 293], [314, 293], [315, 293], [331, 293], [332, 293], [333, 293], [334, 293], [335, 293], [252, 294], [253, 294], [254, 294], [255, 294], [256, 294], [272, 294], [273, 294], [274, 294], [275, 294], [276, 294], [292, 294], [293, 294], [294, 294], [295, 294], [296, 294], [312, 294], [313, 294], [314, 294], [315, 294], [316, 294], [332, 294], [333, 294], [334, 294], [335, 294], [336, 294], [253, 295], [254, 295], [255, 295], [256, 295], [257, 295], [273, 295], [274, 295], [275, 295], [276, 295], [277, 295], [293, 295], [294, 295], [295, 295], [296, 295], [297, 295], [313, 295], [314, 295], [315, 295], [316, 295], [317, 295], [333, 295], [334, 295], [335, 295], [336, 295], [337, 295], [254, 296], [255, 296], [256, 296], [257, 296], [258, 296], [274, 296], [275, 296], [276, 296], [277, 296], [278, 296], [294, 296], [295, 296], [296, 296], [297, 296], [298, 296], [314, 296], [315, 296], [316, 296], [317, 296], [318, 296], [334, 296], [335, 296], [336, 296], [337, 296], [338, 296], [255, 297], [256, 297], [257, 297], [258, 297], [259, 297], [275, 297], [276, 297], [277, 297], [278, 297], [279, 297], [295, 297], [296, 297], [297, 297], [298, 297], [299, 297], [315, 297], [316, 297], [317, 297], [318, 297], [319, 297], [335, 297], [336, 297], [337, 297], [338, 297], [339, 297], [256, 298], [257, 298], [258, 298], [259, 298], [276, 298], [277, 298], [278, 298], [279, 298], [296, 298], [297, 298], [298, 298], [299, 298], [316, 298], [317, 298], [318, 298], [319, 298], [336, 298], [337, 298], [338, 298], [339, 298], [257, 299], [258, 299], [259, 299], [277, 299], [278, 299], [279, 299], [297, 299], [298, 299], [299, 299], [317, 299], [318, 299], [319, 299], [337, 299], [338, 299], [339, 299], [260, 300], [261, 300], [262, 300], [280, 300], [281, 300], [282, 300], [300, 300], [301, 300], [302, 300], [320, 300], [321, 300], [322, 300], [340, 300], [341, 300], [342, 300], [260, 301], [261, 301], [262, 301], [263, 301], [280, 301], [281, 301], [282, 301], [283, 301], [300, 301], [301, 301], [302, 301], [303, 301], [320, 301], [321, 301], [322, 301], [323, 301], [340, 301], [341, 301], [342, 301], [343, 301], [260, 302], [261, 302], [262, 302], [263, 302], [264, 302], [280, 302], [281, 302], [282, 302], [283, 302], [284, 302], [300, 302], [301, 302], [302, 302], [303, 302], [304, 302], [320, 302], [321, 302], [322, 302], [323, 302], [324, 302], [340, 302], [341, 302], [342, 302], [343, 302], [344, 302], [261, 303], [262, 303], [263, 303], [264, 303], [265, 303], [281, 303], [282, 303], [283, 303], [284, 303], [285, 303], [301, 303], [302, 303], [303, 303], [304, 303], [305, 303], [321, 303], [322, 303], [323, 303], [324, 303], [325, 303], [341, 303], [342, 303], [343, 303], [344, 303], [345, 303], [262, 304], [263, 304], [264, 304], [265, 304], [266, 304], [282, 304], [283, 304], [284, 304], [285, 304], [286, 304], [302, 304], [303, 304], [304, 304], [305, 304], [306, 304], [322, 304], [323, 304], [324, 304], [325, 304], [326, 304], [342, 304], [343, 304], [344, 304], [345, 304], [346, 304], [263, 305], [264, 305], [265, 305], [266, 305], [267, 305], [283, 305], [284, 305], [285, 305], [286, 305], [287, 305], [303, 305], [304, 305], [305, 305], [306, 305], [307, 305], [323, 305], [324, 305], [325, 305], [326, 305], [327, 305], [343, 305], [344, 305], [345, 305], [346, 305], [347, 305], [264, 306], [265, 306], [266, 306], [267, 306], [268, 306], [284, 306], [285, 306], [286, 306], [287, 306], [288, 306], [304, 306], [305, 306], [306, 306], [307, 306], [308, 306], [324, 306], [325, 306], [326, 306], [327, 306], [328, 306], [344, 306], [345, 306], [346, 306], [347, 306], [348, 306], [265, 307], [266, 307], [267, 307], [268, 307], [269, 307], [285, 307], [286, 307], [287, 307], [288, 307], [289, 307], [305, 307], [306, 307], [307, 307], [308, 307], [309, 307], [325, 307], [326, 307], [327, 307], [328, 307], [329, 307], [345, 307], [346, 307], [347, 307], [348, 307], [349, 307], [266, 308], [267, 308], [268, 308], [269, 308], [270, 308], [286, 308], [287, 308], [288, 308], [289, 308], [290, 308], [306, 308], [307, 308], [308, 308], [309, 308], [310, 308], [326, 308], [327, 308], [328, 308], [329, 308], [330, 308], [346, 308], [347, 308], [348, 308], [349, 308], [350, 308], [267, 309], [268, 309], [269, 309], [270, 309], [271, 309], [287, 309], [288, 309], [289, 309], [290, 309], [291, 309], [307, 309], [308, 309], [309, 309], [310, 309], [311, 309], [327, 309], [328, 309], [329, 309], [330, 309], [331, 309], [347, 309], [348, 309], [349, 309], [350, 309], [351, 309], [268, 310], [269, 310], [270, 310], [271, 310], [272, 310], [288, 310], [289, 310], [290, 310], [291, 310], [292, 310], [308, 310], [309, 310], [310, 310], [311, 310], [312, 310], [328, 310], [329, 310], [330, 310], [331, 310], [332, 310], [348, 310], [349, 310], [350, 310], [351, 310], [352, 310], [269, 311], [270, 311], [271, 311], [272, 311], [273, 311], [289, 311], [290, 311], [291, 311], [292, 311], [293, 311], [309, 311], [310, 311], [311, 311], [312, 311], [313, 311], [329, 311], [330, 311], [331, 311], [332, 311], [333, 311], [349, 311], [350, 311], [351, 311], [352, 311], [353, 311], [270, 312], [271, 312], [272, 312], [273, 312], [274, 312], [290, 312], [291, 312], [292, 312], [293, 312], [294, 312], [310, 312], [311, 312], [312, 312], [313, 312], [314, 312], [330, 312], [331, 312], [332, 312], [333, 312], [334, 312], [350, 312], [351, 312], [352, 312], [353, 312], [354, 312], [271, 313], [272, 313], [273, 313], [274, 313], [275, 313], [291, 313], [292, 313], [293, 313], [294, 313], [295, 313], [311, 313], [312, 313], [313, 313], [314, 313], [315, 313], [331, 313], [332, 313], [333, 313], [334, 313], [335, 313], [351, 313], [352, 313], [353, 313], [354, 313], [355, 313], [272, 314], [273, 314], [274, 314], [275, 314], [276, 314], [292, 314], [293, 314], [294, 314], [295, 314], [296, 314], [312, 314], [313, 314], [314, 314], [315, 314], [316, 314], [332, 314], [333, 314], [334, 314], [335, 314], [336, 314], [352, 314], [353, 314], [354, 314], [355, 314], [356, 314], [273, 315], [274, 315], [275, 315], [276, 315], [277, 315], [293, 315], [294, 315], [295, 315], [296, 315], [297, 315], [313, 315], [314, 315], [315, 315], [316, 315], [317, 315], [333, 315], [334, 315], [335, 315], [336, 315], [337, 315], [353, 315], [354, 315], [355, 315], [356, 315], [357, 315], [274, 316], [275, 316], [276, 316], [277, 316], [278, 316], [294, 316], [295, 316], [296, 316], [297, 316], [298, 316], [314, 316], [315, 316], [316, 316], [317, 316], [318, 316], [334, 316], [335, 316], [336, 316], [337, 316], [338, 316], [354, 316], [355, 316], [356, 316], [357, 316], [358, 316], [275, 317], [276, 317], [277, 317], [278, 317], [279, 317], [295, 317], [296, 317], [297, 317], [298, 317], [299, 317], [315, 317], [316, 317], [317, 317], [318, 317], [319, 317], [335, 317], [336, 317], [337, 317], [338, 317], [339, 317], [355, 317], [356, 317], [357, 317], [358, 317], [359, 317], [276, 318], [277, 318], [278, 318], [279, 318], [296, 318], [297, 318], [298, 318], [299, 318], [316, 318], [317, 318], [318, 318], [319, 318], [336, 318], [337, 318], [338, 318], [339, 318], [356, 318], [357, 318], [358, 318], [359, 318], [277, 319], [278, 319], [279, 319], [297, 319], [298, 319], [299, 319], [317, 319], [318, 319], [319, 319], [337, 319], [338, 319], [339, 319], [357, 319], [358, 319], [359, 319], [280, 320], [281, 320], [282, 320], [300, 320], [301, 320], [302, 320], [320, 320], [321, 320], [322, 320], [340, 320], [341, 320], [342, 320], [360, 320], [361, 320], [362, 320], [280, 321], [281, 321], [282, 321], [283, 321], [300, 321], [301, 321], [302, 321], [303, 321], [320, 321], [321, 321], [322, 321], [323, 321], [340, 321], [341, 321], [342, 321], [343, 321], [360, 321], [361, 321], [362, 321], [363, 321], [280, 322], [281, 322], [282, 322], [283, 322], [284, 322], [300, 322], [301, 322], [302, 322], [303, 322], [304, 322], [320, 322], [321, 322], [322, 322], [323, 322], [324, 322], [340, 322], [341, 322], [342, 322], [343, 322], [344, 322], [360, 322], [361, 322], [362, 322], [363, 322], [364, 322], [281, 323], [282, 323], [283, 323], [284, 323], [285, 323], [301, 323], [302, 323], [303, 323], [304, 323], [305, 323], [321, 323], [322, 323], [323, 323], [324, 323], [325, 323], [341, 323], [342, 323], [343, 323], [344, 323], [345, 323], [361, 323], [362, 323], [363, 323], [364, 323], [365, 323], [282, 324], [283, 324], [284, 324], [285, 324], [286, 324], [302, 324], [303, 324], [304, 324], [305, 324], [306, 324], [322, 324], [323, 324], [324, 324], [325, 324], [326, 324], [342, 324], [343, 324], [344, 324], [345, 324], [346, 324], [362, 324], [363, 324], [364, 324], [365, 324], [366, 324], [283, 325], [284, 325], [285, 325], [286, 325], [287, 325], [303, 325], [304, 325], [305, 325], [306, 325], [307, 325], [323, 325], [324, 325], [325, 325], [326, 325], [327, 325], [343, 325], [344, 325], [345, 325], [346, 325], [347, 325], [363, 325], [364, 325], [365, 325], [366, 325], [367, 325], [284, 326], [285, 326], [286, 326], [287, 326], [288, 326], [304, 326], [305, 326], [306, 326], [307, 326], [308, 326], [324, 326], [325, 326], [326, 326], [327, 326], [328, 326], [344, 326], [345, 326], [346, 326], [347, 326], [348, 326], [364, 326], [365, 326], [366, 326], [367, 326], [368, 326], [285, 327], [286, 327], [287, 327], [288, 327], [289, 327], [305, 327], [306, 327], [307, 327], [308, 327], [309, 327], [325, 327], [326, 327], [327, 327], [328, 327], [329, 327], [345, 327], [346, 327], [347, 327], [348, 327], [349, 327], [365, 327], [366, 327], [367, 327], [368, 327], [369, 327], [286, 328], [287, 328], [288, 328], [289, 328], [290, 328], [306, 328], [307, 328], [308, 328], [309, 328], [310, 328], [326, 328], [327, 328], [328, 328], [329, 328], [330, 328], [346, 328], [347, 328], [348, 328], [349, 328], [350, 328], [366, 328], [367, 328], [368, 328], [369, 328], [370, 328], [287, 329], [288, 329], [289, 329], [290, 329], [291, 329], [307, 329], [308, 329], [309, 329], [310, 329], [311, 329], [327, 329], [328, 329], [329, 329], [330, 329], [331, 329], [347, 329], [348, 329], [349, 329], [350, 329], [351, 329], [367, 329], [368, 329], [369, 329], [370, 329], [371, 329], [288, 330], [289, 330], [290, 330], [291, 330], [292, 330], [308, 330], [309, 330], [310, 330], [311, 330], [312, 330], [328, 330], [329, 330], [330, 330], [331, 330], [332, 330], [348, 330], [349, 330], [350, 330], [351, 330], [352, 330], [368, 330], [369, 330], [370, 330], [371, 330], [372, 330], [289, 331], [290, 331], [291, 331], [292, 331], [293, 331], [309, 331], [310, 331], [311, 331], [312, 331], [313, 331], [329, 331], [330, 331], [331, 331], [332, 331], [333, 331], [349, 331], [350, 331], [351, 331], [352, 331], [353, 331], [369, 331], [370, 331], [371, 331], [372, 331], [373, 331], [290, 332], [291, 332], [292, 332], [293, 332], [294, 332], [310, 332], [311, 332], [312, 332], [313, 332], [314, 332], [330, 332], [331, 332], [332, 332], [333, 332], [334, 332], [350, 332], [351, 332], [352, 332], [353, 332], [354, 332], [370, 332], [371, 332], [372, 332], [373, 332], [374, 332], [291, 333], [292, 333], [293, 333], [294, 333], [295, 333], [311, 333], [312, 333], [313, 333], [314, 333], [315, 333], [331, 333], [332, 333], [333, 333], [334, 333], [335, 333], [351, 333], [352, 333], [353, 333], [354, 333], [355, 333], [371, 333], [372, 333], [373, 333], [374, 333], [375, 333], [292, 334], [293, 334], [294, 334], [295, 334], [296, 334], [312, 334], [313, 334], [314, 334], [315, 334], [316, 334], [332, 334], [333, 334], [334, 334], [335, 334], [336, 334], [352, 334], [353, 334], [354, 334], [355, 334], [356, 334], [372, 334], [373, 334], [374, 334], [375, 334], [376, 334], [293, 335], [294, 335], [295, 335], [296, 335], [297, 335], [313, 335], [314, 335], [315, 335], [316, 335], [317, 335], [333, 335], [334, 335], [335, 335], [336, 335], [337, 335], [353, 335], [354, 335], [355, 335], [356, 335], [357, 335], [373, 335], [374, 335], [375, 335], [376, 335], [377, 335], [294, 336], [295, 336], [296, 336], [297, 336], [298, 336], [314, 336], [315, 336], [316, 336], [317, 336], [318, 336], [334, 336], [335, 336], [336, 336], [337, 336], [338, 336], [354, 336], [355, 336], [356, 336], [357, 336], [358, 336], [374, 336], [375, 336], [376, 336], [377, 336], [378, 336], [295, 337], [296, 337], [297, 337], [298, 337], [299, 337], [315, 337], [316, 337], [317, 337], [318, 337], [319, 337], [335, 337], [336, 337], [337, 337], [338, 337], [339, 337], [355, 337], [356, 337], [357, 337], [358, 337], [359, 337], [375, 337], [376, 337], [377, 337], [378, 337], [379, 337], [296, 338], [297, 338], [298, 338], [299, 338], [316, 338], [317, 338], [318, 338], [319, 338], [336, 338], [337, 338], [338, 338], [339, 338], [356, 338], [357, 338], [358, 338], [359, 338], [376, 338], [377, 338], [378, 338], [379, 338], [297, 339], [298, 339], [299, 339], [317, 339], [318, 339], [319, 339], [337, 339], [338, 339], [339, 339], [357, 339], [358, 339], [359, 339], [377, 339], [378, 339], [379, 339], [300, 340], [301, 340], [302, 340], [320, 340], [321, 340], [322, 340], [340, 340], [341, 340], [342, 340], [360, 340], [361, 340], [362, 340], [380, 340], [381, 340], [382, 340], [300, 341], [301, 341], [302, 341], [303, 341], [320, 341], [321, 341], [322, 341], [323, 341], [340, 341], [341, 341], [342, 341], [343, 341], [360, 341], [361, 341], [362, 341], [363, 341], [380, 341], [381, 341], [382, 341], [383, 341], [300, 342], [301, 342], [302, 342], [303, 342], [304, 342], [320, 342], [321, 342], [322, 342], [323, 342], [324, 342], [340, 342], [341, 342], [342, 342], [343, 342], [344, 342], [360, 342], [361, 342], [362, 342], [363, 342], [364, 342], [380, 342], [381, 342], [382, 342], [383, 342], [384, 342], [301, 343], [302, 343], [303, 343], [304, 343], [305, 343], [321, 343], [322, 343], [323, 343], [324, 343], [325, 343], [341, 343], [342, 343], [343, 343], [344, 343], [345, 343], [361, 343], [362, 343], [363, 343], [364, 343], [365, 343], [381, 343], [382, 343], [383, 343], [384, 343], [385, 343], [302, 344], [303, 344], [304, 344], [305, 344], [306, 344], [322, 344], [323, 344], [324, 344], [325, 344], [326, 344], [342, 344], [343, 344], [344, 344], [345, 344], [346, 344], [362, 344], [363, 344], [364, 344], [365, 344], [366, 344], [382, 344], [383, 344], [384, 344], [385, 344], [386, 344], [303, 345], [304, 345], [305, 345], [306, 345], [307, 345], [323, 345], [324, 345], [325, 345], [326, 345], [327, 345], [343, 345], [344, 345], [345, 345], [346, 345], [347, 345], [363, 345], [364, 345], [365, 345], [366, 345], [367, 345], [383, 345], [384, 345], [385, 345], [386, 345], [387, 345], [304, 346], [305, 346], [306, 346], [307, 346], [308, 346], [324, 346], [325, 346], [326, 346], [327, 346], [328, 346], [344, 346], [345, 346], [346, 346], [347, 346], [348, 346], [364, 346], [365, 346], [366, 346], [367, 346], [368, 346], [384, 346], [385, 346], [386, 346], [387, 346], [388, 346], [305, 347], [306, 347], [307, 347], [308, 347], [309, 347], [325, 347], [326, 347], [327, 347], [328, 347], [329, 347], [345, 347], [346, 347], [347, 347], [348, 347], [349, 347], [365, 347], [366, 347], [367, 347], [368, 347], [369, 347], [385, 347], [386, 347], [387, 347], [388, 347], [389, 347], [306, 348], [307, 348], [308, 348], [309, 348], [310, 348], [326, 348], [327, 348], [328, 348], [329, 348], [330, 348], [346, 348], [347, 348], [348, 348], [349, 348], [350, 348], [366, 348], [367, 348], [368, 348], [369, 348], [370, 348], [386, 348], [387, 348], [388, 348], [389, 348], [390, 348], [307, 349], [308, 349], [309, 349], [310, 349], [311, 349], [327, 349], [328, 349], [329, 349], [330, 349], [331, 349], [347, 349], [348, 349], [349, 349], [350, 349], [351, 349], [367, 349], [368, 349], [369, 349], [370, 349], [371, 349], [387, 349], [388, 349], [389, 349], [390, 349], [391, 349], [308, 350], [309, 350], [310, 350], [311, 350], [312, 350], [328, 350], [329, 350], [330, 350], [331, 350], [332, 350], [348, 350], [349, 350], [350, 350], [351, 350], [352, 350], [368, 350], [369, 350], [370, 350], [371, 350], [372, 350], [388, 350], [389, 350], [390, 350], [391, 350], [392, 350], [309, 351], [310, 351], [311, 351], [312, 351], [313, 351], [329, 351], [330, 351], [331, 351], [332, 351], [333, 351], [349, 351], [350, 351], [351, 351], [352, 351], [353, 351], [369, 351], [370, 351], [371, 351], [372, 351], [373, 351], [389, 351], [390, 351], [391, 351], [392, 351], [393, 351], [310, 352], [311, 352], [312, 352], [313, 352], [314, 352], [330, 352], [331, 352], [332, 352], [333, 352], [334, 352], [350, 352], [351, 352], [352, 352], [353, 352], [354, 352], [370, 352], [371, 352], [372, 352], [373, 352], [374, 352], [390, 352], [391, 352], [392, 352], [393, 352], [394, 352], [311, 353], [312, 353], [313, 353], [314, 353], [315, 353], [331, 353], [332, 353], [333, 353], [334, 353], [335, 353], [351, 353], [352, 353], [353, 353], [354, 353], [355, 353], [371, 353], [372, 353], [373, 353], [374, 353], [375, 353], [391, 353], [392, 353], [393, 353], [394, 353], [395, 353], [312, 354], [313, 354], [314, 354], [315, 354], [316, 354], [332, 354], [333, 354], [334, 354], [335, 354], [336, 354], [352, 354], [353, 354], [354, 354], [355, 354], [356, 354], [372, 354], [373, 354], [374, 354], [375, 354], [376, 354], [392, 354], [393, 354], [394, 354], [395, 354], [396, 354], [313, 355], [314, 355], [315, 355], [316, 355], [317, 355], [333, 355], [334, 355], [335, 355], [336, 355], [337, 355], [353, 355], [354, 355], [355, 355], [356, 355], [357, 355], [373, 355], [374, 355], [375, 355], [376, 355], [377, 355], [393, 355], [394, 355], [395, 355], [396, 355], [397, 355], [314, 356], [315, 356], [316, 356], [317, 356], [318, 356], [334, 356], [335, 356], [336, 356], [337, 356], [338, 356], [354, 356], [355, 356], [356, 356], [357, 356], [358, 356], [374, 356], [375, 356], [376, 356], [377, 356], [378, 356], [394, 356], [395, 356], [396, 356], [397, 356], [398, 356], [315, 357], [316, 357], [317, 357], [318, 357], [319, 357], [335, 357], [336, 357], [337, 357], [338, 357], [339, 357], [355, 357], [356, 357], [357, 357], [358, 357], [359, 357], [375, 357], [376, 357], [377, 357], [378, 357], [379, 357], [395, 357], [396, 357], [397, 357], [398, 357], [399, 357], [316, 358], [317, 358], [318, 358], [319, 358], [336, 358], [337, 358], [338, 358], [339, 358], [356, 358], [357, 358], [358, 358], [359, 358], [376, 358], [377, 358], [378, 358], [379, 358], [396, 358], [397, 358], [398, 358], [399, 358], [317, 359], [318, 359], [319, 359], [337, 359], [338, 359], [339, 359], [357, 359], [358, 359], [359, 359], [377, 359], [378, 359], [379, 359], [397, 359], [398, 359], [399, 359], [320, 360], [321, 360], [322, 360], [340, 360], [341, 360], [342, 360], [360, 360], [361, 360], [362, 360], [380, 360], [381, 360], [382, 360], [320, 361], [321, 361], [322, 361], [323, 361], [340, 361], [341, 361], [342, 361], [343, 361], [360, 361], [361, 361], [362, 361], [363, 361], [380, 361], [381, 361], [382, 361], [383, 361], [320, 362], [321, 362], [322, 362], [323, 362], [324, 362], [340, 362], [341, 362], [342, 362], [343, 362], [344, 362], [360, 362], [361, 362], [362, 362], [363, 362], [364, 362], [380, 362], [381, 362], [382, 362], [383, 362], [384, 362], [321, 363], [322, 363], [323, 363], [324, 363], [325, 363], [341, 363], [342, 363], [343, 363], [344, 363], [345, 363], [361, 363], [362, 363], [363, 363], [364, 363], [365, 363], [381, 363], [382, 363], [383, 363], [384, 363], [385, 363], [322, 364], [323, 364], [324, 364], [325, 364], [326, 364], [342, 364], [343, 364], [344, 364], [345, 364], [346, 364], [362, 364], [363, 364], [364, 364], [365, 364], [366, 364], [382, 364], [383, 364], [384, 364], [385, 364], [386, 364], [323, 365], [324, 365], [325, 365], [326, 365], [327, 365], [343, 365], [344, 365], [345, 365], [346, 365], [347, 365], [363, 365], [364, 365], [365, 365], [366, 365], [367, 365], [383, 365], [384, 365], [385, 365], [386, 365], [387, 365], [324, 366], [325, 366], [326, 366], [327, 366], [328, 366], [344, 366], [345, 366], [346, 366], [347, 366], [348, 366], [364, 366], [365, 366], [366, 366], [367, 366], [368, 366], [384, 366], [385, 366], [386, 366], [387, 366], [388, 366], [325, 367], [326, 367], [327, 367], [328, 367], [329, 367], [345, 367], [346, 367], [347, 367], [348, 367], [349, 367], [365, 367], [366, 367], [367, 367], [368, 367], [369, 367], [385, 367], [386, 367], [387, 367], [388, 367], [389, 367], [326, 368], [327, 368], [328, 368], [329, 368], [330, 368], [346, 368], [347, 368], [348, 368], [349, 368], [350, 368], [366, 368], [367, 368], [368, 368], [369, 368], [370, 368], [386, 368], [387, 368], [388, 368], [389, 368], [390, 368], [327, 369], [328, 369], [329, 369], [330, 369], [331, 369], [347, 369], [348, 369], [349, 369], [350, 369], [351, 369], [367, 369], [368, 369], [369, 369], [370, 369], [371, 369], [387, 369], [388, 369], [389, 369], [390, 369], [391, 369], [328, 370], [329, 370], [330, 370], [331, 370], [332, 370], [348, 370], [349, 370], [350, 370], [351, 370], [352, 370], [368, 370], [369, 370], [370, 370], [371, 370], [372, 370], [388, 370], [389, 370], [390, 370], [391, 370], [392, 370], [329, 371], [330, 371], [331, 371], [332, 371], [333, 371], [349, 371], [350, 371], [351, 371], [352, 371], [353, 371], [369, 371], [370, 371], [371, 371], [372, 371], [373, 371], [389, 371], [390, 371], [391, 371], [392, 371], [393, 371], [330, 372], [331, 372], [332, 372], [333, 372], [334, 372], [350, 372], [351, 372], [352, 372], [353, 372], [354, 372], [370, 372], [371, 372], [372, 372], [373, 372], [374, 372], [390, 372], [391, 372], [392, 372], [393, 372], [394, 372], [331, 373], [332, 373], [333, 373], [334, 373], [335, 373], [351, 373], [352, 373], [353, 373], [354, 373], [355, 373], [371, 373], [372, 373], [373, 373], [374, 373], [375, 373], [391, 373], [392, 373], [393, 373], [394, 373], [395, 373], [332, 374], [333, 374], [334, 374], [335, 374], [336, 374], [352, 374], [353, 374], [354, 374], [355, 374], [356, 374], [372, 374], [373, 374], [374, 374], [375, 374], [376, 374], [392, 374], [393, 374], [394, 374], [395, 374], [396, 374], [333, 375], [334, 375], [335, 375], [336, 375], [337, 375], [353, 375], [354, 375], [355, 375], [356, 375], [357, 375], [373, 375], [374, 375], [375, 375], [376, 375], [377, 375], [393, 375], [394, 375], [395, 375], [396, 375], [397, 375], [334, 376], [335, 376], [336, 376], [337, 376], [338, 376], [354, 376], [355, 376], [356, 376], [357, 376], [358, 376], [374, 376], [375, 376], [376, 376], [377, 376], [378, 376], [394, 376], [395, 376], [396, 376], [397, 376], [398, 376], [335, 377], [336, 377], [337, 377], [338, 377], [339, 377], [355, 377], [356, 377], [357, 377], [358, 377], [359, 377], [375, 377], [376, 377], [377, 377], [378, 377], [379, 377], [395, 377], [396, 377], [397, 377], [398, 377], [399, 377], [336, 378], [337, 378], [338, 378], [339, 378], [356, 378], [357, 378], [358, 378], [359, 378], [376, 378], [377, 378], [378, 378], [379, 378], [396, 378], [397, 378], [398, 378], [399, 378], [337, 379], [338, 379], [339, 379], [357, 379], [358, 379], [359, 379], [377, 379], [378, 379], [379, 379], [397, 379], [398, 379], [399, 379], [340, 380], [341, 380], [342, 380], [360, 380], [361, 380], [362, 380], [380, 380], [381, 380], [382, 380], [340, 381], [341, 381], [342, 381], [343, 381], [360, 381], [361, 381], [362, 381], [363, 381], [380, 381], [381, 381], [382, 381], [383, 381], [340, 382], [341, 382], [342, 382], [343, 382], [344, 382], [360, 382], [361, 382], [362, 382], [363, 382], [364, 382], [380, 382], [381, 382], [382, 382], [383, 382], [384, 382], [341, 383], [342, 383], [343, 383], [344, 383], [345, 383], [361, 383], [362, 383], [363, 383], [364, 383], [365, 383], [381, 383], [382, 383], [383, 383], [384, 383], [385, 383], [342, 384], [343, 384], [344, 384], [345, 384], [346, 384], [362, 384], [363, 384], [364, 384], [365, 384], [366, 384], [382, 384], [383, 384], [384, 384], [385, 384], [386, 384], [343, 385], [344, 385], [345, 385], [346, 385], [347, 385], [363, 385], [364, 385], [365, 385], [366, 385], [367, 385], [383, 385], [384, 385], [385, 385], [386, 385], [387, 385], [344, 386], [345, 386], [346, 386], [347, 386], [348, 386], [364, 386], [365, 386], [366, 386], [367, 386], [368, 386], [384, 386], [385, 386], [386, 386], [387, 386], [388, 386], [345, 387], [346, 387], [347, 387], [348, 387], [349, 387], [365, 387], [366, 387], [367, 387], [368, 387], [369, 387], [385, 387], [386, 387], [387, 387], [388, 387], [389, 387], [346, 388], [347, 388], [348, 388], [349, 388], [350, 388], [366, 388], [367, 388], [368, 388], [369, 388], [370, 388], [386, 388], [387, 388], [388, 388], [389, 388], [390, 388], [347, 389], [348, 389], [349, 389], [350, 389], [351, 389], [367, 389], [368, 389], [369, 389], [370, 389], [371, 389], [387, 389], [388, 389], [389, 389], [390, 389], [391, 389], [348, 390], [349, 390], [350, 390], [351, 390], [352, 390], [368, 390], [369, 390], [370, 390], [371, 390], [372, 390], [388, 390], [389, 390], [390, 390], [391, 390], [392, 390], [349, 391], [350, 391], [351, 391], [352, 391], [353, 391], [369, 391], [370, 391], [371, 391], [372, 391], [373, 391], [389, 391], [390, 391], [391, 391], [392, 391], [393, 391], [350, 392], [351, 392], [352, 392], [353, 392], [354, 392], [370, 392], [371, 392], [372, 392], [373, 392], [374, 392], [390, 392], [391, 392], [392, 392], [393, 392], [394, 392], [351, 393], [352, 393], [353, 393], [354, 393], [355, 393], [371, 393], [372, 393], [373, 393], [374, 393], [375, 393], [391, 393], [392, 393], [393, 393], [394, 393], [395, 393], [352, 394], [353, 394], [354, 394], [355, 394], [356, 394], [372, 394], [373, 394], [374, 394], [375, 394], [376, 394], [392, 394], [393, 394], [394, 394], [395, 394], [396, 394], [353, 395], [354, 395], [355, 395], [356, 395], [357, 395], [373, 395], [374, 395], [375, 395], [376, 395], [377, 395], [393, 395], [394, 395], [395, 395], [396, 395], [397, 395], [354, 396], [355, 396], [356, 396], [357, 396], [358, 396], [374, 396], [375, 396], [376, 396], [377, 396], [378, 396], [394, 396], [395, 396], [396, 396], [397, 396], [398, 396], [355, 397], [356, 397], [357, 397], [358, 397], [359, 397], [375, 397], [376, 397], [377, 397], [378, 397], [379, 397], [395, 397], [396, 397], [397, 397], [398, 397], [399, 397], [356, 398], [357, 398], [358, 398], [359, 398], [376, 398], [377, 398], [378, 398], [379, 398], [396, 398], [397, 398], [398, 398], [399, 398], [357, 399], [358, 399], [359, 399], [377, 399], [378, 399], [379, 399], [397, 399], [398, 399], [399, 399]]
V1 to V4
[[0, 0], [1, 0], [2, 0], [20, 0], [21, 0], [22, 0], [40, 0], [41, 0], [42, 0], [0, 1], [1, 1], [2, 1], [3, 1], [4, 1], [20, 1], [21, 1], [22, 1], [23, 1], [24, 1], [40, 1], [41, 1], [42, 1], [43, 1], [44, 1], [2, 2], [3, 2], [4, 2], [5, 2], [6, 2], [22, 2], [23, 2], [24, 2], [25, 2], [26, 2], [42, 2], [43, 2], [44, 2], [45, 2], [46, 2], [4, 3], [5, 3], [6, 3], [7, 3], [8, 3], [24, 3], [25, 3], [26, 3], [27, 3], [28, 3], [44, 3], [45, 3], [46, 3], [47, 3], [48, 3], [6, 4], [7, 4], [8, 4], [9, 4], [10, 4], [26, 4], [27, 4], [28, 4], [29, 4], [30, 4], [46, 4], [47, 4], [48, 4], [49, 4], [50, 4], [8, 5], [9, 5], [10, 5], [11, 5], [12, 5], [28, 5], [29, 5], [30, 5], [31, 5], [32, 5], [48, 5], [49, 5], [50, 5], [51, 5], [52, 5], [10, 6], [11, 6], [12, 6], [13, 6], [14, 6], [30, 6], [31, 6], [32, 6], [33, 6], [34, 6], [50, 6], [51, 6], [52, 6], [53, 6], [54, 6], [12, 7], [13, 7], [14, 7], [15, 7], [16, 7], [32, 7], [33, 7], [34, 7], [35, 7], [36, 7], [52, 7], [53, 7], [54, 7], [55, 7], [56, 7], [14, 8], [15, 8], [16, 8], [17, 8], [18, 8], [34, 8], [35, 8], [36, 8], [37, 8], [38, 8], [54, 8], [55, 8], [56, 8], [57, 8], [58, 8], [16, 9], [17, 9], [18, 9], [19, 9], [36, 9], [37, 9], [38, 9], [39, 9], [56, 9], [57, 9], [58, 9], [59, 9], [0, 10], [1, 10], [2, 10], [20, 10], [21, 10], [22, 10], [40, 10], [41, 10], [42, 10], [60, 10], [61, 10], [62, 10], [80, 10], [81, 10], [82, 10], [0, 11], [1, 11], [2, 11], [3, 11], [4, 11], [20, 11], [21, 11], [22, 11], [23, 11], [24, 11], [40, 11], [41, 11], [42, 11], [43, 11], [44, 11], [60, 11], [61, 11], [62, 11], [63, 11], [64, 11], [80, 11], [81, 11], [82, 11], [83, 11], [84, 11], [2, 12], [3, 12], [4, 12], [5, 12], [6, 12], [22, 12], [23, 12], [24, 12], [25, 12], [26, 12], [42, 12], [43, 12], [44, 12], [45, 12], [46, 12], [62, 12], [63, 12], [64, 12], [65, 12], [66, 12], [82, 12], [83, 12], [84, 12], [85, 12], [86, 12], [4, 13], [5, 13], [6, 13], [7, 13], [8, 13], [24, 13], [25, 13], [26, 13], [27, 13], [28, 13], [44, 13], [45, 13], [46, 13], [47, 13], [48, 13], [64, 13], [65, 13], [66, 13], [67, 13], [68, 13], [84, 13], [85, 13], [86, 13], [87, 13], [88, 13], [6, 14], [7, 14], [8, 14], [9, 14], [10, 14], [26, 14], [27, 14], [28, 14], [29, 14], [30, 14], [46, 14], [47, 14], [48, 14], [49, 14], [50, 14], [66, 14], [67, 14], [68, 14], [69, 14], [70, 14], [86, 14], [87, 14], [88, 14], [89, 14], [90, 14], [8, 15], [9, 15], [10, 15], [11, 15], [12, 15], [28, 15], [29, 15], [30, 15], [31, 15], [32, 15], [48, 15], [49, 15], [50, 15], [51, 15], [52, 15], [68, 15], [69, 15], [70, 15], [71, 15], [72, 15], [88, 15], [89, 15], [90, 15], [91, 15], [92, 15], [10, 16], [11, 16], [12, 16], [13, 16], [14, 16], [30, 16], [31, 16], [32, 16], [33, 16], [34, 16], [50, 16], [51, 16], [52, 16], [53, 16], [54, 16], [70, 16], [71, 16], [72, 16], [73, 16], [74, 16], [90, 16], [91, 16], [92, 16], [93, 16], [94, 16], [12, 17], [13, 17], [14, 17], [15, 17], [16, 17], [32, 17], [33, 17], [34, 17], [35, 17], [36, 17], [52, 17], [53, 17], [54, 17], [55, 17], [56, 17], [72, 17], [73, 17], [74, 17], [75, 17], [76, 17], [92, 17], [93, 17], [94, 17], [95, 17], [96, 17], [14, 18], [15, 18], [16, 18], [17, 18], [18, 18], [34, 18], [35, 18], [36, 18], [37, 18], [38, 18], [54, 18], [55, 18], [56, 18], [57, 18], [58, 18], [74, 18], [75, 18], [76, 18], [77, 18], [78, 18], [94, 18], [95, 18], [96, 18], [97, 18], [98, 18], [16, 19], [17, 19], [18, 19], [19, 19], [36, 19], [37, 19], [38, 19], [39, 19], [56, 19], [57, 19], [58, 19], [59, 19], [76, 19], [77, 19], [78, 19], [79, 19], [96, 19], [97, 19], [98, 19], [99, 19], [40, 20], [41, 20], [42, 20], [60, 20], [61, 20], [62, 20], [80, 20], [81, 20], [82, 20], [100, 20], [101, 20], [102, 20], [120, 20], [121, 20], [122, 20], [40, 21], [41, 21], [42, 21], [43, 21], [44, 21], [60, 21], [61, 21], [62, 21], [63, 21], [64, 21], [80, 21], [81, 21], [82, 21], [83, 21], [84, 21], [100, 21], [101, 21], [102, 21], [103, 21], [104, 21], [120, 21], [121, 21], [122, 21], [123, 21], [124, 21], [42, 22], [43, 22], [44, 22], [45, 22], [46, 22], [62, 22], [63, 22], [64, 22], [65, 22], [66, 22], [82, 22], [83, 22], [84, 22], [85, 22], [86, 22], [102, 22], [103, 22], [104, 22], [105, 22], [106, 22], [122, 22], [123, 22], [124, 22], [125, 22], [126, 22], [44, 23], [45, 23], [46, 23], [47, 23], [48, 23], [64, 23], [65, 23], [66, 23], [67, 23], [68, 23], [84, 23], [85, 23], [86, 23], [87, 23], [88, 23], [104, 23], [105, 23], [106, 23], [107, 23], [108, 23], [124, 23], [125, 23], [126, 23], [127, 23], [128, 23], [46, 24], [47, 24], [48, 24], [49, 24], [50, 24], [66, 24], [67, 24], [68, 24], [69, 24], [70, 24], [86, 24], [87, 24], [88, 24], [89, 24], [90, 24], [106, 24], [107, 24], [108, 24], [109, 24], [110, 24], [126, 24], [127, 24], [128, 24], [129, 24], [130, 24], [48, 25], [49, 25], [50, 25], [51, 25], [52, 25], [68, 25], [69, 25], [70, 25], [71, 25], [72, 25], [88, 25], [89, 25], [90, 25], [91, 25], [92, 25], [108, 25], [109, 25], [110, 25], [111, 25], [112, 25], [128, 25], [129, 25], [130, 25], [131, 25], [132, 25], [50, 26], [51, 26], [52, 26], [53, 26], [54, 26], [70, 26], [71, 26], [72, 26], [73, 26], [74, 26], [90, 26], [91, 26], [92, 26], [93, 26], [94, 26], [110, 26], [111, 26], [112, 26], [113, 26], [114, 26], [130, 26], [131, 26], [132, 26], [133, 26], [134, 26], [52, 27], [53, 27], [54, 27], [55, 27], [56, 27], [72, 27], [73, 27], [74, 27], [75, 27], [76, 27], [92, 27], [93, 27], [94, 27], [95, 27], [96, 27], [112, 27], [113, 27], [114, 27], [115, 27], [116, 27], [132, 27], [133, 27], [134, 27], [135, 27], [136, 27], [54, 28], [55, 28], [56, 28], [57, 28], [58, 28], [74, 28], [75, 28], [76, 28], [77, 28], [78, 28], [94, 28], [95, 28], [96, 28], [97, 28], [98, 28], [114, 28], [115, 28], [116, 28], [117, 28], [118, 28], [134, 28], [135, 28], [136, 28], [137, 28], [138, 28], [56, 29], [57, 29], [58, 29], [59, 29], [76, 29], [77, 29], [78, 29], [79, 29], [96, 29], [97, 29], [98, 29], [99, 29], [116, 29], [117, 29], [118, 29], [119, 29], [136, 29], [137, 29], [138, 29], [139, 29], [80, 30], [81, 30], [82, 30], [100, 30], [101, 30], [102, 30], [120, 30], [121, 30], [122, 30], [140, 30], [141, 30], [142, 30], [160, 30], [161, 30], [162, 30], [80, 31], [81, 31], [82, 31], [83, 31], [84, 31], [100, 31], [101, 31], [102, 31], [103, 31], [104, 31], [120, 31], [121, 31], [122, 31], [123, 31], [124, 31], [140, 31], [141, 31], [142, 31], [143, 31], [144, 31], [160, 31], [161, 31], [162, 31], [163, 31], [164, 31], [82, 32], [83, 32], [84, 32], [85, 32], [86, 32], [102, 32], [103, 32], [104, 32], [105, 32], [106, 32], [122, 32], [123, 32], [124, 32], [125, 32], [126, 32], [142, 32], [143, 32], [144, 32], [145, 32], [146, 32], [162, 32], [163, 32], [164, 32], [165, 32], [166, 32], [84, 33], [85, 33], [86, 33], [87, 33], [88, 33], [104, 33], [105, 33], [106, 33], [107, 33], [108, 33], [124, 33], [125, 33], [126, 33], [127, 33], [128, 33], [144, 33], [145, 33], [146, 33], [147, 33], [148, 33], [164, 33], [165, 33], [166, 33], [167, 33], [168, 33], [86, 34], [87, 34], [88, 34], [89, 34], [90, 34], [106, 34], [107, 34], [108, 34], [109, 34], [110, 34], [126, 34], [127, 34], [128, 34], [129, 34], [130, 34], [146, 34], [147, 34], [148, 34], [149, 34], [150, 34], [166, 34], [167, 34], [168, 34], [169, 34], [170, 34], [88, 35], [89, 35], [90, 35], [91, 35], [92, 35], [108, 35], [109, 35], [110, 35], [111, 35], [112, 35], [128, 35], [129, 35], [130, 35], [131, 35], [132, 35], [148, 35], [149, 35], [150, 35], [151, 35], [152, 35], [168, 35], [169, 35], [170, 35], [171, 35], [172, 35], [90, 36], [91, 36], [92, 36], [93, 36], [94, 36], [110, 36], [111, 36], [112, 36], [113, 36], [114, 36], [130, 36], [131, 36], [132, 36], [133, 36], [134, 36], [150, 36], [151, 36], [152, 36], [153, 36], [154, 36], [170, 36], [171, 36], [172, 36], [173, 36], [174, 36], [92, 37], [93, 37], [94, 37], [95, 37], [96, 37], [112, 37], [113, 37], [114, 37], [115, 37], [116, 37], [132, 37], [133, 37], [134, 37], [135, 37], [136, 37], [152, 37], [153, 37], [154, 37], [155, 37], [156, 37], [172, 37], [173, 37], [174, 37], [175, 37], [176, 37], [94, 38], [95, 38], [96, 38], [97, 38], [98, 38], [114, 38], [115, 38], [116, 38], [117, 38], [118, 38], [134, 38], [135, 38], [136, 38], [137, 38], [138, 38], [154, 38], [155, 38], [156, 38], [157, 38], [158, 38], [174, 38], [175, 38], [176, 38], [177, 38], [178, 38], [96, 39], [97, 39], [98, 39], [99, 39], [116, 39], [117, 39], [118, 39], [119, 39], [136, 39], [137, 39], [138, 39], [139, 39], [156, 39], [157, 39], [158, 39], [159, 39], [176, 39], [177, 39], [178, 39], [179, 39], [120, 40], [121, 40], [122, 40], [140, 40], [141, 40], [142, 40], [160, 40], [161, 40], [162, 40], [180, 40], [181, 40], [182, 40], [200, 40], [201, 40], [202, 40], [120, 41], [121, 41], [122, 41], [123, 41], [124, 41], [140, 41], [141, 41], [142, 41], [143, 41], [144, 41], [160, 41], [161, 41], [162, 41], [163, 41], [164, 41], [180, 41], [181, 41], [182, 41], [183, 41], [184, 41], [200, 41], [201, 41], [202, 41], [203, 41], [204, 41], [122, 42], [123, 42], [124, 42], [125, 42], [126, 42], [142, 42], [143, 42], [144, 42], [145, 42], [146, 42], [162, 42], [163, 42], [164, 42], [165, 42], [166, 42], [182, 42], [183, 42], [184, 42], [185, 42], [186, 42], [202, 42], [203, 42], [204, 42], [205, 42], [206, 42], [124, 43], [125, 43], [126, 43], [127, 43], [128, 43], [144, 43], [145, 43], [146, 43], [147, 43], [148, 43], [164, 43], [165, 43], [166, 43], [167, 43], [168, 43], [184, 43], [185, 43], [186, 43], [187, 43], [188, 43], [204, 43], [205, 43], [206, 43], [207, 43], [208, 43], [126, 44], [127, 44], [128, 44], [129, 44], [130, 44], [146, 44], [147, 44], [148, 44], [149, 44], [150, 44], [166, 44], [167, 44], [168, 44], [169, 44], [170, 44], [186, 44], [187, 44], [188, 44], [189, 44], [190, 44], [206, 44], [207, 44], [208, 44], [209, 44], [210, 44], [128, 45], [129, 45], [130, 45], [131, 45], [132, 45], [148, 45], [149, 45], [150, 45], [151, 45], [152, 45], [168, 45], [169, 45], [170, 45], [171, 45], [172, 45], [188, 45], [189, 45], [190, 45], [191, 45], [192, 45], [208, 45], [209, 45], [210, 45], [211, 45], [212, 45], [130, 46], [131, 46], [132, 46], [133, 46], [134, 46], [150, 46], [151, 46], [152, 46], [153, 46], [154, 46], [170, 46], [171, 46], [172, 46], [173, 46], [174, 46], [190, 46], [191, 46], [192, 46], [193, 46], [194, 46], [210, 46], [211, 46], [212, 46], [213, 46], [214, 46], [132, 47], [133, 47], [134, 47], [135, 47], [136, 47], [152, 47], [153, 47], [154, 47], [155, 47], [156, 47], [172, 47], [173, 47], [174, 47], [175, 47], [176, 47], [192, 47], [193, 47], [194, 47], [195, 47], [196, 47], [212, 47], [213, 47], [214, 47], [215, 47], [216, 47], [134, 48], [135, 48], [136, 48], [137, 48], [138, 48], [154, 48], [155, 48], [156, 48], [157, 48], [158, 48], [174, 48], [175, 48], [176, 48], [177, 48], [178, 48], [194, 48], [195, 48], [196, 48], [197, 48], [198, 48], [214, 48], [215, 48], [216, 48], [217, 48], [218, 48], [136, 49], [137, 49], [138, 49], [139, 49], [156, 49], [157, 49], [158, 49], [159, 49], [176, 49], [177, 49], [178, 49], [179, 49], [196, 49], [197, 49], [198, 49], [199, 49], [216, 49], [217, 49], [218, 49], [219, 49], [160, 50], [161, 50], [162, 50], [180, 50], [181, 50], [182, 50], [200, 50], [201, 50], [202, 50], [220, 50], [221, 50], [222, 50], [240, 50], [241, 50], [242, 50], [160, 51], [161, 51], [162, 51], [163, 51], [164, 51], [180, 51], [181, 51], [182, 51], [183, 51], [184, 51], [200, 51], [201, 51], [202, 51], [203, 51], [204, 51], [220, 51], [221, 51], [222, 51], [223, 51], [224, 51], [240, 51], [241, 51], [242, 51], [243, 51], [244, 51], [162, 52], [163, 52], [164, 52], [165, 52], [166, 52], [182, 52], [183, 52], [184, 52], [185, 52], [186, 52], [202, 52], [203, 52], [204, 52], [205, 52], [206, 52], [222, 52], [223, 52], [224, 52], [225, 52], [226, 52], [242, 52], [243, 52], [244, 52], [245, 52], [246, 52], [164, 53], [165, 53], [166, 53], [167, 53], [168, 53], [184, 53], [185, 53], [186, 53], [187, 53], [188, 53], [204, 53], [205, 53], [206, 53], [207, 53], [208, 53], [224, 53], [225, 53], [226, 53], [227, 53], [228, 53], [244, 53], [245, 53], [246, 53], [247, 53], [248, 53], [166, 54], [167, 54], [168, 54], [169, 54], [170, 54], [186, 54], [187, 54], [188, 54], [189, 54], [190, 54], [206, 54], [207, 54], [208, 54], [209, 54], [210, 54], [226, 54], [227, 54], [228, 54], [229, 54], [230, 54], [246, 54], [247, 54], [248, 54], [249, 54], [250, 54], [168, 55], [169, 55], [170, 55], [171, 55], [172, 55], [188, 55], [189, 55], [190, 55], [191, 55], [192, 55], [208, 55], [209, 55], [210, 55], [211, 55], [212, 55], [228, 55], [229, 55], [230, 55], [231, 55], [232, 55], [248, 55], [249, 55], [250, 55], [251, 55], [252, 55], [170, 56], [171, 56], [172, 56], [173, 56], [174, 56], [190, 56], [191, 56], [192, 56], [193, 56], [194, 56], [210, 56], [211, 56], [212, 56], [213, 56], [214, 56], [230, 56], [231, 56], [232, 56], [233, 56], [234, 56], [250, 56], [251, 56], [252, 56], [253, 56], [254, 56], [172, 57], [173, 57], [174, 57], [175, 57], [176, 57], [192, 57], [193, 57], [194, 57], [195, 57], [196, 57], [212, 57], [213, 57], [214, 57], [215, 57], [216, 57], [232, 57], [233, 57], [234, 57], [235, 57], [236, 57], [252, 57], [253, 57], [254, 57], [255, 57], [256, 57], [174, 58], [175, 58], [176, 58], [177, 58], [178, 58], [194, 58], [195, 58], [196, 58], [197, 58], [198, 58], [214, 58], [215, 58], [216, 58], [217, 58], [218, 58], [234, 58], [235, 58], [236, 58], [237, 58], [238, 58], [254, 58], [255, 58], [256, 58], [257, 58], [258, 58], [176, 59], [177, 59], [178, 59], [179, 59], [196, 59], [197, 59], [198, 59], [199, 59], [216, 59], [217, 59], [218, 59], [219, 59], [236, 59], [237, 59], [238, 59], [239, 59], [256, 59], [257, 59], [258, 59], [259, 59], [200, 60], [201, 60], [202, 60], [220, 60], [221, 60], [222, 60], [240, 60], [241, 60], [242, 60], [260, 60], [261, 60], [262, 60], [280, 60], [281, 60], [282, 60], [200, 61], [201, 61], [202, 61], [203, 61], [204, 61], [220, 61], [221, 61], [222, 61], [223, 61], [224, 61], [240, 61], [241, 61], [242, 61], [243, 61], [244, 61], [260, 61], [261, 61], [262, 61], [263, 61], [264, 61], [280, 61], [281, 61], [282, 61], [283, 61], [284, 61], [202, 62], [203, 62], [204, 62], [205, 62], [206, 62], [222, 62], [223, 62], [224, 62], [225, 62], [226, 62], [242, 62], [243, 62], [244, 62], [245, 62], [246, 62], [262, 62], [263, 62], [264, 62], [265, 62], [266, 62], [282, 62], [283, 62], [284, 62], [285, 62], [286, 62], [204, 63], [205, 63], [206, 63], [207, 63], [208, 63], [224, 63], [225, 63], [226, 63], [227, 63], [228, 63], [244, 63], [245, 63], [246, 63], [247, 63], [248, 63], [264, 63], [265, 63], [266, 63], [267, 63], [268, 63], [284, 63], [285, 63], [286, 63], [287, 63], [288, 63], [206, 64], [207, 64], [208, 64], [209, 64], [210, 64], [226, 64], [227, 64], [228, 64], [229, 64], [230, 64], [246, 64], [247, 64], [248, 64], [249, 64], [250, 64], [266, 64], [267, 64], [268, 64], [269, 64], [270, 64], [286, 64], [287, 64], [288, 64], [289, 64], [290, 64], [208, 65], [209, 65], [210, 65], [211, 65], [212, 65], [228, 65], [229, 65], [230, 65], [231, 65], [232, 65], [248, 65], [249, 65], [250, 65], [251, 65], [252, 65], [268, 65], [269, 65], [270, 65], [271, 65], [272, 65], [288, 65], [289, 65], [290, 65], [291, 65], [292, 65], [210, 66], [211, 66], [212, 66], [213, 66], [214, 66], [230, 66], [231, 66], [232, 66], [233, 66], [234, 66], [250, 66], [251, 66], [252, 66], [253, 66], [254, 66], [270, 66], [271, 66], [272, 66], [273, 66], [274, 66], [290, 66], [291, 66], [292, 66], [293, 66], [294, 66], [212, 67], [213, 67], [214, 67], [215, 67], [216, 67], [232, 67], [233, 67], [234, 67], [235, 67], [236, 67], [252, 67], [253, 67], [254, 67], [255, 67], [256, 67], [272, 67], [273, 67], [274, 67], [275, 67], [276, 67], [292, 67], [293, 67], [294, 67], [295, 67], [296, 67], [214, 68], [215, 68], [216, 68], [217, 68], [218, 68], [234, 68], [235, 68], [236, 68], [237, 68], [238, 68], [254, 68], [255, 68], [256, 68], [257, 68], [258, 68], [274, 68], [275, 68], [276, 68], [277, 68], [278, 68], [294, 68], [295, 68], [296, 68], [297, 68], [298, 68], [216, 69], [217, 69], [218, 69], [219, 69], [236, 69], [237, 69], [238, 69], [239, 69], [256, 69], [257, 69], [258, 69], [259, 69], [276, 69], [277, 69], [278, 69], [279, 69], [296, 69], [297, 69], [298, 69], [299, 69], [240, 70], [241, 70], [242, 70], [260, 70], [261, 70], [262, 70], [280, 70], [281, 70], [282, 70], [300, 70], [301, 70], [302, 70], [320, 70], [321, 70], [322, 70], [240, 71], [241, 71], [242, 71], [243, 71], [244, 71], [260, 71], [261, 71], [262, 71], [263, 71], [264, 71], [280, 71], [281, 71], [282, 71], [283, 71], [284, 71], [300, 71], [301, 71], [302, 71], [303, 71], [304, 71], [320, 71], [321, 71], [322, 71], [323, 71], [324, 71], [242, 72], [243, 72], [244, 72], [245, 72], [246, 72], [262, 72], [263, 72], [264, 72], [265, 72], [266, 72], [282, 72], [283, 72], [284, 72], [285, 72], [286, 72], [302, 72], [303, 72], [304, 72], [305, 72], [306, 72], [322, 72], [323, 72], [324, 72], [325, 72], [326, 72], [244, 73], [245, 73], [246, 73], [247, 73], [248, 73], [264, 73], [265, 73], [266, 73], [267, 73], [268, 73], [284, 73], [285, 73], [286, 73], [287, 73], [288, 73], [304, 73], [305, 73], [306, 73], [307, 73], [308, 73], [324, 73], [325, 73], [326, 73], [327, 73], [328, 73], [246, 74], [247, 74], [248, 74], [249, 74], [250, 74], [266, 74], [267, 74], [268, 74], [269, 74], [270, 74], [286, 74], [287, 74], [288, 74], [289, 74], [290, 74], [306, 74], [307, 74], [308, 74], [309, 74], [310, 74], [326, 74], [327, 74], [328, 74], [329, 74], [330, 74], [248, 75], [249, 75], [250, 75], [251, 75], [252, 75], [268, 75], [269, 75], [270, 75], [271, 75], [272, 75], [288, 75], [289, 75], [290, 75], [291, 75], [292, 75], [308, 75], [309, 75], [310, 75], [311, 75], [312, 75], [328, 75], [329, 75], [330, 75], [331, 75], [332, 75], [250, 76], [251, 76], [252, 76], [253, 76], [254, 76], [270, 76], [271, 76], [272, 76], [273, 76], [274, 76], [290, 76], [291, 76], [292, 76], [293, 76], [294, 76], [310, 76], [311, 76], [312, 76], [313, 76], [314, 76], [330, 76], [331, 76], [332, 76], [333, 76], [334, 76], [252, 77], [253, 77], [254, 77], [255, 77], [256, 77], [272, 77], [273, 77], [274, 77], [275, 77], [276, 77], [292, 77], [293, 77], [294, 77], [295, 77], [296, 77], [312, 77], [313, 77], [314, 77], [315, 77], [316, 77], [332, 77], [333, 77], [334, 77], [335, 77], [336, 77], [254, 78], [255, 78], [256, 78], [257, 78], [258, 78], [274, 78], [275, 78], [276, 78], [277, 78], [278, 78], [294, 78], [295, 78], [296, 78], [297, 78], [298, 78], [314, 78], [315, 78], [316, 78], [317, 78], [318, 78], [334, 78], [335, 78], [336, 78], [337, 78], [338, 78], [256, 79], [257, 79], [258, 79], [259, 79], [276, 79], [277, 79], [278, 79], [279, 79], [296, 79], [297, 79], [298, 79], [299, 79], [316, 79], [317, 79], [318, 79], [319, 79], [336, 79], [337, 79], [338, 79], [339, 79], [280, 80], [281, 80], [282, 80], [300, 80], [301, 80], [302, 80], [320, 80], [321, 80], [322, 80], [340, 80], [341, 80], [342, 80], [360, 80], [361, 80], [362, 80], [280, 81], [281, 81], [282, 81], [283, 81], [284, 81], [300, 81], [301, 81], [302, 81], [303, 81], [304, 81], [320, 81], [321, 81], [322, 81], [323, 81], [324, 81], [340, 81], [341, 81], [342, 81], [343, 81], [344, 81], [360, 81], [361, 81], [362, 81], [363, 81], [364, 81], [282, 82], [283, 82], [284, 82], [285, 82], [286, 82], [302, 82], [303, 82], [304, 82], [305, 82], [306, 82], [322, 82], [323, 82], [324, 82], [325, 82], [326, 82], [342, 82], [343, 82], [344, 82], [345, 82], [346, 82], [362, 82], [363, 82], [364, 82], [365, 82], [366, 82], [284, 83], [285, 83], [286, 83], [287, 83], [288, 83], [304, 83], [305, 83], [306, 83], [307, 83], [308, 83], [324, 83], [325, 83], [326, 83], [327, 83], [328, 83], [344, 83], [345, 83], [346, 83], [347, 83], [348, 83], [364, 83], [365, 83], [366, 83], [367, 83], [368, 83], [286, 84], [287, 84], [288, 84], [289, 84], [290, 84], [306, 84], [307, 84], [308, 84], [309, 84], [310, 84], [326, 84], [327, 84], [328, 84], [329, 84], [330, 84], [346, 84], [347, 84], [348, 84], [349, 84], [350, 84], [366, 84], [367, 84], [368, 84], [369, 84], [370, 84], [288, 85], [289, 85], [290, 85], [291, 85], [292, 85], [308, 85], [309, 85], [310, 85], [311, 85], [312, 85], [328, 85], [329, 85], [330, 85], [331, 85], [332, 85], [348, 85], [349, 85], [350, 85], [351, 85], [352, 85], [368, 85], [369, 85], [370, 85], [371, 85], [372, 85], [290, 86], [291, 86], [292, 86], [293, 86], [294, 86], [310, 86], [311, 86], [312, 86], [313, 86], [314, 86], [330, 86], [331, 86], [332, 86], [333, 86], [334, 86], [350, 86], [351, 86], [352, 86], [353, 86], [354, 86], [370, 86], [371, 86], [372, 86], [373, 86], [374, 86], [292, 87], [293, 87], [294, 87], [295, 87], [296, 87], [312, 87], [313, 87], [314, 87], [315, 87], [316, 87], [332, 87], [333, 87], [334, 87], [335, 87], [336, 87], [352, 87], [353, 87], [354, 87], [355, 87], [356, 87], [372, 87], [373, 87], [374, 87], [375, 87], [376, 87], [294, 88], [295, 88], [296, 88], [297, 88], [298, 88], [314, 88], [315, 88], [316, 88], [317, 88], [318, 88], [334, 88], [335, 88], [336, 88], [337, 88], [338, 88], [354, 88], [355, 88], [356, 88], [357, 88], [358, 88], [374, 88], [375, 88], [376, 88], [377, 88], [378, 88], [296, 89], [297, 89], [298, 89], [299, 89], [316, 89], [317, 89], [318, 89], [319, 89], [336, 89], [337, 89], [338, 89], [339, 89], [356, 89], [357, 89], [358, 89], [359, 89], [376, 89], [377, 89], [378, 89], [379, 89], [320, 90], [321, 90], [322, 90], [340, 90], [341, 90], [342, 90], [360, 90], [361, 90], [362, 90], [380, 90], [381, 90], [382, 90], [320, 91], [321, 91], [322, 91], [323, 91], [324, 91], [340, 91], [341, 91], [342, 91], [343, 91], [344, 91], [360, 91], [361, 91], [362, 91], [363, 91], [364, 91], [380, 91], [381, 91], [382, 91], [383, 91], [384, 91], [322, 92], [323, 92], [324, 92], [325, 92], [326, 92], [342, 92], [343, 92], [344, 92], [345, 92], [346, 92], [362, 92], [363, 92], [364, 92], [365, 92], [366, 92], [382, 92], [383, 92], [384, 92], [385, 92], [386, 92], [324, 93], [325, 93], [326, 93], [327, 93], [328, 93], [344, 93], [345, 93], [346, 93], [347, 93], [348, 93], [364, 93], [365, 93], [366, 93], [367, 93], [368, 93], [384, 93], [385, 93], [386, 93], [387, 93], [388, 93], [326, 94], [327, 94], [328, 94], [329, 94], [330, 94], [346, 94], [347, 94], [348, 94], [349, 94], [350, 94], [366, 94], [367, 94], [368, 94], [369, 94], [370, 94], [386, 94], [387, 94], [388, 94], [389, 94], [390, 94], [328, 95], [329, 95], [330, 95], [331, 95], [332, 95], [348, 95], [349, 95], [350, 95], [351, 95], [352, 95], [368, 95], [369, 95], [370, 95], [371, 95], [372, 95], [388, 95], [389, 95], [390, 95], [391, 95], [392, 95], [330, 96], [331, 96], [332, 96], [333, 96], [334, 96], [350, 96], [351, 96], [352, 96], [353, 96], [354, 96], [370, 96], [371, 96], [372, 96], [373, 96], [374, 96], [390, 96], [391, 96], [392, 96], [393, 96], [394, 96], [332, 97], [333, 97], [334, 97], [335, 97], [336, 97], [352, 97], [353, 97], [354, 97], [355, 97], [356, 97], [372, 97], [373, 97], [374, 97], [375, 97], [376, 97], [392, 97], [393, 97], [394, 97], [395, 97], [396, 97], [334, 98], [335, 98], [336, 98], [337, 98], [338, 98], [354, 98], [355, 98], [356, 98], [357, 98], [358, 98], [374, 98], [375, 98], [376, 98], [377, 98], [378, 98], [394, 98], [395, 98], [396, 98], [397, 98], [398, 98], [336, 99], [337, 99], [338, 99], [339, 99], [356, 99], [357, 99], [358, 99], [359, 99], [376, 99], [377, 99], [378, 99], [379, 99], [396, 99], [397, 99], [398, 99], [399, 99]]
V4 to IT
[[0, 0], [1, 0], [2, 0], [3, 0], [10, 0], [11, 0], [12, 0], [13, 0], [20, 0], [21, 0], [22, 0], [23, 0], [30, 0], [31, 0], [32, 0], [33, 0], [0, 1], [1, 1], [2, 1], [3, 1], [4, 1], [5, 1], [10, 1], [11, 1], [12, 1], [13, 1], [14, 1], [15, 1], [20, 1], [21, 1], [22, 1], [23, 1], [24, 1], [25, 1], [30, 1], [31, 1], [32, 1], [33, 1], [34, 1], [35, 1], [1, 2], [2, 2], [3, 2], [4, 2], [5, 2], [6, 2], [7, 2], [11, 2], [12, 2], [13, 2], [14, 2], [15, 2], [16, 2], [17, 2], [21, 2], [22, 2], [23, 2], [24, 2], [25, 2], [26, 2], [27, 2], [31, 2], [32, 2], [33, 2], [34, 2], [35, 2], [36, 2], [37, 2], [3, 3], [4, 3], [5, 3], [6, 3], [7, 3], [8, 3], [9, 3], [13, 3], [14, 3], [15, 3], [16, 3], [17, 3], [18, 3], [19, 3], [23, 3], [24, 3], [25, 3], [26, 3], [27, 3], [28, 3], [29, 3], [33, 3], [34, 3], [35, 3], [36, 3], [37, 3], [38, 3], [39, 3], [5, 4], [6, 4], [7, 4], [8, 4], [9, 4], [15, 4], [16, 4], [17, 4], [18, 4], [19, 4], [25, 4], [26, 4], [27, 4], [28, 4], [29, 4], [35, 4], [36, 4], [37, 4], [38, 4], [39, 4], [0, 5], [1, 5], [2, 5], [3, 5], [10, 5], [11, 5], [12, 5], [13, 5], [20, 5], [21, 5], [22, 5], [23, 5], [30, 5], [31, 5], [32, 5], [33, 5], [40, 5], [41, 5], [42, 5], [43, 5], [50, 5], [51, 5], [52, 5], [53, 5], [0, 6], [1, 6], [2, 6], [3, 6], [4, 6], [5, 6], [10, 6], [11, 6], [12, 6], [13, 6], [14, 6], [15, 6], [20, 6], [21, 6], [22, 6], [23, 6], [24, 6], [25, 6], [30, 6], [31, 6], [32, 6], [33, 6], [34, 6], [35, 6], [40, 6], [41, 6], [42, 6], [43, 6], [44, 6], [45, 6], [50, 6], [51, 6], [52, 6], [53, 6], [54, 6], [55, 6], [1, 7], [2, 7], [3, 7], [4, 7], [5, 7], [6, 7], [7, 7], [11, 7], [12, 7], [13, 7], [14, 7], [15, 7], [16, 7], [17, 7], [21, 7], [22, 7], [23, 7], [24, 7], [25, 7], [26, 7], [27, 7], [31, 7], [32, 7], [33, 7], [34, 7], [35, 7], [36, 7], [37, 7], [41, 7], [42, 7], [43, 7], [44, 7], [45, 7], [46, 7], [47, 7], [51, 7], [52, 7], [53, 7], [54, 7], [55, 7], [56, 7], [57, 7], [3, 8], [4, 8], [5, 8], [6, 8], [7, 8], [8, 8], [9, 8], [13, 8], [14, 8], [15, 8], [16, 8], [17, 8], [18, 8], [19, 8], [23, 8], [24, 8], [25, 8], [26, 8], [27, 8], [28, 8], [29, 8], [33, 8], [34, 8], [35, 8], [36, 8], [37, 8], [38, 8], [39, 8], [43, 8], [44, 8], [45, 8], [46, 8], [47, 8], [48, 8], [49, 8], [53, 8], [54, 8], [55, 8], [56, 8], [57, 8], [58, 8], [59, 8], [5, 9], [6, 9], [7, 9], [8, 9], [9, 9], [15, 9], [16, 9], [17, 9], [18, 9], [19, 9], [25, 9], [26, 9], [27, 9], [28, 9], [29, 9], [35, 9], [36, 9], [37, 9], [38, 9], [39, 9], [45, 9], [46, 9], [47, 9], [48, 9], [49, 9], [55, 9], [56, 9], [57, 9], [58, 9], [59, 9], [10, 10], [11, 10], [12, 10], [13, 10], [20, 10], [21, 10], [22, 10], [23, 10], [30, 10], [31, 10], [32, 10], [33, 10], [40, 10], [41, 10], [42, 10], [43, 10], [50, 10], [51, 10], [52, 10], [53, 10], [60, 10], [61, 10], [62, 10], [63, 10], [70, 10], [71, 10], [72, 10], [73, 10], [10, 11], [11, 11], [12, 11], [13, 11], [14, 11], [15, 11], [20, 11], [21, 11], [22, 11], [23, 11], [24, 11], [25, 11], [30, 11], [31, 11], [32, 11], [33, 11], [34, 11], [35, 11], [40, 11], [41, 11], [42, 11], [43, 11], [44, 11], [45, 11], [50, 11], [51, 11], [52, 11], [53, 11], [54, 11], [55, 11], [60, 11], [61, 11], [62, 11], [63, 11], [64, 11], [65, 11], [70, 11], [71, 11], [72, 11], [73, 11], [74, 11], [75, 11], [11, 12], [12, 12], [13, 12], [14, 12], [15, 12], [16, 12], [17, 12], [21, 12], [22, 12], [23, 12], [24, 12], [25, 12], [26, 12], [27, 12], [31, 12], [32, 12], [33, 12], [34, 12], [35, 12], [36, 12], [37, 12], [41, 12], [42, 12], [43, 12], [44, 12], [45, 12], [46, 12], [47, 12], [51, 12], [52, 12], [53, 12], [54, 12], [55, 12], [56, 12], [57, 12], [61, 12], [62, 12], [63, 12], [64, 12], [65, 12], [66, 12], [67, 12], [71, 12], [72, 12], [73, 12], [74, 12], [75, 12], [76, 12], [77, 12], [13, 13], [14, 13], [15, 13], [16, 13], [17, 13], [18, 13], [19, 13], [23, 13], [24, 13], [25, 13], [26, 13], [27, 13], [28, 13], [29, 13], [33, 13], [34, 13], [35, 13], [36, 13], [37, 13], [38, 13], [39, 13], [43, 13], [44, 13], [45, 13], [46, 13], [47, 13], [48, 13], [49, 13], [53, 13], [54, 13], [55, 13], [56, 13], [57, 13], [58, 13], [59, 13], [63, 13], [64, 13], [65, 13], [66, 13], [67, 13], [68, 13], [69, 13], [73, 13], [74, 13], [75, 13], [76, 13], [77, 13], [78, 13], [79, 13], [15, 14], [16, 14], [17, 14], [18, 14], [19, 14], [25, 14], [26, 14], [27, 14], [28, 14], [29, 14], [35, 14], [36, 14], [37, 14], [38, 14], [39, 14], [45, 14], [46, 14], [47, 14], [48, 14], [49, 14], [55, 14], [56, 14], [57, 14], [58, 14], [59, 14], [65, 14], [66, 14], [67, 14], [68, 14], [69, 14], [75, 14], [76, 14], [77, 14], [78, 14], [79, 14], [30, 15], [31, 15], [32, 15], [33, 15], [40, 15], [41, 15], [42, 15], [43, 15], [50, 15], [51, 15], [52, 15], [53, 15], [60, 15], [61, 15], [62, 15], [63, 15], [70, 15], [71, 15], [72, 15], [73, 15], [80, 15], [81, 15], [82, 15], [83, 15], [90, 15], [91, 15], [92, 15], [93, 15], [30, 16], [31, 16], [32, 16], [33, 16], [34, 16], [35, 16], [40, 16], [41, 16], [42, 16], [43, 16], [44, 16], [45, 16], [50, 16], [51, 16], [52, 16], [53, 16], [54, 16], [55, 16], [60, 16], [61, 16], [62, 16], [63, 16], [64, 16], [65, 16], [70, 16], [71, 16], [72, 16], [73, 16], [74, 16], [75, 16], [80, 16], [81, 16], [82, 16], [83, 16], [84, 16], [85, 16], [90, 16], [91, 16], [92, 16], [93, 16], [94, 16], [95, 16], [31, 17], [32, 17], [33, 17], [34, 17], [35, 17], [36, 17], [37, 17], [41, 17], [42, 17], [43, 17], [44, 17], [45, 17], [46, 17], [47, 17], [51, 17], [52, 17], [53, 17], [54, 17], [55, 17], [56, 17], [57, 17], [61, 17], [62, 17], [63, 17], [64, 17], [65, 17], [66, 17], [67, 17], [71, 17], [72, 17], [73, 17], [74, 17], [75, 17], [76, 17], [77, 17], [81, 17], [82, 17], [83, 17], [84, 17], [85, 17], [86, 17], [87, 17], [91, 17], [92, 17], [93, 17], [94, 17], [95, 17], [96, 17], [97, 17], [33, 18], [34, 18], [35, 18], [36, 18], [37, 18], [38, 18], [39, 18], [43, 18], [44, 18], [45, 18], [46, 18], [47, 18], [48, 18], [49, 18], [53, 18], [54, 18], [55, 18], [56, 18], [57, 18], [58, 18], [59, 18], [63, 18], [64, 18], [65, 18], [66, 18], [67, 18], [68, 18], [69, 18], [73, 18], [74, 18], [75, 18], [76, 18], [77, 18], [78, 18], [79, 18], [83, 18], [84, 18], [85, 18], [86, 18], [87, 18], [88, 18], [89, 18], [93, 18], [94, 18], [95, 18], [96, 18], [97, 18], [98, 18], [99, 18], [35, 19], [36, 19], [37, 19], [38, 19], [39, 19], [45, 19], [46, 19], [47, 19], [48, 19], [49, 19], [55, 19], [56, 19], [57, 19], [58, 19], [59, 19], [65, 19], [66, 19], [67, 19], [68, 19], [69, 19], [75, 19], [76, 19], [77, 19], [78, 19], [79, 19], [85, 19], [86, 19], [87, 19], [88, 19], [89, 19], [95, 19], [96, 19], [97, 19], [98, 19], [99, 19], [50, 20], [51, 20], [52, 20], [53, 20], [60, 20], [61, 20], [62, 20], [63, 20], [70, 20], [71, 20], [72, 20], [73, 20], [80, 20], [81, 20], [82, 20], [83, 20], [90, 20], [91, 20], [92, 20], [93, 20], [50, 21], [51, 21], [52, 21], [53, 21], [54, 21], [55, 21], [60, 21], [61, 21], [62, 21], [63, 21], [64, 21], [65, 21], [70, 21], [71, 21], [72, 21], [73, 21], [74, 21], [75, 21], [80, 21], [81, 21], [82, 21], [83, 21], [84, 21], [85, 21], [90, 21], [91, 21], [92, 21], [93, 21], [94, 21], [95, 21], [51, 22], [52, 22], [53, 22], [54, 22], [55, 22], [56, 22], [57, 22], [61, 22], [62, 22], [63, 22], [64, 22], [65, 22], [66, 22], [67, 22], [71, 22], [72, 22], [73, 22], [74, 22], [75, 22], [76, 22], [77, 22], [81, 22], [82, 22], [83, 22], [84, 22], [85, 22], [86, 22], [87, 22], [91, 22], [92, 22], [93, 22], [94, 22], [95, 22], [96, 22], [97, 22], [53, 23], [54, 23], [55, 23], [56, 23], [57, 23], [58, 23], [59, 23], [63, 23], [64, 23], [65, 23], [66, 23], [67, 23], [68, 23], [69, 23], [73, 23], [74, 23], [75, 23], [76, 23], [77, 23], [78, 23], [79, 23], [83, 23], [84, 23], [85, 23], [86, 23], [87, 23], [88, 23], [89, 23], [93, 23], [94, 23], [95, 23], [96, 23], [97, 23], [98, 23], [99, 23], [55, 24], [56, 24], [57, 24], [58, 24], [59, 24], [65, 24], [66, 24], [67, 24], [68, 24], [69, 24], [75, 24], [76, 24], [77, 24], [78, 24], [79, 24], [85, 24], [86, 24], [87, 24], [88, 24], [89, 24], [95, 24], [96, 24], [97, 24], [98, 24], [99, 24]]
IT to MI
[[0, 0], [1, 0], [2, 0], [5, 0], [6, 0], [7, 0], [10, 0], [11, 0], [12, 0], [0, 1], [1, 1], [2, 1], [3, 1], [5, 1], [6, 1], [7, 1], [8, 1], [10, 1], [11, 1], [12, 1], [13, 1], [0, 2], [1, 2], [2, 2], [3, 2], [4, 2], [5, 2], [6, 2], [7, 2], [8, 2], [9, 2], [10, 2], [11, 2], [12, 2], [13, 2], [14, 2], [1, 3], [2, 3], [3, 3], [4, 3], [6, 3], [7, 3], [8, 3], [9, 3], [11, 3], [12, 3], [13, 3], [14, 3], [2, 4], [3, 4], [4, 4], [7, 4], [8, 4], [9, 4], [12, 4], [13, 4], [14, 4], [0, 5], [1, 5], [2, 5], [5, 5], [6, 5], [7, 5], [10, 5], [11, 5], [12, 5], [15, 5], [16, 5], [17, 5], [0, 6], [1, 6], [2, 6], [3, 6], [5, 6], [6, 6], [7, 6], [8, 6], [10, 6], [11, 6], [12, 6], [13, 6], [15, 6], [16, 6], [17, 6], [18, 6], [0, 7], [1, 7], [2, 7], [3, 7], [4, 7], [5, 7], [6, 7], [7, 7], [8, 7], [9, 7], [10, 7], [11, 7], [12, 7], [13, 7], [14, 7], [15, 7], [16, 7], [17, 7], [18, 7], [19, 7], [1, 8], [2, 8], [3, 8], [4, 8], [6, 8], [7, 8], [8, 8], [9, 8], [11, 8], [12, 8], [13, 8], [14, 8], [16, 8], [17, 8], [18, 8], [19, 8], [2, 9], [3, 9], [4, 9], [7, 9], [8, 9], [9, 9], [12, 9], [13, 9], [14, 9], [17, 9], [18, 9], [19, 9], [0, 10], [1, 10], [2, 10], [5, 10], [6, 10], [7, 10], [10, 10], [11, 10], [12, 10], [15, 10], [16, 10], [17, 10], [20, 10], [21, 10], [22, 10], [0, 11], [1, 11], [2, 11], [3, 11], [5, 11], [6, 11], [7, 11], [8, 11], [10, 11], [11, 11], [12, 11], [13, 11], [15, 11], [16, 11], [17, 11], [18, 11], [20, 11], [21, 11], [22, 11], [23, 11], [0, 12], [1, 12], [2, 12], [3, 12], [4, 12], [5, 12], [6, 12], [7, 12], [8, 12], [9, 12], [10, 12], [11, 12], [12, 12], [13, 12], [14, 12], [15, 12], [16, 12], [17, 12], [18, 12], [19, 12], [20, 12], [21, 12], [22, 12], [23, 12], [24, 12], [1, 13], [2, 13], [3, 13], [4, 13], [6, 13], [7, 13], [8, 13], [9, 13], [11, 13], [12, 13], [13, 13], [14, 13], [16, 13], [17, 13], [18, 13], [19, 13], [21, 13], [22, 13], [23, 13], [24, 13], [2, 14], [3, 14], [4, 14], [7, 14], [8, 14], [9, 14], [12, 14], [13, 14], [14, 14], [17, 14], [18, 14], [19, 14], [22, 14], [23, 14], [24, 14], [5, 15], [6, 15], [7, 15], [10, 15], [11, 15], [12, 15], [15, 15], [16, 15], [17, 15], [20, 15], [21, 15], [22, 15], [5, 16], [6, 16], [7, 16], [8, 16], [10, 16], [11, 16], [12, 16], [13, 16], [15, 16], [16, 16], [17, 16], [18, 16], [20, 16], [21, 16], [22, 16], [23, 16], [5, 17], [6, 17], [7, 17], [8, 17], [9, 17], [10, 17], [11, 17], [12, 17], [13, 17], [14, 17], [15, 17], [16, 17], [17, 17], [18, 17], [19, 17], [20, 17], [21, 17], [22, 17], [23, 17], [24, 17], [6, 18], [7, 18], [8, 18], [9, 18], [11, 18], [12, 18], [13, 18], [14, 18], [16, 18], [17, 18], [18, 18], [19, 18], [21, 18], [22, 18], [23, 18], [24, 18], [7, 19], [8, 19], [9, 19], [12, 19], [13, 19], [14, 19], [17, 19], [18, 19], [19, 19], [22, 19], [23, 19], [24, 19], [10, 20], [11, 20], [12, 20], [15, 20], [16, 20], [17, 20], [20, 20], [21, 20], [22, 20], [10, 21], [11, 21], [12, 21], [13, 21], [15, 21], [16, 21], [17, 21], [18, 21], [20, 21], [21, 21], [22, 21], [23, 21], [10, 22], [11, 22], [12, 22], [13, 22], [14, 22], [15, 22], [16, 22], [17, 22], [18, 22], [19, 22], [20, 22], [21, 22], [22, 22], [23, 22], [24, 22], [11, 23], [12, 23], [13, 23], [14, 23], [16, 23], [17, 23], [18, 23], [19, 23], [21, 23], [22, 23], [23, 23], [24, 23], [12, 24], [13, 24], [14, 24], [17, 24], [18, 24], [19, 24], [22, 24], [23, 24], [24, 24]]
MI to MO
[[0, 0], [1, 0], [2, 0], [3, 0], [4, 0], [5, 0], [6, 0], [7, 0], [8, 0], [9, 0], [10, 0], [11, 0], [12, 0], [13, 0], [14, 0], [15, 0], [16, 0], [17, 0], [18, 0], [19, 0], [20, 0], [21, 0], [22, 0], [23, 0], [24, 0], [0, 1], [1, 1], [2, 1], [3, 1], [4, 1], [5, 1], [6, 1], [7, 1], [8, 1], [9, 1], [10, 1], [11, 1], [12, 1], [13, 1], [14, 1], [15, 1], [16, 1], [17, 1], [18, 1], [19, 1], [20, 1], [21, 1], [22, 1], [23, 1], [24, 1], [0, 2], [1, 2], [2, 2], [3, 2], [4, 2], [5, 2], [6, 2], [7, 2], [8, 2], [9, 2], [10, 2], [11, 2], [12, 2], [13, 2], [14, 2], [15, 2], [16, 2], [17, 2], [18, 2], [19, 2], [20, 2], [21, 2], [22, 2], [23, 2], [24, 2], [0, 3], [1, 3], [2, 3], [3, 3], [4, 3], [5, 3], [6, 3], [7, 3], [8, 3], [9, 3], [10, 3], [11, 3], [12, 3], [13, 3], [14, 3], [15, 3], [16, 3], [17, 3], [18, 3], [19, 3], [20, 3], [21, 3], [22, 3], [23, 3], [24, 3], [0, 4], [1, 4], [2, 4], [3, 4], [4, 4], [5, 4], [6, 4], [7, 4], [8, 4], [9, 4], [10, 4], [11, 4], [12, 4], [13, 4], [14, 4], [15, 4], [16, 4], [17, 4], [18, 4], [19, 4], [20, 4], [21, 4], [22, 4], [23, 4], [24, 4], [0, 5], [1, 5], [2, 5], [3, 5], [4, 5], [5, 5], [6, 5], [7, 5], [8, 5], [9, 5], [10, 5], [11, 5], [12, 5], [13, 5], [14, 5], [15, 5], [16, 5], [17, 5], [18, 5], [19, 5], [20, 5], [21, 5], [22, 5], [23, 5], [24, 5], [0, 6], [1, 6], [2, 6], [3, 6], [4, 6], [5, 6], [6, 6], [7, 6], [8, 6], [9, 6], [10, 6], [11, 6], [12, 6], [13, 6], [14, 6], [15, 6], [16, 6], [17, 6], [18, 6], [19, 6], [20, 6], [21, 6], [22, 6], [23, 6], [24, 6], [0, 7], [1, 7], [2, 7], [3, 7], [4, 7], [5, 7], [6, 7], [7, 7], [8, 7], [9, 7], [10, 7], [11, 7], [12, 7], [13, 7], [14, 7], [15, 7], [16, 7], [17, 7], [18, 7], [19, 7], [20, 7], [21, 7], [22, 7], [23, 7], [24, 7], [0, 8], [1, 8], [2, 8], [3, 8], [4, 8], [5, 8], [6, 8], [7, 8], [8, 8], [9, 8], [10, 8], [11, 8], [12, 8], [13, 8], [14, 8], [15, 8], [16, 8], [17, 8], [18, 8], [19, 8], [20, 8], [21, 8], [22, 8], [23, 8], [24, 8]]
V1 to InV1
[[0, 0], [1, 0], [20, 0], [21, 0], [1, 1], [2, 1], [3, 1], [21, 1], [22, 1], [23, 1], [3, 2], [4, 2], [5, 2], [23, 2], [24, 2], [25, 2], [5, 3], [6, 3], [7, 3], [25, 3], [26, 3], [27, 3], [7, 4], [8, 4], [9, 4], [27, 4], [28, 4], [29, 4], [9, 5], [10, 5], [11, 5], [29, 5], [30, 5], [31, 5], [11, 6], [12, 6], [13, 6], [31, 6], [32, 6], [33, 6], [13, 7], [14, 7], [15, 7], [33, 7], [34, 7], [35, 7], [15, 8], [16, 8], [17, 8], [35, 8], [36, 8], [37, 8], [17, 9], [18, 9], [19, 9], [37, 9], [38, 9], [39, 9], [20, 10], [21, 10], [40, 10], [41, 10], [60, 10], [61, 10], [21, 11], [22, 11], [23, 11], [41, 11], [42, 11], [43, 11], [61, 11], [62, 11], [63, 11], [23, 12], [24, 12], [25, 12], [43, 12], [44, 12], [45, 12], [63, 12], [64, 12], [65, 12], [25, 13], [26, 13], [27, 13], [45, 13], [46, 13], [47, 13], [65, 13], [66, 13], [67, 13], [27, 14], [28, 14], [29, 14], [47, 14], [48, 14], [49, 14], [67, 14], [68, 14], [69, 14], [29, 15], [30, 15], [31, 15], [49, 15], [50, 15], [51, 15], [69, 15], [70, 15], [71, 15], [31, 16], [32, 16], [33, 16], [51, 16], [52, 16], [53, 16], [71, 16], [72, 16], [73, 16], [33, 17], [34, 17], [35, 17], [53, 17], [54, 17], [55, 17], [73, 17], [74, 17], [75, 17], [35, 18], [36, 18], [37, 18], [55, 18], [56, 18], [57, 18], [75, 18], [76, 18], [77, 18], [37, 19], [38, 19], [39, 19], [57, 19], [58, 19], [59, 19], [77, 19], [78, 19], [79, 19], [60, 20], [61, 20], [80, 20], [81, 20], [100, 20], [101, 20], [61, 21], [62, 21], [63, 21], [81, 21], [82, 21], [83, 21], [101, 21], [102, 21], [103, 21], [63, 22], [64, 22], [65, 22], [83, 22], [84, 22], [85, 22], [103, 22], [104, 22], [105, 22], [65, 23], [66, 23], [67, 23], [85, 23], [86, 23], [87, 23], [105, 23], [106, 23], [107, 23], [67, 24], [68, 24], [69, 24], [87, 24], [88, 24], [89, 24], [107, 24], [108, 24], [109, 24], [69, 25], [70, 25], [71, 25], [89, 25], [90, 25], [91, 25], [109, 25], [110, 25], [111, 25], [71, 26], [72, 26], [73, 26], [91, 26], [92, 26], [93, 26], [111, 26], [112, 26], [113, 26], [73, 27], [74, 27], [75, 27], [93, 27], [94, 27], [95, 27], [113, 27], [114, 27], [115, 27], [75, 28], [76, 28], [77, 28], [95, 28], [96, 28], [97, 28], [115, 28], [116, 28], [117, 28], [77, 29], [78, 29], [79, 29], [97, 29], [98, 29], [99, 29], [117, 29], [118, 29], [119, 29], [100, 30], [101, 30], [120, 30], [121, 30], [140, 30], [141, 30], [101, 31], [102, 31], [103, 31], [121, 31], [122, 31], [123, 31], [141, 31], [142, 31], [143, 31], [103, 32], [104, 32], [105, 32], [123, 32], [124, 32], [125, 32], [143, 32], [144, 32], [145, 32], [105, 33], [106, 33], [107, 33], [125, 33], [126, 33], [127, 33], [145, 33], [146, 33], [147, 33], [107, 34], [108, 34], [109, 34], [127, 34], [128, 34], [129, 34], [147, 34], [148, 34], [149, 34], [109, 35], [110, 35], [111, 35], [129, 35], [130, 35], [131, 35], [149, 35], [150, 35], [151, 35], [111, 36], [112, 36], [113, 36], [131, 36], [132, 36], [133, 36], [151, 36], [152, 36], [153, 36], [113, 37], [114, 37], [115, 37], [133, 37], [134, 37], [135, 37], [153, 37], [154, 37], [155, 37], [115, 38], [116, 38], [117, 38], [135, 38], [136, 38], [137, 38], [155, 38], [156, 38], [157, 38], [117, 39], [118, 39], [119, 39], [137, 39], [138, 39], [139, 39], [157, 39], [158, 39], [159, 39], [140, 40], [141, 40], [160, 40], [161, 40], [180, 40], [181, 40], [141, 41], [142, 41], [143, 41], [161, 41], [162, 41], [163, 41], [181, 41], [182, 41], [183, 41], [143, 42], [144, 42], [145, 42], [163, 42], [164, 42], [165, 42], [183, 42], [184, 42], [185, 42], [145, 43], [146, 43], [147, 43], [165, 43], [166, 43], [167, 43], [185, 43], [186, 43], [187, 43], [147, 44], [148, 44], [149, 44], [167, 44], [168, 44], [169, 44], [187, 44], [188, 44], [189, 44], [149, 45], [150, 45], [151, 45], [169, 45], [170, 45], [171, 45], [189, 45], [190, 45], [191, 45], [151, 46], [152, 46], [153, 46], [171, 46], [172, 46], [173, 46], [191, 46], [192, 46], [193, 46], [153, 47], [154, 47], [155, 47], [173, 47], [174, 47], [175, 47], [193, 47], [194, 47], [195, 47], [155, 48], [156, 48], [157, 48], [175, 48], [176, 48], [177, 48], [195, 48], [196, 48], [197, 48], [157, 49], [158, 49], [159, 49], [177, 49], [178, 49], [179, 49], [197, 49], [198, 49], [199, 49], [180, 50], [181, 50], [200, 50], [201, 50], [220, 50], [221, 50], [181, 51], [182, 51], [183, 51], [201, 51], [202, 51], [203, 51], [221, 51], [222, 51], [223, 51], [183, 52], [184, 52], [185, 52], [203, 52], [204, 52], [205, 52], [223, 52], [224, 52], [225, 52], [185, 53], [186, 53], [187, 53], [205, 53], [206, 53], [207, 53], [225, 53], [226, 53], [227, 53], [187, 54], [188, 54], [189, 54], [207, 54], [208, 54], [209, 54], [227, 54], [228, 54], [229, 54], [189, 55], [190, 55], [191, 55], [209, 55], [210, 55], [211, 55], [229, 55], [230, 55], [231, 55], [191, 56], [192, 56], [193, 56], [211, 56], [212, 56], [213, 56], [231, 56], [232, 56], [233, 56], [193, 57], [194, 57], [195, 57], [213, 57], [214, 57], [215, 57], [233, 57], [234, 57], [235, 57], [195, 58], [196, 58], [197, 58], [215, 58], [216, 58], [217, 58], [235, 58], [236, 58], [237, 58], [197, 59], [198, 59], [199, 59], [217, 59], [218, 59], [219, 59], [237, 59], [238, 59], [239, 59], [220, 60], [221, 60], [240, 60], [241, 60], [260, 60], [261, 60], [221, 61], [222, 61], [223, 61], [241, 61], [242, 61], [243, 61], [261, 61], [262, 61], [263, 61], [223, 62], [224, 62], [225, 62], [243, 62], [244, 62], [245, 62], [263, 62], [264, 62], [265, 62], [225, 63], [226, 63], [227, 63], [245, 63], [246, 63], [247, 63], [265, 63], [266, 63], [267, 63], [227, 64], [228, 64], [229, 64], [247, 64], [248, 64], [249, 64], [267, 64], [268, 64], [269, 64], [229, 65], [230, 65], [231, 65], [249, 65], [250, 65], [251, 65], [269, 65], [270, 65], [271, 65], [231, 66], [232, 66], [233, 66], [251, 66], [252, 66], [253, 66], [271, 66], [272, 66], [273, 66], [233, 67], [234, 67], [235, 67], [253, 67], [254, 67], [255, 67], [273, 67], [274, 67], [275, 67], [235, 68], [236, 68], [237, 68], [255, 68], [256, 68], [257, 68], [275, 68], [276, 68], [277, 68], [237, 69], [238, 69], [239, 69], [257, 69], [258, 69], [259, 69], [277, 69], [278, 69], [279, 69], [260, 70], [261, 70], [280, 70], [281, 70], [300, 70], [301, 70], [261, 71], [262, 71], [263, 71], [281, 71], [282, 71], [283, 71], [301, 71], [302, 71], [303, 71], [263, 72], [264, 72], [265, 72], [283, 72], [284, 72], [285, 72], [303, 72], [304, 72], [305, 72], [265, 73], [266, 73], [267, 73], [285, 73], [286, 73], [287, 73], [305, 73], [306, 73], [307, 73], [267, 74], [268, 74], [269, 74], [287, 74], [288, 74], [289, 74], [307, 74], [308, 74], [309, 74], [269, 75], [270, 75], [271, 75], [289, 75], [290, 75], [291, 75], [309, 75], [310, 75], [311, 75], [271, 76], [272, 76], [273, 76], [291, 76], [292, 76], [293, 76], [311, 76], [312, 76], [313, 76], [273, 77], [274, 77], [275, 77], [293, 77], [294, 77], [295, 77], [313, 77], [314, 77], [315, 77], [275, 78], [276, 78], [277, 78], [295, 78], [296, 78], [297, 78], [315, 78], [316, 78], [317, 78], [277, 79], [278, 79], [279, 79], [297, 79], [298, 79], [299, 79], [317, 79], [318, 79], [319, 79], [300, 80], [301, 80], [320, 80], [321, 80], [340, 80], [341, 80], [301, 81], [302, 81], [303, 81], [321, 81], [322, 81], [323, 81], [341, 81], [342, 81], [343, 81], [303, 82], [304, 82], [305, 82], [323, 82], [324, 82], [325, 82], [343, 82], [344, 82], [345, 82], [305, 83], [306, 83], [307, 83], [325, 83], [326, 83], [327, 83], [345, 83], [346, 83], [347, 83], [307, 84], [308, 84], [309, 84], [327, 84], [328, 84], [329, 84], [347, 84], [348, 84], [349, 84], [309, 85], [310, 85], [311, 85], [329, 85], [330, 85], [331, 85], [349, 85], [350, 85], [351, 85], [311, 86], [312, 86], [313, 86], [331, 86], [332, 86], [333, 86], [351, 86], [352, 86], [353, 86], [313, 87], [314, 87], [315, 87], [333, 87], [334, 87], [335, 87], [353, 87], [354, 87], [355, 87], [315, 88], [316, 88], [317, 88], [335, 88], [336, 88], [337, 88], [355, 88], [356, 88], [357, 88], [317, 89], [318, 89], [319, 89], [337, 89], [338, 89], [339, 89], [357, 89], [358, 89], [359, 89], [340, 90], [341, 90], [360, 90], [361, 90], [380, 90], [381, 90], [341, 91], [342, 91], [343, 91], [361, 91], [362, 91], [363, 91], [381, 91], [382, 91], [383, 91], [343, 92], [344, 92], [345, 92], [363, 92], [364, 92], [365, 92], [383, 92], [384, 92], [385, 92], [345, 93], [346, 93], [347, 93], [365, 93], [366, 93], [367, 93], [385, 93], [386, 93], [387, 93], [347, 94], [348, 94], [349, 94], [367, 94], [368, 94], [369, 94], [387, 94], [388, 94], [389, 94], [349, 95], [350, 95], [351, 95], [369, 95], [370, 95], [371, 95], [389, 95], [390, 95], [391, 95], [351, 96], [352, 96], [353, 96], [371, 96], [372, 96], [373, 96], [391, 96], [392, 96], [393, 96], [353, 97], [354, 97], [355, 97], [373, 97], [374, 97], [375, 97], [393, 97], [394, 97], [395, 97], [355, 98], [356, 98], [357, 98], [375, 98], [376, 98], [377, 98], [395, 98], [396, 98], [397, 98], [357, 99], [358, 99], [359, 99], [377, 99], [378, 99], [379, 99], [397, 99], [398, 99], [399, 99]]

V4 to InV4 --- LOOKS OK
[[0, 0], [1, 0], [10, 0], [11, 0], [1, 1], [2, 1], [3, 1], [11, 1], [12, 1], [13, 1], [3, 2], [4, 2], [5, 2], [13, 2], [14, 2], [15, 2], [5, 3], [6, 3], [7, 3], [15, 3], [16, 3], [17, 3], [7, 4], [8, 4], [9, 4], [17, 4], [18, 4], [19, 4], [10, 5], [11, 5], [20, 5], [21, 5], [30, 5], [31, 5], [11, 6], [12, 6], [13, 6], [21, 6], [22, 6], [23, 6], [31, 6], [32, 6], [33, 6], [13, 7], [14, 7], [15, 7], [23, 7], [24, 7], [25, 7], [33, 7], [34, 7], [35, 7], [15, 8], [16, 8], [17, 8], [25, 8], [26, 8], [27, 8], [35, 8], [36, 8], [37, 8], [17, 9], [18, 9], [19, 9], [27, 9], [28, 9], [29, 9], [37, 9], [38, 9], [39, 9], [30, 10], [31, 10], [40, 10], [41, 10], [50, 10], [51, 10], [31, 11], [32, 11], [33, 11], [41, 11], [42, 11], [43, 11], [51, 11], [52, 11], [53, 11], [33, 12], [34, 12], [35, 12], [43, 12], [44, 12], [45, 12], [53, 12], [54, 12], [55, 12], [35, 13], [36, 13], [37, 13], [45, 13], [46, 13], [47, 13], [55, 13], [56, 13], [57, 13], [37, 14], [38, 14], [39, 14], [47, 14], [48, 14], [49, 14], [57, 14], [58, 14], [59, 14], [50, 15], [51, 15], [60, 15], [61, 15], [70, 15], [71, 15], [51, 16], [52, 16], [53, 16], [61, 16], [62, 16], [63, 16], [71, 16], [72, 16], [73, 16], [53, 17], [54, 17], [55, 17], [63, 17], [64, 17], [65, 17], [73, 17], [74, 17], [75, 17], [55, 18], [56, 18], [57, 18], [65, 18], [66, 18], [67, 18], [75, 18], [76, 18], [77, 18], [57, 19], [58, 19], [59, 19], [67, 19], [68, 19], [69, 19], [77, 19], [78, 19], [79, 19], [70, 20], [71, 20], [80, 20], [81, 20], [90, 20], [91, 20], [71, 21], [72, 21], [73, 21], [81, 21], [82, 21], [83, 21], [91, 21], [92, 21], [93, 21], [73, 22], [74, 22], [75, 22], [83, 22], [84, 22], [85, 22], [93, 22], [94, 22], [95, 22], [75, 23], [76, 23], [77, 23], [85, 23], [86, 23], [87, 23], [95, 23], [96, 23], [97, 23], [77, 24], [78, 24], [79, 24], [87, 24], [88, 24], [89, 24], [97, 24], [98, 24], [99, 24]]

IT to InIT --- LOOKS OK
[[0, 0], [1, 0], [5, 0], [6, 0], [1, 1], [2, 1], [3, 1], [6, 1], [7, 1], [8, 1], [3, 2], [4, 2], [8, 2], [9, 2], [5, 3], [6, 3], [10, 3], [11, 3], [15, 3], [16, 3], [6, 4], [7, 4], [8, 4], [11, 4], [12, 4], [13, 4], [16, 4], [17, 4], [18, 4], [8, 5], [9, 5], [13, 5], [14, 5], [18, 5], [19, 5], [15, 6], [16, 6], [20, 6], [21, 6], [16, 7], [17, 7], [18, 7], [21, 7], [22, 7], [23, 7], [18, 8], [19, 8], [23, 8], [24, 8]]

MI to InMI --- LOOKS OK
[[0, 0], [1, 0], [5, 0], [6, 0], 
[1, 1], [2, 1], [3, 1], [6, 1], [7, 1], [8, 1], 
[3, 2], [4, 2], [8, 2], [9, 2], 
[5, 3], [6, 3], [10, 3], [11, 3], [15, 3], [16, 3], 
[6, 4], [7, 4], [8, 4], [11, 4], [12, 4], [13, 4], [16, 4], [17, 4], [18, 4], 
[8, 5], [9, 5], [13, 5], [14, 5], [18, 5], [19, 5], 
[15, 6], [16, 6], [20, 6], [21, 6], 
[16, 7], [17, 7], [18, 7], [21, 7], [22, 7], [23, 7], 
[18, 8], [19, 8], [23, 8], [24, 8]]

InV1 to V1 --- LOOKS OK
[[0, 0], [0, 1], [0, 2], [0, 20], [0, 21], [0, 22], [0, 40], [0, 41], [0, 42], [1, 0], [1, 1], [1, 2], [1, 3], [1, 4], [1, 20], [1, 21], [1, 22], [1, 23], [1, 24], [1, 40], [1, 41], [1, 42], [1, 43], [1, 44], [2, 2], [2, 3], [2, 4], [2, 5], [2, 6], [2, 22], [2, 23], [2, 24], [2, 25], [2, 26], [2, 42], [2, 43], [2, 44], [2, 45], [2, 46], [3, 4], [3, 5], [3, 6], [3, 7], [3, 8], [3, 24], [3, 25], [3, 26], [3, 27], [3, 28], [3, 44], [3, 45], [3, 46], [3, 47], [3, 48], [4, 6], [4, 7], [4, 8], [4, 9], [4, 10], [4, 26], [4, 27], [4, 28], [4, 29], [4, 30], [4, 46], [4, 47], [4, 48], [4, 49], [4, 50], [5, 8], [5, 9], [5, 10], [5, 11], [5, 12], [5, 28], [5, 29], [5, 30], [5, 31], [5, 32], [5, 48], [5, 49], [5, 50], [5, 51], [5, 52], [6, 10], [6, 11], [6, 12], [6, 13], [6, 14], [6, 30], [6, 31], [6, 32], [6, 33], [6, 34], [6, 50], [6, 51], [6, 52], [6, 53], [6, 54], [7, 12], [7, 13], [7, 14], [7, 15], [7, 16], [7, 32], [7, 33], [7, 34], [7, 35], [7, 36], [7, 52], [7, 53], [7, 54], [7, 55], [7, 56], [8, 14], [8, 15], [8, 16], [8, 17], [8, 18], [8, 34], [8, 35], [8, 36], [8, 37], [8, 38], [8, 54], [8, 55], [8, 56], [8, 57], [8, 58], [9, 16], [9, 17], [9, 18], [9, 19], [9, 36], [9, 37], [9, 38], [9, 39], [9, 56], [9, 57], [9, 58], [9, 59], [10, 0], [10, 1], [10, 2], [10, 20], [10, 21], [10, 22], [10, 40], [10, 41], [10, 42], [10, 60], [10, 61], [10, 62], [10, 80], [10, 81], [10, 82], [11, 0], [11, 1], [11, 2], [11, 3], [11, 4], [11, 20], [11, 21], [11, 22], [11, 23], [11, 24], [11, 40], [11, 41], [11, 42], [11, 43], [11, 44], [11, 60], [11, 61], [11, 62], [11, 63], [11, 64], [11, 80], [11, 81], [11, 82], [11, 83], [11, 84], [12, 2], [12, 3], [12, 4], [12, 5], [12, 6], [12, 22], [12, 23], [12, 24], [12, 25], [12, 26], [12, 42], [12, 43], [12, 44], [12, 45], [12, 46], [12, 62], [12, 63], [12, 64], [12, 65], [12, 66], [12, 82], [12, 83], [12, 84], [12, 85], [12, 86], [13, 4], [13, 5], [13, 6], [13, 7], [13, 8], [13, 24], [13, 25], [13, 26], [13, 27], [13, 28], [13, 44], [13, 45], [13, 46], [13, 47], [13, 48], [13, 64], [13, 65], [13, 66], [13, 67], [13, 68], [13, 84], [13, 85], [13, 86], [13, 87], [13, 88], [14, 6], [14, 7], [14, 8], [14, 9], [14, 10], [14, 26], [14, 27], [14, 28], [14, 29], [14, 30], [14, 46], [14, 47], [14, 48], [14, 49], [14, 50], [14, 66], [14, 67], [14, 68], [14, 69], [14, 70], [14, 86], [14, 87], [14, 88], [14, 89], [14, 90], [15, 8], [15, 9], [15, 10], [15, 11], [15, 12], [15, 28], [15, 29], [15, 30], [15, 31], [15, 32], [15, 48], [15, 49], [15, 50], [15, 51], [15, 52], [15, 68], [15, 69], [15, 70], [15, 71], [15, 72], [15, 88], [15, 89], [15, 90], [15, 91], [15, 92], [16, 10], [16, 11], [16, 12], [16, 13], [16, 14], [16, 30], [16, 31], [16, 32], [16, 33], [16, 34], [16, 50], [16, 51], [16, 52], [16, 53], [16, 54], [16, 70], [16, 71], [16, 72], [16, 73], [16, 74], [16, 90], [16, 91], [16, 92], [16, 93], [16, 94], [17, 12], [17, 13], [17, 14], [17, 15], [17, 16], [17, 32], [17, 33], [17, 34], [17, 35], [17, 36], [17, 52], [17, 53], [17, 54], [17, 55], [17, 56], [17, 72], [17, 73], [17, 74], [17, 75], [17, 76], [17, 92], [17, 93], [17, 94], [17, 95], [17, 96], [18, 14], [18, 15], [18, 16], [18, 17], [18, 18], [18, 34], [18, 35], [18, 36], [18, 37], [18, 38], [18, 54], [18, 55], [18, 56], [18, 57], [18, 58], [18, 74], [18, 75], [18, 76], [18, 77], [18, 78], [18, 94], [18, 95], [18, 96], [18, 97], [18, 98], [19, 16], [19, 17], [19, 18], [19, 19], [19, 36], [19, 37], [19, 38], [19, 39], [19, 56], [19, 57], [19, 58], [19, 59], [19, 76], [19, 77], [19, 78], [19, 79], [19, 96], [19, 97], [19, 98], [19, 99], [20, 40], [20, 41], [20, 42], [20, 60], [20, 61], [20, 62], [20, 80], [20, 81], [20, 82], [20, 100], [20, 101], [20, 102], [20, 120], [20, 121], [20, 122], [21, 40], [21, 41], [21, 42], [21, 43], [21, 44], [21, 60], [21, 61], [21, 62], [21, 63], [21, 64], [21, 80], [21, 81], [21, 82], [21, 83], [21, 84], [21, 100], [21, 101], [21, 102], [21, 103], [21, 104], [21, 120], [21, 121], [21, 122], [21, 123], [21, 124], [22, 42], [22, 43], [22, 44], [22, 45], [22, 46], [22, 62], [22, 63], [22, 64], [22, 65], [22, 66], [22, 82], [22, 83], [22, 84], [22, 85], [22, 86], [22, 102], [22, 103], [22, 104], [22, 105], [22, 106], [22, 122], [22, 123], [22, 124], [22, 125], [22, 126], [23, 44], [23, 45], [23, 46], [23, 47], [23, 48], [23, 64], [23, 65], [23, 66], [23, 67], [23, 68], [23, 84], [23, 85], [23, 86], [23, 87], [23, 88], [23, 104], [23, 105], [23, 106], [23, 107], [23, 108], [23, 124], [23, 125], [23, 126], [23, 127], [23, 128], [24, 46], [24, 47], [24, 48], [24, 49], [24, 50], [24, 66], [24, 67], [24, 68], [24, 69], [24, 70], [24, 86], [24, 87], [24, 88], [24, 89], [24, 90], [24, 106], [24, 107], [24, 108], [24, 109], [24, 110], [24, 126], [24, 127], [24, 128], [24, 129], [24, 130], [25, 48], [25, 49], [25, 50], [25, 51], [25, 52], [25, 68], [25, 69], [25, 70], [25, 71], [25, 72], [25, 88], [25, 89], [25, 90], [25, 91], [25, 92], [25, 108], [25, 109], [25, 110], [25, 111], [25, 112], [25, 128], [25, 129], [25, 130], [25, 131], [25, 132], [26, 50], [26, 51], [26, 52], [26, 53], [26, 54], [26, 70], [26, 71], [26, 72], [26, 73], [26, 74], [26, 90], [26, 91], [26, 92], [26, 93], [26, 94], [26, 110], [26, 111], [26, 112], [26, 113], [26, 114], [26, 130], [26, 131], [26, 132], [26, 133], [26, 134], [27, 52], [27, 53], [27, 54], [27, 55], [27, 56], [27, 72], [27, 73], [27, 74], [27, 75], [27, 76], [27, 92], [27, 93], [27, 94], [27, 95], [27, 96], [27, 112], [27, 113], [27, 114], [27, 115], [27, 116], [27, 132], [27, 133], [27, 134], [27, 135], [27, 136], [28, 54], [28, 55], [28, 56], [28, 57], [28, 58], [28, 74], [28, 75], [28, 76], [28, 77], [28, 78], [28, 94], [28, 95], [28, 96], [28, 97], [28, 98], [28, 114], [28, 115], [28, 116], [28, 117], [28, 118], [28, 134], [28, 135], [28, 136], [28, 137], [28, 138], [29, 56], [29, 57], [29, 58], [29, 59], [29, 76], [29, 77], [29, 78], [29, 79], [29, 96], [29, 97], [29, 98], [29, 99], [29, 116], [29, 117], [29, 118], [29, 119], [29, 136], [29, 137], [29, 138], [29, 139], [30, 80], [30, 81], [30, 82], [30, 100], [30, 101], [30, 102], [30, 120], [30, 121], [30, 122], [30, 140], [30, 141], [30, 142], [30, 160], [30, 161], [30, 162], [31, 80], [31, 81], [31, 82], [31, 83], [31, 84], [31, 100], [31, 101], [31, 102], [31, 103], [31, 104], [31, 120], [31, 121], [31, 122], [31, 123], [31, 124], [31, 140], [31, 141], [31, 142], [31, 143], [31, 144], [31, 160], [31, 161], [31, 162], [31, 163], [31, 164], [32, 82], [32, 83], [32, 84], [32, 85], [32, 86], [32, 102], [32, 103], [32, 104], [32, 105], [32, 106], [32, 122], [32, 123], [32, 124], [32, 125], [32, 126], [32, 142], [32, 143], [32, 144], [32, 145], [32, 146], [32, 162], [32, 163], [32, 164], [32, 165], [32, 166], [33, 84], [33, 85], [33, 86], [33, 87], [33, 88], [33, 104], [33, 105], [33, 106], [33, 107], [33, 108], [33, 124], [33, 125], [33, 126], [33, 127], [33, 128], [33, 144], [33, 145], [33, 146], [33, 147], [33, 148], [33, 164], [33, 165], [33, 166], [33, 167], [33, 168], [34, 86], [34, 87], [34, 88], [34, 89], [34, 90], [34, 106], [34, 107], [34, 108], [34, 109], [34, 110], [34, 126], [34, 127], [34, 128], [34, 129], [34, 130], [34, 146], [34, 147], [34, 148], [34, 149], [34, 150], [34, 166], [34, 167], [34, 168], [34, 169], [34, 170], [35, 88], [35, 89], [35, 90], [35, 91], [35, 92], [35, 108], [35, 109], [35, 110], [35, 111], [35, 112], [35, 128], [35, 129], [35, 130], [35, 131], [35, 132], [35, 148], [35, 149], [35, 150], [35, 151], [35, 152], [35, 168], [35, 169], [35, 170], [35, 171], [35, 172], [36, 90], [36, 91], [36, 92], [36, 93], [36, 94], [36, 110], [36, 111], [36, 112], [36, 113], [36, 114], [36, 130], [36, 131], [36, 132], [36, 133], [36, 134], [36, 150], [36, 151], [36, 152], [36, 153], [36, 154], [36, 170], [36, 171], [36, 172], [36, 173], [36, 174], [37, 92], [37, 93], [37, 94], [37, 95], [37, 96], [37, 112], [37, 113], [37, 114], [37, 115], [37, 116], [37, 132], [37, 133], [37, 134], [37, 135], [37, 136], [37, 152], [37, 153], [37, 154], [37, 155], [37, 156], [37, 172], [37, 173], [37, 174], [37, 175], [37, 176], [38, 94], [38, 95], [38, 96], [38, 97], [38, 98], [38, 114], [38, 115], [38, 116], [38, 117], [38, 118], [38, 134], [38, 135], [38, 136], [38, 137], [38, 138], [38, 154], [38, 155], [38, 156], [38, 157], [38, 158], [38, 174], [38, 175], [38, 176], [38, 177], [38, 178], [39, 96], [39, 97], [39, 98], [39, 99], [39, 116], [39, 117], [39, 118], [39, 119], [39, 136], [39, 137], [39, 138], [39, 139], [39, 156], [39, 157], [39, 158], [39, 159], [39, 176], [39, 177], [39, 178], [39, 179], [40, 120], [40, 121], [40, 122], [40, 140], [40, 141], [40, 142], [40, 160], [40, 161], [40, 162], [40, 180], [40, 181], [40, 182], [40, 200], [40, 201], [40, 202], [41, 120], [41, 121], [41, 122], [41, 123], [41, 124], [41, 140], [41, 141], [41, 142], [41, 143], [41, 144], [41, 160], [41, 161], [41, 162], [41, 163], [41, 164], [41, 180], [41, 181], [41, 182], [41, 183], [41, 184], [41, 200], [41, 201], [41, 202], [41, 203], [41, 204], [42, 122], [42, 123], [42, 124], [42, 125], [42, 126], [42, 142], [42, 143], [42, 144], [42, 145], [42, 146], [42, 162], [42, 163], [42, 164], [42, 165], [42, 166], [42, 182], [42, 183], [42, 184], [42, 185], [42, 186], [42, 202], [42, 203], [42, 204], [42, 205], [42, 206], [43, 124], [43, 125], [43, 126], [43, 127], [43, 128], [43, 144], [43, 145], [43, 146], [43, 147], [43, 148], [43, 164], [43, 165], [43, 166], [43, 167], [43, 168], [43, 184], [43, 185], [43, 186], [43, 187], [43, 188], [43, 204], [43, 205], [43, 206], [43, 207], [43, 208], [44, 126], [44, 127], [44, 128], [44, 129], [44, 130], [44, 146], [44, 147], [44, 148], [44, 149], [44, 150], [44, 166], [44, 167], [44, 168], [44, 169], [44, 170], [44, 186], [44, 187], [44, 188], [44, 189], [44, 190], [44, 206], [44, 207], [44, 208], [44, 209], [44, 210], [45, 128], [45, 129], [45, 130], [45, 131], [45, 132], [45, 148], [45, 149], [45, 150], [45, 151], [45, 152], [45, 168], [45, 169], [45, 170], [45, 171], [45, 172], [45, 188], [45, 189], [45, 190], [45, 191], [45, 192], [45, 208], [45, 209], [45, 210], [45, 211], [45, 212], [46, 130], [46, 131], [46, 132], [46, 133], [46, 134], [46, 150], [46, 151], [46, 152], [46, 153], [46, 154], [46, 170], [46, 171], [46, 172], [46, 173], [46, 174], [46, 190], [46, 191], [46, 192], [46, 193], [46, 194], [46, 210], [46, 211], [46, 212], [46, 213], [46, 214], [47, 132], [47, 133], [47, 134], [47, 135], [47, 136], [47, 152], [47, 153], [47, 154], [47, 155], [47, 156], [47, 172], [47, 173], [47, 174], [47, 175], [47, 176], [47, 192], [47, 193], [47, 194], [47, 195], [47, 196], [47, 212], [47, 213], [47, 214], [47, 215], [47, 216], [48, 134], [48, 135], [48, 136], [48, 137], [48, 138], [48, 154], [48, 155], [48, 156], [48, 157], [48, 158], [48, 174], [48, 175], [48, 176], [48, 177], [48, 178], [48, 194], [48, 195], [48, 196], [48, 197], [48, 198], [48, 214], [48, 215], [48, 216], [48, 217], [48, 218], [49, 136], [49, 137], [49, 138], [49, 139], [49, 156], [49, 157], [49, 158], [49, 159], [49, 176], [49, 177], [49, 178], [49, 179], [49, 196], [49, 197], [49, 198], [49, 199], [49, 216], [49, 217], [49, 218], [49, 219], [50, 160], [50, 161], [50, 162], [50, 180], [50, 181], [50, 182], [50, 200], [50, 201], [50, 202], [50, 220], [50, 221], [50, 222], [50, 240], [50, 241], [50, 242], [51, 160], [51, 161], [51, 162], [51, 163], [51, 164], [51, 180], [51, 181], [51, 182], [51, 183], [51, 184], [51, 200], [51, 201], [51, 202], [51, 203], [51, 204], [51, 220], [51, 221], [51, 222], [51, 223], [51, 224], [51, 240], [51, 241], [51, 242], [51, 243], [51, 244], [52, 162], [52, 163], [52, 164], [52, 165], [52, 166], [52, 182], [52, 183], [52, 184], [52, 185], [52, 186], [52, 202], [52, 203], [52, 204], [52, 205], [52, 206], [52, 222], [52, 223], [52, 224], [52, 225], [52, 226], [52, 242], [52, 243], [52, 244], [52, 245], [52, 246], [53, 164], [53, 165], [53, 166], [53, 167], [53, 168], [53, 184], [53, 185], [53, 186], [53, 187], [53, 188], [53, 204], [53, 205], [53, 206], [53, 207], [53, 208], [53, 224], [53, 225], [53, 226], [53, 227], [53, 228], [53, 244], [53, 245], [53, 246], [53, 247], [53, 248], [54, 166], [54, 167], [54, 168], [54, 169], [54, 170], [54, 186], [54, 187], [54, 188], [54, 189], [54, 190], [54, 206], [54, 207], [54, 208], [54, 209], [54, 210], [54, 226], [54, 227], [54, 228], [54, 229], [54, 230], [54, 246], [54, 247], [54, 248], [54, 249], [54, 250], [55, 168], [55, 169], [55, 170], [55, 171], [55, 172], [55, 188], [55, 189], [55, 190], [55, 191], [55, 192], [55, 208], [55, 209], [55, 210], [55, 211], [55, 212], [55, 228], [55, 229], [55, 230], [55, 231], [55, 232], [55, 248], [55, 249], [55, 250], [55, 251], [55, 252], [56, 170], [56, 171], [56, 172], [56, 173], [56, 174], [56, 190], [56, 191], [56, 192], [56, 193], [56, 194], [56, 210], [56, 211], [56, 212], [56, 213], [56, 214], [56, 230], [56, 231], [56, 232], [56, 233], [56, 234], [56, 250], [56, 251], [56, 252], [56, 253], [56, 254], [57, 172], [57, 173], [57, 174], [57, 175], [57, 176], [57, 192], [57, 193], [57, 194], [57, 195], [57, 196], [57, 212], [57, 213], [57, 214], [57, 215], [57, 216], [57, 232], [57, 233], [57, 234], [57, 235], [57, 236], [57, 252], [57, 253], [57, 254], [57, 255], [57, 256], [58, 174], [58, 175], [58, 176], [58, 177], [58, 178], [58, 194], [58, 195], [58, 196], [58, 197], [58, 198], [58, 214], [58, 215], [58, 216], [58, 217], [58, 218], [58, 234], [58, 235], [58, 236], [58, 237], [58, 238], [58, 254], [58, 255], [58, 256], [58, 257], [58, 258], [59, 176], [59, 177], [59, 178], [59, 179], [59, 196], [59, 197], [59, 198], [59, 199], [59, 216], [59, 217], [59, 218], [59, 219], [59, 236], [59, 237], [59, 238], [59, 239], [59, 256], [59, 257], [59, 258], [59, 259], [60, 200], [60, 201], [60, 202], [60, 220], [60, 221], [60, 222], [60, 240], [60, 241], [60, 242], [60, 260], [60, 261], [60, 262], [60, 280], [60, 281], [60, 282], [61, 200], [61, 201], [61, 202], [61, 203], [61, 204], [61, 220], [61, 221], [61, 222], [61, 223], [61, 224], [61, 240], [61, 241], [61, 242], [61, 243], [61, 244], [61, 260], [61, 261], [61, 262], [61, 263], [61, 264], [61, 280], [61, 281], [61, 282], [61, 283], [61, 284], [62, 202], [62, 203], [62, 204], [62, 205], [62, 206], [62, 222], [62, 223], [62, 224], [62, 225], [62, 226], [62, 242], [62, 243], [62, 244], [62, 245], [62, 246], [62, 262], [62, 263], [62, 264], [62, 265], [62, 266], [62, 282], [62, 283], [62, 284], [62, 285], [62, 286], [63, 204], [63, 205], [63, 206], [63, 207], [63, 208], [63, 224], [63, 225], [63, 226], [63, 227], [63, 228], [63, 244], [63, 245], [63, 246], [63, 247], [63, 248], [63, 264], [63, 265], [63, 266], [63, 267], [63, 268], [63, 284], [63, 285], [63, 286], [63, 287], [63, 288], [64, 206], [64, 207], [64, 208], [64, 209], [64, 210], [64, 226], [64, 227], [64, 228], [64, 229], [64, 230], [64, 246], [64, 247], [64, 248], [64, 249], [64, 250], [64, 266], [64, 267], [64, 268], [64, 269], [64, 270], [64, 286], [64, 287], [64, 288], [64, 289], [64, 290], [65, 208], [65, 209], [65, 210], [65, 211], [65, 212], [65, 228], [65, 229], [65, 230], [65, 231], [65, 232], [65, 248], [65, 249], [65, 250], [65, 251], [65, 252], [65, 268], [65, 269], [65, 270], [65, 271], [65, 272], [65, 288], [65, 289], [65, 290], [65, 291], [65, 292], [66, 210], [66, 211], [66, 212], [66, 213], [66, 214], [66, 230], [66, 231], [66, 232], [66, 233], [66, 234], [66, 250], [66, 251], [66, 252], [66, 253], [66, 254], [66, 270], [66, 271], [66, 272], [66, 273], [66, 274], [66, 290], [66, 291], [66, 292], [66, 293], [66, 294], [67, 212], [67, 213], [67, 214], [67, 215], [67, 216], [67, 232], [67, 233], [67, 234], [67, 235], [67, 236], [67, 252], [67, 253], [67, 254], [67, 255], [67, 256], [67, 272], [67, 273], [67, 274], [67, 275], [67, 276], [67, 292], [67, 293], [67, 294], [67, 295], [67, 296], [68, 214], [68, 215], [68, 216], [68, 217], [68, 218], [68, 234], [68, 235], [68, 236], [68, 237], [68, 238], [68, 254], [68, 255], [68, 256], [68, 257], [68, 258], [68, 274], [68, 275], [68, 276], [68, 277], [68, 278], [68, 294], [68, 295], [68, 296], [68, 297], [68, 298], [69, 216], [69, 217], [69, 218], [69, 219], [69, 236], [69, 237], [69, 238], [69, 239], [69, 256], [69, 257], [69, 258], [69, 259], [69, 276], [69, 277], [69, 278], [69, 279], [69, 296], [69, 297], [69, 298], [69, 299], [70, 240], [70, 241], [70, 242], [70, 260], [70, 261], [70, 262], [70, 280], [70, 281], [70, 282], [70, 300], [70, 301], [70, 302], [70, 320], [70, 321], [70, 322], [71, 240], [71, 241], [71, 242], [71, 243], [71, 244], [71, 260], [71, 261], [71, 262], [71, 263], [71, 264], [71, 280], [71, 281], [71, 282], [71, 283], [71, 284], [71, 300], [71, 301], [71, 302], [71, 303], [71, 304], [71, 320], [71, 321], [71, 322], [71, 323], [71, 324], [72, 242], [72, 243], [72, 244], [72, 245], [72, 246], [72, 262], [72, 263], [72, 264], [72, 265], [72, 266], [72, 282], [72, 283], [72, 284], [72, 285], [72, 286], [72, 302], [72, 303], [72, 304], [72, 305], [72, 306], [72, 322], [72, 323], [72, 324], [72, 325], [72, 326], [73, 244], [73, 245], [73, 246], [73, 247], [73, 248], [73, 264], [73, 265], [73, 266], [73, 267], [73, 268], [73, 284], [73, 285], [73, 286], [73, 287], [73, 288], [73, 304], [73, 305], [73, 306], [73, 307], [73, 308], [73, 324], [73, 325], [73, 326], [73, 327], [73, 328], [74, 246], [74, 247], [74, 248], [74, 249], [74, 250], [74, 266], [74, 267], [74, 268], [74, 269], [74, 270], [74, 286], [74, 287], [74, 288], [74, 289], [74, 290], [74, 306], [74, 307], [74, 308], [74, 309], [74, 310], [74, 326], [74, 327], [74, 328], [74, 329], [74, 330], [75, 248], [75, 249], [75, 250], [75, 251], [75, 252], [75, 268], [75, 269], [75, 270], [75, 271], [75, 272], [75, 288], [75, 289], [75, 290], [75, 291], [75, 292], [75, 308], [75, 309], [75, 310], [75, 311], [75, 312], [75, 328], [75, 329], [75, 330], [75, 331], [75, 332], [76, 250], [76, 251], [76, 252], [76, 253], [76, 254], [76, 270], [76, 271], [76, 272], [76, 273], [76, 274], [76, 290], [76, 291], [76, 292], [76, 293], [76, 294], [76, 310], [76, 311], [76, 312], [76, 313], [76, 314], [76, 330], [76, 331], [76, 332], [76, 333], [76, 334], [77, 252], [77, 253], [77, 254], [77, 255], [77, 256], [77, 272], [77, 273], [77, 274], [77, 275], [77, 276], [77, 292], [77, 293], [77, 294], [77, 295], [77, 296], [77, 312], [77, 313], [77, 314], [77, 315], [77, 316], [77, 332], [77, 333], [77, 334], [77, 335], [77, 336], [78, 254], [78, 255], [78, 256], [78, 257], [78, 258], [78, 274], [78, 275], [78, 276], [78, 277], [78, 278], [78, 294], [78, 295], [78, 296], [78, 297], [78, 298], [78, 314], [78, 315], [78, 316], [78, 317], [78, 318], [78, 334], [78, 335], [78, 336], [78, 337], [78, 338], [79, 256], [79, 257], [79, 258], [79, 259], [79, 276], [79, 277], [79, 278], [79, 279], [79, 296], [79, 297], [79, 298], [79, 299], [79, 316], [79, 317], [79, 318], [79, 319], [79, 336], [79, 337], [79, 338], [79, 339], [80, 280], [80, 281], [80, 282], [80, 300], [80, 301], [80, 302], [80, 320], [80, 321], [80, 322], [80, 340], [80, 341], [80, 342], [80, 360], [80, 361], [80, 362], [81, 280], [81, 281], [81, 282], [81, 283], [81, 284], [81, 300], [81, 301], [81, 302], [81, 303], [81, 304], [81, 320], [81, 321], [81, 322], [81, 323], [81, 324], [81, 340], [81, 341], [81, 342], [81, 343], [81, 344], [81, 360], [81, 361], [81, 362], [81, 363], [81, 364], [82, 282], [82, 283], [82, 284], [82, 285], [82, 286], [82, 302], [82, 303], [82, 304], [82, 305], [82, 306], [82, 322], [82, 323], [82, 324], [82, 325], [82, 326], [82, 342], [82, 343], [82, 344], [82, 345], [82, 346], [82, 362], [82, 363], [82, 364], [82, 365], [82, 366], [83, 284], [83, 285], [83, 286], [83, 287], [83, 288], [83, 304], [83, 305], [83, 306], [83, 307], [83, 308], [83, 324], [83, 325], [83, 326], [83, 327], [83, 328], [83, 344], [83, 345], [83, 346], [83, 347], [83, 348], [83, 364], [83, 365], [83, 366], [83, 367], [83, 368], [84, 286], [84, 287], [84, 288], [84, 289], [84, 290], [84, 306], [84, 307], [84, 308], [84, 309], [84, 310], [84, 326], [84, 327], [84, 328], [84, 329], [84, 330], [84, 346], [84, 347], [84, 348], [84, 349], [84, 350], [84, 366], [84, 367], [84, 368], [84, 369], [84, 370], [85, 288], [85, 289], [85, 290], [85, 291], [85, 292], [85, 308], [85, 309], [85, 310], [85, 311], [85, 312], [85, 328], [85, 329], [85, 330], [85, 331], [85, 332], [85, 348], [85, 349], [85, 350], [85, 351], [85, 352], [85, 368], [85, 369], [85, 370], [85, 371], [85, 372], [86, 290], [86, 291], [86, 292], [86, 293], [86, 294], [86, 310], [86, 311], [86, 312], [86, 313], [86, 314], [86, 330], [86, 331], [86, 332], [86, 333], [86, 334], [86, 350], [86, 351], [86, 352], [86, 353], [86, 354], [86, 370], [86, 371], [86, 372], [86, 373], [86, 374], [87, 292], [87, 293], [87, 294], [87, 295], [87, 296], [87, 312], [87, 313], [87, 314], [87, 315], [87, 316], [87, 332], [87, 333], [87, 334], [87, 335], [87, 336], [87, 352], [87, 353], [87, 354], [87, 355], [87, 356], [87, 372], [87, 373], [87, 374], [87, 375], [87, 376], [88, 294], [88, 295], [88, 296], [88, 297], [88, 298], [88, 314], [88, 315], [88, 316], [88, 317], [88, 318], [88, 334], [88, 335], [88, 336], [88, 337], [88, 338], [88, 354], [88, 355], [88, 356], [88, 357], [88, 358], [88, 374], [88, 375], [88, 376], [88, 377], [88, 378], [89, 296], [89, 297], [89, 298], [89, 299], [89, 316], [89, 317], [89, 318], [89, 319], [89, 336], [89, 337], [89, 338], [89, 339], [89, 356], [89, 357], [89, 358], [89, 359], [89, 376], [89, 377], [89, 378], [89, 379], [90, 320], [90, 321], [90, 322], [90, 340], [90, 341], [90, 342], [90, 360], [90, 361], [90, 362], [90, 380], [90, 381], [90, 382], [91, 320], [91, 321], [91, 322], [91, 323], [91, 324], [91, 340], [91, 341], [91, 342], [91, 343], [91, 344], [91, 360], [91, 361], [91, 362], [91, 363], [91, 364], [91, 380], [91, 381], [91, 382], [91, 383], [91, 384], [92, 322], [92, 323], [92, 324], [92, 325], [92, 326], [92, 342], [92, 343], [92, 344], [92, 345], [92, 346], [92, 362], [92, 363], [92, 364], [92, 365], [92, 366], [92, 382], [92, 383], [92, 384], [92, 385], [92, 386], [93, 324], [93, 325], [93, 326], [93, 327], [93, 328], [93, 344], [93, 345], [93, 346], [93, 347], [93, 348], [93, 364], [93, 365], [93, 366], [93, 367], [93, 368], [93, 384], [93, 385], [93, 386], [93, 387], [93, 388], [94, 326], [94, 327], [94, 328], [94, 329], [94, 330], [94, 346], [94, 347], [94, 348], [94, 349], [94, 350], [94, 366], [94, 367], [94, 368], [94, 369], [94, 370], [94, 386], [94, 387], [94, 388], [94, 389], [94, 390], [95, 328], [95, 329], [95, 330], [95, 331], [95, 332], [95, 348], [95, 349], [95, 350], [95, 351], [95, 352], [95, 368], [95, 369], [95, 370], [95, 371], [95, 372], [95, 388], [95, 389], [95, 390], [95, 391], [95, 392], [96, 330], [96, 331], [96, 332], [96, 333], [96, 334], [96, 350], [96, 351], [96, 352], [96, 353], [96, 354], [96, 370], [96, 371], [96, 372], [96, 373], [96, 374], [96, 390], [96, 391], [96, 392], [96, 393], [96, 394], [97, 332], [97, 333], [97, 334], [97, 335], [97, 336], [97, 352], [97, 353], [97, 354], [97, 355], [97, 356], [97, 372], [97, 373], [97, 374], [97, 375], [97, 376], [97, 392], [97, 393], [97, 394], [97, 395], [97, 396], [98, 334], [98, 335], [98, 336], [98, 337], [98, 338], [98, 354], [98, 355], [98, 356], [98, 357], [98, 358], [98, 374], [98, 375], [98, 376], [98, 377], [98, 378], [98, 394], [98, 395], [98, 396], [98, 397], [98, 398], [99, 336], [99, 337], [99, 338], [99, 339], [99, 356], [99, 357], [99, 358], [99, 359], [99, 376], [99, 377], [99, 378], [99, 379], [99, 396], [99, 397], [99, 398], [99, 399]]

InV4 to V4 --- LOOKS OK
[[0, 0], [0, 1], [0, 2], [0, 10], [0, 11], [0, 12], [0, 20], [0, 21], [0, 22], [1, 0], [1, 1], [1, 2], [1, 3], [1, 4], [1, 10], [1, 11], [1, 12], [1, 13], [1, 14], [1, 20], [1, 21], [1, 22], [1, 23], [1, 24], [2, 2], [2, 3], [2, 4], [2, 5], [2, 6], [2, 12], [2, 13], [2, 14], [2, 15], [2, 16], [2, 22], [2, 23], [2, 24], [2, 25], [2, 26], [3, 4], [3, 5], [3, 6], [3, 7], [3, 8], [3, 14], [3, 15], [3, 16], [3, 17], [3, 18], [3, 24], [3, 25], [3, 26], [3, 27], [3, 28], [4, 6], [4, 7], [4, 8], [4, 9], [4, 16], [4, 17], [4, 18], [4, 19], [4, 26], [4, 27], [4, 28], [4, 29], [5, 0], [5, 1], [5, 2], [5, 10], [5, 11], [5, 12], [5, 20], [5, 21], [5, 22], [5, 30], [5, 31], [5, 32], [5, 40], [5, 41], [5, 42], [6, 0], [6, 1], [6, 2], [6, 3], [6, 4], [6, 10], [6, 11], [6, 12], [6, 13], [6, 14], [6, 20], [6, 21], [6, 22], [6, 23], [6, 24], [6, 30], [6, 31], [6, 32], [6, 33], [6, 34], [6, 40], [6, 41], [6, 42], [6, 43], [6, 44], [7, 2], [7, 3], [7, 4], [7, 5], [7, 6], [7, 12], [7, 13], [7, 14], [7, 15], [7, 16], [7, 22], [7, 23], [7, 24], [7, 25], [7, 26], [7, 32], [7, 33], [7, 34], [7, 35], [7, 36], [7, 42], [7, 43], [7, 44], [7, 45], [7, 46], [8, 4], [8, 5], [8, 6], [8, 7], [8, 8], [8, 14], [8, 15], [8, 16], [8, 17], [8, 18], [8, 24], [8, 25], [8, 26], [8, 27], [8, 28], [8, 34], [8, 35], [8, 36], [8, 37], [8, 38], [8, 44], [8, 45], [8, 46], [8, 47], [8, 48], [9, 6], [9, 7], [9, 8], [9, 9], [9, 16], [9, 17], [9, 18], [9, 19], [9, 26], [9, 27], [9, 28], [9, 29], [9, 36], [9, 37], [9, 38], [9, 39], [9, 46], [9, 47], [9, 48], [9, 49], [10, 20], [10, 21], [10, 22], [10, 30], [10, 31], [10, 32], [10, 40], [10, 41], [10, 42], [10, 50], [10, 51], [10, 52], [10, 60], [10, 61], [10, 62], [11, 20], [11, 21], [11, 22], [11, 23], [11, 24], [11, 30], [11, 31], [11, 32], [11, 33], [11, 34], [11, 40], [11, 41], [11, 42], [11, 43], [11, 44], [11, 50], [11, 51], [11, 52], [11, 53], [11, 54], [11, 60], [11, 61], [11, 62], [11, 63], [11, 64], [12, 22], [12, 23], [12, 24], [12, 25], [12, 26], [12, 32], [12, 33], [12, 34], [12, 35], [12, 36], [12, 42], [12, 43], [12, 44], [12, 45], [12, 46], [12, 52], [12, 53], [12, 54], [12, 55], [12, 56], [12, 62], [12, 63], [12, 64], [12, 65], [12, 66], [13, 24], [13, 25], [13, 26], [13, 27], [13, 28], [13, 34], [13, 35], [13, 36], [13, 37], [13, 38], [13, 44], [13, 45], [13, 46], [13, 47], [13, 48], [13, 54], [13, 55], [13, 56], [13, 57], [13, 58], [13, 64], [13, 65], [13, 66], [13, 67], [13, 68], [14, 26], [14, 27], [14, 28], [14, 29], [14, 36], [14, 37], [14, 38], [14, 39], [14, 46], [14, 47], [14, 48], [14, 49], [14, 56], [14, 57], [14, 58], [14, 59], [14, 66], [14, 67], [14, 68], [14, 69], [15, 40], [15, 41], [15, 42], [15, 50], [15, 51], [15, 52], [15, 60], [15, 61], [15, 62], [15, 70], [15, 71], [15, 72], [15, 80], [15, 81], [15, 82], [16, 40], [16, 41], [16, 42], [16, 43], [16, 44], [16, 50], [16, 51], [16, 52], [16, 53], [16, 54], [16, 60], [16, 61], [16, 62], [16, 63], [16, 64], [16, 70], [16, 71], [16, 72], [16, 73], [16, 74], [16, 80], [16, 81], [16, 82], [16, 83], [16, 84], [17, 42], [17, 43], [17, 44], [17, 45], [17, 46], [17, 52], [17, 53], [17, 54], [17, 55], [17, 56], [17, 62], [17, 63], [17, 64], [17, 65], [17, 66], [17, 72], [17, 73], [17, 74], [17, 75], [17, 76], [17, 82], [17, 83], [17, 84], [17, 85], [17, 86], [18, 44], [18, 45], [18, 46], [18, 47], [18, 48], [18, 54], [18, 55], [18, 56], [18, 57], [18, 58], [18, 64], [18, 65], [18, 66], [18, 67], [18, 68], [18, 74], [18, 75], [18, 76], [18, 77], [18, 78], [18, 84], [18, 85], [18, 86], [18, 87], [18, 88], [19, 46], [19, 47], [19, 48], [19, 49], [19, 56], [19, 57], [19, 58], [19, 59], [19, 66], [19, 67], [19, 68], [19, 69], [19, 76], [19, 77], [19, 78], [19, 79], [19, 86], [19, 87], [19, 88], [19, 89], [20, 60], [20, 61], [20, 62], [20, 70], [20, 71], [20, 72], [20, 80], [20, 81], [20, 82], [20, 90], [20, 91], [20, 92], [21, 60], [21, 61], [21, 62], [21, 63], [21, 64], [21, 70], [21, 71], [21, 72], [21, 73], [21, 74], [21, 80], [21, 81], [21, 82], [21, 83], [21, 84], [21, 90], [21, 91], [21, 92], [21, 93], [21, 94], [22, 62], [22, 63], [22, 64], [22, 65], [22, 66], [22, 72], [22, 73], [22, 74], [22, 75], [22, 76], [22, 82], [22, 83], [22, 84], [22, 85], [22, 86], [22, 92], [22, 93], [22, 94], [22, 95], [22, 96], [23, 64], [23, 65], [23, 66], [23, 67], [23, 68], [23, 74], [23, 75], [23, 76], [23, 77], [23, 78], [23, 84], [23, 85], [23, 86], [23, 87], [23, 88], [23, 94], [23, 95], [23, 96], [23, 97], [23, 98], [24, 66], [24, 67], [24, 68], [24, 69], [24, 76], [24, 77], [24, 78], [24, 79], [24, 86], [24, 87], [24, 88], [24, 89], [24, 96], [24, 97], [24, 98], [24, 99]]

InIT to IT - CHECKED - STATUS = 'GOOD'
[[0, 0], [0, 1], [0, 2], [0, 5], [0, 6], [0, 7], [0, 10], [0, 11], [0, 12], 
[1, 0], [1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [1, 9], [1, 10], [1, 11], [1, 12], [1, 13], [1, 14], 
[2, 2], [2, 3], [2, 4], [2, 7], [2, 8], [2, 9], [2, 12], [2, 13], [2, 14], 
[3, 0], [3, 1], [3, 2], [3, 5], [3, 6], [3, 7], [3, 10], [3, 11], [3, 12], [3, 15], [3, 16], [3, 17], [3, 20], [3, 21], [3, 22], [4, 0], [4, 1], [4, 2], [4, 3], [4, 4], [4, 5], [4, 6], [4, 7], [4, 8], [4, 9], [4, 10], [4, 11], [4, 12], [4, 13], [4, 14], [4, 15], [4, 16], [4, 17], [4, 18], [4, 19], [4, 20], [4, 21], [4, 22], [4, 23], [4, 24], 
[5, 2], [5, 3], [5, 4], [5, 7], [5, 8], [5, 9], [5, 12], [5, 13], [5, 14], [5, 17], [5, 18], [5, 19], [5, 22], [5, 23], [5, 24], [6, 10], [6, 11], [6, 12], [6, 15], [6, 16], [6, 17], [6, 20], [6, 21], [6, 22], 
[7, 10], [7, 11], [7, 12], [7, 13], [7, 14], [7, 15], [7, 16], [7, 17], [7, 18], [7, 19], [7, 20], [7, 21], [7, 22], [7, 23], [7, 24], 
[8, 12], [8, 13], [8, 14], [8, 17], [8, 18], [8, 19], [8, 22], [8, 23], [8, 24]]

InMI to MI - CHECKED - STATUS = 'GOOD'
[[0, 0], [0, 1], [0, 2], [0, 5], [0, 6], [0, 7], [0, 10], [0, 11], [0, 12], 
[1, 0], [1, 1], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [1, 9], [1, 10], [1, 11], [1, 12], [1, 13], [1, 14], 
[2, 2], [2, 3], [2, 4], [2, 7], [2, 8], [2, 9], [2, 12], [2, 13], [2, 14], 
[3, 0], [3, 1], [3, 2], [3, 5], [3, 6], [3, 7], [3, 10], [3, 11], [3, 12], [3, 15], [3, 16], [3, 17], [3, 20], [3, 21], [3, 22], 
[4, 0], [4, 1], [4, 2], [4, 3], [4, 4], [4, 5], [4, 6], [4, 7], [4, 8], [4, 9], [4, 10], [4, 11], [4, 12], [4, 13], [4, 14], [4, 15], [4, 16], [4, 17], [4, 18], [4, 19], [4, 20], [4, 21], [4, 22], [4, 23], [4, 24], 
[5, 2], [5, 3], [5, 4], [5, 7], [5, 8], [5, 9], [5, 12], [5, 13], [5, 14], [5, 17], [5, 18], [5, 19], [5, 22], [5, 23], [5, 24], 
[6, 10], [6, 11], [6, 12], [6, 15], [6, 16], [6, 17], [6, 20], [6, 21], [6, 22], 
[7, 10], [7, 11], [7, 12], [7, 13], [7, 14], [7, 15], [7, 16], [7, 17], [7, 18], [7, 19], [7, 20], [7, 21], [7, 22], [7, 23], [7, 24], 
[8, 12], [8, 13], [8, 14], [8, 17], [8, 18], [8, 19], [8, 22], [8, 23], [8, 24]]


*20jan30
**so i confirmed that the connectivity is correct. At least for the current configuration where I have reduced network with 20x20 neurons in R and V1 followed by 10x10 neurons in V4 and 5x5 neurons in IT and so on.
**Until now i have been using delay of 20 ms, which is too long. Biologically, it should be 1 or 2 ms (see for references).
**Changed delays for all synaptic connections to 2 ms.
**Create a new folder 'SMARTAgent_Reduced_01302020' and test output firing rates for different inhibition strengths in FFEtoE_WILEtoI_WILItoE (0.001,0.002,0.004). (WIL - withinlayer and FF is feedforward). WIL E->I (0.002) WIL I->E(0.001,0.002,0.004) and FF E->E (0.002)
**Why there is a lot of noise in R neurons? Can i reduce it?
***May be by adding inhibition in R helps it. so add IR neurons (10x10) and connections R->IR (3) IR->R (5).
**test new model with IR and R->IR->R loop in a folder 'FFEtoE_WILEtoI_WILItoE_withIR' 

*20jan31
**When i tested new model with IR and R->IR->R loop and compared it with R->IR. using IR->R of 0.004 gave me very similar results to IR->R of 0. When i increased IR->R to 0.04, the firing rate of R and IR both went down. But i want to see the oscillations.
**May be i need to reduce the model to 2 layers to understand the interplay between excitation and inhibition.

*20feb3
**running 2 layers model with 5x5 neurons in R and 1 neuron in IR, where 3x3 neurons in R make connections with 1 IR neuron. The input is only corner pixels 5x5.
***I noticed that the strength of poisson neurons (processes converting pixel intensities to firing rate) to R is too much which leads to a burst of activity in which some of the spikes are very small.
** weight reduced to 0.002 as shown below:
netParams.stimTargetParams['stimMod->all'] = {'source': 'stimMod',
        'conds': {'pop': 'R'},
        'convergence': 1,
        'weight': 0.002,
        'delay': 1,
        'synMech': 'AMPA'}
**I found another issue..... firing rate for baseline (black background) was ~7 Hz in addition to the 5Hz provided to all the excitatory neurons. So probably get rid of the baseline activity of ~7Hz i.e. in aigame.py

*20feb4
**running simulations with background and without background in 'SMARTAgent_FFExcitation_WithinLayerInhibition' and 'SMARTAgent_FFExcitation_WithinLayerInhibition/NoNoise'
netParams.stimSourceParams['ebkg'] = {'type': 'NetStim', 'rate': 5, 'noise': 0.0} #noise was 0.3 and weight was 0.01
netParams.stimTargetParams['ebkg->all'] = {'source': 'ebkg', 'conds': {'cellType': ['EV1','EV4','EIT', 'EMI', 'EMO']}, 'weight': 0, 'delay': 'max(1, normal(5,2))', 'synMech': 'AMPA'}


netParams.stimSourceParams['bkg'] = {'type': 'NetStim', 'rate': 20, 'noise': 0.0} #noise was 0.3 and weight was 0.01
netParams.stimTargetParams['bkg->all'] = {'source': 'bkg', 'conds': {'cellType': ['InR','InV1','InV4','InIT', 'InMI']}, 'weight': 0, 'delay': 'max(1, normal(5,2))', 'synMech': 'AMPA'}

**All long range inputs to M1 originates in thalamus or other cortical areas and is exculsively glutamatergic.
**In rodents, these thalamic inputs include motor thalamic nuclei such as Va-VL, posterior sensory nuclei including PO and ventromedial (VM) thalamus. The axons differentially target distinct layers of M1.

*20feb5
**ran the following simulations:
1. No background firing rate:
1a. 100s_withRL -- firing rates of most of the neurons looked stable except motor areas which were increasing
1b. 500s_withRL -- firing rates of IT, MI and MO neurons increased first and then decreases sharply. These effects are probably due to RL between IT, MI and MO.
1c. 200s_noRL--all firing rates stable.
1d. 200s_noRL_noInhib--al firing rate stable but the now the neurons are firing at higher rate.
2. With 5Hz and 20 Hz background firing rates for excitatory and inhibitory neurons.
2a. 100s_withRL -- firing rates of most of the neurons looked stable except motor areas which were increasing
2b. 500s_withRL -- firing rates of IT, MI and MO neurons increased first and then decreases sharply. These effects are probably due to RL between IT, MI and MO.
2c. 200s_noRL--all firing rates stable.
2d. 200s_noRL_noInhib--al firing rate stable but the now the neurons are firing at higher rate.

**start adding RL
1. add between IT and MI. ---> constant increase in weights observed. ALso in the presence of background firing, the firing rates of MI and MO increased. But in the absence of background firing, the firing rates of MI and MO didn't increase.

*20feb6
**firing rate of MO pop increased rapidly and then start dropping. Trying to find why is that? May be connections getting too strong. Look at the MO neurons voltage traces.
**baseline voltage shifts and the firing is going on. Don't see any issue with blocking.

*20feb7
**seems the problem is with background firing rate. background firing rate should be same across areas. right now this is not the case.
**For now get rid of the background firing rate and run with RL between IT and MI and between MI and MO. set 'weight': 0.01 to 'weight': 0.0 for both ['ebkg->all'] and ['bkg->all']---->Still the weights kept strengthening probably because both RL and STDP hebbian learning are working.
**Try activating antihebbian on RL synapses.
from: STDPparamsRL = {'hebbwt': 0.00001, 'antiwt':-0.0000, 'wmax': 50, 'RLon': 1 , 'RLhebbwt': 0.00001, 'RLantiwt': -0.000,
        'tauhebb': 10, 'RLwindhebb': 50, 'useRLexp': 0, 'softthresh': 0, 'verbose':0}
To: STDPparamsRL = {'hebbwt': 0.00001, 'antiwt':-0.00001, 'wmax': 50, 'RLon': 1 , 'RLhebbwt': 0.00001, 'RLantiwt': -0.000,
        'tauhebb': 10, 'RLwindhebb': 50, 'useRLexp': 0, 'softthresh': 0, 'verbose':0}
***Not much different than when antiwt was 0.
**Check what happens if hebbwt is also turned to 0 i.e. both hebbwt and antiwt are 0. ---> overall weight decreased
**Try decreasing weights between (V1->V4),(V4->IT). 0.002 to 0.001 --->Looks better.
**Additionally, try decreasing weights between (IT->MI) and (MI->MO) from 0.002 to 0.001

*20feb10
**Reducing weights between (IT->MI) and (MI->MO) from 0.002 to 0.001 was too much as the firing rate decreased to around 2-3Hz.
**Change weights between IT->MI and MI->MO to 0.0015 ----> Still low firing rate.
**Chnage weights between IT->MI and MI->MO to 0.002----> So i just realized that i was looking at wrong data to draw conclusions. even for 0.0015, the firing rate increases. 
**Change weights between IT->MI and MI->MO to 0.0012 ----> In the beginning the firing rate is still high but then it decreases because of RL i.e. the weight decreases most of the times. ----> run simulation for longer duration (200 s). ---> population firing rates look reasonable. Not same but not too different.
**rerun the simulation (50sec) using shorter game-interaction interval of 10 ms. Still decreasing weights.

*20feb11
**Need to change the RL based STDP mechanism. For now, put a limit such that if the connection has not learned anything it can not forget. which means that whatever weight is assigned in the beginning sould be the absolute minimum i.e. without learning. therefore the weights can not go below that initially assigned weights. 'wmin' is assigned 0.0012.
**wmin is giving error so using wbase. ---> Seems to be stable. atleast not going down.
**Run simulation with real game.
**Motor cortex structure modified.
***Before the model had 2 layers MI and MO with 25 and 10 neurons respectively. IT->MI and MI->MO.
***Now the model has 2 layers ML and MR, each with 25 neurons. IT->ML and IT->MR. All to All connections.
***Decision is made by comparing firing rate of 25 neurons in ML and MR in intervals of 20 ms. such that the model can decide about 5 actions to be taken place in next 100 ms.

*20feb20
**firing rates information while playing the game was not boradcasted to all nodes, so the nodes other than master node didnt know what to do with that--->fixed that on feb14.
**tried running the simulation using mpi after the change in code and everything worked except saving some output parameters into text files----> I observed that firing rate was low, but there is no one-to-one correspondence between parallel simulation and simulation on a single node.
**when i ran simulation on 2 nodes, i observed firing rate calculated twice every time --->problem fixed.

*20feb21
**the racket seems to get stuck on one side. 
**Right now there is no noise, may be add different noise to neurons in ML and MR---->5 Hz noise added to ML and MR neurons.
**With 5Hz, it is still stuck on one corner. Increase noise to 20 Hz and try again.
**With 20 Hz, it is still stuck on one corner. Increase noise to 40 Hz and try again.
**May be something wrong with playgame as the actions seems to be not executed. Try producing random actions.
**based on suggestion by Salva. Changed the scripts. Now calculating firing rate on each node and then summing up using command sim.pc.allreduce(vec.from_python([F_R1]), 1) # sum
F_R1 = vec.to_python()[0] 
**seems like problem fixed. Now getting same level of firing rates as using single node.
**Reduce background firing rate/noise for driving ML and MR neurons to 5Hz.
**IDEAS: we could randomly explore weights by choosing a set of weights for an episode and evaluating the performance of the SmartAgent during that episode with the given weights.
**The other issue is right now, we are only using +1 or -1 for the reward. There are several kinds of performances:
1. Tha SmartAgent hit the ball and didn't let the opponent (computer) score +1 and itself loose a score -1. The SmartAgent gets a 0, but we need to encode this information in the circuit as this move has a positive effect on the outcome of the game.
2. The SmartAgent hit the ball in such a way that the computer could not pick up the ball and therefore SmartAgent made a score +1. This is a reward signal which is used in the model for RL weight adjustment.
3. The SmartAgent misses the ball and the computer made a score, so the SmartAgent gets -1 which act as a punishment in the RL framework.
4. Based on the scores, either SmartAgent wins or the computer. This should also has an impact on the performance or the model. Not urgent but this could be used as a reward signal too.
**remove ML and MR noise from the model and run 1 hr simulation.

*20feb24
**THINGS TO DO:
1) Make connections from earlier visual layers to motor cortex for RL.
2) Check the duration of eligibility trace to make sure that the association between the reward/punishment, action and visual scene can be established.
3) Include reward for the case when the player hits the ball as it prevents from losing the score.
4) Make eligibility trace exponentially dropping instead of square-like. 

**change RL parameters to use RLexp and increase RLlenhebb from 100 ms to 800 ms.
STDPparamsRL = {'hebbwt': 0.0000, 'antiwt':-0.0000, 'wbase': 0.0012, 'wmax': 50, 'RLon': 1 , 'RLhebbwt': 0.00001, 'RLantiwt': -0.000, 'tauhebb': 10, 'RLwindhebb': 50, 'useRLexp': 0, 'softthresh': 0, 'verbose':0}
to
STDPparamsRL = {'hebbwt': 0.0000, 'antiwt':-0.0000, 'wbase': 0.0012, 'wmax': 50, 'RLon': 1 , 'RLhebbwt': 0.00001, 'RLantiwt': -0.000,'tauhebb': 10, 'RLlenhebb': 800 ,'RLwindhebb': 50, 'useRLexp': 1, 'softthresh': 0, 'verbose':0}

**too many no move actions because the firing rate of ML is same as MR. Try picking up random action if ML is equal to MR firing rates.

*20mar4
**THINGS TO DO:
1. Fix videos (follow this: https://hub.packtpub.com/openai-gym-environments-wrappers-and-monitors-tutorial/)
2. Allow saving and loading weights so that we can run loneger simulations.
3. other thing while those types of sims run is to think about whether to have those "fake" rules you suggested - such as reward the model when it moves racket toward ball and when it contacts the ball. can do that via different values of critic signal.

**needed to istall ffmpeg using homebrew - installed


*20mar5
**added "simtype": {"NewSim":0,"ResumeSim":1,"ResumeSimFromFile":"data/20mar1_G2_simConfig.pkl"} in sim.json
***Choose here if need NewSim or ResumeSim. For resume sim, should also include ResumeSimFromFile
**update STDP weights

**testing weight loading - G0: run sim for 100 sec with initial weights.
**testing weight loading - G1: run sim for 100 sec with weights from G0

**WEIGHT RELOADING WORKS- can run long simulations by resuming from last run without problem

*20mar6
**in aigame.py, find the position of ball and racket, then propose action based on the their relative positions. The strategy here is to move towards the ball.
**all proposed actions are returned from playGame to sim.py and appended in sim.allProposedActions and saved in the end of simulation.
**Next step would be to use the proposed actions and compare it with the performed action, if the performed action was similar to the proposed action, give some reward.

*20mar9
**When Sam adjusted temperature to 37 degrees, all of a sudden the spiking behavior of HH neurons got weird.
**Sam suggested that we should try PYR2 (2 compartment pyramidal neuron from Mainen) for E type cells and FS_Basket (only with fast sodium and fast K based on this published work by Sam. Sam et al. 2016 : https://senselab.med.yale.edu/ModelDB/ShowModel?model=185858#tabs-1) for I type cells.

*20mar10
**compute direction of the ball (toward the racket of the player is 1, away from the racket of the player is -1)
**if the ball changes its direction and doesn't lose a score, it means that the ball hit the racket.
**define more types of rewards as "rewardcodes": {"scorePoint": 1, "losePoint": -0.01, "followBall": 0.001, "avoidBall": -0.001, "hitBall": 0.05}
**if the player made a score it gets 'scorePoint' as reward, if the player loses score it get 'losePoint' as punishment.
**if the player follows the ball while its moving towards it, the player gets 'followBall' as reward.
**if the player does not follow the ball while its moving toward it, the player gets 'avoidBall' as punishment.
**if the ball changes its direction and the player does not lose a point, it means that the ball was hit by the racket therefore player get 'hitBall' reward.

*20mar12
**Sam told me that there is too much reward. so testing all reward for "rewardcodes": {"scorePoint": 1, "losePoint": -1, "followBall": 0.5, "avoidBall": -0.001, "hitBall": 0.75}, in 20mar12_TG0_
**load step file in simdat.py
**reduce reward for followBall from 0.5 to 0.001 and Run "rewardcodes": {"scorePoint": 1, "losePoint": -1, "followBall": 0.001, "avoidBall": -0.001, "hitBall": 0.75} in 20mar12_TG1_
**don't use scorePoint and losePoint. Only use followBall, avoidBall and hitBall as rewards: "rewardcodes": {"scorePoint": 0, "losePoint": -0, "followBall": 0.001, "avoidBall": -0.001, "hitBall": 0.1}, in 20mar12_TG2_
**again the problem is too many times, the actions generate avoidBall signal. make followBall = 0.005 and rerun the sim. "rewardcodes": {"scorePoint": 0, "losePoint": -0, "followBall": 0.005, "avoidBall": -0.001, "hitBall": 0.1} in 20mar12_TG3_
**make followBall = 0.002 and rerun the sim. "rewardcodes": {"scorePoint": 0, "losePoint": -0, "followBall": 0.002, "avoidBall": -0.001, "hitBall": 0.1} in 20mar12_TG4_

*20mar13
**Should look at individual synapses
**should try to look at the capcity of network to store input---though not sure how to do that exactly. 
--Input space: nput space is ~number_frames * (Height x Width)^levels, where levels is number of grayscale values
--network space is proportional to number of plastic synapses, but each synapse has continuous range.... to the network capacity? something like synapses ^ NB of synaptic states...NB of synaptic states = number of synaptic values...each one has a range from wbase to wmax, and they're 64 bit numbers, but not using the full 64 bits
**IDEAS to enahnce network storage capacity:
1) use mulitple synapses between each pair of cells with different delays. Could use AMPA and NMDA or AMPA with different delays.
2)recurrent connecitivity with different delays.
3)Using detailed morphologies with multiple synapses at different loactions to allow different integration time constants and thus increasing the capacity of network storage.

**run shorter sim (2000 ms) with followBall reward of 0.004 in "20mar13_TG0_" and "sim": {"duration": 2000, "dt": 0.2, "verbose": 0, "recordStep":0.2,"recordWeightStepSize":1,"RLFakeUpRule": 0,"RLFakeDownRule": 0,"RLFakeStayRule": 0,"name":"20mar13_TG0_","doquit":0,"doplot":1}

**save rewards with more precision.

*20mar17
**plot synaptic weights per post neuron IDs.
**testing new plots.
**create separate figures for each pair of areas e.g. V1 to ML and MR, V4 to ML and MR and IT to ML and MR.
**plot as images

*20mar18
**still not happy with plotting synaptic weights.... difficult to analyze and learn about the learning and dynamics of synapses.
**will leave it for now and start including more synaptic time constants in the model i.e. via including different types of synapses between every pair of neurons connected.

*20mar19
**Using a bit different time constants for NMDA netParams.synMechParams['NMDA'] = {'mod': 'Exp2Syn', 'tau1': 0.15, 'tau2': 166.0, 'e': 0} # NMDA.... arm model had .. netParams.synMechParams['NMDA'] = {'mod': 'Exp2Syn', 'tau1': 0.15, 'tau2': 1.5, 'e': 0} # NMDA

**Based on this paper : Functional Properties of AMPA and NMDA Receptors Expressed in Identified Types of Basal Ganglia Neurons
Thomas Götz, Udo Kraushaar, Jörg Geiger, Joachim Lübke, Thomas Berger and Peter Jonas
Journal of Neuroscience 1 January 1997, 17 (1) 204-215; DOI: https://doi.org/10.1523/JNEUROSCI.17-01-00204.1997
***AMPARs in striatal principal neurons exhibited sloest gating (desnsitization time constant of 11.5 msec, 1 mM glutamate, 22C), whereas those in striatal cholinergic interneurons showed the fastest gating (desensitization time constant of 3.6 msec).
***The lowest permeability of AMPARs was observed in nigral dopaminergic neurons (PCa/PNa = 0.1), where as the highest Ca2+ permeability was found in subthalamic nucleus neurons (PCa/PNa = 1.17).
***NMDARs of different types of basal ganglia neurons were less variable in their functional properties; those expressed in nigral dopaminergic neurons exhibited the slowest gating (deactivation time constant of predominant fast component was 150 msec, 100uM glutamate) and those of globus pallidus neurons showed fastest gating (deactivation of 67 msec).
**deactivation time constant of AMPARs is in range of 1-3 ms.
**desensitization(inactivation) time constant of AMPARs is in range of 3-12 ms.
***deactivation of NMDARs has multiple time constants. The fastes time constant is ~166 ms (64% of recordings) and the second fastest time constant is ~1158 msec (36%).

**another paper  "Cell Type-Specific Development of NMDA Receptors in the Interneurons of Rat Prefrontal Cortex" -- might be useful from developmental perspective.

**Added NMDA synapses to long range connections between Visual areas and motor areas.
**plot weights for a single postsynaptic neuron.---> testing
**test plotting weights for a single post synaptic neuron for 5 different neurons.

*20mar20
**Problem plotting 'AMPA' and 'NMDA' weights for a pair of neurons. -->probably problem saving weights....test using print
**Record synMech with weights.

*20mar23
**plot weights of synaptic connections for only 10% of postsynaptic neurons. --->still not very informative.
**synaptic strengths evolve very similarly.
***May be need to reconsider: what is the purpose of using 2 different types of synapses between two neurons at the same location. since both synapses share same pre and postsynaptic activity, and same RL mechanism, they evolve with same dynamics. We didn't include those 2 types of synapses to behave same. our goal was to introduce multiple time scales in the model. 
**Other options to introduce multiple time scales:
1. use different RL rule AMPA (shorter eligibility) vs NMDA (longer eligibility):
STDPparamsRL1 with 'RLlenhebb': 50 ,'RLlenanti': 50 and 'useRLexp': 1
STDPparamsRL2 with 'RLlenhebb': 800 ,'RLlenanti': 100 and 'useRLexp': 0

*20mar24
**retina has direction selective neurons.
**V1 has direction selective neurons.
**V1 direction selective neurons' functionality doesn't completely depend on retinal direction selective neurons. (Morrie and Feller 2017, Current Biology) 
**should change IT to MT as that is the part of dorsal pathway (Retina-dLGN-V1-V2-MT).
**Probably, V2 also has direction selective neurons but didnt find any paper about that yet.
**MT also has direction selective neurons.
**Include direstion selective neurons in all areas. Start with R and V1.

*20mar25
**create layers of direction selective neurons for V1. (Use information of R for direction selective neurons in V1).
**computing direction of object motion in 3x3 block for visual input.
***if input is 20x20, direction sensitive neurons are 10x10. each direction sensitive neuron captures direction of object in 3x3 blocks with center of the block sliding over 2 neurons in each direction.
***some comments added to the computation of direction of object motion.
***arccos give angle between 0 and 180 degrees. so to extend it from 0 to 360 degrees, add 180 if the object motion direction is in 3 or 4th quadrant.
***if the angle theta is between 315 and 45, should activate R direction neuron.
***if the angle theta is between 135 and 225, should activate L direction neuron.
***if the angle theta is between 45 and 135, should activate Up direction neuron.
***if the angle theta is between 225 and 315, should activate Down direction neuron.
***add NetStim to direction selective neurons.
***broadcast firing rates for direction selective cells from root/Master node to all workers.
***receive firing rates for direction selective cells and assign those firing rates to all direction selective neurons.
***assign firing rates to direction selective neurons.
***test sim...2000ms
***Assigning firing rates to stimMod gave error----out of index. It worked for R neurons because there was no offset. cells were from 0-399. But now the cells have offset. so included offset....hopefully will work.
***Ah another mistake--better use hard coded number for now. change later.

*20mar26
**debug firing rate assignments
***print cells.gids for RDir sensitive neurons.
***cell properties properly assigned
**plot raster.
**use 30Hz instead of 5 Hz. firing for direction selective neurons.
**save raster data in pickle.
**Direction sensitive cells fired only once (all at the same time) during 2s simulation. Should not be the case.

*20mar27
**to understand why direction selective neurons are not firing, pass 30 hz firing rate to all neurons of pop 'EV1RDir0'
**print firing_rates_dirR ---to see if the correct firing rates are broadcasted. ---->correct firing rates are broadcasted.
**print firing_rates_dirR in all nodes --- to see if the broadcast was successful or not. ---->broadcast is working.
**now check if the ISI was assigned to the R-dir selective neuron or not?
***using the statement print('Neuron ', cell, 'on', sim.rank,' was assigned ISI of ', stim['hObj'].interval, ' ms') gave error. The error was probably related with Neuron update on zn.
***remove this statement and rerun. The error was probably related with Neuron update on zn.
***again use print('Neuron ', cell, 'on', sim.rank,' was assigned ISI of ', stim['hObj'].interval, ' ms')---assigned correctly but still no spike.
***to check if 30Hz is a good number or not, may be try using firing rates for R neurons. ---still no firing in raster plot.
***use 10 ms for stim-interval---->same results...no spikes.
***only use stim with RDir neurons.---->same results
***change the sequence of cell creation. first create EV1RDir0 and then ER. same with stimMod->all connections.
***revert changes in sequence of cell creation.
***get rid of offset for assigning rates to R neurons.
***see different firing patterns when use int(cell.gid) vs int(cell.gid-R_offset) ---PROBLEM HERE these two values dont match.
***use 10 ms interval for Rneurons.
***print R offset---R offset is different everytime. Use fix values for now.
***set RDir_offset to 900.
***print list of RDir neurons.
**So the PROBLEM all the way was not with the assignment of ISI for the stim to drive Direction selective neurons, but because the strength was too high and was causing neurons to go into depolarization block.
**started reducing weight from 1 to 0.1 (still high) and now to 0.02.
***to fix connection strengths of stim input, restore original firing rates except for EV1Dir0 (30 Hz.)
**restore all original firing rates.

*20mar30
**Sal suggested to use sim._gatherAllCellTags() to gather tags for all cells. gather and print to see what information is there.
**make a list of gids and find list of gids for ER, EV1D0, EV1D90, EV1D180, EV1D270 to find the offset. (adding additional computation).
**use these lists to find the offset to access firing rates of neurons encoding different directions.
**use 30Hz stim to drive direction selective neurons.
**add more direction selective neurons (for 8 directions now: 'EV1D0','EV1D45','EV1D90','EV1D135','EV1D180','EV1D225','EV1D270','EV1D315')
**Increase the Field of View (FOV) from 3x3 pixels to 5x5 pixels. (to have a better estimate for the direction). This may help in estimating direction of movement better for most of the times, except when ball is very close to the racket.
**Print theta and field of view when theta is not nan.
**debug FOV indexing.--->debugged
**looking at the raster and voltage traces saved as "20Mar30_G0_step_0_g0_02_CellX_200sec_FOV5x5.png" and raster plot ""20Mar30_G0_step_0_g0_02_raster_200sec_FOV5x5.png"", it seems that the strength is too much because 2 cells recorded show block. But at the same time, we need to be careful that the strength is enough to relay the pixel intensities in image. But for now focus on direction.
**In stimtargetparams for direction selective neurons, change connection strength to 0.01.
**comment out print statements used for debugging.
**change baseline firing rate of direction selective neurons to 0.0001 Hz (instead of 1 Hz).
**change firing rate to 10Hz.

*20mar31
**print measured angles.
**was using some numpy functions incorrectly. also was considering best case scenerio with 1 max and 1 min value to measure direction of object motion. sometimes the object does not move in the fielf of view and therefore give same inidices for min and max. so now i take the difference between min and max and then take median to get a direction vector. also was using x direction as y direction. ---->Looks like these issues fixed. IF FIND SOMETHING UNUSUAL, CHECK AGAIN. I CHECKED IT FOR A COUPLE OF IMAGE SEQUENCES AND IT WORKS FINE.
**error on line 252 in aigame.py computing this equation (dir1 = [max_ind[0]-min_ind[0],max_ind[1]-min_ind[1]])--->not robust.
**it broke when the dimensions of max_ind is different than min_ind. check it.
**use the dimensions of max_ind and min_ind to be the lower of both e.g. if one has 2x3 and the other 2x4. Use 2x3 for both.
**test if the above mentioned solution worked or not.

*20april01
**debug angle offset - using x and y inds in matrix is different than x and y axis used to compute angle.
**i think its fixed now- check the debugged version.
**flip y coordinate before computing angle because indexing starts from top left corner of the image.
**again not plotting raster for me. I dont know what is wrong. so trying to plot it outside doplot control.
**Saving and plotting is not working when using if sim.rank==0, therefore i remove that statement.
**when running simulation using "python multistepSim.py sim.json numcores numsteps multirun" plotting and saving doesn't work properly. so include an option usemultirun in the script.

*20april03
**seperate targets of StimMod by creating 2 separate stimTargetParams dictionaries. One is stimMod->R and other is stimMod->DirSelInput.
**Strategy for connections onto EMR and EML neurons.
***Each presynaptic neurons should connect to only 1 postsynaptic neuron. so if we have neurons projecting onto Motor neurons are in the list {"EV1":400,"EV1D0":100,"EV1D45":100,"EV1D90":100,"EV1D135":100,"EV1D180":100,"EV1D225":100,"EV1D270":100,"EV1D315":100,"EV4":100,"EIT":25} -->Total neurons = 1350. Therefore we shoul dhave 1350 neurons for ML and 1350 neurons for MR.
**change pop names from directions in angles to directions in terms of E,NE,N,NW,W,SW,S,SE.
**create a function to make list of connections between neurons in premotor areas and motor areas.
**create lists of connections between neurons in premotor areas and motor areas.
**change IT neurons to MT neurons.
**include long range connections between premotor and motor areas using both AMPA and NMDA synaptic mechanisms.
**run 2sec sim to test if the model runs with all new changes and to detect any errors/bugs.
**update pop tags in plotSpatioTemporalActivity.py
**update pop tags in aigame.py
**correct typo 
**i forgot to update nb of ML and MR neurons in sim.json-----updated NB of ML and MR neurons to 1350 each.
**in function updateInputRates(), forgot to update pop tags for direction selective neurons.----done.
**Looks like the weights are too low. Previously, each neuron in ML and MR was receiving 16 connections. so i decided to change synaptic weights 10 times. for AMPA connections between premotor and motor areas, change synaptic strength from 0.0025 to 0.025. Similarly, change synaptic strength of NMDA connections between premotor and motor areas to 0.02 from 0.002. and run for 20sec.

*20april06
**added recurrent connections with weights recWeight = 0.0001 and recProb = 0.2
**run sim for 20 sec with recurrent connectivity. Raster saved as "20April06_G0_step_0_raster_20sec_RecurEAdded.png"
**include direction selective neurons in simdat.py for analysis.
**debugging simdat.py 
**change firing rate of direction selective neurons to 30 Hz and run for 5 sec.

*20april07
**show image upside down in plotSpatioTemporalActivity using origin='upper' in imshow.
**make initial weight between premotor areas and motor areas same.
**debug plotSpatioTemporalActivity.py 


*20april08
**plot weights evolving with times using function plotSynWeightsPerTimeStep(pdf) in simdat.py
**while testing plotSynWeightsPerTimeStep(pdf), i noticed that the number of connections between premotor and motor areas were different than what i wanted it to be. For 1-1 connections, only 1 premotor neuron should connect to 1 motor neuron in Left and right motor populations. But this was not the case. So need to find the problem and fix it.
**run 500 ms sim to check the connections from V1 to M, V4 to M and MT to M.
**there was a bug in analysis simdat.py:
cpdfR = pdf[(pdf.time==t) & (pdf.postid>=dstartidx['EMR']) & (pdf.postid<=dendidx['EMR']) & (pdf.preid>=dstartidx[src]) & (pdf.preid<=dendidx['EMR'])]
Corrected as:
cpdfR = pdf[(pdf.time==t) & (pdf.postid>=dstartidx['EMR']) & (pdf.postid<=dendidx['EMR']) & (pdf.preid>=dstartidx[src]) & (pdf.preid<=dendidx[src])]
This bug was found in all functions where instead of src, trg was used for dendidx.
**reshape weights for display
**R removed from list + axes indexing debugged
**increase imshow range by 0.1.
**add plt.pause.
**add min range for imshow.
**remove unused axes.
**increasing range by 0.1 was too much. increase by 10% of the range of weights.

*20april09
**save movies of weights evolution as '_weightmap.mp4' in 'data/'
**test if _weightmap.mp4 is working properly.
***movie saved but with following issues: 1. the order is not correct. 2. some glitch (purple-pink color instead of gray scale for a couple of frames) in the color.
**change time-inds instead of time for png files.
***make the name of image.png same for all times by adding tpre using appended '00...' e.g if there are 100 images to be save, images will be saved as 001.png, 002.png .....010.png,020.png,.....,100.png 
***run 10 sec sim.
**To quantify behavior we record:
1. time point
2. action performed by the agent
3. reward (+1 if Agent wins a point, -1 if Agent loses a point)
4. action proposed to follow the ball (the proposed action is to follow the ball)
5. 1 if agent hits the ball (this action leads to avoid loss of point)  

*20april10
**plot FollowBall, HitBall and scorePoint together with weights.
**Looks like Hit Ball is not detected correctly in the algorithm. So need to check that.
**Since there was not hit ball or score point in the behavior, i will plot these behavioral outputs later.
**Right now i am plotting rewards (total rewards) and mean weights onto EML and EMR and mark time.

*20april13
**out of sequence image frames in movies using simdat.py fixed. the problem was with naming the files. previously when i tried to fix it. i didnt use the sting concentration function properly. It works now and all movies have images in sequence.
**plotting only game behavior using testPong.py. This can be integrated with the model output later. This is to understand the game behavior and to validate all the rules used for training the model. Should be run separately.
**saved 1000 steps random game behavior (not driven by the model).

*20april14
**Improved behavior plotting---still with random game.
***display: 
1. Executed actions vs Proposed actions (actions are proposed to follow the ball)
2. number of rewarding actions (when executed action is same as proposed action) vs punishing actions (when exectued action is different than the proposed action) normalized.
3. rewards as a function of actions. (0, -1 or +1)
4. cummulative hits (when racket hits the ball) vs cummulative miss (when racket misses the ball and lose a point).
5. per episode, how many times followed the ball vs not followed the ball.
6. per episode, how many times hit the ball vs missed the ball
7. per episode, how many times scored +1 against the computer.
***testing the code for many many episodes now. 

*20april16
**performance parameters mentioned in 5,6 and 7 are not displaying as i wanted it to be (i.e. as a function of episodes)----Need to be fixed.
**Need to plot following for the performance evaluation.
1. number of rewarding actions (when executed action is same as proposed action) vs punishing actions (when exectued action is different than the proposed action) normalized. (same as mentioned in 2 above for testPong.py)
2. cummulative hits (when racket hits the ball) vs cummulative miss (when racket misses the ball and lose a point). (same as mentioned in 4 above for testPong.py)
3. per episode, how many times followed the ball vs not followed the ball. (same as mentioned in 5 above for testPong.py)
4. per episode, how many times hit the ball vs missed the ball. (same as mentioned in 6 above for testPong.py)
5. per episode, how many times scored +1 against the computer. (same as mentioned in 7 above for testPong.py)
**included 1 in simdat.py. test now.
**adjust positions of subplots. 1 is working fine.
**include 2 in simdat.py. test now.
**use -1 in hits if the racket misses the ball and loses a point.
**update behavior plot in simdat.py using hit values of 1 for hit and -1 for miss.

*20April20
**return Images (of pong without downsampling), racket position, ball position and computed angles of object motion from playGame in aigame.py.
**implementing a plotBehavior function in sim.py using all the behavior related parameters returned from playGame.
**plot behavior with sim. testing now.---->movie not recorded properly.
**may be not close the figure and pass figure handles in and out of function.---try this.
**above test looks OK. saved actmap, weightsmap and behavior as movies with name '20april20_A0_'. Time simulated was 10 sec.
**USE NEW RL SCHEME:
***create 2 lists of STDPmech with postsynaptic neurons in EML and EMR.
***count number of L actions (in 5 steps) and number of R actions (in 5 steps)
***if number of L actions is equal to number of R actions, apply RL to all STDP mechanisms.
***if number of L actions is larger than the number of R actions, apply RL to STDP mechanisms related to EML.
***if number of R actions is larger than the number of L actions, apply RL to STDP mechanisms related to EMR.
****CAUTION: This is very crude form of scheme. Originally each action has a reward associated with it and therefore RL should be applied for each action individually. Here testing the concept and if there is a slight hint of improved behavior, should pursue further.
***BUG Ractions and Lactions could not be computed because actions were available only to sim.rank of 0.
****computed Ractions and Lactions on sim.rank of 0. Declared Ractions and Lactions as global variables expecting that these variables will be available to all nodes. Now hoping that Ractions and Lactions are updated in correct order----not sure how to test that. testing using print statements.---->Didn't work.
***need to broadcast this signal to all nodes. implemented broacdcasting and receiving vec2 with [Ractions, Lactions]. Test if works or not.
***using seperate vectors for each Ractions and Lactions.
****was missing receive call. added receive call for both vec2 and vec3. should work now. testing again.
**remove Ractions and Lactions from global variable list. print values of Ractions and Lactions to figure out why not working.
**convert list to array before applying np.where.
**typo mrSTDPmech was used as rlSTDPmech
**SEEMS TO BE WORKING-----RUN THE SIM FOR 100sec  overnight with recording behavior. prefix "20april20_B0_"

*20April21
**test running sim using a single action of game.
***CHANGES: 
1. tstepPerAction = 20.0
2. dconf['actionsPerPlay'] = 1
3. tPerPlay = tstepPerAction*dconf['actionsPerPlay']
4. sim.runSimWithIntervalFunc(tPerPlay,trainAgent)
5. range(dconf['actionsPerPlay']) in trainAgent(t) func---line 1302 in sim.py
6. t<tPerPlay: in trainAgent(t) func -- line 1300 in sim.py
7.      F_Rs = []
        F_Ls = []
        for ts in range(int(dconf['actionsPerPlay'])):
            ts_end = t-tstepPerAction*(dconf['actionsPerPlay']-ts)
            ts_beg = t-tstepPerAction*(dconf['actionsPerPlay']-ts-1)
            F_Rs.append(getFiringRatesWithInterval([ts_end,ts_beg], sim.net.pops['EMR'].cellGids))
            F_Ls.append(getFiringRatesWithInterval([ts_end,ts_beg], sim.net.pops['EML'].cellGids))
        sim.pc.allreduce(vec.from_python(F_Rs),1) #sum
        F_Rs = vec.to_python()[0]
        sim.pc.allreduce(vec.from_python(F_Ls),1) #sum
        F_Ls = vec.to_python()[0]
-----------------------------------------------------        
8.            for ts in range(int(dconf['actionsPerPlay'])):
                if F_Rs[ts]>F_Ls[ts]:
                    actions.append(dconf['moves']['UP'])
                elif F_Ls[ts]>F_Rs[ts]:
                    actions.append(dconf['moves']['DOWN'])
                else:
                    actions.append(dconf['moves']['NOMOVE']) # No move 
***test changes in sim.py using 5 actionsPerPlay = 5
*** use vec.to_python() instead of vec.to_python()[0]; since passing vector. -- looks good. "20april21_A0_"
**clean the code.
**run with actionsPerPlay = 2 in file with prefix "20april21_B0_"---Bug
***Fix bug: update intaction from sim.json   

*20April22
**problem in plotting behavior when using 2 actionsPerPlay.
***run sim using 2 actionsPerPlay without plotting behavior.
**fixed hits/miss-hits plot in recording behavior. also run simdat.py and actmap.py for "20april21_B0_" for 2 actionsPerPlay. No behavior saved while runing simulation.
**run sim with 2 actionsPerPlay for 100 sec with prefix "20april21_C0_". No behavior movie. only weightsmap and actmap movies.
**ran sim with 2 actionsPerPlay for 5 sec with prefix "20april22_A0_" with randomBehavior movie to test if the brhavior plotting is working fine. updateBehaviorPlot worked FINE with 2 actionsPerPlay. only behavior movie saved.
**Now need to start testing for 1 actionPerPlay.
**function computMotion needs atleast 2 images to compute the motion direction. when we are using 1 actionPerPlay, use previous image with one image to compute the direction.
**CHANGES in aigame.py:
***always process last_obs, whenever it is not empty.
    if len(self.last_obs)==0: #if its the first action of the episode, there won't be any last_obs, therefore no last image
      lobs_gimage_ds = []
    else:
      lobs_gimage = 255.0*rgb2gray(self.last_obs[courtYRng[0]:courtYRng[1],:,:]) 
      lobs_gimage_ds = downscale_local_mean(lobs_gimage,(8,8))
      lobs_gimage_ds = np.where(lobs_gimage_ds>np.min(lobs_gimage_ds)+1,255,lobs_gimage_ds)
      lobs_gimage_ds = 0.5*lobs_gimage_ds #use this image for motion computation only
***Do this only after computing firing rates for E, when number of actionsPerPlay is 1:
    if self.intaction==1: #if only one frame used per play, then add the downsampled and scaled image from last_obs for direction computation 
      if len(lobs_gimage_ds)>0:
        dsum_Images = np.maximum(dsum_Images,lobs_gimage_ds)
    dirs = self.computeMotion(dsum_Images)
***run sim of 100 sec to test the code for actionsPerPlay = 1 and save with prefix: "20april22_B0_"
***sim working, needs to check if directions are computed correctly. so better plotbehavior with sim.
**running 100 sec sim with reduced nb of direction selective neurons, reduced nb of motor neurons, changed from one-one pre-to-post motor connections, actionsPerPlay = 1 and FakeRuleUp=1. The sim results are prefixed "20april23_FU1_". No behavior is saved during sim.---->told sam that the sim was slow (~3PM). (RUNTIME:31664s; 4075 cells,621973 connections, 623807 synaptic contacts, 1936507 spikes, 4.75 Hz)
**running 100 sec sim with reduced nb of direction selective neurons, reduced nb of motor neurons, changed from one-one pre-to-post motor connections, actionsPerPlay = 1. The sim results are prefixed "20april23_A1_". No behavior is saved during sim. ---->may be sam fixed something before i ran this simulation (~8:20PM). conn convergence from pre to post motor synapses is 16. no behavior saving during sim. Use reward coded: BEFORE: "rewardcodes": {"scorePoint": 1, "losePoint": -0.01, "followBall": 0.01, "avoidBall": -0.001, "hitBall": 0.25} and THIS SIM: "rewardcodes": {"scorePoint": 0.2, "losePoint": -0.1, "followBall": 0.01, "avoidBall": -0.01, "hitBall": 0.1} - GOT ABORTED FOR SOME REASON

*20April24
**ALSO FOR COMPARISON: Run same sim with actionsPerPlay =2 and the results prefixed with "20april23_A2_" ---GOT ABORTED FOR UNKNOWN REASON - run again for 50 sec
PROBLEM: LOOKS LIKE A PROBLEM IN ALL 3 SIMS prefixed with "date 20april23_" coz when number of dir selective neurons were reduced it didnt compute the directions for FOV covering whole image. so restore nb of neurons in dir selective layers and rerun with 1 action. outputs in "20april24_A1"

*20April27 and 20April28
**THINGS TRIED FOR OPTICAL FLOW:

**Tried Method Nb 1: (https://scikit-image.org/docs/dev/auto_examples/registration/plot_opticalflow.html#sphx-glr-auto-examples-registration-plot-opticalflow-py)

import cv2
from matplotlib import pyplot as plt
import numpy as np
import gym
env = gym.make('Pong-v0')
env.reset()
observation, reward, done, info = env.step(3)

for _ in range(30): #running 30 times, so that ball appears in the court.
  observation, reward, done, info = env.step(3)
  observation, reward, done, info = env.step(4)
  observation, reward, done, info = env.step(4)
  observation, reward, done, info = env.step(4)
  observation, reward, done, info = env.step(4)

o1, reward, done, info = env.step(4)
o2, reward, done, info = env.step(4)
o3, reward, done, info = env.step(4)

from skimage.color import rgb2gray
from skimage.registration import optical_flow_tvl1
o1 = rgb2gray(o1)
o2 = rgb2gray(o2)
o3 = rgb2gray(o3)
v3, u3= optical_flow_tvl1(o2, o3) ---->METHOD 1
amps = np.add(np.square(u3),np.square(v3))
good_inds = np.where(amps>0.5,1,0) 
u3_filt = np.multiply(u3,good_inds)
v3_filt = np.multiply(v3,good_inds)
angles = np.degrees(np.arctan2(u3_filt,v3_filt))
for i in range(angles.shape[0]):
  for j in range(angles.shape[1]):
    if angles[i,j]<0: angles[i,j]=360+angles[i,j]
fig = plt.figure(figsize=(8,4))
gs = fig.add_gridspec(1,3)
ax0 = fig.add_subplot(gs[0,0])
ax1 = fig.add_subplot(gs[0,1])
ax2 = fig.add_subplot(gs[0,2])
cbaxes = fig.add_axes([0.92, 0.2, 0.01, 0.6])
ax0.imshow(o2)
ax0.set_title('o2')
ax1.imshow(o3)
ax1.set_title('o3')
fa = ax2.imshow(angles,origin='upper',vmin=np.nanmin(angles), vmax=np.nanmax(angles), cmap='Dark2')
ax2.set_title('Dir Angles')
plt.colorbar(fa,cax = cbaxes)
plt.show()


***Shows the location for flow but the angles are neither precise nor informative.

**Tried Method No. 2 (https://sandipanweb.wordpress.com/2018/02/25/implementing-lucas-kanade-optical-flow-algorithm-in-python/)

def optical_flow(I1g, I2g, window_size, tau=1e-2):
  kernel_x = np.array([[-1., 1.], [-1., 1.]])
  kernel_y = np.array([[-1., 1.], [-1., 1.]])
  kernel_y = np.array([[-1., -1.], [1., 1.]])
  kernel_t = np.array([[1., 1.], [1., 1.]])
  w = int(window_size/2)
  I1g = I1g / 255
  I2g = I2g
  mode = 'same'
  fx = signal.convolve2d(I1g, kernel_x, boundary='symm', mode=mode)
  fy = signal.convolve2d(I1g, kernel_y, boundary='symm', mode=mode)
  ft = signal.convolve2d(I2g, kernel_t, boundary='symm', mode=mode) + signal.convolve2d(I1g, -kernel_t,        boundary='symm', mode=mode)
  u = np.zeros(I1g.shape)
  v = np.zeros(I1g.shape)
  for i in range(w, I1g.shape[0]-w):
    for j in range(w, I1g.shape[1]-w):
      Ix = fx[i-w:i+w+1, j-w:j+w+1].flatten()
      Iy = fy[i-w:i+w+1, j-w:j+w+1].flatten()
      It = ft[i-w:i+w+1, j-w:j+w+1].flatten()
      b = np.reshape(It, (It.shape[0],1))
      A = np.vstack((Ix, Iy)).T
      if np.min(abs(np.linalg.eigvals(np.matmul(A.T, A)))) >= tau:
        nu = np.matmul(np.linalg.pinv(A), b) # get velocity here
        u[i,j]=nu[0]
        v[i,j]=nu[1]
  return (u,v)

u,v=optical_flow(I0,I1,3,tau=1e-16) --->This method seems to work better than "optical_flow_tvl1"
angles = np.degrees(np.arctan2(v,u))
for i in range(angles.shape[0]):
  for j in range(angles.shape[1]):
    if angles[i,j]<0: angles[i,j]=360+angles[i,j]
plt.imshow(angles)
plt.colorbar()
plt.show()

***Shows the location for flow, angles are somewhat accurate (~approximately). But still no information at all spatial locations.

**Tried Method Nb. 3 (https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_video/py_lucas_kanade/py_lucas_kanade.html)
***The function p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params) gave me errors. Probably didnt provide p0 properly. In the example, they use p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params) to extract corners using these parameters (feature_params = dict( maxCorners = 100,qualityLevel = 0.3,minDistance = 7,blockSize = 7 ))

*20April29
**Trying Nb. 3 again.

import cv2
flow45 = cv2.calcOpticalFlowFarneback(o4,o5, None, 0.5, 3, 15, 3, 5, 1.2, 0)
mag45, ang45 = cv2.cartToPolar(flow45[...,0], flow45[...,1])
goodInds = np.where(mag45<1e-10,0,1)
plt.imshow(np.degrees(np.multiply(ang45,goodInds)))
plt.colorbar()
plt.show()

0.5 - image pyramid or simple image scale
3 - nb of pyramidal layer. if used 1 means flow is calculated only from previous image.
15 - win size. flow is computed over the window....larger value is more robust to the noise.
3 - nb of iterations
5 - polynominal degree expansion. (recommended 5-7)
1.2 - standard deviation used to smooth used derivatives. (recommended 1.1-1.5)

flow45 = cv2.calcOpticalFlowFarneback(o4,o5, None, 0.5, 3, 15, 3, 5, 1.2, 0)
mag45, ang45 = cv2.cartToPolar(flow45[...,0], flow45[...,1])
goodInds = np.where(mag45<1e-10,0,1)
plt.subplot(2,2,1)
plt.imshow(o4)
plt.colorbar()
plt.subplot(2,2,2)
plt.imshow(o5)
plt.colorbar()
plt.subplot(2,2,3)
plt.imshow(np.degrees(np.multiply(ang45,goodInds)))
plt.colorbar()
plt.subplot(2,2,4)
plt.imshow(np.multiply(mag45,goodInds))
plt.colorbar()
plt.show()


flow35 = cv2.calcOpticalFlowFarneback(o3,o5, None, 0.5, 1, 5, 3, 5, 1.2, 0)
mag35, ang35 = cv2.cartToPolar(flow35[...,0], flow35[...,1])
goodInds = np.where(mag35<1e-10,0,1)
plt.subplot(2,2,1)
plt.imshow(o3)
plt.colorbar()
plt.subplot(2,2,2)
plt.imshow(o5)
plt.colorbar()
plt.subplot(2,2,3)
plt.imshow(np.degrees(np.multiply(ang35,goodInds)))
plt.colorbar()
plt.subplot(2,2,4)
plt.imshow(np.multiply(mag35,goodInds))
plt.colorbar()
plt.show()


flow34 = cv2.calcOpticalFlowFarneback(o3,o4, None, 0, 1, 10, 3, 5, 1.2, 0)
mag34, ang34 = cv2.cartToPolar(flow34[...,0], flow34[...,1])
goodInds = np.where(mag34<1e-10,0,1)
plt.subplot(2,2,1)
plt.imshow(o3)
plt.colorbar()
plt.subplot(2,2,2)
plt.imshow(o4)
plt.colorbar()
plt.subplot(2,2,3)
plt.imshow(np.degrees(np.multiply(ang34,goodInds)))
plt.colorbar()
plt.subplot(2,2,4)
plt.imshow(np.multiply(mag34,goodInds))
plt.colorbar()
plt.show()

*20may1
**create a toy model to understand the homeostatic-synaptic plasticity model 'hsyn'.
***The model has 2 cells, cell 0 is driven by stimMod at 10 Hz, cell 1 is driven by a background firing rate of 5 Hz. 


*20may4
**Using toymodel 
***with STDP-RL:
{preGid: 0, sec: 'soma', loc: 0.5, synMech: 'AMPA', weight: 0.02, delay: 20, plast: {mech: 'STDP', params: {hebbwt: 0.001, antiwt: -0.0005, wmax: 50, STDPon: 1, RLon: 1, RLhebbwt: 0.001, RLantiwt: -0.0002, tauhebb: 10, RLwindhebb: 100, useRLexp: 0, softthresh: 0, verbose: 1}}, label: 'R->M', hObj: NetCon[0], hSTDP: STDP[0], hSTDPprecon: NetCon[1], hSTDPpstcon: NetCon[2], STDPdata: {'preGid': 0, 'postGid': 1, 'receptor': 0}}
***with hsyn:
{preGid: 0, sec: 'soma', loc: 0.5, synMech: 'AMPA', weight: 0.02, delay: 20, plast: {mech: 'hsyn', params: {targetrate: 1, scaling: 1, rateinc: 1, ratedectau: 1000.0, scaleratefctr: 0.001}}, label: 'R->M', hObj: NetCon[0]}
***I thought i could either use STDP-RL or homeostatic synaptic plasticity as 'plasticity' in connections. But in fact, i can use hsyn in the synMechParams and then use STDP-RL for connParams.
**To play with the model:
1. 2Hz stimMod drives 1 ER neuron which in turn drives 1 EM neuron. In the absence of STDP-RL, and targetfiring rate = 0, both neurons ER and EM fire at 2 Hz.
2. Use targetrate = 1:

For 2Hz presynaptic spiking: B is increasing as scalefactor is increasing.
      A = A + w * factor * scalefactor
      B = B + w * factor * scalefactor
NET_RECEIVE@t=6.4: w=0.01: firingrate=0: A=0: B=0: factor=1.05537 scalefactor=1.0064:in
NET_RECEIVE@t=528.4: w=0.01: firingrate=0: A=0: B=1.78758e-45: factor=1.05537 scalefactor=1.5284:in NET_RECEIVE@t=1028.4: w=0.01: firingrate=0: A=0: B=1.72371e-43: factor=1.05537 scalefactor=2.0284:in NET_RECEIVE@t=1528.4: w=0.01: firingrate=0: A=0: B=2.28761e-43: factor=1.05537 scalefactor=2.5284:in NET_RECEIVE@t=2028.4: w=0.01: firingrate=0: A=0: B=2.8515e-43: factor=1.05537 scalefactor=3.0284:in NET_RECEIVE@t=2528.4: w=0.01: firingrate=0: A=0: B=3.41539e-43: factor=1.05537 scalefactor=3.5284:in NET_RECEIVE@t=3028.4: w=0.01: firingrate=0: A=0: B=3.97929e-43: factor=1.05537 scalefactor=4.0284:in NET_RECEIVE@t=3528.4: w=0.01: firingrate=0: A=0: B=4.54318e-43: factor=1.05537 scalefactor=4.5284:in NET_RECEIVE@t=4028.4: w=0.01: firingrate=0: A=0: B=5.10708e-43: factor=1.05537 scalefactor=5.0284:in NET_RECEIVE@t=4528.4: w=0.01: firingrate=0: A=0: B=5.67097e-43: factor=1.05537 scalefactor=5.5284:in NET_RECEIVE@t=5028.4: w=0.01: firingrate=0: A=0: B=6.23487e-43: factor=1.05537 scalefactor=6.0284:in NET_RECEIVE@t=5528.4: w=0.01: firingrate=0: A=0: B=6.79876e-43: factor=1.05537 scalefactor=6.5284:in NET_RECEIVE@t=6028.4: w=0.01: firingrate=0: A=0: B=7.36265e-43: factor=1.05537 scalefactor=7.0284:in NET_RECEIVE@t=6528.4: w=0.01: firingrate=0: A=0: B=7.92655e-43: factor=1.05537 scalefactor=7.5284:in NET_RECEIVE@t=7028.4: w=0.01: firingrate=0: A=0: B=8.49044e-43: factor=1.05537 scalefactor=8.0284:in NET_RECEIVE@t=7528.4: w=0.01: firingrate=0: A=0: B=9.05434e-43: factor=1.05537 scalefactor=8.5284:in NET_RECEIVE@t=8028.4: w=0.01: firingrate=0: A=0: B=9.61823e-43: factor=1.05537 scalefactor=9.0284:in NET_RECEIVE@t=8528.4: w=0.01: firingrate=0: A=0: B=1.01821e-42: factor=1.05537 scalefactor=9.5284:in NET_RECEIVE@t=9028.4: w=0.01: firingrate=0: A=0: B=1.0746e-42: factor=1.05537 scalefactor=10.0284:in NET_RECEIVE@t=9528.4: w=0.01: firingrate=0: A=0: B=1.13099e-42: factor=1.05537 scalefactor=10.5284:in

--i dont understand how A and B are evolving differently.
print before and after A and B assignments.

For 2Hz presynaptic spiking: B is increasing as scalefactor is increasing.
      A = A + w * factor * scalefactor
      B = B + w * factor * scalefactor
NET_RECEIVE@t=6.4: w=0.01: firingrate=0: A=0: B=0: factor=1.05537 scalefactor=1.0064:in 
NET_RECEIVE@t=6.4: A=0.0106213: B=0.0106213:in 
NET_RECEIVE@t=528.4: w=0.01: firingrate=0: A=0: B=1.78758e-45: factor=1.05537 scalefactor=1.5284:in NET_RECEIVE@t=528.4: A=0.0161303: B=0.0161303:in 
NET_RECEIVE@t=1028.4: w=0.01: firingrate=0: A=0: B=1.72371e-43: factor=1.05537 scalefactor=2.0284:in NET_RECEIVE@t=1028.4: A=0.0214071: B=0.0214071:in 
NET_RECEIVE@t=1528.4: w=0.01: firingrate=0: A=0: B=2.28761e-43: factor=1.05537 scalefactor=2.5284:in NET_RECEIVE@t=1528.4: A=0.026684: B=0.026684:in 
NET_RECEIVE@t=2028.4: w=0.01: firingrate=0: A=0: B=2.8515e-43: factor=1.05537 scalefactor=3.0284:in NET_RECEIVE@t=2028.4: A=0.0319609: B=0.0319609:in 
NET_RECEIVE@t=2528.4: w=0.01: firingrate=0: A=0: B=3.41539e-43: factor=1.05537 scalefactor=3.5284:in NET_RECEIVE@t=2528.4: A=0.0372377: B=0.0372377:in 
NET_RECEIVE@t=3028.4: w=0.01: firingrate=0: A=0: B=3.97929e-43: factor=1.05537 scalefactor=4.0284:in NET_RECEIVE@t=3028.4: A=0.0425146: B=0.0425146:in 
NET_RECEIVE@t=3528.4: w=0.01: firingrate=0: A=0: B=4.54318e-43: factor=1.05537 scalefactor=4.5284:in NET_RECEIVE@t=3528.4: A=0.0477914: B=0.0477914:in 
NET_RECEIVE@t=4028.4: w=0.01: firingrate=0: A=0: B=5.10708e-43: factor=1.05537 scalefactor=5.0284:in NET_RECEIVE@t=4028.4: A=0.0530683: B=0.0530683:in 
NET_RECEIVE@t=4528.4: w=0.01: firingrate=0: A=0: B=5.67097e-43: factor=1.05537 scalefactor=5.5284:in NET_RECEIVE@t=4528.4: A=0.0583451: B=0.0583451:in 
NET_RECEIVE@t=5028.4: w=0.01: firingrate=0: A=0: B=6.23487e-43: factor=1.05537 scalefactor=6.0284:in NET_RECEIVE@t=5028.4: A=0.063622: B=0.063622:in 
NET_RECEIVE@t=5528.4: w=0.01: firingrate=0: A=0: B=6.79876e-43: factor=1.05537 scalefactor=6.5284:in NET_RECEIVE@t=5528.4: A=0.0688988: B=0.0688988:in 
NET_RECEIVE@t=6028.4: w=0.01: firingrate=0: A=0: B=7.36265e-43: factor=1.05537 scalefactor=7.0284:in NET_RECEIVE@t=6028.4: A=0.0741757: B=0.0741757:in 
NET_RECEIVE@t=6528.4: w=0.01: firingrate=0: A=0: B=7.92655e-43: factor=1.05537 scalefactor=7.5284:in 
NET_RECEIVE@t=6528.4: A=0.0794526: B=0.0794526:in 
NET_RECEIVE@t=7028.4: w=0.01: firingrate=0: A=0: B=8.49044e-43: factor=1.05537 scalefactor=8.0284:in NET_RECEIVE@t=7028.4: A=0.0847294: B=0.0847294:in 
NET_RECEIVE@t=7528.4: w=0.01: firingrate=0: A=0: B=9.05434e-43: factor=1.05537 scalefactor=8.5284:in NET_RECEIVE@t=7528.4: A=0.0900063: B=0.0900063:in 
NET_RECEIVE@t=8028.4: w=0.01: firingrate=0: A=0: B=9.61823e-43: factor=1.05537 scalefactor=9.0284:in NET_RECEIVE@t=8028.4: A=0.0952831: B=0.0952831:in 
NET_RECEIVE@t=8528.4: w=0.01: firingrate=0: A=0: B=1.01821e-42: factor=1.05537 scalefactor=9.5284:in NET_RECEIVE@t=8528.4: A=0.10056: B=0.10056:in 
NET_RECEIVE@t=9028.4: w=0.01: firingrate=0: A=0: B=1.0746e-42: factor=1.05537 scalefactor=10.0284:in NET_RECEIVE@t=9028.4: A=0.105837: B=0.105837:in 
NET_RECEIVE@t=9528.4: w=0.01: firingrate=0: A=0: B=1.13099e-42: factor=1.05537 scalefactor=10.5284:in NET_RECEIVE@t=9528.4: A=0.111114: B=0.111114

g = B-A

A is 0 whenever a spike is received. B is a very small value inclreasing with spikes.
so based on this, g should be 0 at each time step.
still dont understand

print with NET_RECEIVE and state:

before a spike is received
in state @t=0.2: A=0: B=0: firingrate:0 scalefactor:1.0002
in state @t=0.4: A=0: B=0: firingrate:0 scalefactor:1.0004
in state @t=0.6: A=0: B=0: firingrate:0 scalefactor:1.0006
in state @t=0.8: A=0: B=0: firingrate:0 scalefactor:1.0008
in state @t=1: A=0: B=0: firingrate:0 scalefactor:1.001
in state @t=1.2: A=0: B=0: firingrate:0 scalefactor:1.0012
in state @t=1.4: A=0: B=0: firingrate:0 scalefactor:1.0014
in state @t=1.6: A=0: B=0: firingrate:0 scalefactor:1.0016
in state @t=1.8: A=0: B=0: firingrate:0 scalefactor:1.0018
in state @t=2: A=0: B=0: firingrate:0 scalefactor:1.002
in state @t=2.2: A=0: B=0: firingrate:0 scalefactor:1.0022
in state @t=2.4: A=0: B=0: firingrate:0 scalefactor:1.0024
in state @t=2.6: A=0: B=0: firingrate:0 scalefactor:1.0026
in state @t=2.8: A=0: B=0: firingrate:0 scalefactor:1.0028
in state @t=3: A=0: B=0: firingrate:0 scalefactor:1.003
in state @t=3.2: A=0: B=0: firingrate:0 scalefactor:1.0032
in state @t=3.4: A=0: B=0: firingrate:0 scalefactor:1.0034
in state @t=3.6: A=0: B=0: firingrate:0 scalefactor:1.0036
in state @t=3.8: A=0: B=0: firingrate:0 scalefactor:1.0038
in state @t=4: A=0: B=0: firingrate:0 scalefactor:1.004
in state @t=4.2: A=0: B=0: firingrate:0 scalefactor:1.0042
in state @t=4.4: A=0: B=0: firingrate:0 scalefactor:1.0044
in state @t=4.6: A=0: B=0: firingrate:0 scalefactor:1.0046
in state @t=4.8: A=0: B=0: firingrate:0 scalefactor:1.0048
in state @t=5: A=0: B=0: firingrate:0 scalefactor:1.005
in state @t=5.2: A=0: B=0: firingrate:0 scalefactor:1.0052
in state @t=5.4: A=0: B=0: firingrate:0 scalefactor:1.0054
in state @t=5.6: A=0: B=0: firingrate:0 scalefactor:1.0056
in state @t=5.8: A=0: B=0: firingrate:0 scalefactor:1.0058
in state @t=6: A=0: B=0: firingrate:0 scalefactor:1.006
in state @t=6.2: A=0: B=0: firingrate:0 scalefactor:1.0062
in state @t=6.4: A=0: B=0: firingrate:0 scalefactor:1.0064
in NET_RECEIVE@t=6.4: w=0.01: firingrate=0: A=0: B=0: factor=1.05537 scalefactor=1.0064:
in NET_RECEIVE@t=6.4: A=0.0106213: B=0.0106213:
in state @t=6.6: A=0.000194535: B=0.0102279: firingrate:0 scalefactor:1.0066
in state @t=6.8: A=3.56303e-06: B=0.00984915: firingrate:0 scalefactor:1.0068
in state @t=7: A=6.52592e-08: B=0.00948441: firingrate:0 scalefactor:1.007
in state @t=7.2: A=1.19526e-09: B=0.00913318: firingrate:0 scalefactor:1.0072
in state @t=7.4: A=2.1892e-11: B=0.00879495: firingrate:0 scalefactor:1.0074
in state @t=7.6: A=4.00967e-13: B=0.00846925: firingrate:0 scalefactor:1.0076
...... scalefactor is increasing by 0.0002
...... A and B increased same fraction when a spike is received. 
...... However, A decays very fast whereas B decays much slower at each time step ----> where did that happen? and which parameters are controling the decay ('tau1':0.05,'tau2':5.3--->these are the parameters defining the AMPA properties).
...... this faster vs slower decay is the reason why A is 0 and B is a very small value when next spike is received.

--- SO NEED TO ASSIGN FIRING RATE TO THE MECHANISM.
-assign firing rate using the following:
sim.net.modifySynMechs({'conds':{'label':'AMPA','sec':'soma'}, 'cellConds':{'pop':'EM'},'firingrate':2})
--firingrate needs to be calculated and fed back here.
--ratedectau should be large enough (using 1000ms for now) otherwise when the next spike arrives, synapse already forgets about the activity of the neuron.



sim.net.cells[0].secs['soma']['hObj'](0.5).v

---DEBUGGING OPTIC FLOW:
-
from netpyne import specs, sim
from neuron import h
import numpy as np
import random
from conf import dconf # configuration dictionary
import pandas as pd
import pickle
from collections import OrderedDict
from connUtils import *
from matplotlib import pyplot as plt
import os
import anim
from matplotlib import animation
from aigame import AIGame
sim.AIGame = AIGame()
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[3], epCount = 0)
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[3], epCount = 0)
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[3], epCount = 0)
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[3], epCount = 0)
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[3], epCount = 0)
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[4], epCount = 0)
sim.AIGame.dFiringRates # to see the firing rates of 8 different populations
sim.AIGame.ldflow[-1]['ang'] # to see the angle computed for object motion

fig = plt.figure(figsize=(8,4))
gs = fig.add_gridspec(1,2)
f_ax = []
f_ax.append(fig.add_subplot(gs[0,0])) #for 5-image input - 0
f_ax.append(fig.add_subplot(gs[0,1])) #for single image  - 1
cbaxes = fig.add_axes([0.92, 0.3, 0.01, 0.5])
f_ax[0].imshow(np.add(sim.AIGame.FullImages[-1],sim.AIGame.FullImages[-2]))
fa = f_ax[1].imshow(sim.AIGame.ldflow[-1]['ang'],vmin=0, vmax=359, cmap='Dark2')
c1 = plt.colorbar(fa,cax = cbaxes)
c1.set_ticks([22,67,112,157,202,247,292,337])
c1.set_ticklabels(['E','NE','N','NW','W','SW','S','SE'])
plt.show()

**I think it will be better to use object tracking to compute direction of motion.
**some example codes are discussed here:
https://www.learnopencv.com/multitracker-multiple-object-tracking-using-opencv-c-python/
https://gist.github.com/adioshun/72106c82674fd6cd7b06fe9105c2ab86

**Use K-MEAN CLUSTERING TO DETECT OBJECTS


***INPUTS
1. Input data or Image for CLUSTERING
2. number of clusters required at the end.
3. Critera:
  cv2.TERM_CRITERIA_EPS --stop the algorithm if specified accuracy (epsilon) is reached.
  cv2.TERM_CRITERIA_MAX_ITER --stop the algorithm after specified number of iterations (max_iter)
  cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER --stop when any of the above condition is met.
  max_iter = 10
  epsilon = 1.0
4. attempts = 10 ---- flag to specify the number of times the algorithm is executed using different initial labeling. the algorithm ruturns the labels that yield the best compactness. This compactness is returned as output.
5. cv2.KMEANS_RANDOM_CENTERS
***outputs
1. compactness: sum of squared distance from each point to their corresponding centers.
2. labels: this is the label array where ach element marked '0','1' and so on depending on number of clusters
3. centers: array of centers of clusters.


***TRY FOLLOWING CODE TO TEST OBJECTS
I = sim.AIGame.FullImages[-1]
inds = np.where(I>np.min(I))
Z = np.transpose(np.array(inds))
# convert to np.float32
Z = np.float32(Z)
criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 5, 1.0)
ret,label,center=cv2.kmeans(Z,3,None,criteria,5,cv2.KMEANS_RANDOM_CENTERS)
A = Z[label.ravel()==0]
B = Z[label.ravel()==1]
C = Z[label.ravel()==2]
plt.scatter(A[:,1],A[:,0],c='b')
plt.scatter(B[:,1],B[:,0],c = 'r')
plt.scatter(C[:,1],C[:,0],c = 'g')

o1_x = np.min(A[0])
o1_w = np.max(A[0])-np.min(A[0])
o1_y = np.min(A[1])
o1_h = np.max(A[1])-np.min(A[1])

o2_x = np.min(B[0])
o2_w = np.max(B[0])-np.min(B[0])
o2_y = np.min(B[1])
o2_h = np.max(B[1])-np.min(B[1])

o3_x = np.min(C[0])
o3_w = np.max(C[0])-np.min(C[0])
o3_y = np.min(C[1])
o3_h = np.max(C[1])-np.min(C[1])



--->This was complicated way to do.

** sam suggested much straight forward way of doing this.

mask = im > thresh
from scipy import ndimage
labelim, nlabels = ndimage.label(mask)
  return labelim, nlabels

check details here: https://scipy-lectures.org/intro/scipy/auto_examples/plot_connect_measurements.html

*20may11
**continue with motion direction using object identification and then object racking.
I is a grayscale image with an instance (observation) of aigame 'Pong'.
mask = I > np.min(I)
from scipy import ndimage
labelim, nlabels = ndimage.label(mask)
each pixel in labelim contains labels of the object it belongs to.
>>> np.unique(labelim)
array([0, 1, 2, 3], dtype=int32) ----here 0 is for background and then there are 3 objects labeled 1,2 and 3.

o1 = ndimage.find_objects(labelim==1)
o2 = ndimage.find_objects(labelim==2)
o3 = ndimage.find_objects(labelim==3)

>>> o1
[(slice(0, 6, None), slice(140, 144, None))]
>>> o2
[(slice(115, 131, None), slice(16, 20, None))]
>>> o3
[(slice(115, 119, None), slice(44, 46, None))]

to get a bounding box
x1_o1 = o1[0][0].start
x2_o1 = o1[0][0].stop
y1_o1 = o1[0][1].start
y2_o1 = o1[0][1].stop

# use object tracking code as an example: Code i used to test the tracking is presented below this code.

# initialize a dictionary that maps strings to their corresponding
# OpenCV object tracker implementations
OPENCV_OBJECT_TRACKERS = {
	"csrt": cv2.TrackerCSRT_create,
	"kcf": cv2.TrackerKCF_create,
	"boosting": cv2.TrackerBoosting_create,
	"mil": cv2.TrackerMIL_create,
	"tld": cv2.TrackerTLD_create,
	"medianflow": cv2.TrackerMedianFlow_create,
	"mosse": cv2.TrackerMOSSE_create
}
# KCF: Fast and accurate
# CSRT: More accurate than KCF but slower
# MOSSE: Extremely fast but not as accurate as either KCF or CSRT

# initialize OpenCV's special multi-object tracker
trackers = cv2.MultiTracker_create()
# loop over frames from the video stream
for _ in range(100):
	# grab the current frame, then handle if we are using a
	# VideoStream or VideoCapture object
  rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[4], epCount = 0)
  frame = sim.AIGame.FullImages[-1]
  # grab the updated bounding box coordinates (if any) for each
  # object that is being tracked
  (success, boxes) = trackers.update(frame)
  # loop over the bounding boxes and draw then on the frame
  for box in boxes:
	  (x, y, w, h) = [int(v) for v in box]
	  cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
# create a new object tracker for the bounding box and add it
# to our multi-object tracker

box = [x1_o1, y1_o1, x2_o1-x1_o1, y2_o1, y1_o1]

x1_o1 = o1[0][0].start
x2_o1 = o1[0][0].stop
y1_o1 = o1[0][1].start
y2_o1 = o1[0][1].stop
tracker = OPENCV_OBJECT_TRACKERS[args["moose"]]()
trackers.add(tracker, frame, box)


###################################################
from netpyne import specs, sim
from neuron import h
import numpy as np
import random
from conf import dconf # configuration dictionary
import pandas as pd
import pickle
from collections import OrderedDict
from connUtils import *
from matplotlib import pyplot as plt
import os
import anim
from matplotlib import animation
from aigame import AIGame
sim.AIGame = AIGame()
for _ in range(30):
  cact = random.randint(3,4)
  rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[cact], epCount = 0)
import cv2
# object detection and finding bounding boxes
frame = sim.AIGame.FullImages[-1]
mask = frame > np.min(frame)
from scipy import ndimage
labelim, nlabels = ndimage.label(mask)
# each pixel in labelim contains labels of the object it belongs to.
o1 = ndimage.find_objects(labelim==1)
o2 = ndimage.find_objects(labelim==2)
o3 = ndimage.find_objects(labelim==3)

# to get a bounding box
x1_o1 = o1[0][0].start
x2_o1 = o1[0][0].stop
y1_o1 = o1[0][1].start
y2_o1 = o1[0][1].stop

x1_o2 = o2[0][0].start
x2_o2 = o2[0][0].stop
y1_o2 = o2[0][1].start
y2_o2 = o2[0][1].stop

x1_o3 = o3[0][0].start
x2_o3 = o3[0][0].stop
y1_o3 = o3[0][1].start
y2_o3 = o3[0][1].stop

bbox1 = (x1_o1, y1_o1, x2_o1-x1_o1, y2_o1-y1_o1)
bbox2 = (x1_o2, y1_o2, x2_o2-x1_o2, y2_o2-y1_o2)
bbox3 = (x1_o3, y1_o3, x2_o3-x1_o3, y2_o3-y1_o3)

frame = np.ascontiguousarray(frame, dtype=np.uint8)
cv2.rectangle(frame, (y1_o1,x1_o1), (y2_o1,x2_o1), (0, 255, 0),1)
cv2.rectangle(frame, (y1_o2,x1_o2), (y2_o2,x2_o2), (255, 0, 0),1)
cv2.rectangle(frame, (y1_o3,x1_o3), (y2_o3,x2_o3), (0, 0, 255),1)
plt.imshow(frame)
plt.show()

# initialize OpenCV's special multi-object tracker
tracker = cv2.TrackerMIL_create()
bbox = ()
# grab the updated bounding box coordinates (if any) for each object that is being tracked
ret, bbox = tracker.update(frame) # probably dont need this
bbox = (x1_o1, y1_o1, x2_o1-x1_o1, y2_o1-y1_o1)
tracker = cv2.TrackerMIL_create()
tracker.init(frame, bbox)
steps = 0
cact = 3
while steps<10:
  if (steps/10)==int((steps/10)):
    if cact==3: 
      cact = 4
    else: 
      cact = 3
  rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[cact], epCount = 0)
  frame = sim.AIGame.FullImages[-1]
  bbox1 = bbox
  # tracker.init(frame, bbox)
  frame = np.ascontiguousarray(frame, dtype=np.uint8)
  ret, bbox = tracker.update(frame)
  steps = steps+1
  # (x, y, w, h) = [int(v) for v in bbox1] # mark previous frame 
 	# cv2.rectangle(frame, (y, x), (y + h, x + w), (0, 255, 0), 2)
  (x, y, w, h) = [int(v) for v in bbox] # mark tracked and updated frame
	cv2.rectangle(frame, (y, x), (y + h, x + w), (0, 255, 0), 2)
  cv2.imshow("frame",frame)
  #plt.show()

########################################################################

bug in KCF tracker: https://github.com/opencv/opencv_contrib/issues/640 ---- spent lot of time thinking that i was doing something wrong but found that there was a bug in python version of this tracker.

trackers.add(tracker, frame, box)




#Try other method ----problem with this method was that i could not install dlib to test the code below.
code here: https://www.pyimagesearch.com/2018/10/22/object-tracking-with-dlib/

from netpyne import specs, sim
from neuron import h
import numpy as np
import random
from conf import dconf # configuration dictionary
import pandas as pd
import pickle
from collections import OrderedDict
from connUtils import *
from matplotlib import pyplot as plt
import os
import anim
from matplotlib import animation
from aigame import AIGame
sim.AIGame = AIGame()
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[3], epCount = 0)
import dlib
import cv2
frame = sim.AIGame.FullImages[-1]
mask = frame > np.min(frame)
from scipy import ndimage
labelim, nlabels = ndimage.label(mask)
# each pixel in labelim contains labels of the object it belongs to.
o1 = ndimage.find_objects(labelim==1)
o2 = ndimage.find_objects(labelim==2)
o3 = ndimage.find_objects(labelim==3)
# to get a bounding box
x1_o1 = o1[0][0].start
x2_o1 = o1[0][0].stop
y1_o1 = o1[0][1].start
y2_o1 = o1[0][1].stop
# compute the (x, y)-coordinates of the bounding box for the object
startX = o1[0][0].start
startY = o1[0][1].start
endX = o1[0][0].stop
endY = o1[0][1].stop
# construct a dlib rectangle object from the bounding box coordinates and then start the dlib correlation 
# tracker
tracker = dlib.correlation_tracker()
rect = dlib.rectangle(startX, startY, endX, endY)
tracker.start_track(frame, rect)
# draw the bounding box and text for the object
cv2.rectangle(frame, (startX, startY), (endX, endY),(0, 255, 0), 2)
steps = 0
cact = 3
while steps<10:
  if (steps/10)==int((steps/10)):
    if cact==3: 
      cact = 4
    else: 
      cact = 3
  rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = sim.AIGame.playGame(actions=[cact], epCount = 0)
  frame = sim.AIGame.FullImages[-1]
	tracker.update(frame)
	pos = tracker.get_position()
	# unpack the position object
	startX = int(pos.left())
	startY = int(pos.top())
	endX = int(pos.right())
	endY = int(pos.bottom())
	# draw the bounding box from the correlation object tracker
	cv2.rectangle(frame, (startX, startY), (endX, endY),(0, 255, 0), 2)
  plt.imshow(frame)
  plt.show()


frame = sim.AIGame.FullImages[-1]
bbox1 = bbox
# tracker.init(frame, bbox)
frame = np.ascontiguousarray(frame, dtype=np.uint8)
ret, bbox = tracker.update(frame)
(x, y, w, h) = [int(v) for v in bbox] # mark tracked and updated frame
cv2.rectangle(frame, (y,x), (y + h, x + w), (0, 255, 0), 2)
plt.imshow(frame)
plt.show()


*2020may13

**have already spent 2.5 days to figure out which object tracking algorithm will work best. The goal was to use such algorithm to trck objects in any game and use that to find motion directions.
**Most of the object trackers in cv2 didn't work. Even on internet, i found someone mentioning 'TrackerKCF_create' in python not working properly. Only one algorithm 'TrackerMIL_create' gave me some output but that output was incorrect too.
**I found another object tracker which seemed very simple and straight forward. It was using dlib. I could not install on my machine to try. May be I could try that on 'neurosim' but will leave that for now.
**Probably should use simple tracking algorithm which requires object detection for every single image frame:
https://www.pyimagesearch.com/2018/07/23/simple-object-tracking-with-opencv/
*** STEP1 : Find bounding box coordinates and compute centroids
*** STEP2 : Find euclidean distance between new bounding boxes and existing objects.
*** STEP3 : Update x,y coordinates of existing objects.
*** STEP4 : Register new objects.
*** STEP5 : Deregister old objects (the objects which no longer exist). 

****This method is called centroid tracking.

from scipy.spatial import distance as dist
from collections import OrderedDict
import numpy as np

class CentroidTracker():
	def __init__(self, maxDisappeared=50):
		# initialize the next unique object ID along with two ordered
		# dictionaries used to keep track of mapping a given object
		# ID to its centroid and number of consecutive frames it has
		# been marked as "disappeared", respectively
		self.nextObjectID = 0
		self.objects = OrderedDict()
		self.disappeared = OrderedDict()
		# store the number of maximum consecutive frames a given
		# object is allowed to be marked as "disappeared" until we
		# need to deregister the object from tracking
		self.maxDisappeared = maxDisappeared
  def register(self, centroid):
		# when registering an object we use the next available object
		# ID to store the centroid
		self.objects[self.nextObjectID] = centroid
		self.disappeared[self.nextObjectID] = 0
		self.nextObjectID += 1
  def deregister(self, objectID):
		# to deregister an object ID we delete the object ID from
		# both of our respective dictionaries
		del self.objects[objectID]
		del self.disappeared[objectID]
  def update(self, rects):
		# check to see if the list of input bounding box rectangles
		# is empty
		if len(rects) == 0:
			# loop over any existing tracked objects and mark them
			# as disappeared
			for objectID in list(self.disappeared.keys()):
				self.disappeared[objectID] += 1
				# if we have reached a maximum number of consecutive
				# frames where a given object has been marked as
				# missing, deregister it
				if self.disappeared[objectID] > self.maxDisappeared:
					self.deregister(objectID)
			# return early as there are no centroids or tracking info
			# to update
			return self.objects
    inputCentroids = np.zeros((len(rects), 2), dtype="int")
		# loop over the bounding box rectangles
		for (i, (startX, startY, endX, endY)) in enumerate(rects):
			# use the bounding box coordinates to derive the centroid
			cX = int((startX + endX) / 2.0)
			cY = int((startY + endY) / 2.0)
			inputCentroids[i] = (cX, cY)
	  # if we are currently not tracking any objects take the input
		# centroids and register each of them
		if len(self.objects) == 0:
			for i in range(0, len(inputCentroids)):
				self.register(inputCentroids[i])
    # otherwise, are are currently tracking objects so we need to
		# try to match the input centroids to existing object
		# centroids
		else:
			# grab the set of object IDs and corresponding centroids
			objectIDs = list(self.objects.keys())
			objectCentroids = list(self.objects.values())
			# compute the distance between each pair of object
			# centroids and input centroids, respectively -- our
			# goal will be to match an input centroid to an existing
			# object centroid
			D = dist.cdist(np.array(objectCentroids), inputCentroids)
			# in order to perform this matching we must (1) find the
			# smallest value in each row and then (2) sort the row
			# indexes based on their minimum values so that the row
			# with the smallest value is at the *front* of the index
			# list
			rows = D.min(axis=1).argsort()
			# next, we perform a similar process on the columns by
			# finding the smallest value in each column and then
			# sorting using the previously computed row index list
			cols = D.argmin(axis=1)[rows]
      # in order to determine if we need to update, register,
			# or deregister an object we need to keep track of which
			# of the rows and column indexes we have already examined
			usedRows = set()
			usedCols = set()
			# loop over the combination of the (row, column) index
			# tuples
			for (row, col) in zip(rows, cols):
				# if we have already examined either the row or
				# column value before, ignore it
				# val
				if row in usedRows or col in usedCols:
					continue
				# otherwise, grab the object ID for the current row,
				# set its new centroid, and reset the disappeared
				# counter
				objectID = objectIDs[row]
				self.objects[objectID] = inputCentroids[col]
				self.disappeared[objectID] = 0
				# indicate that we have examined each of the row and
				# column indexes, respectively
				usedRows.add(row)
				usedCols.add(col)
      # compute both the row and column index we have NOT yet
			# examined
			unusedRows = set(range(0, D.shape[0])).difference(usedRows)
			unusedCols = set(range(0, D.shape[1])).difference(usedCols)
      # in the event that the number of object centroids is
			# equal or greater than the number of input centroids
			# we need to check and see if some of these objects have
			# potentially disappeared
			if D.shape[0] >= D.shape[1]:
				# loop over the unused row indexes
				for row in unusedRows:
					# grab the object ID for the corresponding row
					# index and increment the disappeared counter
					objectID = objectIDs[row]
					self.disappeared[objectID] += 1
					# check to see if the number of consecutive
					# frames the object has been marked "disappeared"
					# for warrants deregistering the object
					if self.disappeared[objectID] > self.maxDisappeared:
						self.deregister(objectID)
      # otherwise, if the number of input centroids is greater
			# than the number of existing object centroids we need to
			# register each new input centroid as a trackable object
			else:
				for col in unusedCols:
					self.register(inputCentroids[col])
		# return the set of trackable objects
		return self.objects
    

***for testing the script "centroidtracker.py"

# import the necessary packages
from centroidtracker import CentroidTracker
import numpy as np
import cv2
import random
from matplotlib import pyplot as plt
from scipy import ndimage
from aigame import AIGame

AIGame = AIGame()
rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = AIGame.playGame(actions=[3], epCount = 0)

def getObjectsBoundingBoxes(frame):
  mask = frame > np.min(frame)
  labelim, nlabels = ndimage.label(mask)
  # each pixel in labelim contains labels of the object it belongs to.
  rects = []
  for labels in range(nlabels):
    clabel = labels+1
    o = ndimage.find_objects(labelim==clabel)
    # to get a bounding box
    # compute the (x, y)-coordinates of the bounding box for the object
    startX = o[0][0].start
    startY = o[0][1].start
    endX = o[0][0].stop
    endY = o[0][1].stop
    box = np.array([startX, startY, endX, endY])
    rects.append(box.astype("int"))
  return rects

# initialize our centroid tracker and frame dimensions
ct = CentroidTracker()
while True:
  caction = random.randint(3,4)
	# read the next frame from the AIGame
  rewards, epCount, proposed_actions, total_hits, Racket_pos, Ball_pos = AIGame.playGame(actions=[caction], epCount = 0)
  frame = AIGame.FullImages[-1]
	# Detect the objects, and initialize the list of
	# bounding box rectangles
  rects = getObjectsBoundingBoxes(frame)
  frame = np.ascontiguousarray(frame, dtype=np.uint8)
  # loop over rects
	for i in range(np.shape(rects)[0]):
		startX = rects[i][0]
    startY = rects[i][1]
    endX = rects[i][2]
    endY = rects[i][3]
		cv2.rectangle(frame, (startY, startX), (endY, endX),(0, 255, 0), 1)
  # update our centroid tracker using the computed set of bounding
	# box rectangles
	objects = ct.update(rects)
	# loop over the tracked objects
	for (objectID, centroid) in objects.items():
		# draw both the ID of the object and the centroid of the
		# object on the output frame
		text = "ID {}".format(objectID)
		cv2.putText(frame, text, (centroid[0] - 10, centroid[1] - 10),
			cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
		cv2.circle(frame, (centroid[0], centroid[1]), 4, (0, 255, 0), -1)
	# show the output frame
	cv2.imshow("Frame", frame)
	key = cv2.waitKey(1) & 0xFF
	# if the `q` key was pressed, break from the loop
	if key == ord("q"):
		break
# do a bit of cleanup
cv2.destroyAllWindows()


*20May14
**Before I resolve issue dealing with overlapped objects in centroidtracking.py... i will look into hitBall tracking in the aigame.py


I will need the following code to test it.

import numpy as np
import cv2
import random
from matplotlib import pyplot as plt
from scipy import ndimage
from aigame import AIGame
AIGame = AIGame()


courtYRng = (34, 194) # court y range
courtXRng = (20, 140) # court x range
last_obs = []
last_ball_dir = 0

def findobj (img, xrng, yrng):
  # find an object's x, y position in the image (assumes bright object on dark background)
  subimg = img[yrng[0]:yrng[1],xrng[0]:xrng[1],:]
  sIC = np.sum(subimg,2) #assuming the color of object is uniform, add values or r,g,b to get a single value      
  pixelVal = np.amax(sIC) #find the pixel value representing object assuming a black background
  sIC[sIC<pixelVal]=0 #make binary image
  Obj_inds = []
  for i in range(sIC.shape[0]):
    for j in range(sIC.shape[1]):
      if sIC[i,j]>0:
        Obj_inds.append([i,j])
  if sIC.shape[0]*sIC.shape[1]==np.shape(Obj_inds)[0]: #if there is no object in the subimage
    ypos = -1
    xpos = -1
  else:
    ypos = np.median(Obj_inds,0)[0] #y position of the center of mass of the object
    xpos = np.median(Obj_inds,0)[1] #x position of the center of mass of the object
  return xpos, ypos

if np.shape(last_obs)[0]>0: #if last_obs is not empty              
  xpos_Ball, ypos_Ball = findobj(last_obs, courtXRng, courtYRng)
observation, reward, done, info = env.step(caction)
#find position of ball after action
xpos_Ball2, ypos_Ball2 = findobj(observation, courtXRng, courtYRng)        
if xpos_Ball>0 and xpos_Ball2>0:
  if xpos_Ball2-xpos_Ball>0:
    ball_moves_towards_racket = 1 #use proposed action for reward only when the ball moves towards the racket
    current_ball_dir = 1 
  elif xpos_Ball2-xpos_Ball<0:
    ball_moves_towards_racket = 0
    current_ball_dir = -1
  else:
    ball_moves_towards_racket = 0
    current_ball_dir = 0 #direction can't be determinted  prob. because the ball didn't move in x dir.
else:
  ball_moves_towards_racket = 0
  current_ball_dir = 0 #direction can't be determined because either current or last position of the ball is outside the court

ball_hits_racket = 0
if last_ball_dir==0 or current_ball_dir==0: # no way to find out if the ball hit the racket
  ball_hits_racket = 0 #therefore assumed that ball didn't hit the racket--weak/bad assumption
else:
  if last_ball_dir==1 and current_ball_dir==-1 and reward==0:
    #if the ball was moving towards the racket and now its moving away from racket and didnt lose
    ball_hits_racket = 1
last_ball_dir = current_ball_dir

**OUTPUT of testing script:

1 instance:
np.shape(last_obs)[0]: 210
xpos_Ball: 115.5
xpos_Ball: 115.5
xpos_Ball2: 118.5
reward:  0.0
last ball direction: 1
current ball direction: 1
0  <--- hitBall signal
4
np.shape(last_obs)[0]: 210
xpos_Ball: 118.5
xpos_Ball: 118.5
xpos_Ball2: 115.5
reward:  0.0
last ball direction: 1
current ball direction: -1
1   <--- hitBall signal

2nd instance:
np.shape(last_obs)[0]: 210
xpos_Ball: 115.5
xpos_Ball: 115.5
xpos_Ball2: 118.5
reward:  0.0
last ball direction: 1
current ball direction: 1
0   <--- hitBall signal
3
np.shape(last_obs)[0]: 210
xpos_Ball: 118.5
xpos_Ball: 118.5
xpos_Ball2: 117.5
reward:  0.0
last ball direction: 1
current ball direction: -1
1   <--- hitBall signal


an instance where the algorithm didn't work-----


np.shape(last_obs)[0]: 210
xpos_Ball: 114.5
xpos_Ball: 114.5
xpos_Ball2: 117.5
reward:  0.0
last ball direction: 1
current ball direction: 1
0
4
np.shape(last_obs)[0]: 210
xpos_Ball: 117.5
xpos_Ball: 117.5
xpos_Ball2: 117.5
reward:  0.0
last ball direction: 1
current ball direction: 0
0
4
np.shape(last_obs)[0]: 210
xpos_Ball: 117.5
xpos_Ball: 117.5
xpos_Ball2: 111.5
reward:  0.0
last ball direction: 0
current ball direction: -1
0

***CHANGE CODE IS aigame.py


      if self.last_ball_dir==1 and reward==0:
        # i noticed that sometimesthe ball don't move when it is very close to the racket/edge of the court.
        if current_ball_dir==0 and xpos_Ball2>courtXRng[1]-courtXRng[0]-3: 
          ball_hits_racket = 1 
        elif self.last_ball_dir==1 and current_ball_dir==-1:
          #if the ball was moving towards the racket and now its moving away from racket and didnt lose
          ball_hits_racket = 1
        else: ball_hits_racket = 0
      else: ball_hits_racket = 0




**Looks like its fixed....

np.shape(last_obs)[0]: 210
xpos_Ball: 115.5
xpos_Ball: 115.5
xpos_Ball2: 118.5
reward:  0.0
last ball direction: 1
current ball direction: 1
0
4
np.shape(last_obs)[0]: 210
xpos_Ball: 118.5
xpos_Ball: 118.5
xpos_Ball2: 118.5
reward:  0.0
last ball direction: 1
current ball direction: 0
1   <--- hitBall signal
4
np.shape(last_obs)[0]: 210
xpos_Ball: 118.5
xpos_Ball: 118.5
xpos_Ball2: 112.5
reward:  0.0
last ball direction: 0
current ball direction: -1

** found another problem.... sometimes ball is outside court and still get hit by the racket.


    if current_ball_dir-last_ball_dir<0 and reward==0 and xpos_Ball2>courtXRng[1]-courtXRng[0]-3:
      ball_hits_racket = 1
    elif xpos_Ball==-1 and reward==0 and xpos_Ball2>courtXRng[1]-courtXRng[0]-3:
      ball_hits_racket = 1
** so far works for all tested conditions
** object tracking fixed--- working nicely.....
** displaying object tracking and plotting direction of motion.

** still need to integrate the code in the model.

* 2020may18
** in testCentroidTracking.py, i use FULLImage to compute motion vectors and then downsample matrices with motion vectors to match the number of neurons.
*** This is better to preserve the direction of object motion. Using downsampled image gives less accurate motion directions.
** Part of lack of accuracy seems to be due to downsampling.
** Two options included in sim.json to compute direction flow:
  "DirectionDetectionAlgo":{"CentroidTracker":1,"OpticFlow":0}
** added function in imgutils to get the coordinates of the bounding boxes for non-ovelaping objects.
  -- def getObjectsBoundingBoxes(frame):
** added function in imgutils to get the flow of motion of all existing objects. New objects or disappeaered objects are ignored. 
  -- def getObjectMotionDirection(objects, last_objects, rects, dims):
** initialize the CentroidTracker and related objects in init()
    if dconf['DirectionDetectionAlgo']['CentroidTracker']==1:
      self.ct = CentroidTracker()
      self.objects = OrderedDict() # objects detected in current frame
      self.last_objects = OrderedDict() # objects detected in previous frame
** added function to compute angles of motion.
  -- computeAllObjectsMotionDirections(self, UseFull=True)

** Debugging aigame.....
*** need to explicitly import deepcopy from copy
*** import cv2
*** adjusted plotting in actmap.py because when using CentroidTracking 'flow' is used instead of 'thflow'. Also 'flow' has a different data structure.

*** i think it might be better to change the structure of flow and also save thflow.

    flow = np.zeros(shape=(np.shape(cimage)[0],np.shape(cimage)[1],2))
    flow[:,:,0] = dirX
    flow[:,:,1] = dirY
    goodInds = np.zeros(shape=(np.shape(cimage)[0],np.shape(cimage)[1],2))
    self.ldflow.append({'flow':flow,'mag':mag,'ang':ang,'goodInds':goodInds,'thang':ang,'thflow':flow})

*** add zeros when the last objects is empty.

** More debugging centroid tracking in aigame
*** always compute motion flow using FullImages
*** if dirSensitiveNeuronDim!= cimage.shape[0], resize the direction vectors, angles etc.
*** to match the format of optical flow. keep the flow inverted in y direction.

probably need more testing.

*** X and Y were replaced. Fixed now.
*** too much activity for 0 degrees  i.e. E neurons.
---> solution: ang[mag == 0] = 'nan'
*** looks like 'nan' doesnt work. so use -100.
*** use centroidtracker with both FullImage and ReducedImage.
*** Run for 100 sec.
*** seems too low activity. try increasing the probability of RL connections.


or prety in ['EV1', 'EV1DE', 'EV1DNE', 'EV1DN', 'EV1DNW', 'EV1DW','EV1DSW', 'EV1DS','EV1DSE', 'EV4', 'EMT']:
  for poty in EMotorPops:
    for strty,synmech,weight in zip(['','n'],['AMPA', 'NMDA'],[dconf['net']['EEMWghtAM']*cfg.EEGain, dconf['net']['EEMWghtNM']*cfg.EEGain]):
      k = strty+prety+'->'+strty+poty
      netParams.connParams[k] = {
        'preConds': {'pop': prety},
        'postConds': {'pop': poty},
        'convergence': prob2conv(0.1, dnumc[prety]), #using 0.2 instead of 0.1 dated May18,2020
        'weight': weight,
        'delay': 2,
        'synMech': synmech,
        'sec':'dend', 'loc':0.5
      }
      if dSTDPparamsRL[synmech]['RLon']: # only turn on plasticity when specified to do so
        netParams.connParams[k]['plast'] = {'mech': 'STDP', 'params': dSTDPparamsRL[synmech]}



        Change prob2conv(0.1, dnumc[prety]) to prob2conv(2*0.1, dnumc[prety])

and set doplot=1, doquit=0

*** still racket not moving----probably no activity in motor neurons.

"EEMWghtAM":0.000075,"EEMWghtNM":0.0000075 increase 10 times to "EEMWghtAM":0.00075,"EEMWghtNM":0.000075

raster saves as: 20may18_ZN_B_100sec_raster.png
saving actmap movie .....

** Try running simulation with same parameters but targeted RL in 20may18_ZN_C_....

*20may20
**broadening the flow of each object.... using FlowWidth
*** In addition to assigning direction vectors to the object pixels, now i expand direction vector assignment to additional FlowWidth pixels in each dimension. 
**** e.g. if FlowWith is 8, the direction vectors are assigned to 4 pixels berfor startX of the object and 4 pixels after the endX of the object, similarly 4 pixels before startY of the object and 4 pixels after the endY of the object. 
changes in imgutils.py 
      for i in range(np.shape(rects)[0]):
        startX = rects[i][0]
        if startX<(FlowWidth/2):
          startX =  0
        else:
          startX = startX-(FlowWidth/2) 
        startY = rects[i][1]
        if startY<(FlowWidth/2):
          startY = 0
        else:
          startY = startY-(FlowWidth/2)
        endX = rects[i][2]
        if endX>dims-(FlowWidth/2):
          endX = dims
        else:
          endX = endX+(FlowWidth/2)
        endY = rects[i][3]
        if endY>dims-(FlowWidth/2):
          endY = dims
        else:
          endY = endY+(FlowWidth/2)

and change in aigame.py
dirX, dirY = getObjectMotionDirection(self.objects, self.last_objects, rects, dims=np.shape(cimage)[0],FlowWidth=8)
*** test directions and network activity in file "20may20_A_"
**** Too high activity in motor cortex (~19 Hz).... very few actions during 10 sec sim.
*** reduce the weights and rerun in file "20may20_B_"
------ "EEMWghtAM":0.0005,"EEMWghtNM":0.00005,"EEMWghtThreshMin":0.0005 ---> "EEMWghtAM":0.0002,"EEMWghtNM":0.00002,"EEMWghtThreshMin":0.0002
**** still high firing rate (~15 Hz)....
*** also change ,"EEMWghtThreshMax":0.005 --> "EEMWghtThreshMax":0.002 in file "20may20_B2_"
**** still high firing rate (~11 Hz) ....
*** change the parameters are below and rerun sim in "20may20_C_"
------ "EEMWghtAM":0.0001,"EEMWghtNM":0.00001,"EEMWghtThreshMin":0.0001, "EEMWghtThreshMax":0.001


** DISCUSSION WITH SAM:

*** Haroon: "one problem i see is: we assume where ever the racket is, up and down action should be generated independently which might be right but it kills the purpose of having different associations built between different motor neurons and sensory neurons coz we are summing up the activity"

*** Sam: "why? if the correct inputs activate the right subpopulation through learning ... isn't that the association?" 

*** Haroon: "not saying that associations are not being built properly saying that the actions are not generated based on associations because spatial element is completely lost"

*** Sam: "spatial element = spatial information provided to M?""

*** Haroon: "spatial element for action not for input. if we assume that a sub pop of motor neurons take action when the ball is on top right quadrant and another subpop take action when the ball is on top bottom quadrant, the associations will result in topologically relevant actions"

*** Sam: "so you're saying M should have topographic layout too"

*** Haroon: "yes for outputs, not for inputs"

*** Sam: "not sure what that means for outputs, since your example was dependent on ball's position , which is input related (?)"

*** Haroon: "for inputs it should be probabilistic or even may be all to all, for outputs we just use a map and say neuron 1-10 decides action when the ball is at one region, 1-10 in both UP and DOWN regions"

*** Sam: "so that is input dependent selection of M subpops"

*** Haroon: "or this doesn’t make any sense? yes. no idea how to make that selection though"

*** Sam: "hoping that learning would allow that selection. is there a way to build it into the architecture in a general way?"

*** Haroon: "no idea how to make that selection though biologically speaking"

*** Sam: "yeah, not sure"

*** Haroon: "but one thing is sure , generating action by comparing pop firing rates is incorrect"

*** Sam: "probably. would spatial layout of M help though?"

*** Haroon: "it could"

*** Sam: "it would mean most of the time most M neurons are silent/irrelevant. possibly..."

*** Sam: "seems worth trying anyway...at least the spatial info would then be provided to M. well, more spatial info. so sg. and could possibly allow some prediction..if ball moving right, activate M neurons in a sequence..."

*** Haroon: "yes and then within that pop, some neurons will learn associations between actions, location and direction"

*** Sam: "sg, guess you should implement that...seems like most major change. good idea"

*** Haroon: "ok… will have more questions/problems/challenges when i start building that up. so stay tuned"

*** Sam: "sg. was also looking at adjusting the weight normalization. to additionally match weights to each M pop ... to avoid any bias in output. but that has drawbacks since specific actions should be preferred"

In personal chat:

*** Sam: "was thinking about some of those questions a few days ago (from notebook): "any E M neuron could receive information from spatially separated locations ...
if no topography, then should have recurrent connectivity in EM neurons with RL synapses ...
topographic arrangement of M neurons might allow better prediction on when to move ... for
example if ball is far away but moving in a certain direction, might want to initiate movement
in advance of the ball getting to the paddle ...
so while there's some spatial information with random connectivity, it's less organized/useful if
receiving random (from spatial perspective) inputs?
if ball in middle of screen moving SE, and paddle is at top right stationary, EM Down should be
activated ... so there should be at least one EM Down neuron that receives strong V1 input at top
right and middle of screen SE neuron ... if there was a topographic arrangement of EM neurons,
would that be possible? not if there are restriction of connectivity across spatially distant
neurons... but having additional recurrent connectivity in EM might still allow that encoding to emerge"

*** Sam: "not sure if useful/understandable"

*** Sam: "this case was why wasn't sure: "if ball in middle of screen moving SE, and paddle is at top right stationary, EM Down should be activated ... so there should be at least one EM Down neuron that receives strong V1 input at top right and middle of screen SE neuron""

*** Sam:is that possible with topography. if need both inputs to know to move down

*** Haroon: seems so---need to think more

*** samn: ic, sure. and if recurrent conn could help. difficult/interesting problem here :slightly_smiling_face:

*** Haroon: yes… it is…. i wonder how motor systems are studied… what kind of topological mapping is there. based on input/output or combined

*** samn: good q. suppose if there's no obvious drawback to topographic setup of M should try it

*** Haroon: i think we both agree here that topological setup would be probably helpful, what needs to be determined is how actions will be generated

*** samn: well, i'm not completely sure

*** Haroon: still pop activity?

*** samn: if it will help. since could be useful for a M neuron to gather info from spatially separated locations in space. e..g that example (ball in middle of screen moving SE and paddle at top right), you might want one M neuron to integrate that info. unless the population of M could do it together somehow. pop activity - another good q

*** Haroon: yeah- recurrent conns will make it hard to guess i think

*** samn: for command output - might it help to have a minimum margin between firing rates to generate an action (to avoid noise),recurrent conns make it harder?,suppose could have topology but also some recurrent connectivity,though at that point why not just high recurrent...not really sure

*** Haroon: if some lingering activity left from last time step, due to recurrency, i guess will depend on the architcture, if we keep it recurrency strictly local then probably not or if inhibition is setup in a way to filter those effects spatially

*** samn: yeah, and that raises whether we want some antag inhib effects, one M pop activated I -> M of another pop ... suppose lot of things to try :slightly_smiling_face:

** test sim using optical flow in file "20may20_D_" - run time: 581 sec
----> the raster is saved as "20may20-D0"
** test sim using centroid tracking in file "20may20_D_" with broader flow and with FullImage - run time: 572.71 sec
----> the raster is saved as "20may20-D"
----> Didnt change the file name, so the results for sim with optical flow got overridden.
*** potential problem in plotting actmap.... i noticed that for 10000 ms sim, actmap was plotted for 9960 ms. i.e. roughly 2 frames are skipped. so probably this is the reason why the firing rates of direction selective neurons dont look aligned to the quiver plot.
**** check aigame.py----FullImages were not saved correctly. always previous image was saved. now saving current image.
** test sim using centroid tracking in file "20may20_E_" --- run time: 1257 s --- quite slow.
*** looks like still one frame off.. also sometimes wierd directionsin quiver plot. Not sure why? because when i run testCentroidTracking no such effect appears.
*** test with optic flow in file "20may20_F_" ---- runtime: 3049 sec
**** flow for first frame was missing----- 
*** In computeMotionFields, append zero-valued arrays for all except ang and thang, where 0 were replaced with -100 to avoid 0 considered as movement towards 0 degrees i.e. E.
*** test sim using optic flow in file "20may22_A_"
**** "EEMWghtAM":0.000025,"EEMWghtNM":0.0000025,"EEMWghtThreshMin":0.000025,"EEMWghtThreshMax":0.000075,"EEMProb":0.3,"EEMRecProb":0.0,"EEMPopNorm":0

*20may27
** Needs to confirm: 1) actmap movie is accurate. 2) direction selective neurons are activated properly in both optic flow and centroid tracking cases.
*** add UseFull in sim configuration: "DirectionDetectionAlgo":{"CentroidTracker":0,"OpticFlow":1,"UseFull":0}, For Optic flow set UseFull = 0
*** test sim (2 sec) using optic flow in file "20may27_A0_"
checking details:
InputImages.shape -- prints -- (100,20,20)
np.shape(ldflow) -- prints -- (100,)
t1 -- prints -- range(0,2000,20)
t2 -- prints -- range(20,2020,20)
np.shape(ldflow[0]['thflow']) -- prints -- (20,20,2).... where ldflow[0]['thflow'][:,:,0] is X component of direction vectors and ldflow[0]['thflow'][:,:,1] is Y component of direction vectors.
-- the racket moves south from timestep 6 to timestep 7 (from top edge of racket at 6.5 to top edge of racket at 7.5)
-- quiver plot at timestep 7 shows correct directions (for most of the pixels)
-- the ball moves south west from timestep 20 to timestep 21. rackets dont move.
-- quiver plot at timestep 21 shows correct directions (for most of the pixels)
-- now check the direcrtion sensitive neurons during that timestep.
-- there seems to be a difference of 2 timesteps in datastructures e.g. dact['EV1DSW'][23,:,:] showed the activity for ldflow[21]['thflow']
---- This doesn't make sense... how is this possible. 
dact['EV1DSW'][0,:,:] has activity between 0-20 ms
ldflow[0]['thflow'] has optical flow recorded at 20 ms.---> This will be used to drive activity between 20-40 ms.
InputImage[0] is recorded at 20 ms.

dact['EV1DSW'][1,:,:] has activity between 20-40 ms ---> This should be associated with ldflow[0]
InputImage[1] is recorded at 40 ms.
ldflow[1]['thflow'] is recorded at 40 ms.   

-- run 100 ms sim in 20may27_A1_


* 20may28
**setting up falcor
---got instructions from sam
** NKI VPN notes
To access the new VPN, go to https://sshvpn.rfmh.org and login with your NKI username and password.
After signing in, there will be links to download the VPN client for your operating system and
well as instructions for connecting.
to access the VPN from outside of NKI use cisco anyconnect and go to https://63.117.203.75
then use this username: sneymotin
and the rfmh live.com password
is there x2go for falcor?
alias snnki ssh -X samn@10.76.253.150
alias nkisftp sftp samn@10.76.253.150
alias falcor ssh -X samn@falcor.rfmh.org
alias falcorsftp sftp samn@falcor.rfmh.org
alias vnc2falcor 'ssh -X -L 5901:localhost:5901 samn@falcor.rfmh.org'
alias vncv 'vncviewer localhost:5901'
to use x2go
x2goclient
make sure to use xfce for falcor

-------
using cisco vpn connect using 63.117.203.75 and nki password
login to falcor ssh -X hanwar@falcor.rfmh.org
change session type to xfce
host is falcor.rfmh.org
login is your username on falcor

copy this in .bashrc

export LD_LIBRARY_PATH="/home/samn/miniconda3/lib"
export SITE="/home/samn/site"
# >>> conda initialize >>>
# !! Contents within this block are managed by 'conda init' !!
__conda_setup="$('/home/samn/miniconda3/bin/conda' 'shell.bash' 'hook' 2> /dev/null)"
if [ $? -eq 0 ]; then
    eval "$__conda_setup"
else
    if [ -f "/home/samn/miniconda3/etc/profile.d/conda.sh" ]; then
        . "/home/samn/miniconda3/etc/profile.d/conda.sh"
    else
        export PATH="/home/samn/miniconda3/bin:$PATH"
    fi
fi
unset __conda_setup
# <<< conda initialize <<<

--- testing sims on falcor
-- ran 2 sec sim with optical flow named 20may27_A0_
-- running 2 sec sim with centroid tracking named 20may27_A1_
-- both sims successful---actmap movies copied to local drive SMARTAgent/gif/ using
scp hanwar@falcor.rfmh.org://home/hanwar/GamesProject/SMARTAgent/gif/* Documents/NKI-modeling/SMARTAgent/gif/
-- run 100 sec sim with optical flow and using these parameters
"EEMWghtAM":0.00005,"EEMWghtNM":0.0000025,"EEMWghtThreshMin":0.00005,"EEMWghtThreshMax":0.0001,"EEMProb":0.3,"EEMRecProb":0.1,"EEMPopNorm":0
save results in file 20may28_A0_
-- run 100 sec sim with centroid tracking and flowwidth of 16 and using these parameters
"EEMWghtAM":0.00005,"EEMWghtNM":0.0000025,"EEMWghtThreshMin":0.00005,"EEMWghtThreshMax":0.0001,"EEMProb":0.3,"EEMRecProb":0.1,"EEMPopNorm":0
save results in file 20may28_A1_

**some  potentially useful articles
1. Learning robust cortico-cortical associations with the basal ganglia: An integrative review.
2. From reinforcement learning models of the basal ganglia to the pathophysiology of psychiatric and neurological disorders.
3. The Basal ganglia : a vertebrate solution to the selection problem.
4. Anticipatory control of movement in a thalamo-cortical curcuit model ---- not exactly what i am looking for but may provide some inspirational ideas.

* 20june02

** EMUP and EMDOWN each population has 400 neurons.
-- I want only 3x3 or 5x5 neurons centered around a neuron that represents the location of the object in the game environment to be active.
-- All other neurons should be inhibited.
-- I hope that this will allow actions based on position and direction of objects in the environment.
-- HOW TO ACHIEVE THIS?

Option 1: Make topological connections between visual and motor cortices.
-- For connections from ['EV1', 'EV1DE', 'EV1DNE', 'EV1DN', 'EV1DNW', 'EV1DW','EV1DSW', 'EV1DS','EV1DSE'] to ['EMUP', 'EMDOWN'] use
    (400 neurons to 400 neurons with 3x3 overlap.) 
    use blistEV1toEM = connectLayerswithOverlap(NBpreN = dnumc['EV1'], NBpostN = dnumc['EMUP'], overlap_xdir = 3)
-- For connections from ['EV1DN4'] to ['EMUP', 'EMDOWN'] 
    use blistEV4toEM = connectLayerswithOverlapDiv(NBpreN = dnumc['EV4'], NBpostN = dnumc['EMUP'], overlap_xdir = 3)
-- For connections from ['EMT'] to ['EMUP', 'EMDOWN']
    use blistEMTtoEM = connectLayerswithOverlapDiv(NBpreN = dnumc['EMT'], NBpostN = dnumc['EMUP'], overlap_xdir = 5)
-- Use recurrent connections as in case of non-topological architecture.
-- Leave local E->I->E architecture in motor areas same as before.

** ability to choose architecture type from sim.json
"architecurePreMtoM": {"useProbabilistic":1,"useTopological":0}

** start testing topological architecture between preMotor and Motor areas. run 10 sec in "20june02_A_"

-- no activity generated in M, probably too weak connection stengths---> increase weights
"EEMWghtAM":0.00008,"EEMWghtNM":0.0000025 ---> "EEMWghtAM":0.0008,"EEMWghtNM":0.000025
-- run with new weights.
-- still low firing rates--- but the firing rate in motor areas produced movements.

** also change sn.json --- add "architecurePreMtoM": {"useProbabilistic":1,"useTopological":0},

** Using topological architecture between preMotor and Motor areas. run 200 sec sim in "20june02_B_"

run sim on ZN with "EEMRecProb":0.6 in file "20june02_ZN_B_"
-- was not taking any action so i reduced weights again.
-- was not taking any action, so i reverted weights back and change "EEMRecProb":0.4 and rerun.
-- E and I Firing rates of M neurons are high. (23 Hz). 

** play with convergence of E->I ------------- save in file "20june02_C_"

netParams.connParams['EMDOWN->IM'] = {
        'preConds': {'pop': 'EMDOWN'},
        'postConds': {'pop': 'IM'},
        #'probability': 0.125/2.,     
        'convergence': prob2conv(0.125/4, dnumc['EMDOWN']),
        'weight': 0.02 * cfg.EIGain,
        'delay': 2,
        'synMech': 'AMPA', 'sec':'soma', 'loc':0.5}
netParams.connParams['EMUP->IM'] = {
        'preConds': {'pop': 'EMUP'},
        'postConds': {'pop': 'IM'},
        #'probability': 0.125/2.,       
        'convergence': prob2conv(0.125/4, dnumc['EMUP']),
        'weight': 0.02 * cfg.EIGain,
        'delay': 2,
        'synMech': 'AMPA', 'sec':'soma', 'loc':0.5}

-- Firing rate of E and I neurons in this sim is too high: 23Hz. (Raster saved as 'Raster_June2_2020_C.png')
-- to see the connectivity, sam suggested: look at the inputmap functions in simdat.py


TIPS FROM SAM:


Use this to access the activity

python -i simdat.py backupcfg/20jun1_B2_falcor_sim.json
dstr = '20jun2_'; simstr = dconf['sim']['name'] # date and sim string
#
plotFollowBall(actreward,ax=subplot(1,3,1),msz=3); ylim((0,.6))
plotHitMiss(actreward,ax=subplot(1,3,2),msz=3); ylim((0,120));
plotRewards(actreward,ax=subplot(1,3,3),msz=3);
subplot(1,3,1); plot([40e3,80e3,120e3,160e3,200e3,240e3,280e3,320e3,360e3,400e3],[.45,.45,.45,.45,.45,0.45,.45,.45,.45,.45],'bo',markersize=10) # times of weight norm
savefig('gif/'+dstr+simstr+'perf.png')
clf(); drawraster(dspkT,dspkID); xlim((390e3,400e3)); savefig('gif/'+dstr+simstr+'rast.png')
clf(); drawcellVm(simConfig); xlim((390e3,400e3)); savefig('gif/'+dstr+simstr+'Vm.png')


* 20june03

** on june02, I ran sim on ZN with "EEMRecProb":0.4 in file "20june02_ZN_B_"
-- with weights: 'EEMWghtAM': 0.0008, 'EEWeightNM': 0.00025, 'EEMWghtThreshMin': 0.0002, 'EEMWghtThreshMax':0.0008
-- E and I Firing rates of M neurons were high. (23 Hz).

** reduce weights to: 'EEMWghtAM': 0.0004, 'EEWeightNM': 0.000125 and run for 20 sec in file "20june03_ZN_B_"
-- still very high firing rate (~21Hz).

** reduce weights to: 'EEMWghtAM': 0.0002, 'EEWeightNM': 0.00006 and run for 20 sec in file "20june03_ZN_B2_"
-- still very high firing rate (~18Hz).

** reduce weights to: 'EEMWghtAM': 0.0001, 'EEWeightNM': 0.00003 and run for 300 sec in file "20june03_ZN_B3_"
-- the other weight parameters are 'EEMWghtThreshMin':0.00002, 'EEMWghtThreshMax':0.0008
-- 'EEMRecProb':0.4
-- still very high firing rate (~16 Hz)

** reduce weights to: 'EEMWghtAM': 0.00005, 'EEWeightNM': 0.000015 and run for 20 sec in file "20june04_ZN_B_"
-- the other weight parameters are 'EEMWghtThreshMin':0.00001, 'EEMWghtThreshMax':0.0004
-- 'EEMRecProb':0.4



####################################################
** on june02, I ran sim on falcor with reduced convergence of E->I ------------- saved in file "20june02_C_"
-- had too high firing rate of E and I neurons in M.

** reduce weights to: 'EEMWghtAM': 0.0004, 'EEWeightNM': 0.000125 and run for 20 sec in file "20june03_C_"
-- the other weight parameters are: 'EEMWghtThreshMin': 0.0002, 'EEMWghtThreshMax':0.0008
-- 'EEMRecProb':0.3
-- still high firing rates (~20Hz).

** reduce weights to: 'EEMWghtAM': 0.0002, 'EEWeightNM': 0.00006 and run for 20 sec in file "20june03_C2_"
-- still high firing rates (~17Hz).

** reduce weights to: 'EEMWghtAM': 0.0001, 'EEWeightNM': 0.00003 and run for 20 sec in file "20june03_C3_"
-- the other weight parameters are 'EEMWghtThreshMin':0.00002, 'EEMWghtThreshMax':0.0008
-- firing rate is in reasonable range.
-- record actmap movie as well as weightmap movie. mv those movies to my computer.

** run this simulatio for 200 sec in file "20june03_C4_"
-- Firing rate is in reasonable range (~1Hz for E and ~3Hz for I)
-- record actmap and weightmap movies..copied those movies to my computer

** run this simulation for 400 sec in file "20june03_C5"
-- Firing rate is in reasoanable range.
-- record actmao and weight movies ... copied those movies to my computer.
-- I DON'T SEE ANY LEARNING.

** run a 20 sec sim with .... in file "20june05_C1_"and compare results with "20june03_C3_"
-- 'EEMRecProb':0.4
-- the firing rate increased to ~16Hz. i.e. too high.

** reduce weights to: 'EEMWghtAM': 0.00005, 'EEWeightNM': 0.000015 and run for 20 sec in file "20june05_C2_"
-- the other weight parameters are 'EEMWghtThreshMin':0.00001, 'EEMWghtThreshMax':0.0004
-- The firing rate decreased to 0.17 Hz.

** increase -- 'EEMRecProb' to 0.5 and run 20 sec in "20june05_C3_"
-- firing rate of E neurons didnt change much. Firing rate of I neurons went a bit up.---didnt save raster.
-- need to see connectivity maps.

TRY THIS 

drfmap = plotallinputmaps(pdf, pdf.time[0], dstartidx['EMUP'] + 0, 'EMUP', dnumc, dstartidx, dendidx, lprety)
drfmap = plotallinputmaps(pdf, pdf.time[0], dstartidx['EMUP'] + 1, 'EMUP', dnumc, dstartidx, dendidx, lprety)


** Learning depends on how well the reward is associated with the action. ---> This is somewhat straightforward to test.
** similarly, learning also depends on how well the firing rate of M neural population represent the action generated. ---> This is more difficult to test.

* 20june08
** run 20 sec sim in file "20june08_A_" 
-- 'EEMRecProb' to 0.5
-- 'EEMWghtAM': 0.00005, 'EEWeightNM': 0.000015
-- 'EEMWghtThreshMin':0.00001, 'EEMWghtThreshMax':0.0004
-- no RL between preM and M.
-- RL only between recurrent connections in M.

.... very synchronized activity in M pops.
.... very high firing rate (~15Hz)

** run 20 sec sim in file "20june08_A2_"
-- reduce to 'EEMWghtAM': 0.00001, 'EEWeightNM': 0.000003

... E stopped firing.

-- rerun sim with 'EEMWghtAM': 0.00003, 'EEWeightNM': 0.000009
... very low firing rate. ~0.01 Hz
-- rerun sim with 'EEMWghtAM': 0.00004, 'EEWeightNM': 0.000012
... very low activity ~0.13 Hz. saved raster on falcor.
...


from aigame import AIGame
AIGame = AIGame()
epCount = []

LOOK HERE: IT IS WORKING FINE.

>>> rewards, epCount, proposed_actions, total_hits = AIGame.playGame([3], epCount)
Current_ball_dir 1
Last ball dir 1
current X pos Ball 115.5
last X pos Ball 112.5
Court Range (20, 140)
0
>>> rewards, epCount, proposed_actions, total_hits = AIGame.playGame([3], epCount)
Current_ball_dir 1
Last ball dir 1
current X pos Ball 118.5
last X pos Ball 115.5
Court Range (20, 140)
0
>>> rewards, epCount, proposed_actions, total_hits = AIGame.playGame([3], epCount)
Current_ball_dir -1
Last ball dir 1
current X pos Ball 117.5
last X pos Ball 118.5
Court Range (20, 140)
1


HERE WAS THE Problem


>>> rewards, epCount, proposed_actions, total_hits = AIGame.playGame([4], epCount)
Current_ball_dir 0
Last ball dir 1
current X pos Ball -1 ---> the ball goes out of courtXRng
last X pos Ball 118.5
Court Range (20, 140)
0
>>> rewards, epCount, proposed_actions, total_hits = AIGame.playGame([4], epCount)
Current_ball_dir 0
Last ball dir 0
current X pos Ball 115.5 --> comes back in the courtXRng
last X pos Ball -1
Court Range (20, 140)
0

condition 0:
----If last X pos Ball was 116.5, current X pos Ball would be 119.5. 
    and if its picked up by the racket, in next step last X Ball would be 119.5 and current X pos Ball would be 116.5
condition 1:
----If last X pos Ball was 117.5, current X pos Ball would be 120.5 that would be -1. 
    and if its picked up by the racket, in next step last X Ball would be -1 and current X pos Ball would be 114.5
condition 2:
----If last X pos Ball was 118.5, current X pos Ball would be 121.5 that would be -1. 
    and if its picked up by the racket, in next step last X Ball would be -1 and current X pos Ball would be 115.5
condition 3:
----If last X pos Ball was 119.5, current X pos Ball would be 122.5 that would be -1. 
    and if its picked up by the racket, in next step last X Ball would be -1 and current X pos Ball would be 116.5


if current_ball_dir-self.last_ball_dir<0 and reward==0 and xpos_Ball2>courtXRng[1]-courtXRng[0]-3:
  ball_hits_racket = 1
elif xpos_Ball==-1 and reward==0 and xpos_Ball2>courtXRng[1]-courtXRng[0]-6: # before i was using  xpos_Ball2>courtXRng[1]-courtXRng[0]-3
  ball_hits_racket = 1

>>> rewards, epCount, proposed_actions, total_hits = AIGame.playGame([3], epCount)
Current_ball_dir -1
Last ball dir 1
current X pos Ball 117.5
last X pos Ball 118.5
Court Range (20, 140)
1

>>> rewards, epCount, proposed_actions, total_hits = AIGame.playGame([1], epCount)
Current_ball_dir 0
Last ball dir 1
current X pos Ball 117.5
last X pos Ball 117.5
Court Range (20, 140)
1

IT MISSED AGAIN HERE:

>>> rewards, epCount, proposed_actions, total_hits = AIGame.playGame([1], epCount)
Current_ball_dir -1
Last ball dir 1
current X pos Ball 107.5
last X pos Ball 116.5
Court Range (20, 140)
0

FIX:

if current_ball_dir-self.last_ball_dir<0 and reward==0 and xpos_Ball2>courtXRng[1]-courtXRng[0]-40:
  ball_hits_racket = 1


>>> rewards, epCount, proposed_actions, total_hits = AIGame.playGame([3], epCount)
Current_ball_dir -1
Last ball dir 1
current X pos Ball 116.5
last X pos Ball 119.0
Court Range (20, 140)
1

>>> rewards, epCount, proposed_actions, total_hits = AIGame.playGame([1], epCount)
Current_ball_dir -1
Last ball dir 1
current X pos Ball 113.5
last X pos Ball 119.0
Court Range (20, 140)
1

** adjust sim.json according to sn.json